{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "shuffle = True\n",
    "seed = None\n",
    "\n",
    "input_data_folder = \"Data\"\n",
    "training_data_file = \"Training-datasets-PredNTS.txt\"\n",
    "independent_data_file = \"independent dataset-PredNTS.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define all CUSTOM functions\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode_nt(sequence, char_dict):\n",
    "    \n",
    "    seq_encoded = np.zeros((len(sequence),len(char_dict)))\n",
    "    \n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in char_dict.keys()):\n",
    "            seq_encoded[i][char_dict[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in NT sequence: '+sequence)\n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Build k-fold functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Function to customize the DLNN architecture with parameters\n",
    "# ##################################################################################\n",
    "\n",
    "# def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "#                  conv_filters_per_layer_1 = 10, kernel_length_1 = 10, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "#                  max_pool_width_1 = 3, max_pool_stride_1 = 3, ## 1st Maxpool layer parameters\n",
    "#                  lstm_decode_units = 5, ## LSTM layer parameters\n",
    "#                  conv_filters_per_layer_2 = 10,  kernel_length_2 = 5, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "#                  max_pool_width_2 = 3, max_pool_stride_2 = 3, ## 2nd Maxpool layer parameters\n",
    "#                  dense_decode_units = 128, ## Dense layer parameters\n",
    "#                  prob = 0.5, learn_rate = 0.0005, \n",
    "#                  loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "#     beta = 0.001\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  SEQUENCE  ##################################################################################\n",
    "#     ######################################################################################################\n",
    "    \n",
    "#     input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "\n",
    "#     ## LSTM Path\n",
    "    \n",
    "# #     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(20, return_sequences = True, \n",
    "# #                                                    kernel_regularizer = tf.keras.regularizers.l2(beta)))(input1)\n",
    "\n",
    "#     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(10, return_sequences = True, \n",
    "#                                                    kernel_regularizer = tf.keras.regularizers.l2(beta)))(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(5, return_sequences = True, \n",
    "#                                                    kernel_regularizer = tf.keras.regularizers.l2(beta)))(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(3, return_sequences = True, \n",
    "#                                                    kernel_regularizer = tf.keras.regularizers.l2(beta)))(x1)\n",
    "    \n",
    "# #     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1, return_sequences = True, \n",
    "# #                                                    kernel_regularizer = tf.keras.regularizers.l2(beta)))(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Flatten()(x1)\n",
    "\n",
    "#     ## Conv Path\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  Classifier  ################################################################################\n",
    "#     ######################################################################################################\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(100, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "# #                               activation = 'relu'\n",
    "#                              )(x1)\n",
    "    \n",
    "#     y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(1, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'sigmoid')(y)\n",
    "\n",
    "#     ## Generate Model from input and output\n",
    "#     model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "#     ## Compile model\n",
    "#     if(metrics != None):\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss, metrics = metrics)\n",
    "#     else:\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parallel 1\n",
    "\n",
    "# ##################################################################################\n",
    "# ##### Function to customize the DLNN architecture with parameters\n",
    "# ##################################################################################\n",
    "\n",
    "# def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "#                  conv_filters_per_layer_1 = 10, kernel_length_1 = 10, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "#                  max_pool_width_1 = 3, max_pool_stride_1 = 3, ## 1st Maxpool layer parameters\n",
    "#                  lstm_decode_units = 5, ## LSTM layer parameters\n",
    "#                  conv_filters_per_layer_2 = 10,  kernel_length_2 = 5, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "#                  max_pool_width_2 = 3, max_pool_stride_2 = 3, ## 2nd Maxpool layer parameters\n",
    "#                  dense_decode_units = 128, ## Dense layer parameters\n",
    "#                  prob = 0.5, learn_rate = 0.0005, \n",
    "#                  loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "#     beta = 0.001\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  SEQUENCE  ##################################################################################\n",
    "#     ######################################################################################################\n",
    "    \n",
    "#     input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  RNN  ##################################################################################\n",
    "#     ######################################################################################################\n",
    "    \n",
    "# #     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences = True, \n",
    "# #                                                    kernel_regularizer = tf.keras.regularizers.l2(beta)))(input1)\n",
    "\n",
    "#     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10, return_sequences = True, \n",
    "# #                                                             kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "#                                                            ))(input1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(5, return_sequences = True,\n",
    "# #                                                             kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "#                                                            ))(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(3, return_sequences = True, \n",
    "# #                                                             kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "#                                                            ))(x1)\n",
    "    \n",
    "# #     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1, return_sequences = True, \n",
    "# #                                                    kernel_regularizer = tf.keras.regularizers.l2(beta)))(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Flatten()(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Dense(100, \n",
    "# #                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "# #                               activation = 'relu'\n",
    "#                              )(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Dense(100, \n",
    "# #                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "# #                               activation = 'relu'\n",
    "#                              )(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Dense(1, \n",
    "# #                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'sigmoid')(x1)\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  CONV  ##################################################################################\n",
    "#     ######################################################################################################\n",
    "\n",
    "#     x2 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1, strides = conv_strides_1, \n",
    "# #                                 kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                                 padding = \"same\")(input1)\n",
    "#     x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "#     x2 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x2)\n",
    "#     x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "\n",
    "#     ## Conv Path\n",
    "\n",
    "#     x2 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "# #                                 kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                                 padding = 'same')(x2)\n",
    "#     x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "#     x2 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x2)\n",
    "#     x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "#     x2 = tf.keras.layers.Flatten()(x2)\n",
    "    \n",
    "#     x2 = tf.keras.layers.Dense(100, \n",
    "# #                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "# #                               activation = 'relu'\n",
    "#                              )(x2)\n",
    "    \n",
    "#     x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "#     x2 = tf.keras.layers.Dense(100, \n",
    "# #                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "# #                               activation = 'relu'\n",
    "#                              )(x2)\n",
    "    \n",
    "#     x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "#     x2 = tf.keras.layers.Dense(1, \n",
    "# #                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'sigmoid')(x2)\n",
    "\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  Classifier  ################################################################################\n",
    "#     ######################################################################################################\n",
    "    \n",
    "#     y = tf.keras.layers.Concatenate()([x1,x2])\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(1, \n",
    "#                               activation = 'sigmoid')(y)\n",
    "\n",
    "#     ## Generate Model from input and output\n",
    "#     model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "#     ## Compile model\n",
    "#     if(metrics != None):\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss, metrics = metrics)\n",
    "#     else:\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel 2\n",
    "\n",
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "                 conv_filters_per_layer_1 = 10, kernel_length_1 = 10, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "                 max_pool_width_1 = 3, max_pool_stride_1 = 3, ## 1st Maxpool layer parameters\n",
    "                 lstm_decode_units = 5, ## LSTM layer parameters\n",
    "                 conv_filters_per_layer_2 = 10,  kernel_length_2 = 5, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "                 max_pool_width_2 = 3, max_pool_stride_2 = 3, ## 2nd Maxpool layer parameters\n",
    "                 dense_decode_units = 128, ## Dense layer parameters\n",
    "                 prob = 0.5, learn_rate = 0.001, \n",
    "                 loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  SEQUENCE  ##################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  RNN  ##################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "#     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences = True, \n",
    "#                                                    kernel_regularizer = tf.keras.regularizers.l2(beta)))(input1)\n",
    "\n",
    "    x1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(10, return_sequences = True, \n",
    "#                                                             kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "                                                           ))(input1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(5, return_sequences = True,\n",
    "#                                                             kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "                                                           ))(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(3, return_sequences = True, \n",
    "#                                                             kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "                                                           ))(x1)\n",
    "    \n",
    "#     x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1, return_sequences = True, \n",
    "#                                                    kernel_regularizer = tf.keras.regularizers.l2(beta)))(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(100, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'relu'\n",
    "                             )(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(100, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'relu'\n",
    "                             )(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(1, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'sigmoid')(x1)\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  CONV  ##################################################################################\n",
    "    ######################################################################################################\n",
    "\n",
    "    x2 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1, strides = conv_strides_1, \n",
    "#                                 kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = \"same\")(input1)\n",
    "#     x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "    x2 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x2)\n",
    "\n",
    "    ## Conv Path\n",
    "\n",
    "    x2 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "#                                 kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = 'same')(x2)\n",
    "#     x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dense(100, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'relu'\n",
    "                             )(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dense(100, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'relu'\n",
    "                             )(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dense(1, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'sigmoid')(x2)\n",
    "\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  Classifier  ################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    y = tf.keras.layers.Concatenate()([x1,x2])\n",
    "    \n",
    "    y = tf.keras.layers.Dense(1, \n",
    "                              activation = 'sigmoid')(y)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 41, 21)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 41, 10)       2110        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 41, 20)       1980        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 13, 10)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 41, 10)      810         ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 13, 10)       510         ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 41, 6)       270         ['bidirectional_1[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 4, 10)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 246)          0           ['bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 40)           0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          24700       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 100)          4100        ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100)          10100       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            101         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            101         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2)            0           ['dense_2[0][0]',                \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1)            3           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 54,885\n",
      "Trainable params: 54,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DLNN_CORENup().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step in range(10):\n",
    "#     initial_learning_rate=1e-1\n",
    "#     decay_steps=10000\n",
    "#     decay_rate=0.9\n",
    "#     print(step, ':', initial_learning_rate * decay_rate ** (step / decay_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read training file\n",
    "##################################################################################\n",
    "train_file_path = os.path.join(input_data_folder, training_data_file)\n",
    "train_data = pd.read_csv(train_file_path, sep='\\t', header=None)\n",
    "train_data.columns = ['Sequence', 'name', 'id', 'flag', 'label_original', 'type']\n",
    "train_data.head()\n",
    "\n",
    "##################################################################################\n",
    "##### Create dictionary of all characters in the NT sequence \n",
    "##################################################################################\n",
    "all_char_set = set({})\n",
    "for val in [set(val) for val in train_data['Sequence']]:\n",
    "    all_char_set = all_char_set.union(val)\n",
    "all_char_list = list(all_char_set)\n",
    "all_char_list.sort()\n",
    "all_char_dict = {}\n",
    "for i in range(len(all_char_list)):\n",
    "    all_char_dict[all_char_list[i]] = i\n",
    "    \n",
    "##################################################################################\n",
    "##### Create OHE of sequence\n",
    "##################################################################################\n",
    "train_data['OHE_Sequence'] = pd.Series([one_hot_encode_nt(val, all_char_dict) \n",
    "                                        for val in train_data[\"Sequence\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Fix the labels\n",
    "##################################################################################\n",
    "train_data['label'] = pd.Series([1 if val == 1 else 0 \n",
    "                                 for val in train_data[\"label_original\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "features = np.array(list(train_data['OHE_Sequence']))\n",
    "labels = np.array(list(train_data['label']))\n",
    "labels = labels.reshape((labels.shape[0], 1))\n",
    "\n",
    "input_seq_shape = features[0].shape\n",
    "\n",
    "folds = build_kfold(features, labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "## Write the k-fold dataset to file\n",
    "foldPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(foldPath)):\n",
    "    os.makedirs(foldPath)\n",
    "pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test model on Fold #0.\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6902\n",
      "Epoch 1: val_loss improved from inf to 0.68426, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 11s 154ms/step - loss: 0.6902 - val_loss: 0.6843\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6786\n",
      "Epoch 2: val_loss improved from 0.68426 to 0.67161, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6786 - val_loss: 0.6716\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6679\n",
      "Epoch 3: val_loss improved from 0.67161 to 0.65940, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6679 - val_loss: 0.6594\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6573\n",
      "Epoch 4: val_loss improved from 0.65940 to 0.64791, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6573 - val_loss: 0.6479\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6448\n",
      "Epoch 5: val_loss improved from 0.64791 to 0.63725, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6448 - val_loss: 0.6372\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6339\n",
      "Epoch 6: val_loss improved from 0.63725 to 0.63333, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6339 - val_loss: 0.6333\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6278\n",
      "Epoch 7: val_loss did not improve from 0.63333\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6278 - val_loss: 0.6347\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6201\n",
      "Epoch 8: val_loss improved from 0.63333 to 0.61967, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6201 - val_loss: 0.6197\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6106\n",
      "Epoch 9: val_loss improved from 0.61967 to 0.61440, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.6106 - val_loss: 0.6144\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6034\n",
      "Epoch 10: val_loss improved from 0.61440 to 0.61048, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6034 - val_loss: 0.6105\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5966\n",
      "Epoch 11: val_loss improved from 0.61048 to 0.60695, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5966 - val_loss: 0.6070\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5891\n",
      "Epoch 12: val_loss improved from 0.60695 to 0.60281, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5891 - val_loss: 0.6028\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5814\n",
      "Epoch 13: val_loss improved from 0.60281 to 0.59869, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5814 - val_loss: 0.5987\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5752\n",
      "Epoch 14: val_loss improved from 0.59869 to 0.59639, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5752 - val_loss: 0.5964\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5691\n",
      "Epoch 15: val_loss did not improve from 0.59639\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5691 - val_loss: 0.5992\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5614\n",
      "Epoch 16: val_loss improved from 0.59639 to 0.59231, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.5614 - val_loss: 0.5923\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5559\n",
      "Epoch 17: val_loss improved from 0.59231 to 0.58957, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5559 - val_loss: 0.5896\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5499\n",
      "Epoch 18: val_loss improved from 0.58957 to 0.58562, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5499 - val_loss: 0.5856\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5440\n",
      "Epoch 19: val_loss did not improve from 0.58562\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5440 - val_loss: 0.5858\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5398\n",
      "Epoch 20: val_loss improved from 0.58562 to 0.58301, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5398 - val_loss: 0.5830\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5347\n",
      "Epoch 21: val_loss improved from 0.58301 to 0.58188, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5347 - val_loss: 0.5819\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5311\n",
      "Epoch 22: val_loss improved from 0.58188 to 0.57771, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5311 - val_loss: 0.5777\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5261\n",
      "Epoch 23: val_loss improved from 0.57771 to 0.57513, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5261 - val_loss: 0.5751\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5213\n",
      "Epoch 24: val_loss improved from 0.57513 to 0.57400, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5213 - val_loss: 0.5740\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5192\n",
      "Epoch 25: val_loss improved from 0.57400 to 0.56817, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5192 - val_loss: 0.5682\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5165\n",
      "Epoch 26: val_loss did not improve from 0.56817\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5165 - val_loss: 0.5700\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5148\n",
      "Epoch 27: val_loss improved from 0.56817 to 0.56305, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5148 - val_loss: 0.5630\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5097\n",
      "Epoch 28: val_loss did not improve from 0.56305\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5097 - val_loss: 0.5697\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5073\n",
      "Epoch 29: val_loss did not improve from 0.56305\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5073 - val_loss: 0.5660\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4989\n",
      "Epoch 30: val_loss improved from 0.56305 to 0.56230, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4989 - val_loss: 0.5623\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5020\n",
      "Epoch 31: val_loss did not improve from 0.56230\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5020 - val_loss: 0.5639\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4991\n",
      "Epoch 32: val_loss did not improve from 0.56230\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4991 - val_loss: 0.5653\n",
      "Epoch 33/100\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.5002\n",
      "Epoch 33: val_loss improved from 0.56230 to 0.55341, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.4981 - val_loss: 0.5534\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4960\n",
      "Epoch 34: val_loss did not improve from 0.55341\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4960 - val_loss: 0.5547\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4868\n",
      "Epoch 35: val_loss did not improve from 0.55341\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4868 - val_loss: 0.5573\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4828\n",
      "Epoch 36: val_loss did not improve from 0.55341\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4828 - val_loss: 0.5551\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4764\n",
      "Epoch 37: val_loss did not improve from 0.55341\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4764 - val_loss: 0.5546\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4796\n",
      "Epoch 38: val_loss did not improve from 0.55341\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4796 - val_loss: 0.5537\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4701\n",
      "Epoch 39: val_loss improved from 0.55341 to 0.54556, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4701 - val_loss: 0.5456\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4653\n",
      "Epoch 40: val_loss improved from 0.54556 to 0.54272, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4653 - val_loss: 0.5427\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4632\n",
      "Epoch 41: val_loss did not improve from 0.54272\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4632 - val_loss: 0.5441\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4605\n",
      "Epoch 42: val_loss improved from 0.54272 to 0.54046, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4605 - val_loss: 0.5405\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4580\n",
      "Epoch 43: val_loss improved from 0.54046 to 0.53804, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.4580 - val_loss: 0.5380\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4555\n",
      "Epoch 44: val_loss did not improve from 0.53804\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.4555 - val_loss: 0.5454\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4532\n",
      "Epoch 45: val_loss did not improve from 0.53804\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4532 - val_loss: 0.5422\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4484\n",
      "Epoch 46: val_loss did not improve from 0.53804\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4484 - val_loss: 0.5419\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4471\n",
      "Epoch 47: val_loss did not improve from 0.53804\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4471 - val_loss: 0.5386\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4451\n",
      "Epoch 48: val_loss did not improve from 0.53804\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4451 - val_loss: 0.5395\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4426\n",
      "Epoch 49: val_loss improved from 0.53804 to 0.53754, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4426 - val_loss: 0.5375\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4405\n",
      "Epoch 50: val_loss improved from 0.53754 to 0.53349, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4405 - val_loss: 0.5335\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4379\n",
      "Epoch 51: val_loss improved from 0.53349 to 0.53149, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4379 - val_loss: 0.5315\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4338\n",
      "Epoch 52: val_loss did not improve from 0.53149\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4338 - val_loss: 0.5367\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4340\n",
      "Epoch 53: val_loss improved from 0.53149 to 0.52923, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4340 - val_loss: 0.5292\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4316\n",
      "Epoch 54: val_loss improved from 0.52923 to 0.52882, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4316 - val_loss: 0.5288\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4494\n",
      "Epoch 55: val_loss improved from 0.52882 to 0.52009, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4494 - val_loss: 0.5201\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4387\n",
      "Epoch 56: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4387 - val_loss: 0.5409\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4400\n",
      "Epoch 57: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4400 - val_loss: 0.5285\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4282\n",
      "Epoch 58: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4282 - val_loss: 0.5323\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4258\n",
      "Epoch 59: val_loss did not improve from 0.52009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4258 - val_loss: 0.5266\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4240\n",
      "Epoch 60: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4240 - val_loss: 0.5261\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4186\n",
      "Epoch 61: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4186 - val_loss: 0.5297\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4237\n",
      "Epoch 62: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4237 - val_loss: 0.5241\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4183\n",
      "Epoch 63: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4183 - val_loss: 0.5253\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4142\n",
      "Epoch 64: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4142 - val_loss: 0.5249\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4160\n",
      "Epoch 65: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4160 - val_loss: 0.5263\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4124\n",
      "Epoch 66: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4124 - val_loss: 0.5272\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4063\n",
      "Epoch 67: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4063 - val_loss: 0.5233\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4057\n",
      "Epoch 68: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4057 - val_loss: 0.5274\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4030\n",
      "Epoch 69: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4030 - val_loss: 0.5216\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3996\n",
      "Epoch 70: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3996 - val_loss: 0.5298\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4055\n",
      "Epoch 71: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4055 - val_loss: 0.5261\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4000\n",
      "Epoch 72: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4000 - val_loss: 0.5249\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4014\n",
      "Epoch 73: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4014 - val_loss: 0.5299\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4080\n",
      "Epoch 74: val_loss did not improve from 0.52009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4080 - val_loss: 0.5218\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4173\n",
      "Epoch 75: val_loss improved from 0.52009 to 0.51789, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4173 - val_loss: 0.5179\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4090\n",
      "Epoch 76: val_loss improved from 0.51789 to 0.51636, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.4090 - val_loss: 0.5164\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4023\n",
      "Epoch 77: val_loss did not improve from 0.51636\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4023 - val_loss: 0.5253\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3978\n",
      "Epoch 78: val_loss did not improve from 0.51636\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3978 - val_loss: 0.5259\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4006\n",
      "Epoch 79: val_loss did not improve from 0.51636\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4006 - val_loss: 0.5270\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3869\n",
      "Epoch 80: val_loss did not improve from 0.51636\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3869 - val_loss: 0.5177\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3820\n",
      "Epoch 81: val_loss improved from 0.51636 to 0.51452, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.3820 - val_loss: 0.5145\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3790\n",
      "Epoch 82: val_loss did not improve from 0.51452\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3790 - val_loss: 0.5156\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3790\n",
      "Epoch 83: val_loss did not improve from 0.51452\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3790 - val_loss: 0.5161\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3780\n",
      "Epoch 84: val_loss did not improve from 0.51452\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3780 - val_loss: 0.5174\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3796\n",
      "Epoch 85: val_loss did not improve from 0.51452\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3796 - val_loss: 0.5185\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3732\n",
      "Epoch 86: val_loss improved from 0.51452 to 0.51185, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.3732 - val_loss: 0.5119\n",
      "Epoch 87/100\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.3762\n",
      "Epoch 87: val_loss improved from 0.51185 to 0.51004, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold0.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.3735 - val_loss: 0.5100\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3687\n",
      "Epoch 88: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3687 - val_loss: 0.5151\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3675\n",
      "Epoch 89: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3675 - val_loss: 0.5146\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3725\n",
      "Epoch 90: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3725 - val_loss: 0.5137\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3695\n",
      "Epoch 91: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3695 - val_loss: 0.5110\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3639\n",
      "Epoch 92: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3639 - val_loss: 0.5136\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3625\n",
      "Epoch 93: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3625 - val_loss: 0.5150\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3601\n",
      "Epoch 94: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3601 - val_loss: 0.5122\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.3577\n",
      "Epoch 95: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3577 - val_loss: 0.5139\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3578\n",
      "Epoch 96: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3578 - val_loss: 0.5156\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3573\n",
      "Epoch 97: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3573 - val_loss: 0.5156\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3552\n",
      "Epoch 98: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3552 - val_loss: 0.5168\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3588\n",
      "Epoch 99: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3588 - val_loss: 0.5142\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3534\n",
      "Epoch 100: val_loss did not improve from 0.51004\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3534 - val_loss: 0.5225\n",
      "\n",
      "Train/Test model on Fold #1.\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6943\n",
      "Epoch 1: val_loss improved from inf to 0.68650, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 10s 145ms/step - loss: 0.6943 - val_loss: 0.6865\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6755\n",
      "Epoch 2: val_loss improved from 0.68650 to 0.66618, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6755 - val_loss: 0.6662\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6433\n",
      "Epoch 3: val_loss improved from 0.66618 to 0.63444, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6433 - val_loss: 0.6344\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6020\n",
      "Epoch 4: val_loss improved from 0.63444 to 0.60471, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6020 - val_loss: 0.6047\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5733\n",
      "Epoch 5: val_loss improved from 0.60471 to 0.58789, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5733 - val_loss: 0.5879\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5553\n",
      "Epoch 6: val_loss improved from 0.58789 to 0.58485, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.5553 - val_loss: 0.5848\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5494\n",
      "Epoch 7: val_loss improved from 0.58485 to 0.56855, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5494 - val_loss: 0.5686\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5398\n",
      "Epoch 8: val_loss did not improve from 0.56855\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5398 - val_loss: 0.5707\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5286\n",
      "Epoch 9: val_loss improved from 0.56855 to 0.56815, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5286 - val_loss: 0.5682\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5161\n",
      "Epoch 10: val_loss improved from 0.56815 to 0.55986, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5161 - val_loss: 0.5599\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5103\n",
      "Epoch 11: val_loss did not improve from 0.55986\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5103 - val_loss: 0.5622\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5022\n",
      "Epoch 12: val_loss improved from 0.55986 to 0.55383, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5022 - val_loss: 0.5538\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4870\n",
      "Epoch 13: val_loss improved from 0.55383 to 0.55244, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4870 - val_loss: 0.5524\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4813\n",
      "Epoch 14: val_loss improved from 0.55244 to 0.54991, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4813 - val_loss: 0.5499\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4731\n",
      "Epoch 15: val_loss improved from 0.54991 to 0.54923, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4731 - val_loss: 0.5492\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4652\n",
      "Epoch 16: val_loss improved from 0.54923 to 0.54832, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4652 - val_loss: 0.5483\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4564\n",
      "Epoch 17: val_loss improved from 0.54832 to 0.54824, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.4564 - val_loss: 0.5482\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4489\n",
      "Epoch 18: val_loss did not improve from 0.54824\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4489 - val_loss: 0.5513\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4433\n",
      "Epoch 19: val_loss improved from 0.54824 to 0.54659, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4433 - val_loss: 0.5466\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4375\n",
      "Epoch 20: val_loss improved from 0.54659 to 0.54524, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.4375 - val_loss: 0.5452\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4301\n",
      "Epoch 21: val_loss improved from 0.54524 to 0.54385, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4301 - val_loss: 0.5438\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4226\n",
      "Epoch 22: val_loss did not improve from 0.54385\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4226 - val_loss: 0.5467\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4211\n",
      "Epoch 23: val_loss did not improve from 0.54385\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4211 - val_loss: 0.5516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4161\n",
      "Epoch 24: val_loss did not improve from 0.54385\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4161 - val_loss: 0.5514\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4112\n",
      "Epoch 25: val_loss did not improve from 0.54385\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4112 - val_loss: 0.5518\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4059\n",
      "Epoch 26: val_loss did not improve from 0.54385\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4059 - val_loss: 0.5514\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4063\n",
      "Epoch 27: val_loss did not improve from 0.54385\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4063 - val_loss: 0.5548\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4019\n",
      "Epoch 28: val_loss did not improve from 0.54385\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4019 - val_loss: 0.5503\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4026\n",
      "Epoch 29: val_loss did not improve from 0.54385\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4026 - val_loss: 0.5491\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3974\n",
      "Epoch 30: val_loss did not improve from 0.54385\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3974 - val_loss: 0.5493\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3935\n",
      "Epoch 31: val_loss did not improve from 0.54385\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3935 - val_loss: 0.5475\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3858\n",
      "Epoch 32: val_loss improved from 0.54385 to 0.54108, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold1.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.3858 - val_loss: 0.5411\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3859\n",
      "Epoch 33: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3859 - val_loss: 0.5520\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3809\n",
      "Epoch 34: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3809 - val_loss: 0.5519\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3786\n",
      "Epoch 35: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3786 - val_loss: 0.5511\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3785\n",
      "Epoch 36: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3785 - val_loss: 0.5666\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3772\n",
      "Epoch 37: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3772 - val_loss: 0.5499\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3696\n",
      "Epoch 38: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3696 - val_loss: 0.5462\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3652\n",
      "Epoch 39: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3652 - val_loss: 0.5507\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3642\n",
      "Epoch 40: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3642 - val_loss: 0.5503\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3621\n",
      "Epoch 41: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3621 - val_loss: 0.5580\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3598\n",
      "Epoch 42: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3598 - val_loss: 0.5560\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3551\n",
      "Epoch 43: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3551 - val_loss: 0.5510\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3525\n",
      "Epoch 44: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3525 - val_loss: 0.5579\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3514\n",
      "Epoch 45: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3514 - val_loss: 0.5530\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3536\n",
      "Epoch 46: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3536 - val_loss: 0.5645\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3523\n",
      "Epoch 47: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3523 - val_loss: 0.5657\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3473\n",
      "Epoch 48: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3473 - val_loss: 0.5562\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3462\n",
      "Epoch 49: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3462 - val_loss: 0.5590\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3469\n",
      "Epoch 50: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3469 - val_loss: 0.5483\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3420\n",
      "Epoch 51: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3420 - val_loss: 0.5478\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3480\n",
      "Epoch 52: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3480 - val_loss: 0.5433\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3388\n",
      "Epoch 53: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3388 - val_loss: 0.5718\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3394\n",
      "Epoch 54: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3394 - val_loss: 0.5559\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3327\n",
      "Epoch 55: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3327 - val_loss: 0.5493\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3306\n",
      "Epoch 56: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3306 - val_loss: 0.5508\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3298\n",
      "Epoch 57: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3298 - val_loss: 0.5618\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3277\n",
      "Epoch 58: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3277 - val_loss: 0.5480\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3316\n",
      "Epoch 59: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3316 - val_loss: 0.5591\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3340\n",
      "Epoch 60: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3340 - val_loss: 0.5769\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3392\n",
      "Epoch 61: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.3392 - val_loss: 0.5577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3327\n",
      "Epoch 62: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3327 - val_loss: 0.5630\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3217\n",
      "Epoch 63: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3217 - val_loss: 0.5586\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3207\n",
      "Epoch 64: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3207 - val_loss: 0.5544\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3170\n",
      "Epoch 65: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3170 - val_loss: 0.5662\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3159\n",
      "Epoch 66: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3159 - val_loss: 0.5740\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3162\n",
      "Epoch 67: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.3162 - val_loss: 0.5688\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3112\n",
      "Epoch 68: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3112 - val_loss: 0.5834\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3196\n",
      "Epoch 69: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3196 - val_loss: 0.5708\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3101\n",
      "Epoch 70: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3101 - val_loss: 0.5670\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3056\n",
      "Epoch 71: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3056 - val_loss: 0.5671\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3034\n",
      "Epoch 72: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3034 - val_loss: 0.5687\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3049\n",
      "Epoch 73: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3049 - val_loss: 0.5701\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3024\n",
      "Epoch 74: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3024 - val_loss: 0.5683\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3011\n",
      "Epoch 75: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3011 - val_loss: 0.5725\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2972\n",
      "Epoch 76: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2972 - val_loss: 0.5663\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2979\n",
      "Epoch 77: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2979 - val_loss: 0.5632\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2963\n",
      "Epoch 78: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2963 - val_loss: 0.5669\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2959\n",
      "Epoch 79: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2959 - val_loss: 0.5640\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2938\n",
      "Epoch 80: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2938 - val_loss: 0.5688\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2953\n",
      "Epoch 81: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.2953 - val_loss: 0.5674\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2901\n",
      "Epoch 82: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2901 - val_loss: 0.5697\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2931\n",
      "Epoch 83: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2931 - val_loss: 0.5709\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2903\n",
      "Epoch 84: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2903 - val_loss: 0.5781\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2884\n",
      "Epoch 85: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.2884 - val_loss: 0.5785\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2879\n",
      "Epoch 86: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2879 - val_loss: 0.5694\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2892\n",
      "Epoch 87: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2892 - val_loss: 0.5769\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2938\n",
      "Epoch 88: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2938 - val_loss: 0.5804\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2846\n",
      "Epoch 89: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2846 - val_loss: 0.5758\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2843\n",
      "Epoch 90: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2843 - val_loss: 0.5786\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2822\n",
      "Epoch 91: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2822 - val_loss: 0.5749\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2818\n",
      "Epoch 92: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2818 - val_loss: 0.5772\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2791\n",
      "Epoch 93: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2791 - val_loss: 0.5769\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2800\n",
      "Epoch 94: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2800 - val_loss: 0.5770\n",
      "Epoch 95/100\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.2782\n",
      "Epoch 95: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2785 - val_loss: 0.5823\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2797\n",
      "Epoch 96: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2797 - val_loss: 0.5794\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2778\n",
      "Epoch 97: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2778 - val_loss: 0.5777\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2856\n",
      "Epoch 98: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2856 - val_loss: 0.5803\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2801\n",
      "Epoch 99: val_loss did not improve from 0.54108\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2801 - val_loss: 0.5797\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2757\n",
      "Epoch 100: val_loss did not improve from 0.54108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 34ms/step - loss: 0.2757 - val_loss: 0.5876\n",
      "\n",
      "Train/Test model on Fold #2.\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6962\n",
      "Epoch 1: val_loss improved from inf to 0.69104, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 9s 162ms/step - loss: 0.6962 - val_loss: 0.6910\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6896\n",
      "Epoch 2: val_loss improved from 0.69104 to 0.68823, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6896 - val_loss: 0.6882\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6799\n",
      "Epoch 3: val_loss improved from 0.68823 to 0.67457, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6799 - val_loss: 0.6746\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6579\n",
      "Epoch 4: val_loss improved from 0.67457 to 0.65117, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.6579 - val_loss: 0.6512\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6378\n",
      "Epoch 5: val_loss improved from 0.65117 to 0.63640, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6378 - val_loss: 0.6364\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6269\n",
      "Epoch 6: val_loss improved from 0.63640 to 0.63302, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6269 - val_loss: 0.6330\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6164\n",
      "Epoch 7: val_loss improved from 0.63302 to 0.62786, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6164 - val_loss: 0.6279\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6076\n",
      "Epoch 8: val_loss did not improve from 0.62786\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6076 - val_loss: 0.6279\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5991\n",
      "Epoch 9: val_loss improved from 0.62786 to 0.61689, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5991 - val_loss: 0.6169\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5892\n",
      "Epoch 10: val_loss improved from 0.61689 to 0.61287, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5892 - val_loss: 0.6129\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5803\n",
      "Epoch 11: val_loss improved from 0.61287 to 0.61006, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5803 - val_loss: 0.6101\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5734\n",
      "Epoch 12: val_loss improved from 0.61006 to 0.60813, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5734 - val_loss: 0.6081\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5642\n",
      "Epoch 13: val_loss improved from 0.60813 to 0.60455, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.5642 - val_loss: 0.6046\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5576\n",
      "Epoch 14: val_loss did not improve from 0.60455\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5576 - val_loss: 0.6051\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5515\n",
      "Epoch 15: val_loss did not improve from 0.60455\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5515 - val_loss: 0.6053\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5440\n",
      "Epoch 16: val_loss improved from 0.60455 to 0.59887, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5440 - val_loss: 0.5989\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5383\n",
      "Epoch 17: val_loss improved from 0.59887 to 0.59876, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5383 - val_loss: 0.5988\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5331\n",
      "Epoch 18: val_loss improved from 0.59876 to 0.59562, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5331 - val_loss: 0.5956\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5259\n",
      "Epoch 19: val_loss improved from 0.59562 to 0.59230, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5259 - val_loss: 0.5923\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5204\n",
      "Epoch 20: val_loss improved from 0.59230 to 0.58996, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5204 - val_loss: 0.5900\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5189\n",
      "Epoch 21: val_loss improved from 0.58996 to 0.58860, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.5189 - val_loss: 0.5886\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5125\n",
      "Epoch 22: val_loss improved from 0.58860 to 0.58859, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5125 - val_loss: 0.5886\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5059\n",
      "Epoch 23: val_loss did not improve from 0.58859\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5059 - val_loss: 0.5907\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5023\n",
      "Epoch 24: val_loss did not improve from 0.58859\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5023 - val_loss: 0.5934\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4980\n",
      "Epoch 25: val_loss did not improve from 0.58859\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4980 - val_loss: 0.5925\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4959\n",
      "Epoch 26: val_loss improved from 0.58859 to 0.58672, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4959 - val_loss: 0.5867\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4941\n",
      "Epoch 27: val_loss did not improve from 0.58672\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4941 - val_loss: 0.5934\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.4892\n",
      "Epoch 28: val_loss did not improve from 0.58672\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4892 - val_loss: 0.5895\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4848\n",
      "Epoch 29: val_loss improved from 0.58672 to 0.58608, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4848 - val_loss: 0.5861\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4803\n",
      "Epoch 30: val_loss improved from 0.58608 to 0.58373, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4803 - val_loss: 0.5837\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4781\n",
      "Epoch 31: val_loss did not improve from 0.58373\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4781 - val_loss: 0.5839\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4756\n",
      "Epoch 32: val_loss improved from 0.58373 to 0.58075, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4756 - val_loss: 0.5807\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4717\n",
      "Epoch 33: val_loss improved from 0.58075 to 0.57982, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4717 - val_loss: 0.5798\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4666\n",
      "Epoch 34: val_loss improved from 0.57982 to 0.57600, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.4666 - val_loss: 0.5760\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4639\n",
      "Epoch 35: val_loss did not improve from 0.57600\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4639 - val_loss: 0.5780\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4636\n",
      "Epoch 36: val_loss improved from 0.57600 to 0.57390, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4636 - val_loss: 0.5739\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4580\n",
      "Epoch 37: val_loss did not improve from 0.57390\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4580 - val_loss: 0.5751\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4545\n",
      "Epoch 38: val_loss did not improve from 0.57390\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4545 - val_loss: 0.5758\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4512\n",
      "Epoch 39: val_loss did not improve from 0.57390\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4512 - val_loss: 0.5757\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4480\n",
      "Epoch 40: val_loss improved from 0.57390 to 0.57237, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.4480 - val_loss: 0.5724\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4458\n",
      "Epoch 41: val_loss did not improve from 0.57237\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4458 - val_loss: 0.5727\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4419\n",
      "Epoch 42: val_loss did not improve from 0.57237\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4419 - val_loss: 0.5768\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4407\n",
      "Epoch 43: val_loss did not improve from 0.57237\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4407 - val_loss: 0.5757\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4445\n",
      "Epoch 44: val_loss improved from 0.57237 to 0.57009, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4445 - val_loss: 0.5701\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4392\n",
      "Epoch 45: val_loss did not improve from 0.57009\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4392 - val_loss: 0.5729\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4319\n",
      "Epoch 46: val_loss did not improve from 0.57009\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4319 - val_loss: 0.5702\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4282\n",
      "Epoch 47: val_loss improved from 0.57009 to 0.56943, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4282 - val_loss: 0.5694\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4252\n",
      "Epoch 48: val_loss improved from 0.56943 to 0.56143, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4252 - val_loss: 0.5614\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4258\n",
      "Epoch 49: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4258 - val_loss: 0.5793\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4256\n",
      "Epoch 50: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4256 - val_loss: 0.5646\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4208\n",
      "Epoch 51: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4208 - val_loss: 0.5687\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4185\n",
      "Epoch 52: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4185 - val_loss: 0.5658\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4158\n",
      "Epoch 53: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4158 - val_loss: 0.5639\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4114\n",
      "Epoch 54: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.4114 - val_loss: 0.5729\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4088\n",
      "Epoch 55: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4088 - val_loss: 0.5719\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4048\n",
      "Epoch 56: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4048 - val_loss: 0.5682\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4058\n",
      "Epoch 57: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4058 - val_loss: 0.5723\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4013\n",
      "Epoch 58: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4013 - val_loss: 0.5621\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3987\n",
      "Epoch 59: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3987 - val_loss: 0.5728\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3944\n",
      "Epoch 60: val_loss did not improve from 0.56143\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3944 - val_loss: 0.5679\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.3953\n",
      "Epoch 61: val_loss improved from 0.56143 to 0.56063, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.3953 - val_loss: 0.5606\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3920\n",
      "Epoch 62: val_loss did not improve from 0.56063\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3920 - val_loss: 0.5703\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3883\n",
      "Epoch 63: val_loss did not improve from 0.56063\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3883 - val_loss: 0.5680\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3859\n",
      "Epoch 64: val_loss did not improve from 0.56063\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3859 - val_loss: 0.5702\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3859\n",
      "Epoch 65: val_loss did not improve from 0.56063\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3859 - val_loss: 0.5749\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3798\n",
      "Epoch 66: val_loss did not improve from 0.56063\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3798 - val_loss: 0.5739\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3807\n",
      "Epoch 67: val_loss did not improve from 0.56063\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3807 - val_loss: 0.5655\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3762\n",
      "Epoch 68: val_loss did not improve from 0.56063\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3762 - val_loss: 0.5628\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3736\n",
      "Epoch 69: val_loss did not improve from 0.56063\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3736 - val_loss: 0.5721\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3725\n",
      "Epoch 70: val_loss improved from 0.56063 to 0.55923, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.3725 - val_loss: 0.5592\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3760\n",
      "Epoch 71: val_loss did not improve from 0.55923\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3760 - val_loss: 0.5657\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3751\n",
      "Epoch 72: val_loss did not improve from 0.55923\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3751 - val_loss: 0.5643\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3755\n",
      "Epoch 73: val_loss did not improve from 0.55923\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3755 - val_loss: 0.5598\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3670\n",
      "Epoch 74: val_loss did not improve from 0.55923\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3670 - val_loss: 0.5638\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3648\n",
      "Epoch 75: val_loss improved from 0.55923 to 0.55091, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.3648 - val_loss: 0.5509\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3608\n",
      "Epoch 76: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3608 - val_loss: 0.5533\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3610\n",
      "Epoch 77: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3610 - val_loss: 0.5530\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3604\n",
      "Epoch 78: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3604 - val_loss: 0.5591\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3607\n",
      "Epoch 79: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3607 - val_loss: 0.5579\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3579\n",
      "Epoch 80: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3579 - val_loss: 0.5682\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3564\n",
      "Epoch 81: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3564 - val_loss: 0.5705\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3560\n",
      "Epoch 82: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3560 - val_loss: 0.5687\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3543\n",
      "Epoch 83: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3543 - val_loss: 0.5720\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3499\n",
      "Epoch 84: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3499 - val_loss: 0.5730\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3471\n",
      "Epoch 85: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3471 - val_loss: 0.5742\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3483\n",
      "Epoch 86: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3483 - val_loss: 0.5684\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3483\n",
      "Epoch 87: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3483 - val_loss: 0.5744\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3439\n",
      "Epoch 88: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3439 - val_loss: 0.5630\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3454\n",
      "Epoch 89: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.3454 - val_loss: 0.5691\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3462\n",
      "Epoch 90: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3462 - val_loss: 0.5725\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3414\n",
      "Epoch 91: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3414 - val_loss: 0.5666\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3377\n",
      "Epoch 92: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3377 - val_loss: 0.5601\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3379\n",
      "Epoch 93: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3379 - val_loss: 0.5657\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3354\n",
      "Epoch 94: val_loss did not improve from 0.55091\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3354 - val_loss: 0.5670\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3365\n",
      "Epoch 95: val_loss improved from 0.55091 to 0.54595, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold2.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.3365 - val_loss: 0.5459\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3352\n",
      "Epoch 96: val_loss did not improve from 0.54595\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3352 - val_loss: 0.5498\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3345\n",
      "Epoch 97: val_loss did not improve from 0.54595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3345 - val_loss: 0.5669\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3454\n",
      "Epoch 98: val_loss did not improve from 0.54595\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3454 - val_loss: 0.5968\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3686\n",
      "Epoch 99: val_loss did not improve from 0.54595\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3686 - val_loss: 0.5833\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3439\n",
      "Epoch 100: val_loss did not improve from 0.54595\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3439 - val_loss: 0.5754\n",
      "\n",
      "Train/Test model on Fold #3.\n",
      "Epoch 1/100\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.7000\n",
      "Epoch 1: val_loss improved from inf to 0.68350, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 9s 148ms/step - loss: 0.6994 - val_loss: 0.6835\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6776\n",
      "Epoch 2: val_loss improved from 0.68350 to 0.67353, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6776 - val_loss: 0.6735\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6640\n",
      "Epoch 3: val_loss improved from 0.67353 to 0.66189, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6640 - val_loss: 0.6619\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6539\n",
      "Epoch 4: val_loss improved from 0.66189 to 0.65309, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6539 - val_loss: 0.6531\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6445\n",
      "Epoch 5: val_loss improved from 0.65309 to 0.64028, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6445 - val_loss: 0.6403\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6348\n",
      "Epoch 6: val_loss improved from 0.64028 to 0.63088, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6348 - val_loss: 0.6309\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6235\n",
      "Epoch 7: val_loss improved from 0.63088 to 0.62633, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6235 - val_loss: 0.6263\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6132\n",
      "Epoch 8: val_loss improved from 0.62633 to 0.61709, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6132 - val_loss: 0.6171\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6044\n",
      "Epoch 9: val_loss improved from 0.61709 to 0.61351, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6044 - val_loss: 0.6135\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5936\n",
      "Epoch 10: val_loss improved from 0.61351 to 0.61135, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5936 - val_loss: 0.6114\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5846\n",
      "Epoch 11: val_loss improved from 0.61135 to 0.60661, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5846 - val_loss: 0.6066\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5747\n",
      "Epoch 12: val_loss did not improve from 0.60661\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5747 - val_loss: 0.6108\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5738\n",
      "Epoch 13: val_loss improved from 0.60661 to 0.59738, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5738 - val_loss: 0.5974\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5615\n",
      "Epoch 14: val_loss improved from 0.59738 to 0.59613, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5615 - val_loss: 0.5961\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5552\n",
      "Epoch 15: val_loss improved from 0.59613 to 0.59236, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5552 - val_loss: 0.5924\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5472\n",
      "Epoch 16: val_loss improved from 0.59236 to 0.58656, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.5472 - val_loss: 0.5866\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5379\n",
      "Epoch 17: val_loss improved from 0.58656 to 0.58576, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.5379 - val_loss: 0.5858\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5338\n",
      "Epoch 18: val_loss improved from 0.58576 to 0.58170, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.5338 - val_loss: 0.5817\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5321\n",
      "Epoch 19: val_loss did not improve from 0.58170\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5321 - val_loss: 0.5893\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5241\n",
      "Epoch 20: val_loss improved from 0.58170 to 0.58166, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5241 - val_loss: 0.5817\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5179\n",
      "Epoch 21: val_loss improved from 0.58166 to 0.57737, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5179 - val_loss: 0.5774\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5123\n",
      "Epoch 22: val_loss improved from 0.57737 to 0.57310, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5123 - val_loss: 0.5731\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5096\n",
      "Epoch 23: val_loss did not improve from 0.57310\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5096 - val_loss: 0.5738\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5058\n",
      "Epoch 24: val_loss did not improve from 0.57310\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5058 - val_loss: 0.5755\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.5036\n",
      "Epoch 25: val_loss improved from 0.57310 to 0.56976, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.5036 - val_loss: 0.5698\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4974\n",
      "Epoch 26: val_loss did not improve from 0.56976\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4974 - val_loss: 0.5760\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4913\n",
      "Epoch 27: val_loss improved from 0.56976 to 0.56902, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4913 - val_loss: 0.5690\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4873\n",
      "Epoch 28: val_loss improved from 0.56902 to 0.56598, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4873 - val_loss: 0.5660\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4842\n",
      "Epoch 29: val_loss did not improve from 0.56598\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4842 - val_loss: 0.5684\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4801\n",
      "Epoch 30: val_loss did not improve from 0.56598\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4801 - val_loss: 0.5661\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4768\n",
      "Epoch 31: val_loss did not improve from 0.56598\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4768 - val_loss: 0.5665\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4717\n",
      "Epoch 32: val_loss improved from 0.56598 to 0.56247, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4717 - val_loss: 0.5625\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4690\n",
      "Epoch 33: val_loss did not improve from 0.56247\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4690 - val_loss: 0.5676\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4641\n",
      "Epoch 34: val_loss did not improve from 0.56247\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4641 - val_loss: 0.5625\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4626\n",
      "Epoch 35: val_loss improved from 0.56247 to 0.55859, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4626 - val_loss: 0.5586\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4601\n",
      "Epoch 36: val_loss improved from 0.55859 to 0.55543, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4601 - val_loss: 0.5554\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4550\n",
      "Epoch 37: val_loss improved from 0.55543 to 0.55184, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4550 - val_loss: 0.5518\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4560\n",
      "Epoch 38: val_loss did not improve from 0.55184\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4560 - val_loss: 0.5579\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4523\n",
      "Epoch 39: val_loss did not improve from 0.55184\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4523 - val_loss: 0.5535\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4501\n",
      "Epoch 40: val_loss improved from 0.55184 to 0.54898, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4501 - val_loss: 0.5490\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4451\n",
      "Epoch 41: val_loss did not improve from 0.54898\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4451 - val_loss: 0.5559\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4410\n",
      "Epoch 42: val_loss improved from 0.54898 to 0.54827, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4410 - val_loss: 0.5483\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4380\n",
      "Epoch 43: val_loss improved from 0.54827 to 0.54678, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4380 - val_loss: 0.5468\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4363\n",
      "Epoch 44: val_loss improved from 0.54678 to 0.54518, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4363 - val_loss: 0.5452\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4332\n",
      "Epoch 45: val_loss improved from 0.54518 to 0.54275, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4332 - val_loss: 0.5427\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4279\n",
      "Epoch 46: val_loss did not improve from 0.54275\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4279 - val_loss: 0.5593\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4268\n",
      "Epoch 47: val_loss improved from 0.54275 to 0.53987, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4268 - val_loss: 0.5399\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4240\n",
      "Epoch 48: val_loss did not improve from 0.53987\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4240 - val_loss: 0.5559\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4234\n",
      "Epoch 49: val_loss improved from 0.53987 to 0.53522, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4234 - val_loss: 0.5352\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4211\n",
      "Epoch 50: val_loss did not improve from 0.53522\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4211 - val_loss: 0.5472\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4172\n",
      "Epoch 51: val_loss did not improve from 0.53522\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4172 - val_loss: 0.5452\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4126\n",
      "Epoch 52: val_loss did not improve from 0.53522\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4126 - val_loss: 0.5389\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4107\n",
      "Epoch 53: val_loss did not improve from 0.53522\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4107 - val_loss: 0.5382\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4077\n",
      "Epoch 54: val_loss did not improve from 0.53522\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4077 - val_loss: 0.5509\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4038\n",
      "Epoch 55: val_loss did not improve from 0.53522\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4038 - val_loss: 0.5504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4040\n",
      "Epoch 56: val_loss did not improve from 0.53522\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4040 - val_loss: 0.5391\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4016\n",
      "Epoch 57: val_loss did not improve from 0.53522\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4016 - val_loss: 0.5507\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3994\n",
      "Epoch 58: val_loss did not improve from 0.53522\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3994 - val_loss: 0.5371\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3976\n",
      "Epoch 59: val_loss improved from 0.53522 to 0.53284, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.3976 - val_loss: 0.5328\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3945\n",
      "Epoch 60: val_loss did not improve from 0.53284\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3945 - val_loss: 0.5455\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3940\n",
      "Epoch 61: val_loss did not improve from 0.53284\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3940 - val_loss: 0.5543\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4031\n",
      "Epoch 62: val_loss did not improve from 0.53284\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4031 - val_loss: 0.5437\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3958\n",
      "Epoch 63: val_loss did not improve from 0.53284\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3958 - val_loss: 0.5506\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3884\n",
      "Epoch 64: val_loss did not improve from 0.53284\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3884 - val_loss: 0.5410\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3844\n",
      "Epoch 65: val_loss did not improve from 0.53284\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3844 - val_loss: 0.5376\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3828\n",
      "Epoch 66: val_loss did not improve from 0.53284\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3828 - val_loss: 0.5374\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3831\n",
      "Epoch 67: val_loss did not improve from 0.53284\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3831 - val_loss: 0.5424\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3831\n",
      "Epoch 68: val_loss did not improve from 0.53284\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3831 - val_loss: 0.5438\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3860\n",
      "Epoch 69: val_loss did not improve from 0.53284\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3860 - val_loss: 0.5336\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3771\n",
      "Epoch 70: val_loss improved from 0.53284 to 0.53197, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.3771 - val_loss: 0.5320\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3730\n",
      "Epoch 71: val_loss did not improve from 0.53197\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3730 - val_loss: 0.5362\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3727\n",
      "Epoch 72: val_loss did not improve from 0.53197\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3727 - val_loss: 0.5369\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3716\n",
      "Epoch 73: val_loss did not improve from 0.53197\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3716 - val_loss: 0.5352\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3684\n",
      "Epoch 74: val_loss improved from 0.53197 to 0.53005, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.3684 - val_loss: 0.5300\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3718\n",
      "Epoch 75: val_loss did not improve from 0.53005\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.3718 - val_loss: 0.5372\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3674\n",
      "Epoch 76: val_loss did not improve from 0.53005\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3674 - val_loss: 0.5417\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3645\n",
      "Epoch 77: val_loss did not improve from 0.53005\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3645 - val_loss: 0.5337\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3648\n",
      "Epoch 78: val_loss did not improve from 0.53005\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.3648 - val_loss: 0.5397\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3595\n",
      "Epoch 79: val_loss did not improve from 0.53005\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.3595 - val_loss: 0.5547\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3577\n",
      "Epoch 80: val_loss improved from 0.53005 to 0.52505, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.3577 - val_loss: 0.5251\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3553\n",
      "Epoch 81: val_loss did not improve from 0.52505\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.3553 - val_loss: 0.5282\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3602\n",
      "Epoch 82: val_loss did not improve from 0.52505\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.3602 - val_loss: 0.5290\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3574\n",
      "Epoch 83: val_loss did not improve from 0.52505\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3574 - val_loss: 0.5274\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3562\n",
      "Epoch 84: val_loss did not improve from 0.52505\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.3562 - val_loss: 0.5276\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3598\n",
      "Epoch 85: val_loss did not improve from 0.52505\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.3598 - val_loss: 0.5255\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3569\n",
      "Epoch 86: val_loss did not improve from 0.52505\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3569 - val_loss: 0.5266\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3561\n",
      "Epoch 87: val_loss did not improve from 0.52505\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.3561 - val_loss: 0.5318\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3502\n",
      "Epoch 88: val_loss did not improve from 0.52505\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.3502 - val_loss: 0.5356\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3456\n",
      "Epoch 89: val_loss improved from 0.52505 to 0.51648, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.3456 - val_loss: 0.5165\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3435\n",
      "Epoch 90: val_loss did not improve from 0.51648\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3435 - val_loss: 0.5300\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3406\n",
      "Epoch 91: val_loss improved from 0.51648 to 0.51277, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold3.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 42ms/step - loss: 0.3406 - val_loss: 0.5128\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3405\n",
      "Epoch 92: val_loss did not improve from 0.51277\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3405 - val_loss: 0.5167\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3386\n",
      "Epoch 93: val_loss did not improve from 0.51277\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3386 - val_loss: 0.5259\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3385\n",
      "Epoch 94: val_loss did not improve from 0.51277\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3385 - val_loss: 0.5248\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3376\n",
      "Epoch 95: val_loss did not improve from 0.51277\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3376 - val_loss: 0.5228\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3364\n",
      "Epoch 96: val_loss did not improve from 0.51277\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3364 - val_loss: 0.5427\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3353\n",
      "Epoch 97: val_loss did not improve from 0.51277\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3353 - val_loss: 0.5298\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3343\n",
      "Epoch 98: val_loss did not improve from 0.51277\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3343 - val_loss: 0.5231\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3319\n",
      "Epoch 99: val_loss did not improve from 0.51277\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.3319 - val_loss: 0.5290\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3308\n",
      "Epoch 100: val_loss did not improve from 0.51277\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3308 - val_loss: 0.5228\n",
      "\n",
      "Train/Test model on Fold #4.\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6944\n",
      "Epoch 1: val_loss improved from inf to 0.68665, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 9s 160ms/step - loss: 0.6944 - val_loss: 0.6866\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6752\n",
      "Epoch 2: val_loss improved from 0.68665 to 0.66833, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.6752 - val_loss: 0.6683\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6525\n",
      "Epoch 3: val_loss improved from 0.66833 to 0.64920, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6525 - val_loss: 0.6492\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6247\n",
      "Epoch 4: val_loss improved from 0.64920 to 0.63219, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.6247 - val_loss: 0.6322\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5978\n",
      "Epoch 5: val_loss improved from 0.63219 to 0.61107, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.5978 - val_loss: 0.6111\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5698\n",
      "Epoch 6: val_loss improved from 0.61107 to 0.60038, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.5698 - val_loss: 0.6004\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5487\n",
      "Epoch 7: val_loss improved from 0.60038 to 0.59069, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.5487 - val_loss: 0.5907\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5346\n",
      "Epoch 8: val_loss improved from 0.59069 to 0.58682, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.5346 - val_loss: 0.5868\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5226\n",
      "Epoch 9: val_loss did not improve from 0.58682\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.5226 - val_loss: 0.5887\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5178\n",
      "Epoch 10: val_loss improved from 0.58682 to 0.57941, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.5178 - val_loss: 0.5794\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5064\n",
      "Epoch 11: val_loss did not improve from 0.57941\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5064 - val_loss: 0.5929\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5015\n",
      "Epoch 12: val_loss did not improve from 0.57941\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5015 - val_loss: 0.5809\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4839\n",
      "Epoch 13: val_loss did not improve from 0.57941\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.4839 - val_loss: 0.5831\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4731\n",
      "Epoch 14: val_loss did not improve from 0.57941\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.4731 - val_loss: 0.5796\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4634\n",
      "Epoch 15: val_loss did not improve from 0.57941\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.4634 - val_loss: 0.5796\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4548\n",
      "Epoch 16: val_loss improved from 0.57941 to 0.57808, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4548 - val_loss: 0.5781\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4440\n",
      "Epoch 17: val_loss improved from 0.57808 to 0.57765, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.4440 - val_loss: 0.5777\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4329\n",
      "Epoch 18: val_loss did not improve from 0.57765\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4329 - val_loss: 0.5805\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4296\n",
      "Epoch 19: val_loss did not improve from 0.57765\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4296 - val_loss: 0.5795\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4232\n",
      "Epoch 20: val_loss improved from 0.57765 to 0.57672, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.4232 - val_loss: 0.5767\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4154\n",
      "Epoch 21: val_loss did not improve from 0.57672\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.4154 - val_loss: 0.5776\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4142\n",
      "Epoch 22: val_loss did not improve from 0.57672\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.4142 - val_loss: 0.5800\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4120\n",
      "Epoch 23: val_loss did not improve from 0.57672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 35ms/step - loss: 0.4120 - val_loss: 0.5793\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4064\n",
      "Epoch 24: val_loss improved from 0.57672 to 0.57587, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.4064 - val_loss: 0.5759\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4027\n",
      "Epoch 25: val_loss improved from 0.57587 to 0.57435, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.4027 - val_loss: 0.5744\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3950\n",
      "Epoch 26: val_loss did not improve from 0.57435\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3950 - val_loss: 0.5760\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3937\n",
      "Epoch 27: val_loss did not improve from 0.57435\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3937 - val_loss: 0.5793\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3866\n",
      "Epoch 28: val_loss improved from 0.57435 to 0.57432, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.3866 - val_loss: 0.5743\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3848\n",
      "Epoch 29: val_loss improved from 0.57432 to 0.57292, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\bestModel-fold4.hdf5\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.3848 - val_loss: 0.5729\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3838\n",
      "Epoch 30: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3838 - val_loss: 0.5733\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3778\n",
      "Epoch 31: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.3778 - val_loss: 0.5767\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3775\n",
      "Epoch 32: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3775 - val_loss: 0.5762\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3791\n",
      "Epoch 33: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3791 - val_loss: 0.5743\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3738\n",
      "Epoch 34: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3738 - val_loss: 0.5782\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3700\n",
      "Epoch 35: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3700 - val_loss: 0.5769\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3668\n",
      "Epoch 36: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3668 - val_loss: 0.5780\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3621\n",
      "Epoch 37: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3621 - val_loss: 0.5786\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3603\n",
      "Epoch 38: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3603 - val_loss: 0.5769\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3595\n",
      "Epoch 39: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3595 - val_loss: 0.5777\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3567\n",
      "Epoch 40: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3567 - val_loss: 0.5797\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3570\n",
      "Epoch 41: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3570 - val_loss: 0.5744\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3507\n",
      "Epoch 42: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3507 - val_loss: 0.5757\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3475\n",
      "Epoch 43: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3475 - val_loss: 0.5769\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3473\n",
      "Epoch 44: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3473 - val_loss: 0.5766\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3450\n",
      "Epoch 45: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3450 - val_loss: 0.5818\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3417\n",
      "Epoch 46: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3417 - val_loss: 0.5780\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3403\n",
      "Epoch 47: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3403 - val_loss: 0.5738\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3403\n",
      "Epoch 48: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3403 - val_loss: 0.5824\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3356\n",
      "Epoch 49: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3356 - val_loss: 0.5831\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3327\n",
      "Epoch 50: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3327 - val_loss: 0.5772\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3323\n",
      "Epoch 51: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3323 - val_loss: 0.5779\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3320\n",
      "Epoch 52: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3320 - val_loss: 0.5805\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3279\n",
      "Epoch 53: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3279 - val_loss: 0.5761\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3265\n",
      "Epoch 54: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3265 - val_loss: 0.5754\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3247\n",
      "Epoch 55: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3247 - val_loss: 0.5761\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3224\n",
      "Epoch 56: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3224 - val_loss: 0.5776\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3325\n",
      "Epoch 57: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3325 - val_loss: 0.5831\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3219\n",
      "Epoch 58: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3219 - val_loss: 0.5787\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3190\n",
      "Epoch 59: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3190 - val_loss: 0.5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3186\n",
      "Epoch 60: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3186 - val_loss: 0.5802\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3189\n",
      "Epoch 61: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3189 - val_loss: 0.5805\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3179\n",
      "Epoch 62: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3179 - val_loss: 0.5778\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3152\n",
      "Epoch 63: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3152 - val_loss: 0.5838\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3139\n",
      "Epoch 64: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3139 - val_loss: 0.5838\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3104\n",
      "Epoch 65: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3104 - val_loss: 0.5915\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3114\n",
      "Epoch 66: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3114 - val_loss: 0.5810\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3064\n",
      "Epoch 67: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3064 - val_loss: 0.5799\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3104\n",
      "Epoch 68: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3104 - val_loss: 0.5865\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3125\n",
      "Epoch 69: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3125 - val_loss: 0.5901\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3082\n",
      "Epoch 70: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3082 - val_loss: 0.5919\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3036\n",
      "Epoch 71: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3036 - val_loss: 0.5826\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3001\n",
      "Epoch 72: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3001 - val_loss: 0.5827\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2982\n",
      "Epoch 73: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2982 - val_loss: 0.5856\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2967\n",
      "Epoch 74: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2967 - val_loss: 0.5881\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2981\n",
      "Epoch 75: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2981 - val_loss: 0.5914\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2962\n",
      "Epoch 76: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2962 - val_loss: 0.5848\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2972\n",
      "Epoch 77: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2972 - val_loss: 0.5897\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2960\n",
      "Epoch 78: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2960 - val_loss: 0.5799\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2966\n",
      "Epoch 79: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2966 - val_loss: 0.5878\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2999\n",
      "Epoch 80: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2999 - val_loss: 0.5911\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3041\n",
      "Epoch 81: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3041 - val_loss: 0.5892\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2991\n",
      "Epoch 82: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2991 - val_loss: 0.6023\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3034\n",
      "Epoch 83: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3034 - val_loss: 0.6122\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2948\n",
      "Epoch 84: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2948 - val_loss: 0.6003\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2945\n",
      "Epoch 85: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.2945 - val_loss: 0.5945\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2895\n",
      "Epoch 86: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2895 - val_loss: 0.6012\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2887\n",
      "Epoch 87: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2887 - val_loss: 0.6155\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2830\n",
      "Epoch 88: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2830 - val_loss: 0.6226\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2806\n",
      "Epoch 89: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2806 - val_loss: 0.6173\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2773\n",
      "Epoch 90: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2773 - val_loss: 0.6054\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2764\n",
      "Epoch 91: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.2764 - val_loss: 0.6155\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2745\n",
      "Epoch 92: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.2745 - val_loss: 0.6124\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2765\n",
      "Epoch 93: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.2765 - val_loss: 0.6191\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2767\n",
      "Epoch 94: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.2767 - val_loss: 0.6146\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2745\n",
      "Epoch 95: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.2745 - val_loss: 0.6074\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2726\n",
      "Epoch 96: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.2726 - val_loss: 0.6162\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2722\n",
      "Epoch 97: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.2722 - val_loss: 0.6114\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2721\n",
      "Epoch 98: val_loss did not improve from 0.57292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 35ms/step - loss: 0.2721 - val_loss: 0.6131\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2709\n",
      "Epoch 99: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.2709 - val_loss: 0.6165\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2693\n",
      "Epoch 100: val_loss did not improve from 0.57292\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.2693 - val_loss: 0.6167\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Train/Test model on all folds, generate evaluations\n",
    "##################################################################################\n",
    "\n",
    "## Create and set directory to save model\n",
    "modelPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold), \"models\")\n",
    "if(not os.path.isdir(modelPath)):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "i = -1\n",
    "for fold in folds:\n",
    "    i += 1\n",
    "    \n",
    "    print(\"\\nTrain/Test model on Fold #\"+str(i)+\".\")\n",
    "    \n",
    "    model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "    ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    modelCallbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                           monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                           save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "    ]\n",
    "    \n",
    "    # adding random shuffling of the dataset for training purpose\n",
    "    index_arr = np.arange(fold[\"X_train\"].shape[0])\n",
    "    index_arr = np.random.permutation(index_arr)\n",
    "    \n",
    "    model.fit(x = fold[\"X_train\"][index_arr], y = fold[\"y_train\"][index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "              callbacks = modelCallbacks, validation_data = (fold[\"X_test\"], fold[\"y_test\"]))\n",
    "    \n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TRAIN dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_train\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "    mcc = matthews_corrcoef(fold[\"y_train\"], label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Train\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TEST dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_test\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "    mcc = matthews_corrcoef(fold[\"y_test\"], label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Test\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.749360</td>\n",
       "      <td>0.764719</td>\n",
       "      <td>0.809883</td>\n",
       "      <td>0.720379</td>\n",
       "      <td>0.778338</td>\n",
       "      <td>0.499774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.901129</td>\n",
       "      <td>0.910276</td>\n",
       "      <td>0.926549</td>\n",
       "      <td>0.888965</td>\n",
       "      <td>0.913300</td>\n",
       "      <td>0.802977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                   \n",
       "Test        0.749360   0.764719  0.809883     0.720379     0.778338  0.499774\n",
       "Train       0.901129   0.910276  0.926549     0.888965     0.913300  0.802977"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel 1\n",
    "# \tAccuracy\tPrecision\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# Train_Test\t\t\t\t\t\t\n",
    "# Test\t0.777914\t0.772954\t0.852681\t0.787560\t0.768254\t0.556444\n",
    "# Train\t0.890117\t0.889315\t0.941954\t0.891271\t0.888962\t0.780636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn, 20-10-5\n",
    "# Accuracy\tPrecision\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# Train_Test\t\t\t\t\t\t\n",
    "# Test\t0.744752\t0.731433\t0.825816\t0.776636\t0.712830\t0.491745\n",
    "# Train\t0.787784\t0.778217\t0.871499\t0.806677\t0.768885\t0.576924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.781971</td>\n",
       "      <td>0.802691</td>\n",
       "      <td>[0.0, 0.4560669456066946, 0.4811715481171548, ...</td>\n",
       "      <td>[0.0, 0.0546218487394958, 0.06302521008403361,...</td>\n",
       "      <td>[1.8020394, 0.8020394, 0.8020393, 0.80203927, ...</td>\n",
       "      <td>0.836495</td>\n",
       "      <td>0.748954</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.565274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>[0.0, 0.226890756302521, 0.23949579831932774, ...</td>\n",
       "      <td>[0.0, 0.02092050209205021, 0.02510460251046025...</td>\n",
       "      <td>[1.8141658, 0.81416583, 0.8141658, 0.8141657, ...</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.485432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.741597</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>[0.0, 0.5798319327731093, 0.5882352941176471, ...</td>\n",
       "      <td>[0.0, 0.15126050420168066, 0.15546218487394958...</td>\n",
       "      <td>[1.7551525, 0.75515246, 0.7551524, 0.7551522, ...</td>\n",
       "      <td>0.802786</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.747899</td>\n",
       "      <td>0.483232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.769565</td>\n",
       "      <td>[0.0, 0.3697478991596639, 0.3739495798319328, ...</td>\n",
       "      <td>[0.0, 0.025210084033613446, 0.0252100840336134...</td>\n",
       "      <td>[1.8905818, 0.8905818, 0.89058167, 0.8905815, ...</td>\n",
       "      <td>0.812513</td>\n",
       "      <td>0.743697</td>\n",
       "      <td>0.777311</td>\n",
       "      <td>0.521303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>[0.0, 0.2605042016806723, 0.2689075630252101, ...</td>\n",
       "      <td>[0.0, 0.029411764705882353, 0.0294117647058823...</td>\n",
       "      <td>[1.7516885, 0.75168854, 0.7516884, 0.7516883, ...</td>\n",
       "      <td>0.785467</td>\n",
       "      <td>0.668067</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.443631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Train_Test  Accuracy  Precision  \\\n",
       "1     0       Test  0.781971   0.802691   \n",
       "3     1       Test  0.742138   0.760181   \n",
       "5     2       Test  0.741597   0.744681   \n",
       "7     3       Test  0.760504   0.769565   \n",
       "9     4       Test  0.720588   0.746479   \n",
       "\n",
       "                                                 TPR  \\\n",
       "1  [0.0, 0.4560669456066946, 0.4811715481171548, ...   \n",
       "3  [0.0, 0.226890756302521, 0.23949579831932774, ...   \n",
       "5  [0.0, 0.5798319327731093, 0.5882352941176471, ...   \n",
       "7  [0.0, 0.3697478991596639, 0.3739495798319328, ...   \n",
       "9  [0.0, 0.2605042016806723, 0.2689075630252101, ...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "1  [0.0, 0.0546218487394958, 0.06302521008403361,...   \n",
       "3  [0.0, 0.02092050209205021, 0.02510460251046025...   \n",
       "5  [0.0, 0.15126050420168066, 0.15546218487394958...   \n",
       "7  [0.0, 0.025210084033613446, 0.0252100840336134...   \n",
       "9  [0.0, 0.029411764705882353, 0.0294117647058823...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "1  [1.8020394, 0.8020394, 0.8020393, 0.80203927, ...  0.836495     0.748954   \n",
       "3  [1.8141658, 0.81416583, 0.8141658, 0.8141657, ...  0.812155     0.705882   \n",
       "5  [1.7551525, 0.75515246, 0.7551524, 0.7551522, ...  0.802786     0.735294   \n",
       "7  [1.8905818, 0.8905818, 0.89058167, 0.8905815, ...  0.812513     0.743697   \n",
       "9  [1.7516885, 0.75168854, 0.7516884, 0.7516883, ...  0.785467     0.668067   \n",
       "\n",
       "   Specificity       MCC  \n",
       "1     0.815126  0.565274  \n",
       "3     0.778243  0.485432  \n",
       "5     0.747899  0.483232  \n",
       "7     0.777311  0.521303  \n",
       "9     0.773109  0.443631  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df[evaluations_df[\"Train_Test\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn, 20-10-5\n",
    "# Fold\tTrain_Test\tAccuracy\tPrecision\tTPR\tFPR\tTPR_FPR_Thresholds\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# 1\t0\tTest\t0.721174\t0.690647\t[0.0, 0.0041841004184100415, 0.066945606694560...\t[0.0, 0.0, 0.0, 0.008403361344537815, 0.008403...\t[1.9654377, 0.9654376, 0.94470316, 0.94159025,...\t0.822097\t0.803347\t0.638655\t0.448191\n",
    "# 3\t1\tTest\t0.769392\t0.750000\t[0.0, 0.004201680672268907, 0.1134453781512605...\t[0.0, 0.0, 0.0, 0.0041841004184100415, 0.00418...\t[1.9864669, 0.9864668, 0.94132906, 0.9403602, ...\t0.833023\t0.806723\t0.732218\t0.540396\n",
    "# 5\t2\tTest\t0.758403\t0.770925\t[0.0, 0.004201680672268907, 0.0042016806722689...\t[0.0, 0.0, 0.004201680672268907, 0.00420168067...\t[1.9832542, 0.98325425, 0.979345, 0.8914033, 0...\t0.829073\t0.735294\t0.781513\t0.517360\n",
    "# 7\t3\tTest\t0.760504\t0.734848\t[0.0, 0.004201680672268907, 0.1008403361344537...\t[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...\t[1.978077, 0.97807705, 0.9421845, 0.9375342, 0...\t0.857796\t0.815126\t0.705882\t0.524145\n",
    "# 9\t4\tTest\t0.714286\t0.710744\t[0.0, 0.004201680672268907, 0.0462184873949579...\t[0.0, 0.0, 0.0, 0.008403361344537815, 0.008403...\t[1.997149, 0.99714893, 0.9781189, 0.974313, 0....\t0.787091\t0.722689\t0.705882\t0.428632"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features\n",
    "train_labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read independent data file\n",
    "##################################################################################\n",
    "indpe_file_path = os.path.join(input_data_folder, independent_data_file)\n",
    "indpe_data = pd.read_csv(indpe_file_path, sep='\\t', header=None)\n",
    "indpe_data.columns = ['Sequence', 'name', 'id', 'flag', 'label_original', 'type']\n",
    "indpe_data.head()\n",
    "    \n",
    "##################################################################################\n",
    "##### Create OHE of sequence\n",
    "##################################################################################\n",
    "indpe_data['OHE_Sequence'] = pd.Series([one_hot_encode_nt(val, all_char_dict) \n",
    "                                        for val in indpe_data[\"Sequence\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Fix the labels\n",
    "##################################################################################\n",
    "indpe_data['label'] = pd.Series([1 if val == 1 else 0 \n",
    "                                 for val in indpe_data[\"label_original\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "indpe_features = np.array(list(indpe_data['OHE_Sequence']))\n",
    "indpe_labels = np.array(list(indpe_data['label']))\n",
    "indpe_labels = indpe_labels.reshape((indpe_labels.shape[0], 1))\n",
    "\n",
    "input_seq_shape = indpe_features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using k-fold Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of each k-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.633306</td>\n",
       "      <td>0.244401</td>\n",
       "      <td>0.640599</td>\n",
       "      <td>0.57931</td>\n",
       "      <td>0.644031</td>\n",
       "      <td>0.17015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity      MCC\n",
       "Train_Test                                                                   \n",
       "Independent  0.633306   0.244401  0.640599      0.57931     0.644031  0.17015"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    label_pred = pred2label(y_pred)\n",
    "\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(indpe_labels, label_pred)\n",
    "    prec = precision_score(indpe_labels,label_pred)\n",
    "    mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "    conf = confusion_matrix(indpe_labels, label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "    auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.249458</td>\n",
       "      <td>[0.0, 0.270935960591133, 0.2857142857142857, 0...</td>\n",
       "      <td>[0.0, 0.16731898238747553, 0.17906066536203522...</td>\n",
       "      <td>[1.8020394, 0.8020394, 0.8020393, 0.80203927, ...</td>\n",
       "      <td>0.632429</td>\n",
       "      <td>0.566502</td>\n",
       "      <td>0.661448</td>\n",
       "      <td>0.174951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.643265</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>[0.0, 0.16748768472906403, 0.18719211822660098...</td>\n",
       "      <td>[0.0, 0.0812133072407045, 0.08512720156555773,...</td>\n",
       "      <td>[1.8141658, 0.81416583, 0.8141658, 0.8141656, ...</td>\n",
       "      <td>0.653861</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.175358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.626122</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>[0.0, 0.41379310344827586, 0.4187192118226601,...</td>\n",
       "      <td>[0.0, 0.24951076320939333, 0.2573385518590998,...</td>\n",
       "      <td>[1.7551525, 0.75515246, 0.7551524, 0.75515234,...</td>\n",
       "      <td>0.629614</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.634051</td>\n",
       "      <td>0.167004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.613878</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>[0.0, 0.2315270935960591, 0.24630541871921183,...</td>\n",
       "      <td>[0.0, 0.12720156555772993, 0.12915851272015655...</td>\n",
       "      <td>[1.8905818, 0.8905818, 0.89058167, 0.8905814, ...</td>\n",
       "      <td>0.640806</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.612524</td>\n",
       "      <td>0.175354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.637551</td>\n",
       "      <td>0.240860</td>\n",
       "      <td>[0.0, 0.11822660098522167, 0.12315270935960591...</td>\n",
       "      <td>[0.0, 0.0821917808219178, 0.08414872798434442,...</td>\n",
       "      <td>[1.7516885, 0.75168854, 0.7516885, 0.7516884, ...</td>\n",
       "      <td>0.646284</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.654599</td>\n",
       "      <td>0.158084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold   Train_Test  Accuracy  Precision  \\\n",
       "0     0  Independent  0.645714   0.249458   \n",
       "1     1  Independent  0.643265   0.248927   \n",
       "2     2  Independent  0.626122   0.241379   \n",
       "3     3  Independent  0.613878   0.241379   \n",
       "4     4  Independent  0.637551   0.240860   \n",
       "\n",
       "                                                 TPR  \\\n",
       "0  [0.0, 0.270935960591133, 0.2857142857142857, 0...   \n",
       "1  [0.0, 0.16748768472906403, 0.18719211822660098...   \n",
       "2  [0.0, 0.41379310344827586, 0.4187192118226601,...   \n",
       "3  [0.0, 0.2315270935960591, 0.24630541871921183,...   \n",
       "4  [0.0, 0.11822660098522167, 0.12315270935960591...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "0  [0.0, 0.16731898238747553, 0.17906066536203522...   \n",
       "1  [0.0, 0.0812133072407045, 0.08512720156555773,...   \n",
       "2  [0.0, 0.24951076320939333, 0.2573385518590998,...   \n",
       "3  [0.0, 0.12720156555772993, 0.12915851272015655...   \n",
       "4  [0.0, 0.0821917808219178, 0.08414872798434442,...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0  [1.8020394, 0.8020394, 0.8020393, 0.80203927, ...  0.632429     0.566502   \n",
       "1  [1.8141658, 0.81416583, 0.8141658, 0.8141656, ...  0.653861     0.571429   \n",
       "2  [1.7551525, 0.75515246, 0.7551524, 0.75515234,...  0.629614     0.586207   \n",
       "3  [1.8905818, 0.8905818, 0.89058167, 0.8905814, ...  0.640806     0.620690   \n",
       "4  [1.7516885, 0.75168854, 0.7516885, 0.7516884, ...  0.646284     0.551724   \n",
       "\n",
       "   Specificity       MCC  \n",
       "0     0.661448  0.174951  \n",
       "1     0.657534  0.175358  \n",
       "2     0.634051  0.167004  \n",
       "3     0.612524  0.175354  \n",
       "4     0.654599  0.158084  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.630204</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.657891</td>\n",
       "      <td>0.591133</td>\n",
       "      <td>0.637965</td>\n",
       "      <td>0.173881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.630204   0.244898  0.657891     0.591133     0.637965  0.173881"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    total_pred += y_pred\n",
    "    all_preds.append(y_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.254737</td>\n",
       "      <td>0.658031</td>\n",
       "      <td>0.596059</td>\n",
       "      <td>0.65362</td>\n",
       "      <td>0.190537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.644082   0.254737  0.658031     0.596059      0.65362  0.190537"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    vote_pred = pred2label(y_pred)\n",
    "    total_pred += vote_pred\n",
    "    all_preds.append(vote_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using New Model\n",
    "\n",
    "Train model on full data from training. Predict and evaluate on Independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_indexes = np.where(indpe_labels==1)[0]\n",
    "neg_indexes = np.random.permutation(np.where(indpe_labels==0)[0])[0:pos_indexes.shape[0]]\n",
    "indpe_val_indexes = np.concatenate((pos_indexes, neg_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6873\n",
      "Epoch 1: val_loss improved from inf to 0.68639, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\_fullModel.hdf5\n",
      "19/19 [==============================] - 9s 129ms/step - loss: 0.6873 - val_loss: 0.6864\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6488\n",
      "Epoch 2: val_loss improved from 0.68639 to 0.67962, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_deepRNN\\5fold\\models\\_fullModel.hdf5\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.6488 - val_loss: 0.6796\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6027\n",
      "Epoch 3: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.6027 - val_loss: 0.6818\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5703\n",
      "Epoch 4: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.5703 - val_loss: 0.6884\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5488\n",
      "Epoch 5: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.5488 - val_loss: 0.6911\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5349\n",
      "Epoch 6: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.5349 - val_loss: 0.6910\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5263\n",
      "Epoch 7: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.5263 - val_loss: 0.6841\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5176\n",
      "Epoch 8: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.5176 - val_loss: 0.6885\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5014\n",
      "Epoch 9: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.5014 - val_loss: 0.6878\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4890\n",
      "Epoch 10: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.4890 - val_loss: 0.6899\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4810\n",
      "Epoch 11: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.4810 - val_loss: 0.6905\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4702\n",
      "Epoch 12: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.4702 - val_loss: 0.6909\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4574\n",
      "Epoch 13: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.4574 - val_loss: 0.6959\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4501\n",
      "Epoch 14: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.4501 - val_loss: 0.7041\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4413\n",
      "Epoch 15: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.4413 - val_loss: 0.7031\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4326\n",
      "Epoch 16: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.4326 - val_loss: 0.7072\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4258\n",
      "Epoch 17: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.4258 - val_loss: 0.7019\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4195\n",
      "Epoch 18: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.4195 - val_loss: 0.7084\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4170\n",
      "Epoch 19: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.4170 - val_loss: 0.7016\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4101\n",
      "Epoch 20: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.4101 - val_loss: 0.7086\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4040\n",
      "Epoch 21: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.4040 - val_loss: 0.7058\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4005\n",
      "Epoch 22: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.4005 - val_loss: 0.7124\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3962\n",
      "Epoch 23: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3962 - val_loss: 0.7169\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3947\n",
      "Epoch 24: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3947 - val_loss: 0.7181\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3920\n",
      "Epoch 25: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3920 - val_loss: 0.7256\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3887\n",
      "Epoch 26: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3887 - val_loss: 0.7194\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3836\n",
      "Epoch 27: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3836 - val_loss: 0.7310\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3798\n",
      "Epoch 28: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3798 - val_loss: 0.7258\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3731\n",
      "Epoch 29: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3731 - val_loss: 0.7266\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3739\n",
      "Epoch 30: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3739 - val_loss: 0.7261\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3735\n",
      "Epoch 31: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.3735 - val_loss: 0.7305\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3700\n",
      "Epoch 32: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3700 - val_loss: 0.7269\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3668\n",
      "Epoch 33: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3668 - val_loss: 0.7358\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3628\n",
      "Epoch 34: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3628 - val_loss: 0.7391\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3587\n",
      "Epoch 35: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3587 - val_loss: 0.7332\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3560\n",
      "Epoch 36: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.3560 - val_loss: 0.7420\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3535\n",
      "Epoch 37: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3535 - val_loss: 0.7459\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3585\n",
      "Epoch 38: val_loss did not improve from 0.67962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3585 - val_loss: 0.7477\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3514\n",
      "Epoch 39: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3514 - val_loss: 0.7406\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3468\n",
      "Epoch 40: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.3468 - val_loss: 0.7480\n",
      "Epoch 41/100\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3463\n",
      "Epoch 41: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.3447 - val_loss: 0.7475\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3436\n",
      "Epoch 42: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3436 - val_loss: 0.7425\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3463\n",
      "Epoch 43: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.3463 - val_loss: 0.7506\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3382\n",
      "Epoch 44: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3382 - val_loss: 0.7507\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3367\n",
      "Epoch 45: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3367 - val_loss: 0.7546\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3318\n",
      "Epoch 46: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3318 - val_loss: 0.7683\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3300\n",
      "Epoch 47: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3300 - val_loss: 0.7532\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3291\n",
      "Epoch 48: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3291 - val_loss: 0.7552\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3315\n",
      "Epoch 49: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.3315 - val_loss: 0.7558\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3274\n",
      "Epoch 50: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.3274 - val_loss: 0.7553\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3248\n",
      "Epoch 51: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.3248 - val_loss: 0.7784\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3503\n",
      "Epoch 52: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.3503 - val_loss: 0.7705\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3335\n",
      "Epoch 53: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3335 - val_loss: 0.7714\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3257\n",
      "Epoch 54: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3257 - val_loss: 0.7878\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3236\n",
      "Epoch 55: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3236 - val_loss: 0.7682\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3204\n",
      "Epoch 56: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3204 - val_loss: 0.7823\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3166\n",
      "Epoch 57: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3166 - val_loss: 0.7794\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3172\n",
      "Epoch 58: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.3172 - val_loss: 0.7820\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3120\n",
      "Epoch 59: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.3120 - val_loss: 0.7980\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3084\n",
      "Epoch 60: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.3084 - val_loss: 0.7973\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3102\n",
      "Epoch 61: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.3102 - val_loss: 0.7939\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3065\n",
      "Epoch 62: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.3065 - val_loss: 0.7871\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3121\n",
      "Epoch 63: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.3121 - val_loss: 0.8075\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3059\n",
      "Epoch 64: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.3059 - val_loss: 0.7945\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3024\n",
      "Epoch 65: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.3024 - val_loss: 0.8120\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2959\n",
      "Epoch 66: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.2959 - val_loss: 0.8060\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2921\n",
      "Epoch 67: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2921 - val_loss: 0.8049\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2908\n",
      "Epoch 68: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2908 - val_loss: 0.7945\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2895\n",
      "Epoch 69: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2895 - val_loss: 0.8113\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2890\n",
      "Epoch 70: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.2890 - val_loss: 0.8037\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2896\n",
      "Epoch 71: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2896 - val_loss: 0.8211\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2865\n",
      "Epoch 72: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2865 - val_loss: 0.8167\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2842\n",
      "Epoch 73: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2842 - val_loss: 0.8045\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2986\n",
      "Epoch 74: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2986 - val_loss: 0.8438\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2887\n",
      "Epoch 75: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2887 - val_loss: 0.8211\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2864\n",
      "Epoch 76: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2864 - val_loss: 0.8300\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.2846\n",
      "Epoch 77: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2846 - val_loss: 0.8214\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2804\n",
      "Epoch 78: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2804 - val_loss: 0.8277\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2820\n",
      "Epoch 79: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2820 - val_loss: 0.8243\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2780\n",
      "Epoch 80: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2780 - val_loss: 0.8273\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2752\n",
      "Epoch 81: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2752 - val_loss: 0.8312\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2749\n",
      "Epoch 82: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2749 - val_loss: 0.8261\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2780\n",
      "Epoch 83: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2780 - val_loss: 0.8323\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2724\n",
      "Epoch 84: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2724 - val_loss: 0.8459\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2740\n",
      "Epoch 85: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2740 - val_loss: 0.8450\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2758\n",
      "Epoch 86: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2758 - val_loss: 0.8518\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2743\n",
      "Epoch 87: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2743 - val_loss: 0.8452\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2694\n",
      "Epoch 88: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2694 - val_loss: 0.8486\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2710\n",
      "Epoch 89: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2710 - val_loss: 0.8519\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2664\n",
      "Epoch 90: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2664 - val_loss: 0.8484\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2698\n",
      "Epoch 91: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2698 - val_loss: 0.8652\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2698\n",
      "Epoch 92: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2698 - val_loss: 0.8570\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2662\n",
      "Epoch 93: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2662 - val_loss: 0.8694\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2650\n",
      "Epoch 94: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2650 - val_loss: 0.8654\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2609\n",
      "Epoch 95: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2609 - val_loss: 0.8531\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2658\n",
      "Epoch 96: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2658 - val_loss: 0.8730\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2670\n",
      "Epoch 97: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2670 - val_loss: 0.8724\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2610\n",
      "Epoch 98: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2610 - val_loss: 0.8624\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2578\n",
      "Epoch 99: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2578 - val_loss: 0.8796\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2597\n",
      "Epoch 100: val_loss did not improve from 0.67962\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2597 - val_loss: 0.8738\n"
     ]
    }
   ],
   "source": [
    "model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "current_model_path = os.path.join(modelPath, \"_fullModel.hdf5\")\n",
    "modelCallbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                       monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                       save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "]\n",
    "\n",
    "# adding random shuffling of the dataset for training purpose\n",
    "index_arr = np.arange(train_features.shape[0])\n",
    "index_arr = np.random.permutation(index_arr)\n",
    "\n",
    "model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "          callbacks = modelCallbacks, validation_data = (indpe_features[indpe_val_indexes], indpe_labels[indpe_val_indexes]))\n",
    "# model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "#           callbacks = modelCallbacks, validation_split = 0.2)\n",
    "\n",
    "model = tf.keras.models.load_model(current_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.66449</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.607714</td>\n",
       "      <td>0.472906</td>\n",
       "      <td>0.702544</td>\n",
       "      <td>0.139114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent   0.66449       0.24  0.607714     0.472906     0.702544  0.139114"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "y_pred = model.predict(indpe_features)\n",
    "label_pred = pred2label(y_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn, 20-10-5\n",
    "# \tAccuracy\tPrecision\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# Train_Test\t\t\t\t\t\t\n",
    "# Independent\t0.647347\t0.253763\t0.675021\t0.581281\t0.66047\t0.185228"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
