{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"NT_Site_PredNTS_Classification_DLNN_KgapRFE\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "shuffle = True\n",
    "seed = None\n",
    "\n",
    "input_data_folder = \"PredNTS_MathFeature_ENC\"\n",
    "\n",
    "monitor = 'val_accuracy'\n",
    "\n",
    "sub_feature_count = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgap_max = 4\n",
    "\n",
    "train_data_filename = 'Training-datasets-PredNTS_kgap_{}.csv'\n",
    "indpe_data_filename = 'independent-dataset-PredNTS_kgap_{}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, classification_report, matthews_corrcoef\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### define all CUSTOM functions\n",
    "# ##################################################################################\n",
    "\n",
    "# def one_hot_encode_nt(sequence, char_dict):\n",
    "    \n",
    "#     seq_encoded = np.zeros((len(sequence),len(char_dict)))\n",
    "    \n",
    "#     i = 0\n",
    "#     for single_character in sequence:\n",
    "#         if(single_character.upper() in char_dict.keys()):\n",
    "#             seq_encoded[i][char_dict[single_character.upper()]] = 1\n",
    "#             i = i+1\n",
    "#         else:\n",
    "#             raise ValueError('Incorrect character in NT sequence: '+sequence)\n",
    "#     return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Build k-fold functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_Classifier(input_vec_shape,\n",
    "                    dense_decode_units = 128, ## Dense layer parameters\n",
    "                    prob = 0.5, learn_rate = 0.0001, loss = 'binary_crossentropy', metrics = 'accuracy'):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_vec_shape)\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  Classifier  ################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    y = tf.keras.layers.Dense(dense_decode_units, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta))(input1)\n",
    "    \n",
    "    y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(int(dense_decode_units/2), \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'relu')(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(int(dense_decode_units/4), \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'relu')(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(1, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'sigmoid')(y)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), \n",
    "                      loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), \n",
    "                      loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 200\n",
    "# batch_size = 16\n",
    "\n",
    "# ##################################################################################\n",
    "# ##### Function to customize the DLNN architecture with parameters\n",
    "# ##################################################################################\n",
    "\n",
    "# def DLNN_Classifier(input_vec_shape,\n",
    "#                     dense_decode_units = 8, ## Dense layer parameters,\n",
    "#                     dense_layers = 2,\n",
    "#                     prob = 0.5, learn_rate = 0.0001, loss = 'binary_crossentropy', metrics = 'accuracy'):\n",
    "    \n",
    "#     beta = 0.001\n",
    "    \n",
    "#     input1 = tf.keras.layers.Input(shape=input_vec_shape)\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  Classifier  ################################################################################\n",
    "#     ######################################################################################################\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(dense_decode_units, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta))(input1)\n",
    "#     y = tf.keras.layers.BatchNormalization()(y)\n",
    "#     y = tf.keras.layers.GaussianNoise(stddev=0.1)(y)\n",
    "#     y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "#     for i in range(1,dense_layers+1):\n",
    "    \n",
    "#         y = tf.keras.layers.Dense(int(dense_decode_units/(2**i)), \n",
    "#                                   kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                                  )(y)\n",
    "#         y = tf.keras.layers.BatchNormalization()(y)\n",
    "#         y = tf.keras.layers.GaussianNoise(stddev=0.1)(y)\n",
    "#         y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(1, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'sigmoid')(y)\n",
    "\n",
    "#     ## Generate Model from input and output\n",
    "#     model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "#     ## Compile model\n",
    "#     if(metrics != None):\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), \n",
    "#                       loss = loss, metrics = metrics)\n",
    "#     else:\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), \n",
    "#                       loss = loss)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               25728     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,097\n",
      "Trainable params: 36,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DLNN_Classifier((sub_feature_count)).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Read CSV data\n",
    "##################################################################################\n",
    "\n",
    "for i in range(kgap_max+1):\n",
    "    \n",
    "    current_train_data_filepath = os.path.join(input_data_folder, train_data_filename.format(i))\n",
    "    current_train_data = pd.read_csv(current_train_data_filepath, sep=',', header=0)\n",
    "    current_train_data = current_train_data.drop('label', axis=1)\n",
    "    \n",
    "    if i == 0:\n",
    "        train_data = current_train_data\n",
    "    else:\n",
    "        train_data = pd.merge(\n",
    "            train_data,\n",
    "            current_train_data,\n",
    "            how=\"inner\",\n",
    "            on='nameseq'\n",
    "        )\n",
    "\n",
    "train_data['label'] = pd.Series([int(val.split('_')[-2])\n",
    "                                 for val in train_data['nameseq']])\n",
    "\n",
    "train_data = train_data.drop('nameseq', axis=1)\n",
    "\n",
    "train_features = np.array(train_data.drop('label', axis=1))\n",
    "train_labels = np.array(train_data['label'])\n",
    "train_labels = train_labels.reshape((train_labels.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Recursive feature selection\n",
    "##################################################################################\n",
    "\n",
    "model = DecisionTreeClassifier(criterion=\"gini\")\n",
    "\n",
    "selector = RFE(model, n_features_to_select=sub_feature_count, step=50)\n",
    "selector = selector.fit(train_features, train_labels)\n",
    "\n",
    "feature_indices = np.where(selector.ranking_ == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "train_features = train_features[:, feature_indices]\n",
    "\n",
    "folds = build_kfold(train_features, train_labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "input_vec_shape = train_features[0].shape\n",
    "\n",
    "## Write the k-fold dataset to file\n",
    "foldPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(foldPath)):\n",
    "    os.makedirs(foldPath)\n",
    "pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Read CSV data\n",
    "##################################################################################\n",
    "\n",
    "for i in range(kgap_max+1):\n",
    "\n",
    "    current_indpe_data_filepath = os.path.join(input_data_folder, indpe_data_filename.format(i))\n",
    "    current_indpe_data = pd.read_csv(current_indpe_data_filepath, sep=',', header=0)\n",
    "    current_indpe_data = current_indpe_data.drop('label', axis=1)\n",
    "    \n",
    "    if i == 0:\n",
    "        indpe_data = current_indpe_data\n",
    "    else:\n",
    "        indpe_data = pd.merge(\n",
    "            indpe_data,\n",
    "            current_indpe_data,\n",
    "            how=\"inner\",\n",
    "            on='nameseq'\n",
    "        )\n",
    "\n",
    "indpe_data['label'] = pd.Series([int(val.split('_')[-2])\n",
    "                                 for val in indpe_data['nameseq']])\n",
    "\n",
    "indpe_data = indpe_data.drop('nameseq', axis=1)\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "indpe_features = np.array(indpe_data.drop('label', axis=1))\n",
    "indpe_features = indpe_features[:, feature_indices]\n",
    "\n",
    "indpe_labels = np.array(indpe_data['label'])\n",
    "indpe_labels = indpe_labels.reshape((indpe_labels.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test model on Fold #0.\n",
      "Epoch 1/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 1.0578 - accuracy: 0.5123\n",
      "Epoch 1: val_loss improved from inf to 0.96763, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 2s 5ms/step - loss: 1.0540 - accuracy: 0.5113 - val_loss: 0.9676 - val_accuracy: 0.5451\n",
      "Epoch 2/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 1.0304 - accuracy: 0.5304\n",
      "Epoch 2: val_loss improved from 0.96763 to 0.95796, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0313 - accuracy: 0.5270 - val_loss: 0.9580 - val_accuracy: 0.5891\n",
      "Epoch 3/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 1.0154 - accuracy: 0.5426\n",
      "Epoch 3: val_loss improved from 0.95796 to 0.95065, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0169 - accuracy: 0.5365 - val_loss: 0.9507 - val_accuracy: 0.6143\n",
      "Epoch 4/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 1.0110 - accuracy: 0.5230\n",
      "Epoch 4: val_loss improved from 0.95065 to 0.94534, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0070 - accuracy: 0.5276 - val_loss: 0.9453 - val_accuracy: 0.6373\n",
      "Epoch 5/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9799 - accuracy: 0.5459\n",
      "Epoch 5: val_loss improved from 0.94534 to 0.94044, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9799 - accuracy: 0.5459 - val_loss: 0.9404 - val_accuracy: 0.6436\n",
      "Epoch 6/200\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.9745 - accuracy: 0.5702\n",
      "Epoch 6: val_loss improved from 0.94044 to 0.93648, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9730 - accuracy: 0.5732 - val_loss: 0.9365 - val_accuracy: 0.6667\n",
      "Epoch 7/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.9649 - accuracy: 0.5706\n",
      "Epoch 7: val_loss improved from 0.93648 to 0.93196, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9630 - accuracy: 0.5732 - val_loss: 0.9320 - val_accuracy: 0.6813\n",
      "Epoch 8/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.9634 - accuracy: 0.5522\n",
      "Epoch 8: val_loss improved from 0.93196 to 0.92740, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9661 - accuracy: 0.5533 - val_loss: 0.9274 - val_accuracy: 0.6751\n",
      "Epoch 9/200\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.9601 - accuracy: 0.5833\n",
      "Epoch 9: val_loss improved from 0.92740 to 0.92347, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9597 - accuracy: 0.5801 - val_loss: 0.9235 - val_accuracy: 0.6709\n",
      "Epoch 10/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.9541 - accuracy: 0.5631\n",
      "Epoch 10: val_loss improved from 0.92347 to 0.91888, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9517 - accuracy: 0.5643 - val_loss: 0.9189 - val_accuracy: 0.6855\n",
      "Epoch 11/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9434 - accuracy: 0.5816\n",
      "Epoch 11: val_loss improved from 0.91888 to 0.91271, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9434 - accuracy: 0.5816 - val_loss: 0.9127 - val_accuracy: 0.6939\n",
      "Epoch 12/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.9189 - accuracy: 0.6168\n",
      "Epoch 12: val_loss improved from 0.91271 to 0.90685, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9205 - accuracy: 0.6084 - val_loss: 0.9068 - val_accuracy: 0.6918\n",
      "Epoch 13/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.9267 - accuracy: 0.5943\n",
      "Epoch 13: val_loss improved from 0.90685 to 0.90040, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9268 - accuracy: 0.5932 - val_loss: 0.9004 - val_accuracy: 0.6855\n",
      "Epoch 14/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.9043 - accuracy: 0.6284\n",
      "Epoch 14: val_loss improved from 0.90040 to 0.89342, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9044 - accuracy: 0.6283 - val_loss: 0.8934 - val_accuracy: 0.6855\n",
      "Epoch 15/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.9090 - accuracy: 0.6127\n",
      "Epoch 15: val_loss improved from 0.89342 to 0.88596, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9050 - accuracy: 0.6168 - val_loss: 0.8860 - val_accuracy: 0.6855\n",
      "Epoch 16/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8905 - accuracy: 0.6472\n",
      "Epoch 16: val_loss improved from 0.88596 to 0.87764, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8905 - accuracy: 0.6472 - val_loss: 0.8776 - val_accuracy: 0.6918\n",
      "Epoch 17/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.8848 - accuracy: 0.6415\n",
      "Epoch 17: val_loss improved from 0.87764 to 0.86827, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8821 - accuracy: 0.6451 - val_loss: 0.8683 - val_accuracy: 0.6939\n",
      "Epoch 18/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.8897 - accuracy: 0.6445\n",
      "Epoch 18: val_loss improved from 0.86827 to 0.85935, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8854 - accuracy: 0.6488 - val_loss: 0.8594 - val_accuracy: 0.6918\n",
      "Epoch 19/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.8681 - accuracy: 0.6617\n",
      "Epoch 19: val_loss improved from 0.85935 to 0.84920, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8692 - accuracy: 0.6588 - val_loss: 0.8492 - val_accuracy: 0.7065\n",
      "Epoch 20/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8598 - accuracy: 0.6717\n",
      "Epoch 20: val_loss improved from 0.84920 to 0.84142, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8598 - accuracy: 0.6719 - val_loss: 0.8414 - val_accuracy: 0.7044\n",
      "Epoch 21/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.8548 - accuracy: 0.6562\n",
      "Epoch 21: val_loss improved from 0.84142 to 0.83425, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8563 - accuracy: 0.6562 - val_loss: 0.8342 - val_accuracy: 0.7044\n",
      "Epoch 22/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8597 - accuracy: 0.6654\n",
      "Epoch 22: val_loss improved from 0.83425 to 0.82926, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8597 - accuracy: 0.6656 - val_loss: 0.8293 - val_accuracy: 0.7023\n",
      "Epoch 23/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.8286 - accuracy: 0.7000\n",
      "Epoch 23: val_loss improved from 0.82926 to 0.82233, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8288 - accuracy: 0.7003 - val_loss: 0.8223 - val_accuracy: 0.7023\n",
      "Epoch 24/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.8263 - accuracy: 0.7020\n",
      "Epoch 24: val_loss improved from 0.82233 to 0.81637, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.8290 - accuracy: 0.7024 - val_loss: 0.8164 - val_accuracy: 0.7023\n",
      "Epoch 25/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.8331 - accuracy: 0.6998\n",
      "Epoch 25: val_loss improved from 0.81637 to 0.81135, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8296 - accuracy: 0.7024 - val_loss: 0.8114 - val_accuracy: 0.7086\n",
      "Epoch 26/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.8283 - accuracy: 0.7013\n",
      "Epoch 26: val_loss improved from 0.81135 to 0.80817, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8251 - accuracy: 0.7024 - val_loss: 0.8082 - val_accuracy: 0.7086\n",
      "Epoch 27/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.8251 - accuracy: 0.6817\n",
      "Epoch 27: val_loss improved from 0.80817 to 0.80563, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8228 - accuracy: 0.6850 - val_loss: 0.8056 - val_accuracy: 0.6981\n",
      "Epoch 28/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.8006 - accuracy: 0.7104\n",
      "Epoch 28: val_loss improved from 0.80563 to 0.80127, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.8011 - accuracy: 0.7102 - val_loss: 0.8013 - val_accuracy: 0.7023\n",
      "Epoch 29/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8155 - accuracy: 0.7045\n",
      "Epoch 29: val_loss improved from 0.80127 to 0.79794, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8155 - accuracy: 0.7045 - val_loss: 0.7979 - val_accuracy: 0.7044\n",
      "Epoch 30/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.8088 - accuracy: 0.7127\n",
      "Epoch 30: val_loss improved from 0.79794 to 0.79360, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8096 - accuracy: 0.7081 - val_loss: 0.7936 - val_accuracy: 0.7044\n",
      "Epoch 31/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.7811 - accuracy: 0.7235\n",
      "Epoch 31: val_loss improved from 0.79360 to 0.79008, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7792 - accuracy: 0.7249 - val_loss: 0.7901 - val_accuracy: 0.7065\n",
      "Epoch 32/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.7713 - accuracy: 0.7264\n",
      "Epoch 32: val_loss improved from 0.79008 to 0.78808, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7777 - accuracy: 0.7213 - val_loss: 0.7881 - val_accuracy: 0.7044\n",
      "Epoch 33/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.7703 - accuracy: 0.7350\n",
      "Epoch 33: val_loss improved from 0.78808 to 0.78489, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7724 - accuracy: 0.7323 - val_loss: 0.7849 - val_accuracy: 0.7086\n",
      "Epoch 34/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7790 - accuracy: 0.7403\n",
      "Epoch 34: val_loss improved from 0.78489 to 0.78324, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7778 - accuracy: 0.7417 - val_loss: 0.7832 - val_accuracy: 0.7044\n",
      "Epoch 35/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7820 - accuracy: 0.7295\n",
      "Epoch 35: val_loss improved from 0.78324 to 0.78080, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7817 - accuracy: 0.7297 - val_loss: 0.7808 - val_accuracy: 0.7023\n",
      "Epoch 36/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.7671 - accuracy: 0.7292\n",
      "Epoch 36: val_loss improved from 0.78080 to 0.77943, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7687 - accuracy: 0.7328 - val_loss: 0.7794 - val_accuracy: 0.7023\n",
      "Epoch 37/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7632 - accuracy: 0.7262\n",
      "Epoch 37: val_loss improved from 0.77943 to 0.77727, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7642 - accuracy: 0.7260 - val_loss: 0.7773 - val_accuracy: 0.7002\n",
      "Epoch 38/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7736 - accuracy: 0.7328\n",
      "Epoch 38: val_loss improved from 0.77727 to 0.77482, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.7720 - accuracy: 0.7344 - val_loss: 0.7748 - val_accuracy: 0.7128\n",
      "Epoch 39/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7574 - accuracy: 0.7389\n",
      "Epoch 39: val_loss improved from 0.77482 to 0.77290, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7589 - accuracy: 0.7386 - val_loss: 0.7729 - val_accuracy: 0.7065\n",
      "Epoch 40/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.7430 - accuracy: 0.7545\n",
      "Epoch 40: val_loss improved from 0.77290 to 0.77174, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7444 - accuracy: 0.7554 - val_loss: 0.7717 - val_accuracy: 0.7065\n",
      "Epoch 41/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.7347 - accuracy: 0.7617\n",
      "Epoch 41: val_loss improved from 0.77174 to 0.77103, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.7633 - val_loss: 0.7710 - val_accuracy: 0.7065\n",
      "Epoch 42/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.7250 - accuracy: 0.7669\n",
      "Epoch 42: val_loss improved from 0.77103 to 0.76918, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7265 - accuracy: 0.7648 - val_loss: 0.7692 - val_accuracy: 0.7065\n",
      "Epoch 43/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.7250 - accuracy: 0.7467\n",
      "Epoch 43: val_loss improved from 0.76918 to 0.76804, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7217 - accuracy: 0.7496 - val_loss: 0.7680 - val_accuracy: 0.7107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.7226 - accuracy: 0.7641\n",
      "Epoch 44: val_loss improved from 0.76804 to 0.76755, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7276 - accuracy: 0.7585 - val_loss: 0.7675 - val_accuracy: 0.7044\n",
      "Epoch 45/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.7355 - accuracy: 0.7472\n",
      "Epoch 45: val_loss improved from 0.76755 to 0.76571, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7329 - accuracy: 0.7501 - val_loss: 0.7657 - val_accuracy: 0.7107\n",
      "Epoch 46/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.7362 - accuracy: 0.7444\n",
      "Epoch 46: val_loss improved from 0.76571 to 0.76335, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7338 - accuracy: 0.7491 - val_loss: 0.7633 - val_accuracy: 0.7086\n",
      "Epoch 47/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.7177 - accuracy: 0.7634\n",
      "Epoch 47: val_loss improved from 0.76335 to 0.76223, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7204 - accuracy: 0.7612 - val_loss: 0.7622 - val_accuracy: 0.7149\n",
      "Epoch 48/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.7182 - accuracy: 0.7641\n",
      "Epoch 48: val_loss improved from 0.76223 to 0.76129, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7244 - accuracy: 0.7643 - val_loss: 0.7613 - val_accuracy: 0.7149\n",
      "Epoch 49/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7247 - accuracy: 0.7463\n",
      "Epoch 49: val_loss improved from 0.76129 to 0.75955, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7267 - accuracy: 0.7465 - val_loss: 0.7595 - val_accuracy: 0.7170\n",
      "Epoch 50/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7142 - accuracy: 0.7705\n",
      "Epoch 50: val_loss improved from 0.75955 to 0.75928, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7149 - accuracy: 0.7706 - val_loss: 0.7593 - val_accuracy: 0.7107\n",
      "Epoch 51/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.7077 - accuracy: 0.7626\n",
      "Epoch 51: val_loss improved from 0.75928 to 0.75819, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7037 - accuracy: 0.7669 - val_loss: 0.7582 - val_accuracy: 0.7086\n",
      "Epoch 52/200\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.7149 - accuracy: 0.7607\n",
      "Epoch 52: val_loss improved from 0.75819 to 0.75754, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7108 - accuracy: 0.7617 - val_loss: 0.7575 - val_accuracy: 0.7086\n",
      "Epoch 53/200\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.7041 - accuracy: 0.7649\n",
      "Epoch 53: val_loss improved from 0.75754 to 0.75628, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7143 - accuracy: 0.7612 - val_loss: 0.7563 - val_accuracy: 0.7065\n",
      "Epoch 54/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.7149 - accuracy: 0.7586\n",
      "Epoch 54: val_loss improved from 0.75628 to 0.75500, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7048 - accuracy: 0.7627 - val_loss: 0.7550 - val_accuracy: 0.7107\n",
      "Epoch 55/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6960 - accuracy: 0.7793\n",
      "Epoch 55: val_loss improved from 0.75500 to 0.75449, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6996 - accuracy: 0.7738 - val_loss: 0.7545 - val_accuracy: 0.7086\n",
      "Epoch 56/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6975 - accuracy: 0.7676\n",
      "Epoch 56: val_loss did not improve from 0.75449\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6980 - accuracy: 0.7664 - val_loss: 0.7550 - val_accuracy: 0.7107\n",
      "Epoch 57/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.7009 - accuracy: 0.7681\n",
      "Epoch 57: val_loss improved from 0.75449 to 0.75175, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6994 - accuracy: 0.7717 - val_loss: 0.7517 - val_accuracy: 0.7086\n",
      "Epoch 58/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.7047 - accuracy: 0.7620\n",
      "Epoch 58: val_loss improved from 0.75175 to 0.75110, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7000 - accuracy: 0.7643 - val_loss: 0.7511 - val_accuracy: 0.7086\n",
      "Epoch 59/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6859 - accuracy: 0.7682\n",
      "Epoch 59: val_loss did not improve from 0.75110\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6877 - accuracy: 0.7675 - val_loss: 0.7514 - val_accuracy: 0.7044\n",
      "Epoch 60/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.7717\n",
      "Epoch 60: val_loss improved from 0.75110 to 0.74975, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6791 - accuracy: 0.7717 - val_loss: 0.7498 - val_accuracy: 0.7044\n",
      "Epoch 61/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6880 - accuracy: 0.7679\n",
      "Epoch 61: val_loss improved from 0.74975 to 0.74930, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6896 - accuracy: 0.7659 - val_loss: 0.7493 - val_accuracy: 0.7044\n",
      "Epoch 62/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.6703 - accuracy: 0.7751\n",
      "Epoch 62: val_loss improved from 0.74930 to 0.74571, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6737 - accuracy: 0.7738 - val_loss: 0.7457 - val_accuracy: 0.7044\n",
      "Epoch 63/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.6750 - accuracy: 0.7784\n",
      "Epoch 63: val_loss improved from 0.74571 to 0.74380, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6777 - accuracy: 0.7753 - val_loss: 0.7438 - val_accuracy: 0.7065\n",
      "Epoch 64/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.7715\n",
      "Epoch 64: val_loss improved from 0.74380 to 0.74369, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6718 - accuracy: 0.7711 - val_loss: 0.7437 - val_accuracy: 0.7065\n",
      "Epoch 65/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.6725 - accuracy: 0.7776\n",
      "Epoch 65: val_loss improved from 0.74369 to 0.74264, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6764 - accuracy: 0.7732 - val_loss: 0.7426 - val_accuracy: 0.7065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.6855 - accuracy: 0.7727\n",
      "Epoch 66: val_loss did not improve from 0.74264\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.7764 - val_loss: 0.7429 - val_accuracy: 0.7044\n",
      "Epoch 67/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6668 - accuracy: 0.7838\n",
      "Epoch 67: val_loss improved from 0.74264 to 0.74108, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6712 - accuracy: 0.7832 - val_loss: 0.7411 - val_accuracy: 0.7044\n",
      "Epoch 68/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6760 - accuracy: 0.7721\n",
      "Epoch 68: val_loss improved from 0.74108 to 0.74080, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6732 - accuracy: 0.7753 - val_loss: 0.7408 - val_accuracy: 0.7065\n",
      "Epoch 69/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6671 - accuracy: 0.7869\n",
      "Epoch 69: val_loss improved from 0.74080 to 0.73945, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6667 - accuracy: 0.7879 - val_loss: 0.7395 - val_accuracy: 0.7086\n",
      "Epoch 70/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6593 - accuracy: 0.7791\n",
      "Epoch 70: val_loss improved from 0.73945 to 0.73912, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6593 - accuracy: 0.7785 - val_loss: 0.7391 - val_accuracy: 0.7086\n",
      "Epoch 71/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6575 - accuracy: 0.7799\n",
      "Epoch 71: val_loss improved from 0.73912 to 0.73859, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.7785 - val_loss: 0.7386 - val_accuracy: 0.7044\n",
      "Epoch 72/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.6612 - accuracy: 0.7974\n",
      "Epoch 72: val_loss improved from 0.73859 to 0.73749, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.7921 - val_loss: 0.7375 - val_accuracy: 0.7002\n",
      "Epoch 73/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6525 - accuracy: 0.7739\n",
      "Epoch 73: val_loss improved from 0.73749 to 0.73536, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6535 - accuracy: 0.7753 - val_loss: 0.7354 - val_accuracy: 0.7065\n",
      "Epoch 74/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6577 - accuracy: 0.7761\n",
      "Epoch 74: val_loss improved from 0.73536 to 0.73531, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6558 - accuracy: 0.7774 - val_loss: 0.7353 - val_accuracy: 0.7044\n",
      "Epoch 75/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6523 - accuracy: 0.7847\n",
      "Epoch 75: val_loss improved from 0.73531 to 0.73361, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6515 - accuracy: 0.7858 - val_loss: 0.7336 - val_accuracy: 0.7086\n",
      "Epoch 76/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6581 - accuracy: 0.7874\n",
      "Epoch 76: val_loss improved from 0.73361 to 0.73134, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6570 - accuracy: 0.7895 - val_loss: 0.7313 - val_accuracy: 0.7107\n",
      "Epoch 77/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.6548 - accuracy: 0.7778\n",
      "Epoch 77: val_loss did not improve from 0.73134\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6616 - accuracy: 0.7790 - val_loss: 0.7317 - val_accuracy: 0.7065\n",
      "Epoch 78/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6603 - accuracy: 0.7664\n",
      "Epoch 78: val_loss improved from 0.73134 to 0.73084, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6585 - accuracy: 0.7680 - val_loss: 0.7308 - val_accuracy: 0.7086\n",
      "Epoch 79/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.6316 - accuracy: 0.7863\n",
      "Epoch 79: val_loss improved from 0.73084 to 0.73083, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.7858 - val_loss: 0.7308 - val_accuracy: 0.7086\n",
      "Epoch 80/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6505 - accuracy: 0.7887\n",
      "Epoch 80: val_loss improved from 0.73083 to 0.72796, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.7885 - val_loss: 0.7280 - val_accuracy: 0.7065\n",
      "Epoch 81/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.6392 - accuracy: 0.7975\n",
      "Epoch 81: val_loss did not improve from 0.72796\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.7953 - val_loss: 0.7306 - val_accuracy: 0.7065\n",
      "Epoch 82/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6448 - accuracy: 0.7838\n",
      "Epoch 82: val_loss did not improve from 0.72796\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.7858 - val_loss: 0.7295 - val_accuracy: 0.7002\n",
      "Epoch 83/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6378 - accuracy: 0.7821\n",
      "Epoch 83: val_loss did not improve from 0.72796\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.7837 - val_loss: 0.7289 - val_accuracy: 0.7044\n",
      "Epoch 84/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6261 - accuracy: 0.7937\n",
      "Epoch 84: val_loss did not improve from 0.72796\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.7937 - val_loss: 0.7280 - val_accuracy: 0.7023\n",
      "Epoch 85/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.6247 - accuracy: 0.7937\n",
      "Epoch 85: val_loss did not improve from 0.72796\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7932 - val_loss: 0.7289 - val_accuracy: 0.7044\n",
      "Epoch 86/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.6224 - accuracy: 0.7922\n",
      "Epoch 86: val_loss did not improve from 0.72796\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.7921 - val_loss: 0.7292 - val_accuracy: 0.7023\n",
      "Epoch 87/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.6331 - accuracy: 0.7939\n",
      "Epoch 87: val_loss improved from 0.72796 to 0.72795, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.7911 - val_loss: 0.7280 - val_accuracy: 0.7086\n",
      "Epoch 88/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6196 - accuracy: 0.7961\n",
      "Epoch 88: val_loss improved from 0.72795 to 0.72538, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6300 - accuracy: 0.7921 - val_loss: 0.7254 - val_accuracy: 0.7107\n",
      "Epoch 89/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.6220 - accuracy: 0.7913\n",
      "Epoch 89: val_loss improved from 0.72538 to 0.72405, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.7895 - val_loss: 0.7241 - val_accuracy: 0.7107\n",
      "Epoch 90/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6250 - accuracy: 0.7878\n",
      "Epoch 90: val_loss did not improve from 0.72405\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.7879 - val_loss: 0.7247 - val_accuracy: 0.7107\n",
      "Epoch 91/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6220 - accuracy: 0.7992\n",
      "Epoch 91: val_loss improved from 0.72405 to 0.72286, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.7990 - val_loss: 0.7229 - val_accuracy: 0.7107\n",
      "Epoch 92/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.6261 - accuracy: 0.7841\n",
      "Epoch 92: val_loss did not improve from 0.72286\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.7869 - val_loss: 0.7236 - val_accuracy: 0.7065\n",
      "Epoch 93/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.6140 - accuracy: 0.7907\n",
      "Epoch 93: val_loss did not improve from 0.72286\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.7927 - val_loss: 0.7243 - val_accuracy: 0.7128\n",
      "Epoch 94/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6051 - accuracy: 0.8085\n",
      "Epoch 94: val_loss did not improve from 0.72286\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.8073 - val_loss: 0.7250 - val_accuracy: 0.7149\n",
      "Epoch 95/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6022 - accuracy: 0.7896\n",
      "Epoch 95: val_loss did not improve from 0.72286\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.7906 - val_loss: 0.7235 - val_accuracy: 0.7170\n",
      "Epoch 96/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.6125 - accuracy: 0.8041\n",
      "Epoch 96: val_loss did not improve from 0.72286\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.8031 - val_loss: 0.7242 - val_accuracy: 0.7107\n",
      "Epoch 97/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6062 - accuracy: 0.7994\n",
      "Epoch 97: val_loss improved from 0.72286 to 0.72222, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6066 - accuracy: 0.7990 - val_loss: 0.7222 - val_accuracy: 0.7086\n",
      "Epoch 98/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.6078 - accuracy: 0.7920\n",
      "Epoch 98: val_loss improved from 0.72222 to 0.71939, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6077 - accuracy: 0.7948 - val_loss: 0.7194 - val_accuracy: 0.7107\n",
      "Epoch 99/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5942 - accuracy: 0.7987\n",
      "Epoch 99: val_loss did not improve from 0.71939\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5986 - accuracy: 0.7942 - val_loss: 0.7201 - val_accuracy: 0.7107\n",
      "Epoch 100/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6036 - accuracy: 0.8001\n",
      "Epoch 100: val_loss improved from 0.71939 to 0.71868, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6034 - accuracy: 0.7995 - val_loss: 0.7187 - val_accuracy: 0.7191\n",
      "Epoch 101/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5949 - accuracy: 0.7980\n",
      "Epoch 101: val_loss improved from 0.71868 to 0.71718, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5926 - accuracy: 0.7995 - val_loss: 0.7172 - val_accuracy: 0.7191\n",
      "Epoch 102/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5952 - accuracy: 0.8011\n",
      "Epoch 102: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.7974 - val_loss: 0.7177 - val_accuracy: 0.7254\n",
      "Epoch 103/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5930 - accuracy: 0.8007\n",
      "Epoch 103: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5909 - accuracy: 0.8021 - val_loss: 0.7221 - val_accuracy: 0.7233\n",
      "Epoch 104/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.5898 - accuracy: 0.8074\n",
      "Epoch 104: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.8068 - val_loss: 0.7239 - val_accuracy: 0.7233\n",
      "Epoch 105/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5932 - accuracy: 0.8078\n",
      "Epoch 105: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.8047 - val_loss: 0.7221 - val_accuracy: 0.7233\n",
      "Epoch 106/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.5901 - accuracy: 0.8032\n",
      "Epoch 106: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.8037 - val_loss: 0.7206 - val_accuracy: 0.7212\n",
      "Epoch 107/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.5905 - accuracy: 0.8056\n",
      "Epoch 107: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.8026 - val_loss: 0.7180 - val_accuracy: 0.7191\n",
      "Epoch 108/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5818 - accuracy: 0.8026\n",
      "Epoch 108: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.8026 - val_loss: 0.7210 - val_accuracy: 0.7212\n",
      "Epoch 109/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5834 - accuracy: 0.8009\n",
      "Epoch 109: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.8010 - val_loss: 0.7202 - val_accuracy: 0.7233\n",
      "Epoch 110/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5902 - accuracy: 0.7981\n",
      "Epoch 110: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.7969 - val_loss: 0.7185 - val_accuracy: 0.7233\n",
      "Epoch 111/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5871 - accuracy: 0.8046\n",
      "Epoch 111: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.8047 - val_loss: 0.7178 - val_accuracy: 0.7212\n",
      "Epoch 112/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5823 - accuracy: 0.8012\n",
      "Epoch 112: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5847 - accuracy: 0.7990 - val_loss: 0.7185 - val_accuracy: 0.7191\n",
      "Epoch 113/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5651 - accuracy: 0.8014\n",
      "Epoch 113: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5663 - accuracy: 0.8005 - val_loss: 0.7207 - val_accuracy: 0.7233\n",
      "Epoch 114/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5800 - accuracy: 0.8136\n",
      "Epoch 114: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.8131 - val_loss: 0.7216 - val_accuracy: 0.7233\n",
      "Epoch 115/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.5880 - accuracy: 0.8010\n",
      "Epoch 115: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.8073 - val_loss: 0.7198 - val_accuracy: 0.7212\n",
      "Epoch 116/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5835 - accuracy: 0.8019\n",
      "Epoch 116: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.8037 - val_loss: 0.7177 - val_accuracy: 0.7233\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 0.5723 - accuracy: 0.8178\n",
      "Epoch 117: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.8178 - val_loss: 0.7196 - val_accuracy: 0.7212\n",
      "Epoch 118/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5786 - accuracy: 0.8057\n",
      "Epoch 118: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.8052 - val_loss: 0.7194 - val_accuracy: 0.7191\n",
      "Epoch 119/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.8013\n",
      "Epoch 119: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5721 - accuracy: 0.8016 - val_loss: 0.7201 - val_accuracy: 0.7212\n",
      "Epoch 120/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.8000\n",
      "Epoch 120: val_loss did not improve from 0.71718\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.8000 - val_loss: 0.7201 - val_accuracy: 0.7233\n",
      "Epoch 121/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.8047\n",
      "Epoch 121: val_loss improved from 0.71718 to 0.71555, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5751 - accuracy: 0.8047 - val_loss: 0.7156 - val_accuracy: 0.7212\n",
      "Epoch 122/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.5621 - accuracy: 0.8090\n",
      "Epoch 122: val_loss improved from 0.71555 to 0.71534, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold0.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5664 - accuracy: 0.8063 - val_loss: 0.7153 - val_accuracy: 0.7254\n",
      "Epoch 123/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5667 - accuracy: 0.8068\n",
      "Epoch 123: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.8089 - val_loss: 0.7168 - val_accuracy: 0.7254\n",
      "Epoch 124/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.8068\n",
      "Epoch 124: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.8068 - val_loss: 0.7189 - val_accuracy: 0.7254\n",
      "Epoch 125/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5664 - accuracy: 0.8074\n",
      "Epoch 125: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.8084 - val_loss: 0.7154 - val_accuracy: 0.7233\n",
      "Epoch 126/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.5588 - accuracy: 0.8091\n",
      "Epoch 126: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.8079 - val_loss: 0.7194 - val_accuracy: 0.7233\n",
      "Epoch 127/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5606 - accuracy: 0.7983\n",
      "Epoch 127: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7984 - val_loss: 0.7195 - val_accuracy: 0.7233\n",
      "Epoch 128/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5562 - accuracy: 0.8130\n",
      "Epoch 128: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5546 - accuracy: 0.8147 - val_loss: 0.7175 - val_accuracy: 0.7296\n",
      "Epoch 129/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.5553 - accuracy: 0.8096\n",
      "Epoch 129: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.8100 - val_loss: 0.7220 - val_accuracy: 0.7317\n",
      "Epoch 130/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5558 - accuracy: 0.8136\n",
      "Epoch 130: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5544 - accuracy: 0.8147 - val_loss: 0.7186 - val_accuracy: 0.7317\n",
      "Epoch 131/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5383 - accuracy: 0.8147\n",
      "Epoch 131: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.8147 - val_loss: 0.7203 - val_accuracy: 0.7275\n",
      "Epoch 132/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5396 - accuracy: 0.8200\n",
      "Epoch 132: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5400 - accuracy: 0.8184 - val_loss: 0.7213 - val_accuracy: 0.7275\n",
      "Epoch 133/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5433 - accuracy: 0.8137\n",
      "Epoch 133: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.8131 - val_loss: 0.7228 - val_accuracy: 0.7233\n",
      "Epoch 134/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5451 - accuracy: 0.8176\n",
      "Epoch 134: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.8194 - val_loss: 0.7212 - val_accuracy: 0.7296\n",
      "Epoch 135/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5427 - accuracy: 0.8237\n",
      "Epoch 135: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5410 - accuracy: 0.8247 - val_loss: 0.7220 - val_accuracy: 0.7254\n",
      "Epoch 136/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5444 - accuracy: 0.8207\n",
      "Epoch 136: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5417 - accuracy: 0.8220 - val_loss: 0.7235 - val_accuracy: 0.7317\n",
      "Epoch 137/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5411 - accuracy: 0.8162\n",
      "Epoch 137: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.8163 - val_loss: 0.7209 - val_accuracy: 0.7254\n",
      "Epoch 138/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5406 - accuracy: 0.8136\n",
      "Epoch 138: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5399 - accuracy: 0.8136 - val_loss: 0.7200 - val_accuracy: 0.7296\n",
      "Epoch 139/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5450 - accuracy: 0.8158\n",
      "Epoch 139: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5438 - accuracy: 0.8142 - val_loss: 0.7178 - val_accuracy: 0.7254\n",
      "Epoch 140/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5382 - accuracy: 0.8183\n",
      "Epoch 140: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.8199 - val_loss: 0.7182 - val_accuracy: 0.7254\n",
      "Epoch 141/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5285 - accuracy: 0.8178\n",
      "Epoch 141: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5307 - accuracy: 0.8163 - val_loss: 0.7228 - val_accuracy: 0.7296\n",
      "Epoch 142/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5166 - accuracy: 0.8196\n",
      "Epoch 142: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5222 - accuracy: 0.8163 - val_loss: 0.7259 - val_accuracy: 0.7254\n",
      "Epoch 143/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5231 - accuracy: 0.8236\n",
      "Epoch 143: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.8236 - val_loss: 0.7276 - val_accuracy: 0.7212\n",
      "Epoch 144/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5167 - accuracy: 0.8162\n",
      "Epoch 144: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5211 - accuracy: 0.8163 - val_loss: 0.7311 - val_accuracy: 0.7254\n",
      "Epoch 145/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5167 - accuracy: 0.8147\n",
      "Epoch 145: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5215 - accuracy: 0.8121 - val_loss: 0.7299 - val_accuracy: 0.7212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5242 - accuracy: 0.8169\n",
      "Epoch 146: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5268 - accuracy: 0.8157 - val_loss: 0.7251 - val_accuracy: 0.7233\n",
      "Epoch 147/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5317 - accuracy: 0.8090\n",
      "Epoch 147: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5317 - accuracy: 0.8100 - val_loss: 0.7227 - val_accuracy: 0.7149\n",
      "Epoch 148/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5227 - accuracy: 0.8189\n",
      "Epoch 148: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5239 - accuracy: 0.8189 - val_loss: 0.7240 - val_accuracy: 0.7191\n",
      "Epoch 149/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5248 - accuracy: 0.8177\n",
      "Epoch 149: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.8163 - val_loss: 0.7264 - val_accuracy: 0.7317\n",
      "Epoch 150/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5159 - accuracy: 0.8177\n",
      "Epoch 150: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.8210 - val_loss: 0.7263 - val_accuracy: 0.7254\n",
      "Epoch 151/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.8142\n",
      "Epoch 151: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5263 - accuracy: 0.8142 - val_loss: 0.7237 - val_accuracy: 0.7296\n",
      "Epoch 152/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5194 - accuracy: 0.8245\n",
      "Epoch 152: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5220 - accuracy: 0.8220 - val_loss: 0.7249 - val_accuracy: 0.7275\n",
      "Epoch 153/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5143 - accuracy: 0.8318\n",
      "Epoch 153: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.8257 - val_loss: 0.7269 - val_accuracy: 0.7254\n",
      "Epoch 154/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5175 - accuracy: 0.8252\n",
      "Epoch 154: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.5170 - accuracy: 0.8252 - val_loss: 0.7282 - val_accuracy: 0.7275\n",
      "Epoch 155/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5037 - accuracy: 0.8296\n",
      "Epoch 155: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.8299 - val_loss: 0.7281 - val_accuracy: 0.7233\n",
      "Epoch 156/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5072 - accuracy: 0.8211\n",
      "Epoch 156: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.8226 - val_loss: 0.7333 - val_accuracy: 0.7254\n",
      "Epoch 157/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5127 - accuracy: 0.8231\n",
      "Epoch 157: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.8231 - val_loss: 0.7330 - val_accuracy: 0.7233\n",
      "Epoch 158/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5124 - accuracy: 0.8220\n",
      "Epoch 158: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.8247 - val_loss: 0.7304 - val_accuracy: 0.7233\n",
      "Epoch 159/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5230 - accuracy: 0.8240\n",
      "Epoch 159: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.8252 - val_loss: 0.7273 - val_accuracy: 0.7233\n",
      "Epoch 160/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.8360\n",
      "Epoch 160: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5000 - accuracy: 0.8367 - val_loss: 0.7342 - val_accuracy: 0.7275\n",
      "Epoch 161/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.8284\n",
      "Epoch 161: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4999 - accuracy: 0.8283 - val_loss: 0.7319 - val_accuracy: 0.7338\n",
      "Epoch 162/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5053 - accuracy: 0.8380\n",
      "Epoch 162: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.8352 - val_loss: 0.7289 - val_accuracy: 0.7338\n",
      "Epoch 163/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5005 - accuracy: 0.8278\n",
      "Epoch 163: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5023 - accuracy: 0.8252 - val_loss: 0.7216 - val_accuracy: 0.7317\n",
      "Epoch 164/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4950 - accuracy: 0.8391\n",
      "Epoch 164: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.8388 - val_loss: 0.7288 - val_accuracy: 0.7317\n",
      "Epoch 165/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4904 - accuracy: 0.8356\n",
      "Epoch 165: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4907 - accuracy: 0.8352 - val_loss: 0.7364 - val_accuracy: 0.7400\n",
      "Epoch 166/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4815 - accuracy: 0.8399\n",
      "Epoch 166: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4823 - accuracy: 0.8383 - val_loss: 0.7319 - val_accuracy: 0.7275\n",
      "Epoch 167/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.8378\n",
      "Epoch 167: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.8378 - val_loss: 0.7325 - val_accuracy: 0.7275\n",
      "Epoch 168/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5010 - accuracy: 0.8273\n",
      "Epoch 168: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.8268 - val_loss: 0.7312 - val_accuracy: 0.7317\n",
      "Epoch 169/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4953 - accuracy: 0.8347\n",
      "Epoch 169: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.8315 - val_loss: 0.7314 - val_accuracy: 0.7317\n",
      "Epoch 170/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.4786 - accuracy: 0.8489\n",
      "Epoch 170: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4801 - accuracy: 0.8451 - val_loss: 0.7370 - val_accuracy: 0.7296\n",
      "Epoch 171/200\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.4765 - accuracy: 0.8554\n",
      "Epoch 171: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4776 - accuracy: 0.8514 - val_loss: 0.7362 - val_accuracy: 0.7317\n",
      "Epoch 172/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.4913 - accuracy: 0.8308\n",
      "Epoch 172: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4899 - accuracy: 0.8304 - val_loss: 0.7305 - val_accuracy: 0.7317\n",
      "Epoch 173/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4941 - accuracy: 0.8330\n",
      "Epoch 173: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.8325 - val_loss: 0.7308 - val_accuracy: 0.7317\n",
      "Epoch 174/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.4820 - accuracy: 0.8391\n",
      "Epoch 174: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4828 - accuracy: 0.8388 - val_loss: 0.7292 - val_accuracy: 0.7379\n",
      "Epoch 175/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4796 - accuracy: 0.8438\n",
      "Epoch 175: val_loss did not improve from 0.71534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4797 - accuracy: 0.8462 - val_loss: 0.7356 - val_accuracy: 0.7421\n",
      "Epoch 176/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.4753 - accuracy: 0.8354\n",
      "Epoch 176: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4762 - accuracy: 0.8320 - val_loss: 0.7374 - val_accuracy: 0.7358\n",
      "Epoch 177/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4728 - accuracy: 0.8406\n",
      "Epoch 177: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.8415 - val_loss: 0.7346 - val_accuracy: 0.7296\n",
      "Epoch 178/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.8328\n",
      "Epoch 178: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4852 - accuracy: 0.8336 - val_loss: 0.7361 - val_accuracy: 0.7338\n",
      "Epoch 179/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4785 - accuracy: 0.8386\n",
      "Epoch 179: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4769 - accuracy: 0.8388 - val_loss: 0.7341 - val_accuracy: 0.7379\n",
      "Epoch 180/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.8340\n",
      "Epoch 180: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.8336 - val_loss: 0.7392 - val_accuracy: 0.7400\n",
      "Epoch 181/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4765 - accuracy: 0.8475\n",
      "Epoch 181: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.8467 - val_loss: 0.7356 - val_accuracy: 0.7317\n",
      "Epoch 182/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4730 - accuracy: 0.8464\n",
      "Epoch 182: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.8472 - val_loss: 0.7323 - val_accuracy: 0.7338\n",
      "Epoch 183/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4688 - accuracy: 0.8513\n",
      "Epoch 183: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.8504 - val_loss: 0.7373 - val_accuracy: 0.7317\n",
      "Epoch 184/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4618 - accuracy: 0.8420\n",
      "Epoch 184: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.8430 - val_loss: 0.7359 - val_accuracy: 0.7338\n",
      "Epoch 185/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.4577 - accuracy: 0.8538\n",
      "Epoch 185: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4611 - accuracy: 0.8535 - val_loss: 0.7374 - val_accuracy: 0.7317\n",
      "Epoch 186/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4520 - accuracy: 0.8574\n",
      "Epoch 186: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.8551 - val_loss: 0.7423 - val_accuracy: 0.7338\n",
      "Epoch 187/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4550 - accuracy: 0.8558\n",
      "Epoch 187: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.8588 - val_loss: 0.7455 - val_accuracy: 0.7358\n",
      "Epoch 188/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.8496\n",
      "Epoch 188: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4627 - accuracy: 0.8493 - val_loss: 0.7441 - val_accuracy: 0.7358\n",
      "Epoch 189/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.4446 - accuracy: 0.8551\n",
      "Epoch 189: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4458 - accuracy: 0.8546 - val_loss: 0.7448 - val_accuracy: 0.7379\n",
      "Epoch 190/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.8480\n",
      "Epoch 190: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.8462 - val_loss: 0.7445 - val_accuracy: 0.7379\n",
      "Epoch 191/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.4409 - accuracy: 0.8595\n",
      "Epoch 191: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.8577 - val_loss: 0.7407 - val_accuracy: 0.7317\n",
      "Epoch 192/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4500 - accuracy: 0.8568\n",
      "Epoch 192: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4455 - accuracy: 0.8609 - val_loss: 0.7430 - val_accuracy: 0.7233\n",
      "Epoch 193/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8562\n",
      "Epoch 193: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4481 - accuracy: 0.8562 - val_loss: 0.7441 - val_accuracy: 0.7296\n",
      "Epoch 194/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.4480 - accuracy: 0.8538\n",
      "Epoch 194: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8535 - val_loss: 0.7439 - val_accuracy: 0.7338\n",
      "Epoch 195/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4513 - accuracy: 0.8528\n",
      "Epoch 195: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.8551 - val_loss: 0.7448 - val_accuracy: 0.7296\n",
      "Epoch 196/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.4518 - accuracy: 0.8486\n",
      "Epoch 196: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8472 - val_loss: 0.7474 - val_accuracy: 0.7317\n",
      "Epoch 197/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4642 - accuracy: 0.8522\n",
      "Epoch 197: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.8530 - val_loss: 0.7480 - val_accuracy: 0.7296\n",
      "Epoch 198/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.4258 - accuracy: 0.8694\n",
      "Epoch 198: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8677 - val_loss: 0.7596 - val_accuracy: 0.7379\n",
      "Epoch 199/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4243 - accuracy: 0.8668\n",
      "Epoch 199: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8661 - val_loss: 0.7649 - val_accuracy: 0.7338\n",
      "Epoch 200/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4322 - accuracy: 0.8591\n",
      "Epoch 200: val_loss did not improve from 0.71534\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8588 - val_loss: 0.7597 - val_accuracy: 0.7358\n",
      "\n",
      "Train/Test model on Fold #1.\n",
      "Epoch 1/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 1.1003 - accuracy: 0.4957\n",
      "Epoch 1: val_loss improved from inf to 0.97603, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1.0977 - accuracy: 0.4976 - val_loss: 0.9760 - val_accuracy: 0.5178\n",
      "Epoch 2/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 1.0433 - accuracy: 0.5197\n",
      "Epoch 2: val_loss improved from 0.97603 to 0.96407, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0414 - accuracy: 0.5192 - val_loss: 0.9641 - val_accuracy: 0.5618\n",
      "Epoch 3/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 1.0390 - accuracy: 0.5080\n",
      "Epoch 3: val_loss improved from 0.96407 to 0.95674, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0377 - accuracy: 0.5118 - val_loss: 0.9567 - val_accuracy: 0.5681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 1.0100 - accuracy: 0.5277\n",
      "Epoch 4: val_loss improved from 0.95674 to 0.95051, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0076 - accuracy: 0.5312 - val_loss: 0.9505 - val_accuracy: 0.5828\n",
      "Epoch 5/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.9979 - accuracy: 0.5476\n",
      "Epoch 5: val_loss improved from 0.95051 to 0.94464, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0003 - accuracy: 0.5449 - val_loss: 0.9446 - val_accuracy: 0.6122\n",
      "Epoch 6/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9929 - accuracy: 0.5428\n",
      "Epoch 6: val_loss improved from 0.94464 to 0.94015, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9929 - accuracy: 0.5428 - val_loss: 0.9401 - val_accuracy: 0.6205\n",
      "Epoch 7/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9651 - accuracy: 0.5669\n",
      "Epoch 7: val_loss improved from 0.94015 to 0.93419, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9651 - accuracy: 0.5669 - val_loss: 0.9342 - val_accuracy: 0.6289\n",
      "Epoch 8/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.9674 - accuracy: 0.5494\n",
      "Epoch 8: val_loss improved from 0.93419 to 0.92988, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9676 - accuracy: 0.5491 - val_loss: 0.9299 - val_accuracy: 0.6457\n",
      "Epoch 9/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.9586 - accuracy: 0.5608\n",
      "Epoch 9: val_loss improved from 0.92988 to 0.92527, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9586 - accuracy: 0.5633 - val_loss: 0.9253 - val_accuracy: 0.6562\n",
      "Epoch 10/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.9413 - accuracy: 0.5577\n",
      "Epoch 10: val_loss improved from 0.92527 to 0.91997, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9424 - accuracy: 0.5554 - val_loss: 0.9200 - val_accuracy: 0.6583\n",
      "Epoch 11/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.9308 - accuracy: 0.5894\n",
      "Epoch 11: val_loss improved from 0.91997 to 0.91372, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9333 - accuracy: 0.5864 - val_loss: 0.9137 - val_accuracy: 0.6688\n",
      "Epoch 12/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.9320 - accuracy: 0.5792\n",
      "Epoch 12: val_loss improved from 0.91372 to 0.90798, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.9296 - accuracy: 0.5827 - val_loss: 0.9080 - val_accuracy: 0.6771\n",
      "Epoch 13/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.9262 - accuracy: 0.6170\n",
      "Epoch 13: val_loss improved from 0.90798 to 0.90208, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9281 - accuracy: 0.6157 - val_loss: 0.9021 - val_accuracy: 0.6834\n",
      "Epoch 14/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.9181 - accuracy: 0.6016\n",
      "Epoch 14: val_loss improved from 0.90208 to 0.89640, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9154 - accuracy: 0.6042 - val_loss: 0.8964 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.9065 - accuracy: 0.6255\n",
      "Epoch 15: val_loss improved from 0.89640 to 0.88991, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9070 - accuracy: 0.6231 - val_loss: 0.8899 - val_accuracy: 0.6918\n",
      "Epoch 16/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8967 - accuracy: 0.6136\n",
      "Epoch 16: val_loss improved from 0.88991 to 0.88356, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8967 - accuracy: 0.6136 - val_loss: 0.8836 - val_accuracy: 0.7002\n",
      "Epoch 17/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.8994 - accuracy: 0.6202\n",
      "Epoch 17: val_loss improved from 0.88356 to 0.87663, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8991 - accuracy: 0.6215 - val_loss: 0.8766 - val_accuracy: 0.7107\n",
      "Epoch 18/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.8785 - accuracy: 0.6449\n",
      "Epoch 18: val_loss improved from 0.87663 to 0.87054, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8786 - accuracy: 0.6446 - val_loss: 0.8705 - val_accuracy: 0.7170\n",
      "Epoch 19/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.8864 - accuracy: 0.6370\n",
      "Epoch 19: val_loss improved from 0.87054 to 0.86310, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.8826 - accuracy: 0.6441 - val_loss: 0.8631 - val_accuracy: 0.7233\n",
      "Epoch 20/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.8773 - accuracy: 0.6341\n",
      "Epoch 20: val_loss improved from 0.86310 to 0.85568, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8718 - accuracy: 0.6388 - val_loss: 0.8557 - val_accuracy: 0.7317\n",
      "Epoch 21/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.8654 - accuracy: 0.6449\n",
      "Epoch 21: val_loss improved from 0.85568 to 0.84852, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8652 - accuracy: 0.6451 - val_loss: 0.8485 - val_accuracy: 0.7275\n",
      "Epoch 22/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.8431 - accuracy: 0.6720\n",
      "Epoch 22: val_loss improved from 0.84852 to 0.84015, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8424 - accuracy: 0.6730 - val_loss: 0.8402 - val_accuracy: 0.7358\n",
      "Epoch 23/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.8524 - accuracy: 0.6802\n",
      "Epoch 23: val_loss improved from 0.84015 to 0.83298, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8530 - accuracy: 0.6782 - val_loss: 0.8330 - val_accuracy: 0.7358\n",
      "Epoch 24/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8469 - accuracy: 0.6812\n",
      "Epoch 24: val_loss improved from 0.83298 to 0.82963, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8470 - accuracy: 0.6808 - val_loss: 0.8296 - val_accuracy: 0.7338\n",
      "Epoch 25/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.8196 - accuracy: 0.6989\n",
      "Epoch 25: val_loss improved from 0.82963 to 0.82217, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8164 - accuracy: 0.7024 - val_loss: 0.8222 - val_accuracy: 0.7317\n",
      "Epoch 26/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.8368 - accuracy: 0.6896\n",
      "Epoch 26: val_loss improved from 0.82217 to 0.81719, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8362 - accuracy: 0.6892 - val_loss: 0.8172 - val_accuracy: 0.7379\n",
      "Epoch 27/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.8227 - accuracy: 0.7025\n",
      "Epoch 27: val_loss improved from 0.81719 to 0.81018, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8229 - accuracy: 0.7018 - val_loss: 0.8102 - val_accuracy: 0.7358\n",
      "Epoch 28/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.8047 - accuracy: 0.7070\n",
      "Epoch 28: val_loss improved from 0.81018 to 0.80392, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8050 - accuracy: 0.7050 - val_loss: 0.8039 - val_accuracy: 0.7379\n",
      "Epoch 29/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.8119 - accuracy: 0.6963\n",
      "Epoch 29: val_loss improved from 0.80392 to 0.79890, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8079 - accuracy: 0.6955 - val_loss: 0.7989 - val_accuracy: 0.7379\n",
      "Epoch 30/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.7977 - accuracy: 0.7124\n",
      "Epoch 30: val_loss improved from 0.79890 to 0.79494, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7981 - accuracy: 0.7139 - val_loss: 0.7949 - val_accuracy: 0.7317\n",
      "Epoch 31/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.8018 - accuracy: 0.7107\n",
      "Epoch 31: val_loss improved from 0.79494 to 0.79289, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8029 - accuracy: 0.7092 - val_loss: 0.7929 - val_accuracy: 0.7358\n",
      "Epoch 32/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.7772 - accuracy: 0.7342\n",
      "Epoch 32: val_loss improved from 0.79289 to 0.78861, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7838 - accuracy: 0.7281 - val_loss: 0.7886 - val_accuracy: 0.7379\n",
      "Epoch 33/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7823 - accuracy: 0.7137\n",
      "Epoch 33: val_loss improved from 0.78861 to 0.78619, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7820 - accuracy: 0.7139 - val_loss: 0.7862 - val_accuracy: 0.7379\n",
      "Epoch 34/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7768 - accuracy: 0.7341\n",
      "Epoch 34: val_loss improved from 0.78619 to 0.78256, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7767 - accuracy: 0.7339 - val_loss: 0.7826 - val_accuracy: 0.7358\n",
      "Epoch 35/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7760 - accuracy: 0.7198\n",
      "Epoch 35: val_loss improved from 0.78256 to 0.77978, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7780 - accuracy: 0.7176 - val_loss: 0.7798 - val_accuracy: 0.7442\n",
      "Epoch 36/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7652 - accuracy: 0.7301\n",
      "Epoch 36: val_loss improved from 0.77978 to 0.77650, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7631 - accuracy: 0.7307 - val_loss: 0.7765 - val_accuracy: 0.7463\n",
      "Epoch 37/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.7781 - accuracy: 0.7145\n",
      "Epoch 37: val_loss improved from 0.77650 to 0.77469, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7700 - accuracy: 0.7239 - val_loss: 0.7747 - val_accuracy: 0.7421\n",
      "Epoch 38/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.7631 - accuracy: 0.7357\n",
      "Epoch 38: val_loss improved from 0.77469 to 0.77245, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7630 - accuracy: 0.7360 - val_loss: 0.7725 - val_accuracy: 0.7421\n",
      "Epoch 39/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7534 - accuracy: 0.7374\n",
      "Epoch 39: val_loss improved from 0.77245 to 0.77023, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7536 - accuracy: 0.7370 - val_loss: 0.7702 - val_accuracy: 0.7338\n",
      "Epoch 40/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7607 - accuracy: 0.7421\n",
      "Epoch 40: val_loss improved from 0.77023 to 0.76854, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7606 - accuracy: 0.7423 - val_loss: 0.7685 - val_accuracy: 0.7358\n",
      "Epoch 41/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.7445 - accuracy: 0.7364\n",
      "Epoch 41: val_loss improved from 0.76854 to 0.76677, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7442 - accuracy: 0.7344 - val_loss: 0.7668 - val_accuracy: 0.7379\n",
      "Epoch 42/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7391 - accuracy: 0.7383\n",
      "Epoch 42: val_loss improved from 0.76677 to 0.76527, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7407 - accuracy: 0.7370 - val_loss: 0.7653 - val_accuracy: 0.7400\n",
      "Epoch 43/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7503 - accuracy: 0.7436\n",
      "Epoch 43: val_loss improved from 0.76527 to 0.76463, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7494 - accuracy: 0.7444 - val_loss: 0.7646 - val_accuracy: 0.7379\n",
      "Epoch 44/200\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.7436 - accuracy: 0.7250\n",
      "Epoch 44: val_loss improved from 0.76463 to 0.76269, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7413 - accuracy: 0.7302 - val_loss: 0.7627 - val_accuracy: 0.7317\n",
      "Epoch 45/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.7389 - accuracy: 0.7494\n",
      "Epoch 45: val_loss improved from 0.76269 to 0.76069, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7377 - accuracy: 0.7501 - val_loss: 0.7607 - val_accuracy: 0.7358\n",
      "Epoch 46/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.7440 - accuracy: 0.7331\n",
      "Epoch 46: val_loss improved from 0.76069 to 0.75983, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7432 - accuracy: 0.7323 - val_loss: 0.7598 - val_accuracy: 0.7358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.7162 - accuracy: 0.7552\n",
      "Epoch 47: val_loss improved from 0.75983 to 0.75862, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7157 - accuracy: 0.7522 - val_loss: 0.7586 - val_accuracy: 0.7338\n",
      "Epoch 48/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.7290 - accuracy: 0.7467\n",
      "Epoch 48: val_loss improved from 0.75862 to 0.75732, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.7438 - val_loss: 0.7573 - val_accuracy: 0.7338\n",
      "Epoch 49/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.7302 - accuracy: 0.7419\n",
      "Epoch 49: val_loss improved from 0.75732 to 0.75622, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7249 - accuracy: 0.7454 - val_loss: 0.7562 - val_accuracy: 0.7317\n",
      "Epoch 50/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.7135 - accuracy: 0.7642\n",
      "Epoch 50: val_loss improved from 0.75622 to 0.75460, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7120 - accuracy: 0.7643 - val_loss: 0.7546 - val_accuracy: 0.7358\n",
      "Epoch 51/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.7142 - accuracy: 0.7512\n",
      "Epoch 51: val_loss improved from 0.75460 to 0.75287, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7131 - accuracy: 0.7507 - val_loss: 0.7529 - val_accuracy: 0.7317\n",
      "Epoch 52/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.7245 - accuracy: 0.7557\n",
      "Epoch 52: val_loss improved from 0.75287 to 0.75100, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7282 - accuracy: 0.7507 - val_loss: 0.7510 - val_accuracy: 0.7379\n",
      "Epoch 53/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.7122 - accuracy: 0.7535\n",
      "Epoch 53: val_loss improved from 0.75100 to 0.74976, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7117 - accuracy: 0.7517 - val_loss: 0.7498 - val_accuracy: 0.7358\n",
      "Epoch 54/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.6848 - accuracy: 0.7662\n",
      "Epoch 54: val_loss improved from 0.74976 to 0.74906, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.7643 - val_loss: 0.7491 - val_accuracy: 0.7379\n",
      "Epoch 55/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6983 - accuracy: 0.7548\n",
      "Epoch 55: val_loss improved from 0.74906 to 0.74850, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6976 - accuracy: 0.7559 - val_loss: 0.7485 - val_accuracy: 0.7379\n",
      "Epoch 56/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6915 - accuracy: 0.7652\n",
      "Epoch 56: val_loss improved from 0.74850 to 0.74735, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6918 - accuracy: 0.7648 - val_loss: 0.7473 - val_accuracy: 0.7421\n",
      "Epoch 57/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6918 - accuracy: 0.7621\n",
      "Epoch 57: val_loss improved from 0.74735 to 0.74490, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6915 - accuracy: 0.7622 - val_loss: 0.7449 - val_accuracy: 0.7421\n",
      "Epoch 58/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6817 - accuracy: 0.7757\n",
      "Epoch 58: val_loss improved from 0.74490 to 0.74423, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6852 - accuracy: 0.7711 - val_loss: 0.7442 - val_accuracy: 0.7442\n",
      "Epoch 59/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6841 - accuracy: 0.7726\n",
      "Epoch 59: val_loss improved from 0.74423 to 0.74356, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6839 - accuracy: 0.7727 - val_loss: 0.7436 - val_accuracy: 0.7421\n",
      "Epoch 60/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6914 - accuracy: 0.7613\n",
      "Epoch 60: val_loss improved from 0.74356 to 0.74273, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6898 - accuracy: 0.7612 - val_loss: 0.7427 - val_accuracy: 0.7505\n",
      "Epoch 61/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6869 - accuracy: 0.7586\n",
      "Epoch 61: val_loss improved from 0.74273 to 0.74169, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6841 - accuracy: 0.7585 - val_loss: 0.7417 - val_accuracy: 0.7442\n",
      "Epoch 62/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.6746 - accuracy: 0.7703\n",
      "Epoch 62: val_loss improved from 0.74169 to 0.74166, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6778 - accuracy: 0.7680 - val_loss: 0.7417 - val_accuracy: 0.7421\n",
      "Epoch 63/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6868 - accuracy: 0.7704\n",
      "Epoch 63: val_loss improved from 0.74166 to 0.74045, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6866 - accuracy: 0.7717 - val_loss: 0.7404 - val_accuracy: 0.7442\n",
      "Epoch 64/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6832 - accuracy: 0.7623\n",
      "Epoch 64: val_loss improved from 0.74045 to 0.73957, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6808 - accuracy: 0.7659 - val_loss: 0.7396 - val_accuracy: 0.7442\n",
      "Epoch 65/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.7738\n",
      "Epoch 65: val_loss improved from 0.73957 to 0.73823, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6787 - accuracy: 0.7738 - val_loss: 0.7382 - val_accuracy: 0.7421\n",
      "Epoch 66/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6754 - accuracy: 0.7747\n",
      "Epoch 66: val_loss improved from 0.73823 to 0.73774, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7748 - val_loss: 0.7377 - val_accuracy: 0.7484\n",
      "Epoch 67/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6646 - accuracy: 0.7815\n",
      "Epoch 67: val_loss improved from 0.73774 to 0.73693, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6603 - accuracy: 0.7816 - val_loss: 0.7369 - val_accuracy: 0.7442\n",
      "Epoch 68/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6731 - accuracy: 0.7717\n",
      "Epoch 68: val_loss improved from 0.73693 to 0.73670, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6731 - accuracy: 0.7717 - val_loss: 0.7367 - val_accuracy: 0.7421\n",
      "Epoch 69/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.6673 - accuracy: 0.7727\n",
      "Epoch 69: val_loss did not improve from 0.73670\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6689 - accuracy: 0.7711 - val_loss: 0.7369 - val_accuracy: 0.7442\n",
      "Epoch 70/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6555 - accuracy: 0.7769\n",
      "Epoch 70: val_loss did not improve from 0.73670\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.7795 - val_loss: 0.7370 - val_accuracy: 0.7400\n",
      "Epoch 71/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.6550 - accuracy: 0.7842\n",
      "Epoch 71: val_loss improved from 0.73670 to 0.73586, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6544 - accuracy: 0.7811 - val_loss: 0.7359 - val_accuracy: 0.7421\n",
      "Epoch 72/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.6544 - accuracy: 0.7791\n",
      "Epoch 72: val_loss improved from 0.73586 to 0.73571, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.6534 - accuracy: 0.7795 - val_loss: 0.7357 - val_accuracy: 0.7358\n",
      "Epoch 73/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6482 - accuracy: 0.7710\n",
      "Epoch 73: val_loss improved from 0.73571 to 0.73496, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6494 - accuracy: 0.7696 - val_loss: 0.7350 - val_accuracy: 0.7317\n",
      "Epoch 74/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6506 - accuracy: 0.7821\n",
      "Epoch 74: val_loss improved from 0.73496 to 0.73418, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6516 - accuracy: 0.7816 - val_loss: 0.7342 - val_accuracy: 0.7442\n",
      "Epoch 75/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6433 - accuracy: 0.7770\n",
      "Epoch 75: val_loss did not improve from 0.73418\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6429 - accuracy: 0.7774 - val_loss: 0.7342 - val_accuracy: 0.7400\n",
      "Epoch 76/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6463 - accuracy: 0.7695\n",
      "Epoch 76: val_loss did not improve from 0.73418\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6523 - accuracy: 0.7675 - val_loss: 0.7344 - val_accuracy: 0.7400\n",
      "Epoch 77/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6641 - accuracy: 0.7729\n",
      "Epoch 77: val_loss improved from 0.73418 to 0.73194, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6623 - accuracy: 0.7727 - val_loss: 0.7319 - val_accuracy: 0.7463\n",
      "Epoch 78/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6573 - accuracy: 0.7687\n",
      "Epoch 78: val_loss improved from 0.73194 to 0.73127, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6569 - accuracy: 0.7685 - val_loss: 0.7313 - val_accuracy: 0.7358\n",
      "Epoch 79/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6442 - accuracy: 0.7756\n",
      "Epoch 79: val_loss improved from 0.73127 to 0.73039, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6438 - accuracy: 0.7759 - val_loss: 0.7304 - val_accuracy: 0.7379\n",
      "Epoch 80/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6476 - accuracy: 0.7890\n",
      "Epoch 80: val_loss improved from 0.73039 to 0.72872, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6498 - accuracy: 0.7879 - val_loss: 0.7287 - val_accuracy: 0.7421\n",
      "Epoch 81/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6294 - accuracy: 0.7829\n",
      "Epoch 81: val_loss did not improve from 0.72872\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6315 - accuracy: 0.7832 - val_loss: 0.7290 - val_accuracy: 0.7442\n",
      "Epoch 82/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6359 - accuracy: 0.7877\n",
      "Epoch 82: val_loss improved from 0.72872 to 0.72800, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6364 - accuracy: 0.7874 - val_loss: 0.7280 - val_accuracy: 0.7421\n",
      "Epoch 83/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.6320 - accuracy: 0.7903\n",
      "Epoch 83: val_loss improved from 0.72800 to 0.72671, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6267 - accuracy: 0.7900 - val_loss: 0.7267 - val_accuracy: 0.7442\n",
      "Epoch 84/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6300 - accuracy: 0.7810\n",
      "Epoch 84: val_loss improved from 0.72671 to 0.72577, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.7832 - val_loss: 0.7258 - val_accuracy: 0.7400\n",
      "Epoch 85/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.6399 - accuracy: 0.7673\n",
      "Epoch 85: val_loss did not improve from 0.72577\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6380 - accuracy: 0.7685 - val_loss: 0.7262 - val_accuracy: 0.7421\n",
      "Epoch 86/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6276 - accuracy: 0.7832\n",
      "Epoch 86: val_loss did not improve from 0.72577\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6272 - accuracy: 0.7848 - val_loss: 0.7265 - val_accuracy: 0.7421\n",
      "Epoch 87/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.6338 - accuracy: 0.7823\n",
      "Epoch 87: val_loss improved from 0.72577 to 0.72497, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6322 - accuracy: 0.7811 - val_loss: 0.7250 - val_accuracy: 0.7400\n",
      "Epoch 88/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.6249 - accuracy: 0.7898\n",
      "Epoch 88: val_loss did not improve from 0.72497\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.7869 - val_loss: 0.7250 - val_accuracy: 0.7421\n",
      "Epoch 89/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6204 - accuracy: 0.7873\n",
      "Epoch 89: val_loss improved from 0.72497 to 0.72382, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6265 - accuracy: 0.7827 - val_loss: 0.7238 - val_accuracy: 0.7421\n",
      "Epoch 90/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.6135 - accuracy: 0.7907\n",
      "Epoch 90: val_loss did not improve from 0.72382\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.7921 - val_loss: 0.7239 - val_accuracy: 0.7463\n",
      "Epoch 91/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.5975 - accuracy: 0.7967\n",
      "Epoch 91: val_loss did not improve from 0.72382\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.7921 - val_loss: 0.7258 - val_accuracy: 0.7421\n",
      "Epoch 92/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.6093 - accuracy: 0.7834\n",
      "Epoch 92: val_loss did not improve from 0.72382\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6111 - accuracy: 0.7822 - val_loss: 0.7249 - val_accuracy: 0.7463\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/120 [==========================>...] - ETA: 0s - loss: 0.6197 - accuracy: 0.7849\n",
      "Epoch 93: val_loss improved from 0.72382 to 0.72325, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.7848 - val_loss: 0.7232 - val_accuracy: 0.7463\n",
      "Epoch 94/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.6098 - accuracy: 0.7898\n",
      "Epoch 94: val_loss improved from 0.72325 to 0.72263, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold1.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6063 - accuracy: 0.7916 - val_loss: 0.7226 - val_accuracy: 0.7463\n",
      "Epoch 95/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6025 - accuracy: 0.7932\n",
      "Epoch 95: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.7932 - val_loss: 0.7233 - val_accuracy: 0.7442\n",
      "Epoch 96/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.6117 - accuracy: 0.7951\n",
      "Epoch 96: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.7995 - val_loss: 0.7238 - val_accuracy: 0.7442\n",
      "Epoch 97/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6069 - accuracy: 0.7875\n",
      "Epoch 97: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6055 - accuracy: 0.7879 - val_loss: 0.7235 - val_accuracy: 0.7463\n",
      "Epoch 98/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6004 - accuracy: 0.7909\n",
      "Epoch 98: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.7911 - val_loss: 0.7242 - val_accuracy: 0.7463\n",
      "Epoch 99/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.7759\n",
      "Epoch 99: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6085 - accuracy: 0.7759 - val_loss: 0.7233 - val_accuracy: 0.7505\n",
      "Epoch 100/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6028 - accuracy: 0.7867\n",
      "Epoch 100: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.7853 - val_loss: 0.7256 - val_accuracy: 0.7484\n",
      "Epoch 101/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5946 - accuracy: 0.7945\n",
      "Epoch 101: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.7953 - val_loss: 0.7252 - val_accuracy: 0.7463\n",
      "Epoch 102/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5972 - accuracy: 0.7859\n",
      "Epoch 102: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.7858 - val_loss: 0.7264 - val_accuracy: 0.7484\n",
      "Epoch 103/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5956 - accuracy: 0.7895\n",
      "Epoch 103: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5953 - accuracy: 0.7885 - val_loss: 0.7263 - val_accuracy: 0.7505\n",
      "Epoch 104/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5868 - accuracy: 0.7852\n",
      "Epoch 104: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.7843 - val_loss: 0.7261 - val_accuracy: 0.7484\n",
      "Epoch 105/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5978 - accuracy: 0.7965\n",
      "Epoch 105: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7984 - val_loss: 0.7267 - val_accuracy: 0.7484\n",
      "Epoch 106/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5871 - accuracy: 0.7987\n",
      "Epoch 106: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.8000 - val_loss: 0.7263 - val_accuracy: 0.7484\n",
      "Epoch 107/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5813 - accuracy: 0.7928\n",
      "Epoch 107: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5834 - accuracy: 0.7932 - val_loss: 0.7270 - val_accuracy: 0.7463\n",
      "Epoch 108/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.5862 - accuracy: 0.7932\n",
      "Epoch 108: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.7916 - val_loss: 0.7267 - val_accuracy: 0.7442\n",
      "Epoch 109/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5973 - accuracy: 0.7870\n",
      "Epoch 109: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7900 - val_loss: 0.7263 - val_accuracy: 0.7463\n",
      "Epoch 110/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5776 - accuracy: 0.7898\n",
      "Epoch 110: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5799 - accuracy: 0.7869 - val_loss: 0.7277 - val_accuracy: 0.7484\n",
      "Epoch 111/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5762 - accuracy: 0.7969\n",
      "Epoch 111: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5762 - accuracy: 0.7969 - val_loss: 0.7263 - val_accuracy: 0.7400\n",
      "Epoch 112/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.5653 - accuracy: 0.7939\n",
      "Epoch 112: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7948 - val_loss: 0.7284 - val_accuracy: 0.7505\n",
      "Epoch 113/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5840 - accuracy: 0.7933\n",
      "Epoch 113: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5846 - accuracy: 0.7937 - val_loss: 0.7272 - val_accuracy: 0.7526\n",
      "Epoch 114/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.8110\n",
      "Epoch 114: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5719 - accuracy: 0.8110 - val_loss: 0.7285 - val_accuracy: 0.7484\n",
      "Epoch 115/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.8037\n",
      "Epoch 115: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.8037 - val_loss: 0.7290 - val_accuracy: 0.7547\n",
      "Epoch 116/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.7946\n",
      "Epoch 116: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5685 - accuracy: 0.7942 - val_loss: 0.7305 - val_accuracy: 0.7526\n",
      "Epoch 117/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5681 - accuracy: 0.7893\n",
      "Epoch 117: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5659 - accuracy: 0.7906 - val_loss: 0.7299 - val_accuracy: 0.7505\n",
      "Epoch 118/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7963\n",
      "Epoch 118: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5653 - accuracy: 0.7963 - val_loss: 0.7337 - val_accuracy: 0.7463\n",
      "Epoch 119/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5537 - accuracy: 0.8105\n",
      "Epoch 119: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5537 - accuracy: 0.8105 - val_loss: 0.7341 - val_accuracy: 0.7484\n",
      "Epoch 120/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5546 - accuracy: 0.7978\n",
      "Epoch 120: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7963 - val_loss: 0.7338 - val_accuracy: 0.7484\n",
      "Epoch 121/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5430 - accuracy: 0.8119\n",
      "Epoch 121: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.8026 - val_loss: 0.7361 - val_accuracy: 0.7442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5536 - accuracy: 0.8080\n",
      "Epoch 122: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5517 - accuracy: 0.8089 - val_loss: 0.7353 - val_accuracy: 0.7463\n",
      "Epoch 123/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5474 - accuracy: 0.8065\n",
      "Epoch 123: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5469 - accuracy: 0.8073 - val_loss: 0.7384 - val_accuracy: 0.7505\n",
      "Epoch 124/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.8104\n",
      "Epoch 124: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.8110 - val_loss: 0.7390 - val_accuracy: 0.7484\n",
      "Epoch 125/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5625 - accuracy: 0.8049\n",
      "Epoch 125: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5610 - accuracy: 0.8073 - val_loss: 0.7366 - val_accuracy: 0.7463\n",
      "Epoch 126/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5589 - accuracy: 0.8013\n",
      "Epoch 126: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5572 - accuracy: 0.8016 - val_loss: 0.7374 - val_accuracy: 0.7442\n",
      "Epoch 127/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5565 - accuracy: 0.7973\n",
      "Epoch 127: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5566 - accuracy: 0.7974 - val_loss: 0.7407 - val_accuracy: 0.7484\n",
      "Epoch 128/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5472 - accuracy: 0.7982\n",
      "Epoch 128: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7984 - val_loss: 0.7366 - val_accuracy: 0.7484\n",
      "Epoch 129/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5426 - accuracy: 0.8130\n",
      "Epoch 129: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.8131 - val_loss: 0.7393 - val_accuracy: 0.7505\n",
      "Epoch 130/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5488 - accuracy: 0.8055\n",
      "Epoch 130: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5497 - accuracy: 0.8052 - val_loss: 0.7410 - val_accuracy: 0.7484\n",
      "Epoch 131/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5437 - accuracy: 0.8011\n",
      "Epoch 131: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5458 - accuracy: 0.8005 - val_loss: 0.7420 - val_accuracy: 0.7442\n",
      "Epoch 132/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.8094\n",
      "Epoch 132: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.8094 - val_loss: 0.7458 - val_accuracy: 0.7442\n",
      "Epoch 133/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.8017\n",
      "Epoch 133: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.8016 - val_loss: 0.7447 - val_accuracy: 0.7442\n",
      "Epoch 134/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5376 - accuracy: 0.7937\n",
      "Epoch 134: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5345 - accuracy: 0.7963 - val_loss: 0.7491 - val_accuracy: 0.7484\n",
      "Epoch 135/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5317 - accuracy: 0.8113\n",
      "Epoch 135: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5347 - accuracy: 0.8110 - val_loss: 0.7471 - val_accuracy: 0.7421\n",
      "Epoch 136/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5254 - accuracy: 0.8067\n",
      "Epoch 136: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.8068 - val_loss: 0.7493 - val_accuracy: 0.7442\n",
      "Epoch 137/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.8021\n",
      "Epoch 137: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.8021 - val_loss: 0.7518 - val_accuracy: 0.7442\n",
      "Epoch 138/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5308 - accuracy: 0.8087\n",
      "Epoch 138: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.5319 - accuracy: 0.8079 - val_loss: 0.7520 - val_accuracy: 0.7379\n",
      "Epoch 139/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5277 - accuracy: 0.8136\n",
      "Epoch 139: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5297 - accuracy: 0.8110 - val_loss: 0.7516 - val_accuracy: 0.7442\n",
      "Epoch 140/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5270 - accuracy: 0.8051\n",
      "Epoch 140: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5284 - accuracy: 0.8037 - val_loss: 0.7559 - val_accuracy: 0.7505\n",
      "Epoch 141/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.5199 - accuracy: 0.8228\n",
      "Epoch 141: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5186 - accuracy: 0.8215 - val_loss: 0.7567 - val_accuracy: 0.7421\n",
      "Epoch 142/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.5279 - accuracy: 0.8119\n",
      "Epoch 142: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.8115 - val_loss: 0.7552 - val_accuracy: 0.7442\n",
      "Epoch 143/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5120 - accuracy: 0.8099\n",
      "Epoch 143: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5156 - accuracy: 0.8079 - val_loss: 0.7609 - val_accuracy: 0.7442\n",
      "Epoch 144/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.5209 - accuracy: 0.8165\n",
      "Epoch 144: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5219 - accuracy: 0.8157 - val_loss: 0.7586 - val_accuracy: 0.7421\n",
      "Epoch 145/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.5328 - accuracy: 0.7964\n",
      "Epoch 145: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7942 - val_loss: 0.7570 - val_accuracy: 0.7484\n",
      "Epoch 146/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5204 - accuracy: 0.8189\n",
      "Epoch 146: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.8189 - val_loss: 0.7614 - val_accuracy: 0.7463\n",
      "Epoch 147/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5136 - accuracy: 0.8257\n",
      "Epoch 147: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5121 - accuracy: 0.8257 - val_loss: 0.7622 - val_accuracy: 0.7421\n",
      "Epoch 148/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5088 - accuracy: 0.8164\n",
      "Epoch 148: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.8199 - val_loss: 0.7642 - val_accuracy: 0.7505\n",
      "Epoch 149/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.5155 - accuracy: 0.8228\n",
      "Epoch 149: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.8199 - val_loss: 0.7608 - val_accuracy: 0.7547\n",
      "Epoch 150/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5058 - accuracy: 0.8114\n",
      "Epoch 150: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5081 - accuracy: 0.8110 - val_loss: 0.7639 - val_accuracy: 0.7442\n",
      "Epoch 151/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5126 - accuracy: 0.8091\n",
      "Epoch 151: val_loss did not improve from 0.72263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5134 - accuracy: 0.8094 - val_loss: 0.7639 - val_accuracy: 0.7442\n",
      "Epoch 152/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5084 - accuracy: 0.8192\n",
      "Epoch 152: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5045 - accuracy: 0.8205 - val_loss: 0.7670 - val_accuracy: 0.7484\n",
      "Epoch 153/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5087 - accuracy: 0.8152\n",
      "Epoch 153: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5119 - accuracy: 0.8131 - val_loss: 0.7694 - val_accuracy: 0.7463\n",
      "Epoch 154/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.5074 - accuracy: 0.8195\n",
      "Epoch 154: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5033 - accuracy: 0.8199 - val_loss: 0.7640 - val_accuracy: 0.7463\n",
      "Epoch 155/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.4917 - accuracy: 0.8219\n",
      "Epoch 155: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4930 - accuracy: 0.8189 - val_loss: 0.7679 - val_accuracy: 0.7463\n",
      "Epoch 156/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.5075 - accuracy: 0.8271\n",
      "Epoch 156: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.8283 - val_loss: 0.7652 - val_accuracy: 0.7568\n",
      "Epoch 157/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.4935 - accuracy: 0.8310\n",
      "Epoch 157: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4920 - accuracy: 0.8310 - val_loss: 0.7707 - val_accuracy: 0.7568\n",
      "Epoch 158/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4961 - accuracy: 0.8273\n",
      "Epoch 158: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.8283 - val_loss: 0.7762 - val_accuracy: 0.7589\n",
      "Epoch 159/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4970 - accuracy: 0.8231\n",
      "Epoch 159: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4957 - accuracy: 0.8241 - val_loss: 0.7771 - val_accuracy: 0.7610\n",
      "Epoch 160/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4817 - accuracy: 0.8347\n",
      "Epoch 160: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4837 - accuracy: 0.8320 - val_loss: 0.7848 - val_accuracy: 0.7568\n",
      "Epoch 161/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4962 - accuracy: 0.8194\n",
      "Epoch 161: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.8215 - val_loss: 0.7845 - val_accuracy: 0.7589\n",
      "Epoch 162/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4972 - accuracy: 0.8235\n",
      "Epoch 162: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.8226 - val_loss: 0.7772 - val_accuracy: 0.7568\n",
      "Epoch 163/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.4786 - accuracy: 0.8378\n",
      "Epoch 163: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4820 - accuracy: 0.8331 - val_loss: 0.7858 - val_accuracy: 0.7610\n",
      "Epoch 164/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.4751 - accuracy: 0.8418\n",
      "Epoch 164: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4821 - accuracy: 0.8378 - val_loss: 0.7825 - val_accuracy: 0.7589\n",
      "Epoch 165/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4889 - accuracy: 0.8257\n",
      "Epoch 165: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4893 - accuracy: 0.8273 - val_loss: 0.7826 - val_accuracy: 0.7526\n",
      "Epoch 166/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4952 - accuracy: 0.8273\n",
      "Epoch 166: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4964 - accuracy: 0.8257 - val_loss: 0.7801 - val_accuracy: 0.7526\n",
      "Epoch 167/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4797 - accuracy: 0.8333\n",
      "Epoch 167: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.8315 - val_loss: 0.7806 - val_accuracy: 0.7484\n",
      "Epoch 168/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.8325\n",
      "Epoch 168: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4922 - accuracy: 0.8325 - val_loss: 0.7779 - val_accuracy: 0.7526\n",
      "Epoch 169/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4820 - accuracy: 0.8305\n",
      "Epoch 169: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.8310 - val_loss: 0.7881 - val_accuracy: 0.7547\n",
      "Epoch 170/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4786 - accuracy: 0.8438\n",
      "Epoch 170: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4811 - accuracy: 0.8388 - val_loss: 0.7900 - val_accuracy: 0.7463\n",
      "Epoch 171/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.8362\n",
      "Epoch 171: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4742 - accuracy: 0.8362 - val_loss: 0.7882 - val_accuracy: 0.7505\n",
      "Epoch 172/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4743 - accuracy: 0.8339\n",
      "Epoch 172: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4739 - accuracy: 0.8341 - val_loss: 0.7940 - val_accuracy: 0.7526\n",
      "Epoch 173/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4750 - accuracy: 0.8279\n",
      "Epoch 173: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4773 - accuracy: 0.8273 - val_loss: 0.7976 - val_accuracy: 0.7484\n",
      "Epoch 174/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4729 - accuracy: 0.8392\n",
      "Epoch 174: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.8388 - val_loss: 0.7937 - val_accuracy: 0.7526\n",
      "Epoch 175/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.8336\n",
      "Epoch 175: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.8336 - val_loss: 0.7902 - val_accuracy: 0.7526\n",
      "Epoch 176/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.4777 - accuracy: 0.8386\n",
      "Epoch 176: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4753 - accuracy: 0.8388 - val_loss: 0.7921 - val_accuracy: 0.7484\n",
      "Epoch 177/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.4702 - accuracy: 0.8379\n",
      "Epoch 177: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4737 - accuracy: 0.8352 - val_loss: 0.7887 - val_accuracy: 0.7463\n",
      "Epoch 178/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4708 - accuracy: 0.8427\n",
      "Epoch 178: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4705 - accuracy: 0.8415 - val_loss: 0.7903 - val_accuracy: 0.7463\n",
      "Epoch 179/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4698 - accuracy: 0.8440\n",
      "Epoch 179: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.8441 - val_loss: 0.7935 - val_accuracy: 0.7484\n",
      "Epoch 180/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4679 - accuracy: 0.8368\n",
      "Epoch 180: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.8373 - val_loss: 0.8004 - val_accuracy: 0.7484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4473 - accuracy: 0.8511\n",
      "Epoch 181: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.8509 - val_loss: 0.8064 - val_accuracy: 0.7505\n",
      "Epoch 182/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4496 - accuracy: 0.8496\n",
      "Epoch 182: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.8509 - val_loss: 0.8112 - val_accuracy: 0.7505\n",
      "Epoch 183/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4525 - accuracy: 0.8432\n",
      "Epoch 183: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.8436 - val_loss: 0.8139 - val_accuracy: 0.7463\n",
      "Epoch 184/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.8514\n",
      "Epoch 184: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8514 - val_loss: 0.8164 - val_accuracy: 0.7400\n",
      "Epoch 185/200\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.4522 - accuracy: 0.8589\n",
      "Epoch 185: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8630 - val_loss: 0.8190 - val_accuracy: 0.7421\n",
      "Epoch 186/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4392 - accuracy: 0.8455\n",
      "Epoch 186: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8420 - val_loss: 0.8195 - val_accuracy: 0.7484\n",
      "Epoch 187/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.8525\n",
      "Epoch 187: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.8525 - val_loss: 0.8157 - val_accuracy: 0.7400\n",
      "Epoch 188/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4528 - accuracy: 0.8449\n",
      "Epoch 188: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.8446 - val_loss: 0.8158 - val_accuracy: 0.7379\n",
      "Epoch 189/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4467 - accuracy: 0.8561\n",
      "Epoch 189: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.8562 - val_loss: 0.8135 - val_accuracy: 0.7400\n",
      "Epoch 190/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4520 - accuracy: 0.8498\n",
      "Epoch 190: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.8499 - val_loss: 0.8151 - val_accuracy: 0.7358\n",
      "Epoch 191/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4414 - accuracy: 0.8574\n",
      "Epoch 191: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.8551 - val_loss: 0.8228 - val_accuracy: 0.7379\n",
      "Epoch 192/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.8472\n",
      "Epoch 192: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8472 - val_loss: 0.8216 - val_accuracy: 0.7400\n",
      "Epoch 193/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4340 - accuracy: 0.8591\n",
      "Epoch 193: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8604 - val_loss: 0.8327 - val_accuracy: 0.7400\n",
      "Epoch 194/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4363 - accuracy: 0.8563\n",
      "Epoch 194: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8562 - val_loss: 0.8270 - val_accuracy: 0.7421\n",
      "Epoch 195/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4231 - accuracy: 0.8627\n",
      "Epoch 195: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8598 - val_loss: 0.8281 - val_accuracy: 0.7463\n",
      "Epoch 196/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4268 - accuracy: 0.8594\n",
      "Epoch 196: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8609 - val_loss: 0.8401 - val_accuracy: 0.7463\n",
      "Epoch 197/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4438 - accuracy: 0.8519\n",
      "Epoch 197: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8509 - val_loss: 0.8378 - val_accuracy: 0.7442\n",
      "Epoch 198/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4345 - accuracy: 0.8547\n",
      "Epoch 198: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8562 - val_loss: 0.8425 - val_accuracy: 0.7379\n",
      "Epoch 199/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.4272 - accuracy: 0.8578\n",
      "Epoch 199: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8567 - val_loss: 0.8426 - val_accuracy: 0.7421\n",
      "Epoch 200/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4295 - accuracy: 0.8634\n",
      "Epoch 200: val_loss did not improve from 0.72263\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8604 - val_loss: 0.8347 - val_accuracy: 0.7505\n",
      "\n",
      "Train/Test model on Fold #2.\n",
      "Epoch 1/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 1.0292 - accuracy: 0.5189\n",
      "Epoch 1: val_loss improved from inf to 0.97536, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0312 - accuracy: 0.5163 - val_loss: 0.9754 - val_accuracy: 0.5021\n",
      "Epoch 2/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 1.0206 - accuracy: 0.4920\n",
      "Epoch 2: val_loss improved from 0.97536 to 0.96715, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0181 - accuracy: 0.4984 - val_loss: 0.9672 - val_accuracy: 0.5231\n",
      "Epoch 3/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 1.0040 - accuracy: 0.5179\n",
      "Epoch 3: val_loss improved from 0.96715 to 0.96096, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0044 - accuracy: 0.5178 - val_loss: 0.9610 - val_accuracy: 0.5483\n",
      "Epoch 4/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.9935 - accuracy: 0.5292\n",
      "Epoch 4: val_loss improved from 0.96096 to 0.95596, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9934 - accuracy: 0.5268 - val_loss: 0.9560 - val_accuracy: 0.5588\n",
      "Epoch 5/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.9810 - accuracy: 0.5447\n",
      "Epoch 5: val_loss improved from 0.95596 to 0.95104, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9813 - accuracy: 0.5451 - val_loss: 0.9510 - val_accuracy: 0.5714\n",
      "Epoch 6/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.9752 - accuracy: 0.5480\n",
      "Epoch 6: val_loss improved from 0.95104 to 0.94581, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9756 - accuracy: 0.5483 - val_loss: 0.9458 - val_accuracy: 0.6092\n",
      "Epoch 7/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.9717 - accuracy: 0.5411\n",
      "Epoch 7: val_loss improved from 0.94581 to 0.94169, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9705 - accuracy: 0.5378 - val_loss: 0.9417 - val_accuracy: 0.6218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.9646 - accuracy: 0.5485\n",
      "Epoch 8: val_loss improved from 0.94169 to 0.93555, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9668 - accuracy: 0.5462 - val_loss: 0.9356 - val_accuracy: 0.6387\n",
      "Epoch 9/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.9579 - accuracy: 0.5515\n",
      "Epoch 9: val_loss improved from 0.93555 to 0.92985, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9582 - accuracy: 0.5498 - val_loss: 0.9299 - val_accuracy: 0.6450\n",
      "Epoch 10/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.9426 - accuracy: 0.5636\n",
      "Epoch 10: val_loss improved from 0.92985 to 0.92461, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9456 - accuracy: 0.5588 - val_loss: 0.9246 - val_accuracy: 0.6576\n",
      "Epoch 11/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.9353 - accuracy: 0.5909\n",
      "Epoch 11: val_loss improved from 0.92461 to 0.91832, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9354 - accuracy: 0.5897 - val_loss: 0.9183 - val_accuracy: 0.6513\n",
      "Epoch 12/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.9318 - accuracy: 0.5808\n",
      "Epoch 12: val_loss improved from 0.91832 to 0.91123, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9314 - accuracy: 0.5797 - val_loss: 0.9112 - val_accuracy: 0.6723\n",
      "Epoch 13/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.9338 - accuracy: 0.5789\n",
      "Epoch 13: val_loss improved from 0.91123 to 0.90471, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9336 - accuracy: 0.5787 - val_loss: 0.9047 - val_accuracy: 0.6786\n",
      "Epoch 14/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9175 - accuracy: 0.5986\n",
      "Epoch 14: val_loss improved from 0.90471 to 0.89797, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9175 - accuracy: 0.5986 - val_loss: 0.8980 - val_accuracy: 0.6870\n",
      "Epoch 15/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.9082 - accuracy: 0.6022\n",
      "Epoch 15: val_loss improved from 0.89797 to 0.88938, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9088 - accuracy: 0.5976 - val_loss: 0.8894 - val_accuracy: 0.6870\n",
      "Epoch 16/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.9147 - accuracy: 0.5856\n",
      "Epoch 16: val_loss improved from 0.88938 to 0.88123, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9144 - accuracy: 0.5860 - val_loss: 0.8812 - val_accuracy: 0.6975\n",
      "Epoch 17/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.9042 - accuracy: 0.6049\n",
      "Epoch 17: val_loss improved from 0.88123 to 0.87251, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9047 - accuracy: 0.6044 - val_loss: 0.8725 - val_accuracy: 0.6933\n",
      "Epoch 18/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.8908 - accuracy: 0.6362\n",
      "Epoch 18: val_loss improved from 0.87251 to 0.86252, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8911 - accuracy: 0.6301 - val_loss: 0.8625 - val_accuracy: 0.7017\n",
      "Epoch 19/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8764 - accuracy: 0.6443\n",
      "Epoch 19: val_loss improved from 0.86252 to 0.85140, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8764 - accuracy: 0.6443 - val_loss: 0.8514 - val_accuracy: 0.7038\n",
      "Epoch 20/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.8685 - accuracy: 0.6399\n",
      "Epoch 20: val_loss improved from 0.85140 to 0.84131, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8728 - accuracy: 0.6375 - val_loss: 0.8413 - val_accuracy: 0.6975\n",
      "Epoch 21/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.8664 - accuracy: 0.6468\n",
      "Epoch 21: val_loss improved from 0.84131 to 0.83491, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8649 - accuracy: 0.6516 - val_loss: 0.8349 - val_accuracy: 0.7101\n",
      "Epoch 22/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.8566 - accuracy: 0.6679\n",
      "Epoch 22: val_loss improved from 0.83491 to 0.82461, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8544 - accuracy: 0.6695 - val_loss: 0.8246 - val_accuracy: 0.7059\n",
      "Epoch 23/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.8430 - accuracy: 0.6616\n",
      "Epoch 23: val_loss improved from 0.82461 to 0.81571, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8429 - accuracy: 0.6611 - val_loss: 0.8157 - val_accuracy: 0.7164\n",
      "Epoch 24/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.8516 - accuracy: 0.6615\n",
      "Epoch 24: val_loss improved from 0.81571 to 0.80912, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8511 - accuracy: 0.6626 - val_loss: 0.8091 - val_accuracy: 0.7185\n",
      "Epoch 25/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8354 - accuracy: 0.6843\n",
      "Epoch 25: val_loss improved from 0.80912 to 0.80241, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8353 - accuracy: 0.6847 - val_loss: 0.8024 - val_accuracy: 0.7164\n",
      "Epoch 26/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.8327 - accuracy: 0.6721\n",
      "Epoch 26: val_loss improved from 0.80241 to 0.79700, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8323 - accuracy: 0.6716 - val_loss: 0.7970 - val_accuracy: 0.7164\n",
      "Epoch 27/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8131 - accuracy: 0.7054\n",
      "Epoch 27: val_loss improved from 0.79700 to 0.79121, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8129 - accuracy: 0.7051 - val_loss: 0.7912 - val_accuracy: 0.7206\n",
      "Epoch 28/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8133 - accuracy: 0.7067\n",
      "Epoch 28: val_loss improved from 0.79121 to 0.78631, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8133 - accuracy: 0.7067 - val_loss: 0.7863 - val_accuracy: 0.7227\n",
      "Epoch 29/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.8103 - accuracy: 0.7221\n",
      "Epoch 29: val_loss improved from 0.78631 to 0.78180, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8126 - accuracy: 0.7183 - val_loss: 0.7818 - val_accuracy: 0.7206\n",
      "Epoch 30/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.8128 - accuracy: 0.7124\n",
      "Epoch 30: val_loss improved from 0.78180 to 0.77747, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8113 - accuracy: 0.7093 - val_loss: 0.7775 - val_accuracy: 0.7206\n",
      "Epoch 31/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.7927 - accuracy: 0.7220\n",
      "Epoch 31: val_loss improved from 0.77747 to 0.77321, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7932 - accuracy: 0.7204 - val_loss: 0.7732 - val_accuracy: 0.7164\n",
      "Epoch 32/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.8035 - accuracy: 0.7190\n",
      "Epoch 32: val_loss improved from 0.77321 to 0.76991, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8036 - accuracy: 0.7177 - val_loss: 0.7699 - val_accuracy: 0.7206\n",
      "Epoch 33/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7848 - accuracy: 0.7264\n",
      "Epoch 33: val_loss improved from 0.76991 to 0.76574, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7860 - accuracy: 0.7261 - val_loss: 0.7657 - val_accuracy: 0.7206\n",
      "Epoch 34/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7821 - accuracy: 0.7356\n",
      "Epoch 34: val_loss improved from 0.76574 to 0.76225, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7821 - accuracy: 0.7356 - val_loss: 0.7622 - val_accuracy: 0.7185\n",
      "Epoch 35/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7746 - accuracy: 0.7188\n",
      "Epoch 35: val_loss improved from 0.76225 to 0.75868, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7752 - accuracy: 0.7188 - val_loss: 0.7587 - val_accuracy: 0.7227\n",
      "Epoch 36/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.7626 - accuracy: 0.7334\n",
      "Epoch 36: val_loss improved from 0.75868 to 0.75599, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7634 - accuracy: 0.7308 - val_loss: 0.7560 - val_accuracy: 0.7248\n",
      "Epoch 37/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7570 - accuracy: 0.7399\n",
      "Epoch 37: val_loss improved from 0.75599 to 0.75268, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7570 - accuracy: 0.7387 - val_loss: 0.7527 - val_accuracy: 0.7269\n",
      "Epoch 38/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.7743 - accuracy: 0.7266\n",
      "Epoch 38: val_loss improved from 0.75268 to 0.75019, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7700 - accuracy: 0.7314 - val_loss: 0.7502 - val_accuracy: 0.7248\n",
      "Epoch 39/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.7521 - accuracy: 0.7296\n",
      "Epoch 39: val_loss improved from 0.75019 to 0.74843, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7542 - accuracy: 0.7335 - val_loss: 0.7484 - val_accuracy: 0.7269\n",
      "Epoch 40/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.7614 - accuracy: 0.7361\n",
      "Epoch 40: val_loss improved from 0.74843 to 0.74636, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7591 - accuracy: 0.7387 - val_loss: 0.7464 - val_accuracy: 0.7290\n",
      "Epoch 41/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.7548 - accuracy: 0.7362\n",
      "Epoch 41: val_loss improved from 0.74636 to 0.74395, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7536 - accuracy: 0.7403 - val_loss: 0.7439 - val_accuracy: 0.7269\n",
      "Epoch 42/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.7496 - accuracy: 0.7477\n",
      "Epoch 42: val_loss improved from 0.74395 to 0.74185, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7486 - accuracy: 0.7476 - val_loss: 0.7418 - val_accuracy: 0.7290\n",
      "Epoch 43/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.7351 - accuracy: 0.7443\n",
      "Epoch 43: val_loss improved from 0.74185 to 0.73995, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7333 - accuracy: 0.7455 - val_loss: 0.7400 - val_accuracy: 0.7332\n",
      "Epoch 44/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7305 - accuracy: 0.7566\n",
      "Epoch 44: val_loss improved from 0.73995 to 0.73749, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7305 - accuracy: 0.7566 - val_loss: 0.7375 - val_accuracy: 0.7311\n",
      "Epoch 45/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.7323 - accuracy: 0.7494\n",
      "Epoch 45: val_loss improved from 0.73749 to 0.73723, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7322 - accuracy: 0.7497 - val_loss: 0.7372 - val_accuracy: 0.7290\n",
      "Epoch 46/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.7195 - accuracy: 0.7529\n",
      "Epoch 46: val_loss improved from 0.73723 to 0.73540, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7188 - accuracy: 0.7534 - val_loss: 0.7354 - val_accuracy: 0.7353\n",
      "Epoch 47/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7333 - accuracy: 0.7575\n",
      "Epoch 47: val_loss improved from 0.73540 to 0.73368, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7329 - accuracy: 0.7576 - val_loss: 0.7337 - val_accuracy: 0.7374\n",
      "Epoch 48/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7122 - accuracy: 0.7555\n",
      "Epoch 48: val_loss improved from 0.73368 to 0.73211, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7122 - accuracy: 0.7555 - val_loss: 0.7321 - val_accuracy: 0.7353\n",
      "Epoch 49/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.7147 - accuracy: 0.7517\n",
      "Epoch 49: val_loss improved from 0.73211 to 0.73010, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7167 - accuracy: 0.7487 - val_loss: 0.7301 - val_accuracy: 0.7374\n",
      "Epoch 50/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.7062 - accuracy: 0.7635\n",
      "Epoch 50: val_loss improved from 0.73010 to 0.72884, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.7623 - val_loss: 0.7288 - val_accuracy: 0.7353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.7144 - accuracy: 0.7556\n",
      "Epoch 51: val_loss improved from 0.72884 to 0.72844, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7141 - accuracy: 0.7587 - val_loss: 0.7284 - val_accuracy: 0.7374\n",
      "Epoch 52/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.7103 - accuracy: 0.7528\n",
      "Epoch 52: val_loss improved from 0.72844 to 0.72752, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7116 - accuracy: 0.7534 - val_loss: 0.7275 - val_accuracy: 0.7353\n",
      "Epoch 53/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.7145 - accuracy: 0.7477\n",
      "Epoch 53: val_loss improved from 0.72752 to 0.72612, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7136 - accuracy: 0.7503 - val_loss: 0.7261 - val_accuracy: 0.7374\n",
      "Epoch 54/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.7000 - accuracy: 0.7630\n",
      "Epoch 54: val_loss improved from 0.72612 to 0.72493, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7045 - accuracy: 0.7592 - val_loss: 0.7249 - val_accuracy: 0.7374\n",
      "Epoch 55/200\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.6958 - accuracy: 0.7560\n",
      "Epoch 55: val_loss improved from 0.72493 to 0.72375, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6964 - accuracy: 0.7571 - val_loss: 0.7237 - val_accuracy: 0.7416\n",
      "Epoch 56/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.7067 - accuracy: 0.7644\n",
      "Epoch 56: val_loss improved from 0.72375 to 0.72273, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7087 - accuracy: 0.7634 - val_loss: 0.7227 - val_accuracy: 0.7479\n",
      "Epoch 57/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.7749\n",
      "Epoch 57: val_loss improved from 0.72273 to 0.72228, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6890 - accuracy: 0.7749 - val_loss: 0.7223 - val_accuracy: 0.7353\n",
      "Epoch 58/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.6936 - accuracy: 0.7675\n",
      "Epoch 58: val_loss improved from 0.72228 to 0.72188, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6930 - accuracy: 0.7681 - val_loss: 0.7219 - val_accuracy: 0.7416\n",
      "Epoch 59/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.6892 - accuracy: 0.7563\n",
      "Epoch 59: val_loss improved from 0.72188 to 0.72061, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6871 - accuracy: 0.7592 - val_loss: 0.7206 - val_accuracy: 0.7395\n",
      "Epoch 60/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6890 - accuracy: 0.7543\n",
      "Epoch 60: val_loss improved from 0.72061 to 0.72014, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6889 - accuracy: 0.7508 - val_loss: 0.7201 - val_accuracy: 0.7353\n",
      "Epoch 61/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.6830 - accuracy: 0.7653\n",
      "Epoch 61: val_loss improved from 0.72014 to 0.71910, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6811 - accuracy: 0.7671 - val_loss: 0.7191 - val_accuracy: 0.7332\n",
      "Epoch 62/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6840 - accuracy: 0.7658\n",
      "Epoch 62: val_loss improved from 0.71910 to 0.71811, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6850 - accuracy: 0.7602 - val_loss: 0.7181 - val_accuracy: 0.7353\n",
      "Epoch 63/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.6746 - accuracy: 0.7736\n",
      "Epoch 63: val_loss improved from 0.71811 to 0.71701, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6751 - accuracy: 0.7707 - val_loss: 0.7170 - val_accuracy: 0.7353\n",
      "Epoch 64/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6717 - accuracy: 0.7716\n",
      "Epoch 64: val_loss improved from 0.71701 to 0.71619, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6695 - accuracy: 0.7718 - val_loss: 0.7162 - val_accuracy: 0.7374\n",
      "Epoch 65/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6668 - accuracy: 0.7815\n",
      "Epoch 65: val_loss improved from 0.71619 to 0.71554, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6669 - accuracy: 0.7802 - val_loss: 0.7155 - val_accuracy: 0.7332\n",
      "Epoch 66/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6751 - accuracy: 0.7765\n",
      "Epoch 66: val_loss improved from 0.71554 to 0.71513, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6744 - accuracy: 0.7770 - val_loss: 0.7151 - val_accuracy: 0.7353\n",
      "Epoch 67/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6728 - accuracy: 0.7880\n",
      "Epoch 67: val_loss improved from 0.71513 to 0.71359, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6728 - accuracy: 0.7880 - val_loss: 0.7136 - val_accuracy: 0.7353\n",
      "Epoch 68/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.6602 - accuracy: 0.7754\n",
      "Epoch 68: val_loss did not improve from 0.71359\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.7739 - val_loss: 0.7140 - val_accuracy: 0.7332\n",
      "Epoch 69/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.6680 - accuracy: 0.7761\n",
      "Epoch 69: val_loss improved from 0.71359 to 0.71186, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6648 - accuracy: 0.7754 - val_loss: 0.7119 - val_accuracy: 0.7290\n",
      "Epoch 70/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.6500 - accuracy: 0.7922\n",
      "Epoch 70: val_loss did not improve from 0.71186\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.7922 - val_loss: 0.7124 - val_accuracy: 0.7332\n",
      "Epoch 71/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6524 - accuracy: 0.7833\n",
      "Epoch 71: val_loss did not improve from 0.71186\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.7833 - val_loss: 0.7123 - val_accuracy: 0.7332\n",
      "Epoch 72/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.6585 - accuracy: 0.7769\n",
      "Epoch 72: val_loss improved from 0.71186 to 0.71033, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6571 - accuracy: 0.7786 - val_loss: 0.7103 - val_accuracy: 0.7332\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6458 - accuracy: 0.7856\n",
      "Epoch 73: val_loss improved from 0.71033 to 0.70980, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6446 - accuracy: 0.7838 - val_loss: 0.7098 - val_accuracy: 0.7269\n",
      "Epoch 74/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.6516 - accuracy: 0.7782\n",
      "Epoch 74: val_loss improved from 0.70980 to 0.70932, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6521 - accuracy: 0.7786 - val_loss: 0.7093 - val_accuracy: 0.7269\n",
      "Epoch 75/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.6570 - accuracy: 0.7695\n",
      "Epoch 75: val_loss improved from 0.70932 to 0.70792, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.7707 - val_loss: 0.7079 - val_accuracy: 0.7290\n",
      "Epoch 76/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6443 - accuracy: 0.7924\n",
      "Epoch 76: val_loss improved from 0.70792 to 0.70739, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6471 - accuracy: 0.7907 - val_loss: 0.7074 - val_accuracy: 0.7311\n",
      "Epoch 77/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6454 - accuracy: 0.7874\n",
      "Epoch 77: val_loss improved from 0.70739 to 0.70553, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6500 - accuracy: 0.7849 - val_loss: 0.7055 - val_accuracy: 0.7332\n",
      "Epoch 78/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6401 - accuracy: 0.7755\n",
      "Epoch 78: val_loss did not improve from 0.70553\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6430 - accuracy: 0.7749 - val_loss: 0.7065 - val_accuracy: 0.7332\n",
      "Epoch 79/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.6316 - accuracy: 0.7963\n",
      "Epoch 79: val_loss did not improve from 0.70553\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.7959 - val_loss: 0.7059 - val_accuracy: 0.7332\n",
      "Epoch 80/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6352 - accuracy: 0.7856\n",
      "Epoch 80: val_loss improved from 0.70553 to 0.70546, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6339 - accuracy: 0.7875 - val_loss: 0.7055 - val_accuracy: 0.7332\n",
      "Epoch 81/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6411 - accuracy: 0.7769\n",
      "Epoch 81: val_loss improved from 0.70546 to 0.70529, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6431 - accuracy: 0.7760 - val_loss: 0.7053 - val_accuracy: 0.7311\n",
      "Epoch 82/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.6248 - accuracy: 0.7894\n",
      "Epoch 82: val_loss did not improve from 0.70529\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.7938 - val_loss: 0.7061 - val_accuracy: 0.7311\n",
      "Epoch 83/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.6375 - accuracy: 0.7705\n",
      "Epoch 83: val_loss improved from 0.70529 to 0.70457, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6362 - accuracy: 0.7739 - val_loss: 0.7046 - val_accuracy: 0.7353\n",
      "Epoch 84/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6292 - accuracy: 0.7786\n",
      "Epoch 84: val_loss improved from 0.70457 to 0.70387, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6357 - accuracy: 0.7796 - val_loss: 0.7039 - val_accuracy: 0.7353\n",
      "Epoch 85/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6281 - accuracy: 0.7906\n",
      "Epoch 85: val_loss improved from 0.70387 to 0.70323, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6271 - accuracy: 0.7912 - val_loss: 0.7032 - val_accuracy: 0.7353\n",
      "Epoch 86/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6278 - accuracy: 0.7883\n",
      "Epoch 86: val_loss improved from 0.70323 to 0.70249, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6276 - accuracy: 0.7886 - val_loss: 0.7025 - val_accuracy: 0.7353\n",
      "Epoch 87/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6218 - accuracy: 0.7853\n",
      "Epoch 87: val_loss improved from 0.70249 to 0.70225, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold2.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6246 - accuracy: 0.7849 - val_loss: 0.7023 - val_accuracy: 0.7332\n",
      "Epoch 88/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.7886\n",
      "Epoch 88: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.7886 - val_loss: 0.7024 - val_accuracy: 0.7332\n",
      "Epoch 89/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6235 - accuracy: 0.7896\n",
      "Epoch 89: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.7891 - val_loss: 0.7023 - val_accuracy: 0.7353\n",
      "Epoch 90/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.6105 - accuracy: 0.7879\n",
      "Epoch 90: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.7849 - val_loss: 0.7028 - val_accuracy: 0.7353\n",
      "Epoch 91/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.6010 - accuracy: 0.8066\n",
      "Epoch 91: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.8075 - val_loss: 0.7041 - val_accuracy: 0.7353\n",
      "Epoch 92/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.6108 - accuracy: 0.7995\n",
      "Epoch 92: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.7964 - val_loss: 0.7045 - val_accuracy: 0.7353\n",
      "Epoch 93/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6047 - accuracy: 0.7863\n",
      "Epoch 93: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6051 - accuracy: 0.7849 - val_loss: 0.7050 - val_accuracy: 0.7395\n",
      "Epoch 94/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.6150 - accuracy: 0.7821\n",
      "Epoch 94: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.7896 - val_loss: 0.7055 - val_accuracy: 0.7395\n",
      "Epoch 95/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.6005 - accuracy: 0.7896\n",
      "Epoch 95: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6044 - accuracy: 0.7886 - val_loss: 0.7080 - val_accuracy: 0.7353\n",
      "Epoch 96/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6067 - accuracy: 0.7826\n",
      "Epoch 96: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6067 - accuracy: 0.7823 - val_loss: 0.7062 - val_accuracy: 0.7395\n",
      "Epoch 97/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6021 - accuracy: 0.7913\n",
      "Epoch 97: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6039 - accuracy: 0.7901 - val_loss: 0.7067 - val_accuracy: 0.7395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6077 - accuracy: 0.7931\n",
      "Epoch 98: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6022 - accuracy: 0.7964 - val_loss: 0.7054 - val_accuracy: 0.7374\n",
      "Epoch 99/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5993 - accuracy: 0.7871\n",
      "Epoch 99: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.7901 - val_loss: 0.7066 - val_accuracy: 0.7395\n",
      "Epoch 100/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5873 - accuracy: 0.7963\n",
      "Epoch 100: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5892 - accuracy: 0.7985 - val_loss: 0.7069 - val_accuracy: 0.7395\n",
      "Epoch 101/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5856 - accuracy: 0.7967\n",
      "Epoch 101: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5871 - accuracy: 0.7964 - val_loss: 0.7077 - val_accuracy: 0.7395\n",
      "Epoch 102/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6004 - accuracy: 0.7893\n",
      "Epoch 102: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5982 - accuracy: 0.7912 - val_loss: 0.7076 - val_accuracy: 0.7374\n",
      "Epoch 103/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5875 - accuracy: 0.7951\n",
      "Epoch 103: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7980 - val_loss: 0.7078 - val_accuracy: 0.7374\n",
      "Epoch 104/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5765 - accuracy: 0.7948\n",
      "Epoch 104: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.7886 - val_loss: 0.7090 - val_accuracy: 0.7353\n",
      "Epoch 105/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5752 - accuracy: 0.7940\n",
      "Epoch 105: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7959 - val_loss: 0.7122 - val_accuracy: 0.7332\n",
      "Epoch 106/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5824 - accuracy: 0.7880\n",
      "Epoch 106: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.7880 - val_loss: 0.7115 - val_accuracy: 0.7416\n",
      "Epoch 107/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5888 - accuracy: 0.7925\n",
      "Epoch 107: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.7896 - val_loss: 0.7111 - val_accuracy: 0.7395\n",
      "Epoch 108/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5807 - accuracy: 0.7888\n",
      "Epoch 108: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7949 - val_loss: 0.7127 - val_accuracy: 0.7416\n",
      "Epoch 109/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.5700 - accuracy: 0.8043\n",
      "Epoch 109: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.8022 - val_loss: 0.7146 - val_accuracy: 0.7353\n",
      "Epoch 110/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5694 - accuracy: 0.7951\n",
      "Epoch 110: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5677 - accuracy: 0.7943 - val_loss: 0.7167 - val_accuracy: 0.7353\n",
      "Epoch 111/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5838 - accuracy: 0.7907\n",
      "Epoch 111: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.7907 - val_loss: 0.7170 - val_accuracy: 0.7353\n",
      "Epoch 112/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.5710 - accuracy: 0.7967\n",
      "Epoch 112: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5725 - accuracy: 0.7980 - val_loss: 0.7148 - val_accuracy: 0.7395\n",
      "Epoch 113/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.7922\n",
      "Epoch 113: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5674 - accuracy: 0.7928 - val_loss: 0.7167 - val_accuracy: 0.7395\n",
      "Epoch 114/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5661 - accuracy: 0.7943\n",
      "Epoch 114: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.5661 - accuracy: 0.7949 - val_loss: 0.7173 - val_accuracy: 0.7395\n",
      "Epoch 115/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5763 - accuracy: 0.8021\n",
      "Epoch 115: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5821 - accuracy: 0.7996 - val_loss: 0.7161 - val_accuracy: 0.7416\n",
      "Epoch 116/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5627 - accuracy: 0.7947\n",
      "Epoch 116: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5632 - accuracy: 0.7928 - val_loss: 0.7163 - val_accuracy: 0.7395\n",
      "Epoch 117/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.5561 - accuracy: 0.8035\n",
      "Epoch 117: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5557 - accuracy: 0.8027 - val_loss: 0.7186 - val_accuracy: 0.7437\n",
      "Epoch 118/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5615 - accuracy: 0.8153\n",
      "Epoch 118: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5610 - accuracy: 0.8122 - val_loss: 0.7195 - val_accuracy: 0.7437\n",
      "Epoch 119/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5591 - accuracy: 0.8020\n",
      "Epoch 119: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5592 - accuracy: 0.8022 - val_loss: 0.7201 - val_accuracy: 0.7395\n",
      "Epoch 120/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5556 - accuracy: 0.8142\n",
      "Epoch 120: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5618 - accuracy: 0.8111 - val_loss: 0.7215 - val_accuracy: 0.7374\n",
      "Epoch 121/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.8069\n",
      "Epoch 121: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5549 - accuracy: 0.8069 - val_loss: 0.7219 - val_accuracy: 0.7332\n",
      "Epoch 122/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5578 - accuracy: 0.8086\n",
      "Epoch 122: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5554 - accuracy: 0.8090 - val_loss: 0.7194 - val_accuracy: 0.7311\n",
      "Epoch 123/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5576 - accuracy: 0.8072\n",
      "Epoch 123: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5599 - accuracy: 0.8080 - val_loss: 0.7233 - val_accuracy: 0.7269\n",
      "Epoch 124/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.5605 - accuracy: 0.7956\n",
      "Epoch 124: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.7985 - val_loss: 0.7251 - val_accuracy: 0.7332\n",
      "Epoch 125/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5531 - accuracy: 0.8196\n",
      "Epoch 125: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.8169 - val_loss: 0.7280 - val_accuracy: 0.7395\n",
      "Epoch 126/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5642 - accuracy: 0.8040\n",
      "Epoch 126: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5637 - accuracy: 0.8054 - val_loss: 0.7258 - val_accuracy: 0.7353\n",
      "Epoch 127/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5476 - accuracy: 0.8097\n",
      "Epoch 127: val_loss did not improve from 0.70225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5489 - accuracy: 0.8090 - val_loss: 0.7259 - val_accuracy: 0.7374\n",
      "Epoch 128/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5364 - accuracy: 0.8098\n",
      "Epoch 128: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5419 - accuracy: 0.8085 - val_loss: 0.7271 - val_accuracy: 0.7395\n",
      "Epoch 129/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5345 - accuracy: 0.8130\n",
      "Epoch 129: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5347 - accuracy: 0.8132 - val_loss: 0.7281 - val_accuracy: 0.7395\n",
      "Epoch 130/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.8103\n",
      "Epoch 130: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5480 - accuracy: 0.8106 - val_loss: 0.7274 - val_accuracy: 0.7437\n",
      "Epoch 131/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5295 - accuracy: 0.8172\n",
      "Epoch 131: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5291 - accuracy: 0.8174 - val_loss: 0.7337 - val_accuracy: 0.7395\n",
      "Epoch 132/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5357 - accuracy: 0.8209\n",
      "Epoch 132: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5367 - accuracy: 0.8211 - val_loss: 0.7366 - val_accuracy: 0.7395\n",
      "Epoch 133/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5290 - accuracy: 0.8097\n",
      "Epoch 133: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5349 - accuracy: 0.8101 - val_loss: 0.7357 - val_accuracy: 0.7374\n",
      "Epoch 134/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5262 - accuracy: 0.8162\n",
      "Epoch 134: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5268 - accuracy: 0.8153 - val_loss: 0.7374 - val_accuracy: 0.7374\n",
      "Epoch 135/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.5385 - accuracy: 0.8080\n",
      "Epoch 135: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5374 - accuracy: 0.8090 - val_loss: 0.7358 - val_accuracy: 0.7374\n",
      "Epoch 136/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5244 - accuracy: 0.8210\n",
      "Epoch 136: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5235 - accuracy: 0.8200 - val_loss: 0.7420 - val_accuracy: 0.7353\n",
      "Epoch 137/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.5361 - accuracy: 0.8114\n",
      "Epoch 137: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.8158 - val_loss: 0.7406 - val_accuracy: 0.7332\n",
      "Epoch 138/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5316 - accuracy: 0.8113\n",
      "Epoch 138: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.8111 - val_loss: 0.7439 - val_accuracy: 0.7311\n",
      "Epoch 139/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.8069\n",
      "Epoch 139: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.8069 - val_loss: 0.7450 - val_accuracy: 0.7332\n",
      "Epoch 140/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5172 - accuracy: 0.8054\n",
      "Epoch 140: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5223 - accuracy: 0.8075 - val_loss: 0.7422 - val_accuracy: 0.7353\n",
      "Epoch 141/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.5167 - accuracy: 0.8265\n",
      "Epoch 141: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.8248 - val_loss: 0.7455 - val_accuracy: 0.7332\n",
      "Epoch 142/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5164 - accuracy: 0.8147\n",
      "Epoch 142: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5186 - accuracy: 0.8143 - val_loss: 0.7474 - val_accuracy: 0.7311\n",
      "Epoch 143/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5272 - accuracy: 0.8185\n",
      "Epoch 143: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5279 - accuracy: 0.8158 - val_loss: 0.7474 - val_accuracy: 0.7332\n",
      "Epoch 144/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.8237\n",
      "Epoch 144: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5088 - accuracy: 0.8237 - val_loss: 0.7502 - val_accuracy: 0.7332\n",
      "Epoch 145/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5174 - accuracy: 0.8195\n",
      "Epoch 145: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5181 - accuracy: 0.8190 - val_loss: 0.7532 - val_accuracy: 0.7311\n",
      "Epoch 146/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5193 - accuracy: 0.8181\n",
      "Epoch 146: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5209 - accuracy: 0.8137 - val_loss: 0.7494 - val_accuracy: 0.7311\n",
      "Epoch 147/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5003 - accuracy: 0.8291\n",
      "Epoch 147: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5009 - accuracy: 0.8269 - val_loss: 0.7530 - val_accuracy: 0.7290\n",
      "Epoch 148/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5008 - accuracy: 0.8290\n",
      "Epoch 148: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.8290 - val_loss: 0.7546 - val_accuracy: 0.7311\n",
      "Epoch 149/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5177 - accuracy: 0.8146\n",
      "Epoch 149: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.8148 - val_loss: 0.7565 - val_accuracy: 0.7311\n",
      "Epoch 150/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5155 - accuracy: 0.8300\n",
      "Epoch 150: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5151 - accuracy: 0.8316 - val_loss: 0.7540 - val_accuracy: 0.7311\n",
      "Epoch 151/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5088 - accuracy: 0.8303\n",
      "Epoch 151: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5103 - accuracy: 0.8274 - val_loss: 0.7560 - val_accuracy: 0.7269\n",
      "Epoch 152/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.4943 - accuracy: 0.8321\n",
      "Epoch 152: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4937 - accuracy: 0.8342 - val_loss: 0.7639 - val_accuracy: 0.7311\n",
      "Epoch 153/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.5020 - accuracy: 0.8226\n",
      "Epoch 153: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.8227 - val_loss: 0.7635 - val_accuracy: 0.7311\n",
      "Epoch 154/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.5028 - accuracy: 0.8252\n",
      "Epoch 154: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.8274 - val_loss: 0.7606 - val_accuracy: 0.7311\n",
      "Epoch 155/200\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.4996 - accuracy: 0.8238\n",
      "Epoch 155: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.8284 - val_loss: 0.7627 - val_accuracy: 0.7311\n",
      "Epoch 156/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4750 - accuracy: 0.8384\n",
      "Epoch 156: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4751 - accuracy: 0.8389 - val_loss: 0.7717 - val_accuracy: 0.7311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4950 - accuracy: 0.8331\n",
      "Epoch 157: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.8326 - val_loss: 0.7745 - val_accuracy: 0.7311\n",
      "Epoch 158/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4854 - accuracy: 0.8362\n",
      "Epoch 158: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.8342 - val_loss: 0.7743 - val_accuracy: 0.7332\n",
      "Epoch 159/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.5011 - accuracy: 0.8343\n",
      "Epoch 159: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.8316 - val_loss: 0.7719 - val_accuracy: 0.7332\n",
      "Epoch 160/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4835 - accuracy: 0.8429\n",
      "Epoch 160: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.8437 - val_loss: 0.7742 - val_accuracy: 0.7332\n",
      "Epoch 161/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.8400\n",
      "Epoch 161: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.8400 - val_loss: 0.7799 - val_accuracy: 0.7269\n",
      "Epoch 162/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.8405\n",
      "Epoch 162: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.8405 - val_loss: 0.7792 - val_accuracy: 0.7311\n",
      "Epoch 163/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4978 - accuracy: 0.8290\n",
      "Epoch 163: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4973 - accuracy: 0.8295 - val_loss: 0.7682 - val_accuracy: 0.7332\n",
      "Epoch 164/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.8405\n",
      "Epoch 164: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.8405 - val_loss: 0.7668 - val_accuracy: 0.7374\n",
      "Epoch 165/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.4824 - accuracy: 0.8348\n",
      "Epoch 165: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4827 - accuracy: 0.8342 - val_loss: 0.7752 - val_accuracy: 0.7416\n",
      "Epoch 166/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.4823 - accuracy: 0.8376\n",
      "Epoch 166: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.8342 - val_loss: 0.7804 - val_accuracy: 0.7353\n",
      "Epoch 167/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4721 - accuracy: 0.8356\n",
      "Epoch 167: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.8368 - val_loss: 0.7832 - val_accuracy: 0.7353\n",
      "Epoch 168/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4756 - accuracy: 0.8353\n",
      "Epoch 168: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4748 - accuracy: 0.8358 - val_loss: 0.7816 - val_accuracy: 0.7416\n",
      "Epoch 169/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.8351\n",
      "Epoch 169: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.8353 - val_loss: 0.7836 - val_accuracy: 0.7374\n",
      "Epoch 170/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.4801 - accuracy: 0.8402\n",
      "Epoch 170: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4789 - accuracy: 0.8416 - val_loss: 0.7804 - val_accuracy: 0.7290\n",
      "Epoch 171/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4713 - accuracy: 0.8536\n",
      "Epoch 171: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4759 - accuracy: 0.8526 - val_loss: 0.7799 - val_accuracy: 0.7395\n",
      "Epoch 172/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4816 - accuracy: 0.8303\n",
      "Epoch 172: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4819 - accuracy: 0.8305 - val_loss: 0.7779 - val_accuracy: 0.7395\n",
      "Epoch 173/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4840 - accuracy: 0.8351\n",
      "Epoch 173: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.8342 - val_loss: 0.7775 - val_accuracy: 0.7416\n",
      "Epoch 174/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4664 - accuracy: 0.8491\n",
      "Epoch 174: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4658 - accuracy: 0.8489 - val_loss: 0.7855 - val_accuracy: 0.7353\n",
      "Epoch 175/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4714 - accuracy: 0.8464\n",
      "Epoch 175: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.8520 - val_loss: 0.7877 - val_accuracy: 0.7416\n",
      "Epoch 176/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4697 - accuracy: 0.8459\n",
      "Epoch 176: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4672 - accuracy: 0.8468 - val_loss: 0.7911 - val_accuracy: 0.7311\n",
      "Epoch 177/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4614 - accuracy: 0.8470\n",
      "Epoch 177: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4632 - accuracy: 0.8431 - val_loss: 0.7896 - val_accuracy: 0.7311\n",
      "Epoch 178/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.4631 - accuracy: 0.8543\n",
      "Epoch 178: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4653 - accuracy: 0.8531 - val_loss: 0.7920 - val_accuracy: 0.7332\n",
      "Epoch 179/200\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.4711 - accuracy: 0.8460\n",
      "Epoch 179: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4683 - accuracy: 0.8478 - val_loss: 0.7965 - val_accuracy: 0.7311\n",
      "Epoch 180/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4491 - accuracy: 0.8470\n",
      "Epoch 180: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4480 - accuracy: 0.8478 - val_loss: 0.7988 - val_accuracy: 0.7374\n",
      "Epoch 181/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4539 - accuracy: 0.8503\n",
      "Epoch 181: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4534 - accuracy: 0.8499 - val_loss: 0.7961 - val_accuracy: 0.7374\n",
      "Epoch 182/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.4522 - accuracy: 0.8507\n",
      "Epoch 182: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4508 - accuracy: 0.8510 - val_loss: 0.7997 - val_accuracy: 0.7353\n",
      "Epoch 183/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4597 - accuracy: 0.8520\n",
      "Epoch 183: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4581 - accuracy: 0.8536 - val_loss: 0.7992 - val_accuracy: 0.7374\n",
      "Epoch 184/200\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.4489 - accuracy: 0.8595\n",
      "Epoch 184: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.8604 - val_loss: 0.8076 - val_accuracy: 0.7353\n",
      "Epoch 185/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4625 - accuracy: 0.8400\n",
      "Epoch 185: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.8410 - val_loss: 0.8034 - val_accuracy: 0.7395\n",
      "Epoch 186/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4428 - accuracy: 0.8587\n",
      "Epoch 186: val_loss did not improve from 0.70225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8589 - val_loss: 0.8099 - val_accuracy: 0.7353\n",
      "Epoch 187/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4483 - accuracy: 0.8542\n",
      "Epoch 187: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.8552 - val_loss: 0.8071 - val_accuracy: 0.7395\n",
      "Epoch 188/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.4466 - accuracy: 0.8481\n",
      "Epoch 188: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.8473 - val_loss: 0.8100 - val_accuracy: 0.7353\n",
      "Epoch 189/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4374 - accuracy: 0.8633\n",
      "Epoch 189: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8657 - val_loss: 0.8055 - val_accuracy: 0.7353\n",
      "Epoch 190/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4454 - accuracy: 0.8657\n",
      "Epoch 190: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8631 - val_loss: 0.8167 - val_accuracy: 0.7395\n",
      "Epoch 191/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.8568\n",
      "Epoch 191: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8568 - val_loss: 0.8091 - val_accuracy: 0.7395\n",
      "Epoch 192/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4422 - accuracy: 0.8639\n",
      "Epoch 192: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8673 - val_loss: 0.8139 - val_accuracy: 0.7395\n",
      "Epoch 193/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4316 - accuracy: 0.8610\n",
      "Epoch 193: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8615 - val_loss: 0.8135 - val_accuracy: 0.7395\n",
      "Epoch 194/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4331 - accuracy: 0.8561\n",
      "Epoch 194: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8578 - val_loss: 0.8097 - val_accuracy: 0.7416\n",
      "Epoch 195/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4287 - accuracy: 0.8652\n",
      "Epoch 195: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8652 - val_loss: 0.8127 - val_accuracy: 0.7395\n",
      "Epoch 196/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4327 - accuracy: 0.8708\n",
      "Epoch 196: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8709 - val_loss: 0.8151 - val_accuracy: 0.7374\n",
      "Epoch 197/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4338 - accuracy: 0.8567\n",
      "Epoch 197: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8594 - val_loss: 0.8163 - val_accuracy: 0.7458\n",
      "Epoch 198/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4103 - accuracy: 0.8662\n",
      "Epoch 198: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8652 - val_loss: 0.8178 - val_accuracy: 0.7437\n",
      "Epoch 199/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.4177 - accuracy: 0.8732\n",
      "Epoch 199: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8709 - val_loss: 0.8242 - val_accuracy: 0.7374\n",
      "Epoch 200/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4207 - accuracy: 0.8738\n",
      "Epoch 200: val_loss did not improve from 0.70225\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8631 - val_loss: 0.8214 - val_accuracy: 0.7395\n",
      "\n",
      "Train/Test model on Fold #3.\n",
      "Epoch 1/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 1.0937 - accuracy: 0.4855\n",
      "Epoch 1: val_loss improved from inf to 0.97708, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0920 - accuracy: 0.4874 - val_loss: 0.9771 - val_accuracy: 0.5105\n",
      "Epoch 2/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 1.0443 - accuracy: 0.5016\n",
      "Epoch 2: val_loss improved from 0.97708 to 0.96655, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0444 - accuracy: 0.5016 - val_loss: 0.9666 - val_accuracy: 0.5546\n",
      "Epoch 3/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 1.0276 - accuracy: 0.5124\n",
      "Epoch 3: val_loss improved from 0.96655 to 0.95936, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0258 - accuracy: 0.5094 - val_loss: 0.9594 - val_accuracy: 0.5798\n",
      "Epoch 4/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.0109 - accuracy: 0.5252\n",
      "Epoch 4: val_loss improved from 0.95936 to 0.95335, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0109 - accuracy: 0.5252 - val_loss: 0.9534 - val_accuracy: 0.6029\n",
      "Epoch 5/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.9965 - accuracy: 0.5318\n",
      "Epoch 5: val_loss improved from 0.95335 to 0.94895, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9940 - accuracy: 0.5357 - val_loss: 0.9490 - val_accuracy: 0.6261\n",
      "Epoch 6/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9853 - accuracy: 0.5483\n",
      "Epoch 6: val_loss improved from 0.94895 to 0.94423, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9853 - accuracy: 0.5483 - val_loss: 0.9442 - val_accuracy: 0.6450\n",
      "Epoch 7/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.9722 - accuracy: 0.5548\n",
      "Epoch 7: val_loss improved from 0.94423 to 0.94030, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9741 - accuracy: 0.5540 - val_loss: 0.9403 - val_accuracy: 0.6513\n",
      "Epoch 8/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9638 - accuracy: 0.5535\n",
      "Epoch 8: val_loss improved from 0.94030 to 0.93587, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9638 - accuracy: 0.5535 - val_loss: 0.9359 - val_accuracy: 0.6534\n",
      "Epoch 9/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.9558 - accuracy: 0.5577\n",
      "Epoch 9: val_loss improved from 0.93587 to 0.93136, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9548 - accuracy: 0.5598 - val_loss: 0.9314 - val_accuracy: 0.6618\n",
      "Epoch 10/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.9482 - accuracy: 0.5625\n",
      "Epoch 10: val_loss improved from 0.93136 to 0.92620, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9479 - accuracy: 0.5619 - val_loss: 0.9262 - val_accuracy: 0.6765\n",
      "Epoch 11/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.9340 - accuracy: 0.5927\n",
      "Epoch 11: val_loss improved from 0.92620 to 0.92040, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9346 - accuracy: 0.5902 - val_loss: 0.9204 - val_accuracy: 0.6786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.9346 - accuracy: 0.5877\n",
      "Epoch 12: val_loss improved from 0.92040 to 0.91326, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9342 - accuracy: 0.5881 - val_loss: 0.9133 - val_accuracy: 0.6828\n",
      "Epoch 13/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.9399 - accuracy: 0.5807\n",
      "Epoch 13: val_loss improved from 0.91326 to 0.90720, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9397 - accuracy: 0.5803 - val_loss: 0.9072 - val_accuracy: 0.6786\n",
      "Epoch 14/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9289 - accuracy: 0.5892\n",
      "Epoch 14: val_loss improved from 0.90720 to 0.89887, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9289 - accuracy: 0.5892 - val_loss: 0.8989 - val_accuracy: 0.6870\n",
      "Epoch 15/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.9042 - accuracy: 0.6098\n",
      "Epoch 15: val_loss improved from 0.89887 to 0.89041, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9043 - accuracy: 0.6097 - val_loss: 0.8904 - val_accuracy: 0.6975\n",
      "Epoch 16/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.9111 - accuracy: 0.6082\n",
      "Epoch 16: val_loss improved from 0.89041 to 0.88317, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9106 - accuracy: 0.6086 - val_loss: 0.8832 - val_accuracy: 0.7038\n",
      "Epoch 17/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.8934 - accuracy: 0.6279\n",
      "Epoch 17: val_loss improved from 0.88317 to 0.87349, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8938 - accuracy: 0.6280 - val_loss: 0.8735 - val_accuracy: 0.7017\n",
      "Epoch 18/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8920 - accuracy: 0.6213\n",
      "Epoch 18: val_loss improved from 0.87349 to 0.86491, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8918 - accuracy: 0.6217 - val_loss: 0.8649 - val_accuracy: 0.7143\n",
      "Epoch 19/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8673 - accuracy: 0.6570\n",
      "Epoch 19: val_loss improved from 0.86491 to 0.85473, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8674 - accuracy: 0.6569 - val_loss: 0.8547 - val_accuracy: 0.7164\n",
      "Epoch 20/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8630 - accuracy: 0.6576\n",
      "Epoch 20: val_loss improved from 0.85473 to 0.84568, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8629 - accuracy: 0.6579 - val_loss: 0.8457 - val_accuracy: 0.7038\n",
      "Epoch 21/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.8635 - accuracy: 0.6631\n",
      "Epoch 21: val_loss improved from 0.84568 to 0.83830, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8632 - accuracy: 0.6632 - val_loss: 0.8383 - val_accuracy: 0.7122\n",
      "Epoch 22/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8594 - accuracy: 0.6689\n",
      "Epoch 22: val_loss improved from 0.83830 to 0.83211, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8594 - accuracy: 0.6689 - val_loss: 0.8321 - val_accuracy: 0.7143\n",
      "Epoch 23/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.8498 - accuracy: 0.6688\n",
      "Epoch 23: val_loss improved from 0.83211 to 0.82564, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8488 - accuracy: 0.6689 - val_loss: 0.8256 - val_accuracy: 0.7185\n",
      "Epoch 24/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8406 - accuracy: 0.6817\n",
      "Epoch 24: val_loss improved from 0.82564 to 0.81998, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8404 - accuracy: 0.6815 - val_loss: 0.8200 - val_accuracy: 0.7206\n",
      "Epoch 25/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8370 - accuracy: 0.6791\n",
      "Epoch 25: val_loss improved from 0.81998 to 0.81532, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8366 - accuracy: 0.6794 - val_loss: 0.8153 - val_accuracy: 0.7185\n",
      "Epoch 26/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.8219 - accuracy: 0.7073\n",
      "Epoch 26: val_loss improved from 0.81532 to 0.80898, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8227 - accuracy: 0.7083 - val_loss: 0.8090 - val_accuracy: 0.7164\n",
      "Epoch 27/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.8236 - accuracy: 0.6975\n",
      "Epoch 27: val_loss improved from 0.80898 to 0.80441, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8234 - accuracy: 0.6978 - val_loss: 0.8044 - val_accuracy: 0.7143\n",
      "Epoch 28/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8254 - accuracy: 0.6941\n",
      "Epoch 28: val_loss improved from 0.80441 to 0.80068, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8254 - accuracy: 0.6941 - val_loss: 0.8007 - val_accuracy: 0.7206\n",
      "Epoch 29/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.8203 - accuracy: 0.6934\n",
      "Epoch 29: val_loss improved from 0.80068 to 0.79631, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8232 - accuracy: 0.6910 - val_loss: 0.7963 - val_accuracy: 0.7227\n",
      "Epoch 30/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.8030 - accuracy: 0.7044\n",
      "Epoch 30: val_loss improved from 0.79631 to 0.79342, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8028 - accuracy: 0.7046 - val_loss: 0.7934 - val_accuracy: 0.7227\n",
      "Epoch 31/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7937 - accuracy: 0.7076\n",
      "Epoch 31: val_loss improved from 0.79342 to 0.78968, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7965 - accuracy: 0.7062 - val_loss: 0.7897 - val_accuracy: 0.7227\n",
      "Epoch 32/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7908 - accuracy: 0.7073\n",
      "Epoch 32: val_loss improved from 0.78968 to 0.78679, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7936 - accuracy: 0.7057 - val_loss: 0.7868 - val_accuracy: 0.7185\n",
      "Epoch 33/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7766 - accuracy: 0.7198\n",
      "Epoch 33: val_loss improved from 0.78679 to 0.78299, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7766 - accuracy: 0.7188 - val_loss: 0.7830 - val_accuracy: 0.7164\n",
      "Epoch 34/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7895 - accuracy: 0.7206\n",
      "Epoch 34: val_loss improved from 0.78299 to 0.77915, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7893 - accuracy: 0.7209 - val_loss: 0.7792 - val_accuracy: 0.7290\n",
      "Epoch 35/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7983 - accuracy: 0.7169\n",
      "Epoch 35: val_loss improved from 0.77915 to 0.77734, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7979 - accuracy: 0.7172 - val_loss: 0.7773 - val_accuracy: 0.7227\n",
      "Epoch 36/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7777 - accuracy: 0.7279\n",
      "Epoch 36: val_loss improved from 0.77734 to 0.77527, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7757 - accuracy: 0.7288 - val_loss: 0.7753 - val_accuracy: 0.7206\n",
      "Epoch 37/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7625 - accuracy: 0.7409\n",
      "Epoch 37: val_loss improved from 0.77527 to 0.77223, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7626 - accuracy: 0.7408 - val_loss: 0.7722 - val_accuracy: 0.7227\n",
      "Epoch 38/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7688 - accuracy: 0.7188\n",
      "Epoch 38: val_loss improved from 0.77223 to 0.76961, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7710 - accuracy: 0.7183 - val_loss: 0.7696 - val_accuracy: 0.7248\n",
      "Epoch 39/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7667 - accuracy: 0.7299\n",
      "Epoch 39: val_loss improved from 0.76961 to 0.76726, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7672 - accuracy: 0.7293 - val_loss: 0.7673 - val_accuracy: 0.7227\n",
      "Epoch 40/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7644 - accuracy: 0.7318\n",
      "Epoch 40: val_loss improved from 0.76726 to 0.76494, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7653 - accuracy: 0.7298 - val_loss: 0.7649 - val_accuracy: 0.7248\n",
      "Epoch 41/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7544 - accuracy: 0.7345\n",
      "Epoch 41: val_loss improved from 0.76494 to 0.76174, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7544 - accuracy: 0.7345 - val_loss: 0.7617 - val_accuracy: 0.7248\n",
      "Epoch 42/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7465 - accuracy: 0.7434\n",
      "Epoch 42: val_loss improved from 0.76174 to 0.76075, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7465 - accuracy: 0.7434 - val_loss: 0.7608 - val_accuracy: 0.7227\n",
      "Epoch 43/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7543 - accuracy: 0.7349\n",
      "Epoch 43: val_loss improved from 0.76075 to 0.75720, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7527 - accuracy: 0.7345 - val_loss: 0.7572 - val_accuracy: 0.7185\n",
      "Epoch 44/200\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.7296 - accuracy: 0.7418\n",
      "Epoch 44: val_loss improved from 0.75720 to 0.75591, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7328 - accuracy: 0.7413 - val_loss: 0.7559 - val_accuracy: 0.7185\n",
      "Epoch 45/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7416 - accuracy: 0.7346\n",
      "Epoch 45: val_loss improved from 0.75591 to 0.75391, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7410 - accuracy: 0.7350 - val_loss: 0.7539 - val_accuracy: 0.7227\n",
      "Epoch 46/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7357 - accuracy: 0.7511\n",
      "Epoch 46: val_loss improved from 0.75391 to 0.75293, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7356 - accuracy: 0.7513 - val_loss: 0.7529 - val_accuracy: 0.7269\n",
      "Epoch 47/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7203 - accuracy: 0.7632\n",
      "Epoch 47: val_loss improved from 0.75293 to 0.75097, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7229 - accuracy: 0.7634 - val_loss: 0.7510 - val_accuracy: 0.7290\n",
      "Epoch 48/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7321 - accuracy: 0.7584\n",
      "Epoch 48: val_loss improved from 0.75097 to 0.74975, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7318 - accuracy: 0.7587 - val_loss: 0.7498 - val_accuracy: 0.7290\n",
      "Epoch 49/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7356 - accuracy: 0.7489\n",
      "Epoch 49: val_loss improved from 0.74975 to 0.74801, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7354 - accuracy: 0.7492 - val_loss: 0.7480 - val_accuracy: 0.7290\n",
      "Epoch 50/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7203 - accuracy: 0.7596\n",
      "Epoch 50: val_loss improved from 0.74801 to 0.74695, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7198 - accuracy: 0.7597 - val_loss: 0.7470 - val_accuracy: 0.7290\n",
      "Epoch 51/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7048 - accuracy: 0.7642\n",
      "Epoch 51: val_loss improved from 0.74695 to 0.74517, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7047 - accuracy: 0.7639 - val_loss: 0.7452 - val_accuracy: 0.7269\n",
      "Epoch 52/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7175 - accuracy: 0.7516\n",
      "Epoch 52: val_loss did not improve from 0.74517\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.7175 - accuracy: 0.7518 - val_loss: 0.7464 - val_accuracy: 0.7311\n",
      "Epoch 53/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7093 - accuracy: 0.7537\n",
      "Epoch 53: val_loss improved from 0.74517 to 0.74333, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7095 - accuracy: 0.7534 - val_loss: 0.7433 - val_accuracy: 0.7332\n",
      "Epoch 54/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7089 - accuracy: 0.7575\n",
      "Epoch 54: val_loss improved from 0.74333 to 0.74261, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7074 - accuracy: 0.7587 - val_loss: 0.7426 - val_accuracy: 0.7332\n",
      "Epoch 55/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7080 - accuracy: 0.7710\n",
      "Epoch 55: val_loss improved from 0.74261 to 0.74075, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7070 - accuracy: 0.7712 - val_loss: 0.7408 - val_accuracy: 0.7269\n",
      "Epoch 56/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7097 - accuracy: 0.7660\n",
      "Epoch 56: val_loss improved from 0.74075 to 0.73897, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7112 - accuracy: 0.7660 - val_loss: 0.7390 - val_accuracy: 0.7269\n",
      "Epoch 57/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6837 - accuracy: 0.7701\n",
      "Epoch 57: val_loss did not improve from 0.73897\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6819 - accuracy: 0.7712 - val_loss: 0.7394 - val_accuracy: 0.7290\n",
      "Epoch 58/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6953 - accuracy: 0.7743\n",
      "Epoch 58: val_loss improved from 0.73897 to 0.73867, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6938 - accuracy: 0.7749 - val_loss: 0.7387 - val_accuracy: 0.7248\n",
      "Epoch 59/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7069 - accuracy: 0.7579\n",
      "Epoch 59: val_loss improved from 0.73867 to 0.73609, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7068 - accuracy: 0.7581 - val_loss: 0.7361 - val_accuracy: 0.7290\n",
      "Epoch 60/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6981 - accuracy: 0.7684\n",
      "Epoch 60: val_loss did not improve from 0.73609\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.7686 - val_loss: 0.7364 - val_accuracy: 0.7332\n",
      "Epoch 61/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6982 - accuracy: 0.7705\n",
      "Epoch 61: val_loss improved from 0.73609 to 0.73549, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6978 - accuracy: 0.7707 - val_loss: 0.7355 - val_accuracy: 0.7353\n",
      "Epoch 62/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6745 - accuracy: 0.7655\n",
      "Epoch 62: val_loss improved from 0.73549 to 0.73379, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6746 - accuracy: 0.7655 - val_loss: 0.7338 - val_accuracy: 0.7353\n",
      "Epoch 63/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6878 - accuracy: 0.7689\n",
      "Epoch 63: val_loss improved from 0.73379 to 0.73305, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6876 - accuracy: 0.7692 - val_loss: 0.7330 - val_accuracy: 0.7395\n",
      "Epoch 64/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7046 - accuracy: 0.7568\n",
      "Epoch 64: val_loss improved from 0.73305 to 0.73040, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7046 - accuracy: 0.7566 - val_loss: 0.7304 - val_accuracy: 0.7290\n",
      "Epoch 65/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.6815 - accuracy: 0.7599\n",
      "Epoch 65: val_loss improved from 0.73040 to 0.73010, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6832 - accuracy: 0.7592 - val_loss: 0.7301 - val_accuracy: 0.7374\n",
      "Epoch 66/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6757 - accuracy: 0.7656\n",
      "Epoch 66: val_loss improved from 0.73010 to 0.72820, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6768 - accuracy: 0.7665 - val_loss: 0.7282 - val_accuracy: 0.7353\n",
      "Epoch 67/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6808 - accuracy: 0.7668\n",
      "Epoch 67: val_loss improved from 0.72820 to 0.72664, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6803 - accuracy: 0.7671 - val_loss: 0.7266 - val_accuracy: 0.7353\n",
      "Epoch 68/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.7860\n",
      "Epoch 68: val_loss improved from 0.72664 to 0.72539, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6714 - accuracy: 0.7865 - val_loss: 0.7254 - val_accuracy: 0.7353\n",
      "Epoch 69/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6635 - accuracy: 0.7699\n",
      "Epoch 69: val_loss did not improve from 0.72539\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6627 - accuracy: 0.7702 - val_loss: 0.7259 - val_accuracy: 0.7353\n",
      "Epoch 70/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6589 - accuracy: 0.7861\n",
      "Epoch 70: val_loss improved from 0.72539 to 0.72446, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6602 - accuracy: 0.7844 - val_loss: 0.7245 - val_accuracy: 0.7311\n",
      "Epoch 71/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6678 - accuracy: 0.7696\n",
      "Epoch 71: val_loss improved from 0.72446 to 0.72431, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6669 - accuracy: 0.7707 - val_loss: 0.7243 - val_accuracy: 0.7374\n",
      "Epoch 72/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6490 - accuracy: 0.7773\n",
      "Epoch 72: val_loss improved from 0.72431 to 0.72166, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6490 - accuracy: 0.7770 - val_loss: 0.7217 - val_accuracy: 0.7353\n",
      "Epoch 73/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6676 - accuracy: 0.7810\n",
      "Epoch 73: val_loss improved from 0.72166 to 0.72063, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6678 - accuracy: 0.7817 - val_loss: 0.7206 - val_accuracy: 0.7395\n",
      "Epoch 74/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6681 - accuracy: 0.7740\n",
      "Epoch 74: val_loss improved from 0.72063 to 0.71861, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6681 - accuracy: 0.7739 - val_loss: 0.7186 - val_accuracy: 0.7395\n",
      "Epoch 75/200\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.6447 - accuracy: 0.7752\n",
      "Epoch 75: val_loss improved from 0.71861 to 0.71740, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6450 - accuracy: 0.7765 - val_loss: 0.7174 - val_accuracy: 0.7437\n",
      "Epoch 76/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6546 - accuracy: 0.7738\n",
      "Epoch 76: val_loss did not improve from 0.71740\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.7749 - val_loss: 0.7179 - val_accuracy: 0.7395\n",
      "Epoch 77/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6510 - accuracy: 0.7856\n",
      "Epoch 77: val_loss did not improve from 0.71740\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.7854 - val_loss: 0.7175 - val_accuracy: 0.7332\n",
      "Epoch 78/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6426 - accuracy: 0.7924\n",
      "Epoch 78: val_loss did not improve from 0.71740\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.7928 - val_loss: 0.7178 - val_accuracy: 0.7416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6403 - accuracy: 0.7847\n",
      "Epoch 79: val_loss did not improve from 0.71740\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.7865 - val_loss: 0.7186 - val_accuracy: 0.7416\n",
      "Epoch 80/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6503 - accuracy: 0.7852\n",
      "Epoch 80: val_loss improved from 0.71740 to 0.71557, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6501 - accuracy: 0.7854 - val_loss: 0.7156 - val_accuracy: 0.7416\n",
      "Epoch 81/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6456 - accuracy: 0.7735\n",
      "Epoch 81: val_loss improved from 0.71557 to 0.71464, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6448 - accuracy: 0.7739 - val_loss: 0.7146 - val_accuracy: 0.7395\n",
      "Epoch 82/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6488 - accuracy: 0.7839\n",
      "Epoch 82: val_loss did not improve from 0.71464\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.7838 - val_loss: 0.7151 - val_accuracy: 0.7416\n",
      "Epoch 83/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6366 - accuracy: 0.7834\n",
      "Epoch 83: val_loss improved from 0.71464 to 0.71456, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6375 - accuracy: 0.7828 - val_loss: 0.7146 - val_accuracy: 0.7416\n",
      "Epoch 84/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.7791\n",
      "Epoch 84: val_loss improved from 0.71456 to 0.71304, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6355 - accuracy: 0.7791 - val_loss: 0.7130 - val_accuracy: 0.7437\n",
      "Epoch 85/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6337 - accuracy: 0.7783\n",
      "Epoch 85: val_loss improved from 0.71304 to 0.71072, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6317 - accuracy: 0.7791 - val_loss: 0.7107 - val_accuracy: 0.7458\n",
      "Epoch 86/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7907\n",
      "Epoch 86: val_loss improved from 0.71072 to 0.70996, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6352 - accuracy: 0.7907 - val_loss: 0.7100 - val_accuracy: 0.7416\n",
      "Epoch 87/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6301 - accuracy: 0.7863\n",
      "Epoch 87: val_loss did not improve from 0.70996\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.7849 - val_loss: 0.7110 - val_accuracy: 0.7416\n",
      "Epoch 88/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6246 - accuracy: 0.7892\n",
      "Epoch 88: val_loss did not improve from 0.70996\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.7896 - val_loss: 0.7105 - val_accuracy: 0.7416\n",
      "Epoch 89/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6203 - accuracy: 0.7929\n",
      "Epoch 89: val_loss did not improve from 0.70996\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.7922 - val_loss: 0.7119 - val_accuracy: 0.7437\n",
      "Epoch 90/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6235 - accuracy: 0.7812\n",
      "Epoch 90: val_loss did not improve from 0.70996\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.7812 - val_loss: 0.7115 - val_accuracy: 0.7416\n",
      "Epoch 91/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6246 - accuracy: 0.7812\n",
      "Epoch 91: val_loss did not improve from 0.70996\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.7817 - val_loss: 0.7121 - val_accuracy: 0.7437\n",
      "Epoch 92/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6231 - accuracy: 0.7853\n",
      "Epoch 92: val_loss did not improve from 0.70996\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6229 - accuracy: 0.7854 - val_loss: 0.7104 - val_accuracy: 0.7437\n",
      "Epoch 93/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6146 - accuracy: 0.7974\n",
      "Epoch 93: val_loss did not improve from 0.70996\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6148 - accuracy: 0.7964 - val_loss: 0.7101 - val_accuracy: 0.7437\n",
      "Epoch 94/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.6120 - accuracy: 0.7948\n",
      "Epoch 94: val_loss did not improve from 0.70996\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6160 - accuracy: 0.7922 - val_loss: 0.7119 - val_accuracy: 0.7374\n",
      "Epoch 95/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6191 - accuracy: 0.7767\n",
      "Epoch 95: val_loss improved from 0.70996 to 0.70979, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6174 - accuracy: 0.7786 - val_loss: 0.7098 - val_accuracy: 0.7395\n",
      "Epoch 96/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6239 - accuracy: 0.7836\n",
      "Epoch 96: val_loss improved from 0.70979 to 0.70809, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6242 - accuracy: 0.7833 - val_loss: 0.7081 - val_accuracy: 0.7437\n",
      "Epoch 97/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6026 - accuracy: 0.7982\n",
      "Epoch 97: val_loss did not improve from 0.70809\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.7964 - val_loss: 0.7085 - val_accuracy: 0.7416\n",
      "Epoch 98/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6120 - accuracy: 0.7888\n",
      "Epoch 98: val_loss improved from 0.70809 to 0.70641, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6093 - accuracy: 0.7917 - val_loss: 0.7064 - val_accuracy: 0.7395\n",
      "Epoch 99/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6001 - accuracy: 0.7890\n",
      "Epoch 99: val_loss did not improve from 0.70641\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.7907 - val_loss: 0.7092 - val_accuracy: 0.7437\n",
      "Epoch 100/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.6000 - accuracy: 0.7830\n",
      "Epoch 100: val_loss did not improve from 0.70641\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.7886 - val_loss: 0.7109 - val_accuracy: 0.7416\n",
      "Epoch 101/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5913 - accuracy: 0.7922\n",
      "Epoch 101: val_loss did not improve from 0.70641\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.7912 - val_loss: 0.7111 - val_accuracy: 0.7437\n",
      "Epoch 102/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6064 - accuracy: 0.7865\n",
      "Epoch 102: val_loss did not improve from 0.70641\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.7854 - val_loss: 0.7095 - val_accuracy: 0.7416\n",
      "Epoch 103/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5969 - accuracy: 0.7909\n",
      "Epoch 103: val_loss did not improve from 0.70641\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5932 - accuracy: 0.7928 - val_loss: 0.7102 - val_accuracy: 0.7416\n",
      "Epoch 104/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6052 - accuracy: 0.7920\n",
      "Epoch 104: val_loss did not improve from 0.70641\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6032 - accuracy: 0.7938 - val_loss: 0.7077 - val_accuracy: 0.7395\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/120 [============================>.] - ETA: 0s - loss: 0.5894 - accuracy: 0.7934\n",
      "Epoch 105: val_loss did not improve from 0.70641\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.7922 - val_loss: 0.7075 - val_accuracy: 0.7395\n",
      "Epoch 106/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5949 - accuracy: 0.7897\n",
      "Epoch 106: val_loss did not improve from 0.70641\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.7896 - val_loss: 0.7065 - val_accuracy: 0.7395\n",
      "Epoch 107/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6067 - accuracy: 0.7875\n",
      "Epoch 107: val_loss improved from 0.70641 to 0.70580, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6067 - accuracy: 0.7875 - val_loss: 0.7058 - val_accuracy: 0.7395\n",
      "Epoch 108/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6032 - accuracy: 0.7961\n",
      "Epoch 108: val_loss improved from 0.70580 to 0.70258, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold3.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6047 - accuracy: 0.7954 - val_loss: 0.7026 - val_accuracy: 0.7437\n",
      "Epoch 109/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5912 - accuracy: 0.7891\n",
      "Epoch 109: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5937 - accuracy: 0.7880 - val_loss: 0.7034 - val_accuracy: 0.7395\n",
      "Epoch 110/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5794 - accuracy: 0.8020\n",
      "Epoch 110: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.8022 - val_loss: 0.7059 - val_accuracy: 0.7395\n",
      "Epoch 111/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5778 - accuracy: 0.7996\n",
      "Epoch 111: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5781 - accuracy: 0.7985 - val_loss: 0.7081 - val_accuracy: 0.7437\n",
      "Epoch 112/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5781 - accuracy: 0.7988\n",
      "Epoch 112: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7991 - val_loss: 0.7101 - val_accuracy: 0.7437\n",
      "Epoch 113/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5740 - accuracy: 0.7988\n",
      "Epoch 113: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.7985 - val_loss: 0.7110 - val_accuracy: 0.7416\n",
      "Epoch 114/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5801 - accuracy: 0.7951\n",
      "Epoch 114: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5803 - accuracy: 0.7964 - val_loss: 0.7087 - val_accuracy: 0.7437\n",
      "Epoch 115/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5761 - accuracy: 0.7988\n",
      "Epoch 115: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7985 - val_loss: 0.7086 - val_accuracy: 0.7437\n",
      "Epoch 116/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5712 - accuracy: 0.8041\n",
      "Epoch 116: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.8038 - val_loss: 0.7065 - val_accuracy: 0.7458\n",
      "Epoch 117/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5778 - accuracy: 0.7929\n",
      "Epoch 117: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.7938 - val_loss: 0.7042 - val_accuracy: 0.7458\n",
      "Epoch 118/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5778 - accuracy: 0.7983\n",
      "Epoch 118: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.8012 - val_loss: 0.7036 - val_accuracy: 0.7542\n",
      "Epoch 119/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5641 - accuracy: 0.8015\n",
      "Epoch 119: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.8012 - val_loss: 0.7055 - val_accuracy: 0.7500\n",
      "Epoch 120/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5597 - accuracy: 0.8082\n",
      "Epoch 120: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5581 - accuracy: 0.8095 - val_loss: 0.7068 - val_accuracy: 0.7500\n",
      "Epoch 121/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5757 - accuracy: 0.7991\n",
      "Epoch 121: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.8012 - val_loss: 0.7046 - val_accuracy: 0.7500\n",
      "Epoch 122/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5657 - accuracy: 0.7981\n",
      "Epoch 122: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5670 - accuracy: 0.7975 - val_loss: 0.7028 - val_accuracy: 0.7479\n",
      "Epoch 123/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5594 - accuracy: 0.8093\n",
      "Epoch 123: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5630 - accuracy: 0.8085 - val_loss: 0.7052 - val_accuracy: 0.7500\n",
      "Epoch 124/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5645 - accuracy: 0.7947\n",
      "Epoch 124: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5622 - accuracy: 0.7970 - val_loss: 0.7045 - val_accuracy: 0.7500\n",
      "Epoch 125/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5623 - accuracy: 0.8076\n",
      "Epoch 125: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5624 - accuracy: 0.8054 - val_loss: 0.7057 - val_accuracy: 0.7500\n",
      "Epoch 126/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5468 - accuracy: 0.8051\n",
      "Epoch 126: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.8048 - val_loss: 0.7081 - val_accuracy: 0.7500\n",
      "Epoch 127/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5529 - accuracy: 0.7971\n",
      "Epoch 127: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5500 - accuracy: 0.7985 - val_loss: 0.7073 - val_accuracy: 0.7479\n",
      "Epoch 128/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5586 - accuracy: 0.8011\n",
      "Epoch 128: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7991 - val_loss: 0.7059 - val_accuracy: 0.7521\n",
      "Epoch 129/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5522 - accuracy: 0.7978\n",
      "Epoch 129: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.7980 - val_loss: 0.7054 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5492 - accuracy: 0.8157\n",
      "Epoch 130: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.8137 - val_loss: 0.7055 - val_accuracy: 0.7521\n",
      "Epoch 131/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5458 - accuracy: 0.8179\n",
      "Epoch 131: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5420 - accuracy: 0.8206 - val_loss: 0.7080 - val_accuracy: 0.7563\n",
      "Epoch 132/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5438 - accuracy: 0.8057\n",
      "Epoch 132: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.8054 - val_loss: 0.7084 - val_accuracy: 0.7479\n",
      "Epoch 133/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5555 - accuracy: 0.8027\n",
      "Epoch 133: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5554 - accuracy: 0.8022 - val_loss: 0.7041 - val_accuracy: 0.7479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5390 - accuracy: 0.8130\n",
      "Epoch 134: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5389 - accuracy: 0.8127 - val_loss: 0.7083 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5373 - accuracy: 0.8045\n",
      "Epoch 135: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.8043 - val_loss: 0.7093 - val_accuracy: 0.7605\n",
      "Epoch 136/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.8216\n",
      "Epoch 136: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.8211 - val_loss: 0.7149 - val_accuracy: 0.7479\n",
      "Epoch 137/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.8050\n",
      "Epoch 137: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5483 - accuracy: 0.8038 - val_loss: 0.7079 - val_accuracy: 0.7521\n",
      "Epoch 138/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5448 - accuracy: 0.8067\n",
      "Epoch 138: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.8080 - val_loss: 0.7087 - val_accuracy: 0.7479\n",
      "Epoch 139/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5427 - accuracy: 0.8061\n",
      "Epoch 139: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.8059 - val_loss: 0.7039 - val_accuracy: 0.7521\n",
      "Epoch 140/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5204 - accuracy: 0.8130\n",
      "Epoch 140: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.8116 - val_loss: 0.7078 - val_accuracy: 0.7521\n",
      "Epoch 141/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5356 - accuracy: 0.8050\n",
      "Epoch 141: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.8048 - val_loss: 0.7082 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5274 - accuracy: 0.8162\n",
      "Epoch 142: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.8174 - val_loss: 0.7112 - val_accuracy: 0.7479\n",
      "Epoch 143/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.8103\n",
      "Epoch 143: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.8101 - val_loss: 0.7095 - val_accuracy: 0.7479\n",
      "Epoch 144/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5253 - accuracy: 0.8125\n",
      "Epoch 144: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5321 - accuracy: 0.8095 - val_loss: 0.7118 - val_accuracy: 0.7458\n",
      "Epoch 145/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5238 - accuracy: 0.8152\n",
      "Epoch 145: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5214 - accuracy: 0.8179 - val_loss: 0.7070 - val_accuracy: 0.7521\n",
      "Epoch 146/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5238 - accuracy: 0.8141\n",
      "Epoch 146: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5225 - accuracy: 0.8164 - val_loss: 0.7091 - val_accuracy: 0.7563\n",
      "Epoch 147/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5264 - accuracy: 0.8157\n",
      "Epoch 147: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5264 - accuracy: 0.8153 - val_loss: 0.7092 - val_accuracy: 0.7563\n",
      "Epoch 148/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5187 - accuracy: 0.8125\n",
      "Epoch 148: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5197 - accuracy: 0.8122 - val_loss: 0.7120 - val_accuracy: 0.7563\n",
      "Epoch 149/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5166 - accuracy: 0.8212\n",
      "Epoch 149: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5154 - accuracy: 0.8242 - val_loss: 0.7132 - val_accuracy: 0.7563\n",
      "Epoch 150/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5092 - accuracy: 0.8226\n",
      "Epoch 150: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.8221 - val_loss: 0.7187 - val_accuracy: 0.7605\n",
      "Epoch 151/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5111 - accuracy: 0.8264\n",
      "Epoch 151: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5083 - accuracy: 0.8284 - val_loss: 0.7185 - val_accuracy: 0.7563\n",
      "Epoch 152/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5057 - accuracy: 0.8232\n",
      "Epoch 152: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.8216 - val_loss: 0.7176 - val_accuracy: 0.7563\n",
      "Epoch 153/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5074 - accuracy: 0.8215\n",
      "Epoch 153: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.8221 - val_loss: 0.7225 - val_accuracy: 0.7542\n",
      "Epoch 154/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5096 - accuracy: 0.8168\n",
      "Epoch 154: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5094 - accuracy: 0.8153 - val_loss: 0.7226 - val_accuracy: 0.7584\n",
      "Epoch 155/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5162 - accuracy: 0.8205\n",
      "Epoch 155: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5129 - accuracy: 0.8227 - val_loss: 0.7188 - val_accuracy: 0.7626\n",
      "Epoch 156/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5099 - accuracy: 0.8189\n",
      "Epoch 156: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.8179 - val_loss: 0.7194 - val_accuracy: 0.7584\n",
      "Epoch 157/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5083 - accuracy: 0.8259\n",
      "Epoch 157: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.8258 - val_loss: 0.7193 - val_accuracy: 0.7584\n",
      "Epoch 158/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8242\n",
      "Epoch 158: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.8242 - val_loss: 0.7186 - val_accuracy: 0.7626\n",
      "Epoch 159/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5004 - accuracy: 0.8309\n",
      "Epoch 159: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4961 - accuracy: 0.8347 - val_loss: 0.7210 - val_accuracy: 0.7605\n",
      "Epoch 160/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5051 - accuracy: 0.8152\n",
      "Epoch 160: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.8153 - val_loss: 0.7209 - val_accuracy: 0.7626\n",
      "Epoch 161/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5024 - accuracy: 0.8152\n",
      "Epoch 161: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.8137 - val_loss: 0.7251 - val_accuracy: 0.7542\n",
      "Epoch 162/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5010 - accuracy: 0.8238\n",
      "Epoch 162: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5047 - accuracy: 0.8206 - val_loss: 0.7227 - val_accuracy: 0.7563\n",
      "Epoch 163/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4895 - accuracy: 0.8280\n",
      "Epoch 163: val_loss did not improve from 0.70258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.8279 - val_loss: 0.7301 - val_accuracy: 0.7563\n",
      "Epoch 164/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5072 - accuracy: 0.8289\n",
      "Epoch 164: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5093 - accuracy: 0.8279 - val_loss: 0.7249 - val_accuracy: 0.7542\n",
      "Epoch 165/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4923 - accuracy: 0.8267\n",
      "Epoch 165: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.8248 - val_loss: 0.7312 - val_accuracy: 0.7542\n",
      "Epoch 166/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4932 - accuracy: 0.8353\n",
      "Epoch 166: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.8353 - val_loss: 0.7287 - val_accuracy: 0.7626\n",
      "Epoch 167/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4899 - accuracy: 0.8322\n",
      "Epoch 167: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4925 - accuracy: 0.8316 - val_loss: 0.7313 - val_accuracy: 0.7605\n",
      "Epoch 168/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4981 - accuracy: 0.8249\n",
      "Epoch 168: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4959 - accuracy: 0.8258 - val_loss: 0.7283 - val_accuracy: 0.7584\n",
      "Epoch 169/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4983 - accuracy: 0.8294\n",
      "Epoch 169: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.8284 - val_loss: 0.7255 - val_accuracy: 0.7668\n",
      "Epoch 170/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4832 - accuracy: 0.8321\n",
      "Epoch 170: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.8316 - val_loss: 0.7315 - val_accuracy: 0.7605\n",
      "Epoch 171/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4855 - accuracy: 0.8414\n",
      "Epoch 171: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.8416 - val_loss: 0.7317 - val_accuracy: 0.7647\n",
      "Epoch 172/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4833 - accuracy: 0.8362\n",
      "Epoch 172: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.8368 - val_loss: 0.7326 - val_accuracy: 0.7626\n",
      "Epoch 173/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4816 - accuracy: 0.8361\n",
      "Epoch 173: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.8363 - val_loss: 0.7315 - val_accuracy: 0.7647\n",
      "Epoch 174/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4668 - accuracy: 0.8411\n",
      "Epoch 174: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4664 - accuracy: 0.8416 - val_loss: 0.7379 - val_accuracy: 0.7605\n",
      "Epoch 175/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4883 - accuracy: 0.8314\n",
      "Epoch 175: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4877 - accuracy: 0.8326 - val_loss: 0.7292 - val_accuracy: 0.7668\n",
      "Epoch 176/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.8388\n",
      "Epoch 176: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.8384 - val_loss: 0.7321 - val_accuracy: 0.7668\n",
      "Epoch 177/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.8403\n",
      "Epoch 177: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.8400 - val_loss: 0.7363 - val_accuracy: 0.7626\n",
      "Epoch 178/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.4743 - accuracy: 0.8337\n",
      "Epoch 178: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4765 - accuracy: 0.8321 - val_loss: 0.7353 - val_accuracy: 0.7689\n",
      "Epoch 179/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4778 - accuracy: 0.8353\n",
      "Epoch 179: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.8353 - val_loss: 0.7356 - val_accuracy: 0.7710\n",
      "Epoch 180/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4693 - accuracy: 0.8374\n",
      "Epoch 180: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.8374 - val_loss: 0.7416 - val_accuracy: 0.7689\n",
      "Epoch 181/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4622 - accuracy: 0.8459\n",
      "Epoch 181: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.8447 - val_loss: 0.7368 - val_accuracy: 0.7710\n",
      "Epoch 182/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4692 - accuracy: 0.8377\n",
      "Epoch 182: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4658 - accuracy: 0.8384 - val_loss: 0.7355 - val_accuracy: 0.7710\n",
      "Epoch 183/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4640 - accuracy: 0.8492\n",
      "Epoch 183: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4656 - accuracy: 0.8468 - val_loss: 0.7381 - val_accuracy: 0.7731\n",
      "Epoch 184/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4649 - accuracy: 0.8443\n",
      "Epoch 184: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4662 - accuracy: 0.8431 - val_loss: 0.7408 - val_accuracy: 0.7752\n",
      "Epoch 185/200\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.4814 - accuracy: 0.8293\n",
      "Epoch 185: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4739 - accuracy: 0.8363 - val_loss: 0.7306 - val_accuracy: 0.7752\n",
      "Epoch 186/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4670 - accuracy: 0.8451\n",
      "Epoch 186: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.8463 - val_loss: 0.7366 - val_accuracy: 0.7710\n",
      "Epoch 187/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8432\n",
      "Epoch 187: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.8431 - val_loss: 0.7369 - val_accuracy: 0.7731\n",
      "Epoch 188/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.4587 - accuracy: 0.8429\n",
      "Epoch 188: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4551 - accuracy: 0.8452 - val_loss: 0.7385 - val_accuracy: 0.7731\n",
      "Epoch 189/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.4570 - accuracy: 0.8527\n",
      "Epoch 189: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4587 - accuracy: 0.8520 - val_loss: 0.7425 - val_accuracy: 0.7710\n",
      "Epoch 190/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4450 - accuracy: 0.8547\n",
      "Epoch 190: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.8547 - val_loss: 0.7452 - val_accuracy: 0.7731\n",
      "Epoch 191/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4649 - accuracy: 0.8496\n",
      "Epoch 191: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.8494 - val_loss: 0.7443 - val_accuracy: 0.7668\n",
      "Epoch 192/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4465 - accuracy: 0.8538\n",
      "Epoch 192: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4495 - accuracy: 0.8531 - val_loss: 0.7504 - val_accuracy: 0.7752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4644 - accuracy: 0.8443\n",
      "Epoch 193: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4647 - accuracy: 0.8447 - val_loss: 0.7475 - val_accuracy: 0.7689\n",
      "Epoch 194/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4554 - accuracy: 0.8531\n",
      "Epoch 194: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.8552 - val_loss: 0.7389 - val_accuracy: 0.7689\n",
      "Epoch 195/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4643 - accuracy: 0.8531\n",
      "Epoch 195: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4651 - accuracy: 0.8520 - val_loss: 0.7347 - val_accuracy: 0.7668\n",
      "Epoch 196/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4554 - accuracy: 0.8491\n",
      "Epoch 196: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4557 - accuracy: 0.8484 - val_loss: 0.7367 - val_accuracy: 0.7647\n",
      "Epoch 197/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4525 - accuracy: 0.8627\n",
      "Epoch 197: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.8615 - val_loss: 0.7364 - val_accuracy: 0.7626\n",
      "Epoch 198/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4390 - accuracy: 0.8623\n",
      "Epoch 198: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8631 - val_loss: 0.7467 - val_accuracy: 0.7668\n",
      "Epoch 199/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4363 - accuracy: 0.8619\n",
      "Epoch 199: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8620 - val_loss: 0.7423 - val_accuracy: 0.7689\n",
      "Epoch 200/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4441 - accuracy: 0.8522\n",
      "Epoch 200: val_loss did not improve from 0.70258\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.8515 - val_loss: 0.7479 - val_accuracy: 0.7710\n",
      "\n",
      "Train/Test model on Fold #4.\n",
      "Epoch 1/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 1.0956 - accuracy: 0.5096\n",
      "Epoch 1: val_loss improved from inf to 0.97747, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1.0931 - accuracy: 0.5089 - val_loss: 0.9775 - val_accuracy: 0.4916\n",
      "Epoch 2/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 1.0471 - accuracy: 0.5169\n",
      "Epoch 2: val_loss improved from 0.97747 to 0.96712, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0478 - accuracy: 0.5173 - val_loss: 0.9671 - val_accuracy: 0.5357\n",
      "Epoch 3/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 1.0421 - accuracy: 0.5121\n",
      "Epoch 3: val_loss improved from 0.96712 to 0.96121, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0418 - accuracy: 0.5126 - val_loss: 0.9612 - val_accuracy: 0.5714\n",
      "Epoch 4/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 1.0015 - accuracy: 0.5307\n",
      "Epoch 4: val_loss improved from 0.96121 to 0.95599, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0018 - accuracy: 0.5294 - val_loss: 0.9560 - val_accuracy: 0.5777\n",
      "Epoch 5/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.0001 - accuracy: 0.5352\n",
      "Epoch 5: val_loss improved from 0.95599 to 0.95116, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0001 - accuracy: 0.5352 - val_loss: 0.9512 - val_accuracy: 0.6008\n",
      "Epoch 6/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.9850 - accuracy: 0.5545\n",
      "Epoch 6: val_loss improved from 0.95116 to 0.94628, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9852 - accuracy: 0.5546 - val_loss: 0.9463 - val_accuracy: 0.6261\n",
      "Epoch 7/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9889 - accuracy: 0.5273\n",
      "Epoch 7: val_loss improved from 0.94628 to 0.94197, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9889 - accuracy: 0.5273 - val_loss: 0.9420 - val_accuracy: 0.6282\n",
      "Epoch 8/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.9817 - accuracy: 0.5228\n",
      "Epoch 8: val_loss improved from 0.94197 to 0.93738, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9788 - accuracy: 0.5268 - val_loss: 0.9374 - val_accuracy: 0.6408\n",
      "Epoch 9/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.9708 - accuracy: 0.5614\n",
      "Epoch 9: val_loss improved from 0.93738 to 0.93337, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9707 - accuracy: 0.5614 - val_loss: 0.9334 - val_accuracy: 0.6471\n",
      "Epoch 10/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.9565 - accuracy: 0.5625\n",
      "Epoch 10: val_loss improved from 0.93337 to 0.92829, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9565 - accuracy: 0.5630 - val_loss: 0.9283 - val_accuracy: 0.6555\n",
      "Epoch 11/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.9405 - accuracy: 0.5768\n",
      "Epoch 11: val_loss improved from 0.92829 to 0.92181, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9392 - accuracy: 0.5787 - val_loss: 0.9218 - val_accuracy: 0.6702\n",
      "Epoch 12/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.9531 - accuracy: 0.5513\n",
      "Epoch 12: val_loss improved from 0.92181 to 0.91540, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9542 - accuracy: 0.5498 - val_loss: 0.9154 - val_accuracy: 0.6702\n",
      "Epoch 13/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.9393 - accuracy: 0.5844\n",
      "Epoch 13: val_loss improved from 0.91540 to 0.90978, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9395 - accuracy: 0.5834 - val_loss: 0.9098 - val_accuracy: 0.6807\n",
      "Epoch 14/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.9239 - accuracy: 0.5962\n",
      "Epoch 14: val_loss improved from 0.90978 to 0.90294, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9245 - accuracy: 0.5960 - val_loss: 0.9029 - val_accuracy: 0.6849\n",
      "Epoch 15/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.9266 - accuracy: 0.5887\n",
      "Epoch 15: val_loss improved from 0.90294 to 0.89667, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9262 - accuracy: 0.5902 - val_loss: 0.8967 - val_accuracy: 0.6807\n",
      "Epoch 16/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.9173 - accuracy: 0.6098\n",
      "Epoch 16: val_loss improved from 0.89667 to 0.88921, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9171 - accuracy: 0.6102 - val_loss: 0.8892 - val_accuracy: 0.6828\n",
      "Epoch 17/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.9209 - accuracy: 0.6103\n",
      "Epoch 17: val_loss improved from 0.88921 to 0.88161, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9211 - accuracy: 0.6076 - val_loss: 0.8816 - val_accuracy: 0.6954\n",
      "Epoch 18/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.9039 - accuracy: 0.6272\n",
      "Epoch 18: val_loss improved from 0.88161 to 0.87337, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9036 - accuracy: 0.6285 - val_loss: 0.8734 - val_accuracy: 0.7017\n",
      "Epoch 19/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.8988 - accuracy: 0.6345\n",
      "Epoch 19: val_loss improved from 0.87337 to 0.86546, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8980 - accuracy: 0.6369 - val_loss: 0.8655 - val_accuracy: 0.7185\n",
      "Epoch 20/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.8789 - accuracy: 0.6410\n",
      "Epoch 20: val_loss improved from 0.86546 to 0.85733, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8797 - accuracy: 0.6406 - val_loss: 0.8573 - val_accuracy: 0.7227\n",
      "Epoch 21/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.8864 - accuracy: 0.6455\n",
      "Epoch 21: val_loss improved from 0.85733 to 0.84921, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8840 - accuracy: 0.6474 - val_loss: 0.8492 - val_accuracy: 0.7227\n",
      "Epoch 22/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.8780 - accuracy: 0.6496\n",
      "Epoch 22: val_loss improved from 0.84921 to 0.84194, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8779 - accuracy: 0.6506 - val_loss: 0.8419 - val_accuracy: 0.7290\n",
      "Epoch 23/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.8525 - accuracy: 0.6576\n",
      "Epoch 23: val_loss improved from 0.84194 to 0.83298, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8535 - accuracy: 0.6569 - val_loss: 0.8330 - val_accuracy: 0.7311\n",
      "Epoch 24/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.8621 - accuracy: 0.6677\n",
      "Epoch 24: val_loss improved from 0.83298 to 0.82714, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8611 - accuracy: 0.6679 - val_loss: 0.8271 - val_accuracy: 0.7353\n",
      "Epoch 25/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.8489 - accuracy: 0.6739\n",
      "Epoch 25: val_loss improved from 0.82714 to 0.81995, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8477 - accuracy: 0.6758 - val_loss: 0.8199 - val_accuracy: 0.7353\n",
      "Epoch 26/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.8458 - accuracy: 0.6864\n",
      "Epoch 26: val_loss improved from 0.81995 to 0.81205, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8437 - accuracy: 0.6884 - val_loss: 0.8120 - val_accuracy: 0.7332\n",
      "Epoch 27/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.8285 - accuracy: 0.6897\n",
      "Epoch 27: val_loss improved from 0.81205 to 0.80340, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8285 - accuracy: 0.6889 - val_loss: 0.8034 - val_accuracy: 0.7332\n",
      "Epoch 28/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.8229 - accuracy: 0.6875\n",
      "Epoch 28: val_loss improved from 0.80340 to 0.79727, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8216 - accuracy: 0.6889 - val_loss: 0.7973 - val_accuracy: 0.7332\n",
      "Epoch 29/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.8203 - accuracy: 0.6928\n",
      "Epoch 29: val_loss improved from 0.79727 to 0.79271, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8208 - accuracy: 0.6925 - val_loss: 0.7927 - val_accuracy: 0.7332\n",
      "Epoch 30/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.8154 - accuracy: 0.6940\n",
      "Epoch 30: val_loss improved from 0.79271 to 0.78641, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8150 - accuracy: 0.6931 - val_loss: 0.7864 - val_accuracy: 0.7374\n",
      "Epoch 31/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.8267 - accuracy: 0.6944\n",
      "Epoch 31: val_loss improved from 0.78641 to 0.78266, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8266 - accuracy: 0.6936 - val_loss: 0.7827 - val_accuracy: 0.7395\n",
      "Epoch 32/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.8090 - accuracy: 0.7097\n",
      "Epoch 32: val_loss improved from 0.78266 to 0.77852, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8082 - accuracy: 0.7088 - val_loss: 0.7785 - val_accuracy: 0.7353\n",
      "Epoch 33/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.8125 - accuracy: 0.7064\n",
      "Epoch 33: val_loss improved from 0.77852 to 0.77548, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8131 - accuracy: 0.7062 - val_loss: 0.7755 - val_accuracy: 0.7374\n",
      "Epoch 34/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.7908 - accuracy: 0.7259\n",
      "Epoch 34: val_loss improved from 0.77548 to 0.77097, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7939 - accuracy: 0.7204 - val_loss: 0.7710 - val_accuracy: 0.7458\n",
      "Epoch 35/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7901 - accuracy: 0.7055\n",
      "Epoch 35: val_loss improved from 0.77097 to 0.76703, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7894 - accuracy: 0.7067 - val_loss: 0.7670 - val_accuracy: 0.7416\n",
      "Epoch 36/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7925 - accuracy: 0.7268\n",
      "Epoch 36: val_loss improved from 0.76703 to 0.76355, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7918 - accuracy: 0.7251 - val_loss: 0.7636 - val_accuracy: 0.7458\n",
      "Epoch 37/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7814 - accuracy: 0.7180\n",
      "Epoch 37: val_loss improved from 0.76355 to 0.75966, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7810 - accuracy: 0.7183 - val_loss: 0.7597 - val_accuracy: 0.7521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7812 - accuracy: 0.7270\n",
      "Epoch 38: val_loss improved from 0.75966 to 0.75707, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7809 - accuracy: 0.7267 - val_loss: 0.7571 - val_accuracy: 0.7563\n",
      "Epoch 39/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.7660 - accuracy: 0.7370\n",
      "Epoch 39: val_loss improved from 0.75707 to 0.75335, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7651 - accuracy: 0.7371 - val_loss: 0.7534 - val_accuracy: 0.7542\n",
      "Epoch 40/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7728 - accuracy: 0.7311\n",
      "Epoch 40: val_loss improved from 0.75335 to 0.75175, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7717 - accuracy: 0.7324 - val_loss: 0.7518 - val_accuracy: 0.7521\n",
      "Epoch 41/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7724 - accuracy: 0.7340\n",
      "Epoch 41: val_loss improved from 0.75175 to 0.74834, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7707 - accuracy: 0.7345 - val_loss: 0.7483 - val_accuracy: 0.7605\n",
      "Epoch 42/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7534 - accuracy: 0.7392\n",
      "Epoch 42: val_loss improved from 0.74834 to 0.74457, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7503 - accuracy: 0.7424 - val_loss: 0.7446 - val_accuracy: 0.7626\n",
      "Epoch 43/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7543 - accuracy: 0.7328\n",
      "Epoch 43: val_loss improved from 0.74457 to 0.74108, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7534 - accuracy: 0.7324 - val_loss: 0.7411 - val_accuracy: 0.7647\n",
      "Epoch 44/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7418 - accuracy: 0.7548\n",
      "Epoch 44: val_loss improved from 0.74108 to 0.73853, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7395 - accuracy: 0.7560 - val_loss: 0.7385 - val_accuracy: 0.7626\n",
      "Epoch 45/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7453 - accuracy: 0.7478\n",
      "Epoch 45: val_loss improved from 0.73853 to 0.73568, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7484 - accuracy: 0.7455 - val_loss: 0.7357 - val_accuracy: 0.7626\n",
      "Epoch 46/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.7287 - accuracy: 0.7527\n",
      "Epoch 46: val_loss improved from 0.73568 to 0.73259, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7303 - accuracy: 0.7518 - val_loss: 0.7326 - val_accuracy: 0.7647\n",
      "Epoch 47/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7399 - accuracy: 0.7468\n",
      "Epoch 47: val_loss improved from 0.73259 to 0.73186, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7406 - accuracy: 0.7461 - val_loss: 0.7319 - val_accuracy: 0.7626\n",
      "Epoch 48/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7408 - accuracy: 0.7405\n",
      "Epoch 48: val_loss improved from 0.73186 to 0.72963, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7407 - accuracy: 0.7403 - val_loss: 0.7296 - val_accuracy: 0.7626\n",
      "Epoch 49/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.7321 - accuracy: 0.7532\n",
      "Epoch 49: val_loss improved from 0.72963 to 0.72759, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7323 - accuracy: 0.7534 - val_loss: 0.7276 - val_accuracy: 0.7605\n",
      "Epoch 50/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.7260 - accuracy: 0.7429\n",
      "Epoch 50: val_loss improved from 0.72759 to 0.72506, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7251 - accuracy: 0.7429 - val_loss: 0.7251 - val_accuracy: 0.7605\n",
      "Epoch 51/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7272 - accuracy: 0.7629\n",
      "Epoch 51: val_loss improved from 0.72506 to 0.72309, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7276 - accuracy: 0.7608 - val_loss: 0.7231 - val_accuracy: 0.7584\n",
      "Epoch 52/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.7644\n",
      "Epoch 52: val_loss improved from 0.72309 to 0.72081, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7153 - accuracy: 0.7644 - val_loss: 0.7208 - val_accuracy: 0.7563\n",
      "Epoch 53/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7338 - accuracy: 0.7403\n",
      "Epoch 53: val_loss improved from 0.72081 to 0.71940, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7364 - accuracy: 0.7382 - val_loss: 0.7194 - val_accuracy: 0.7563\n",
      "Epoch 54/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.7171 - accuracy: 0.7532\n",
      "Epoch 54: val_loss improved from 0.71940 to 0.71900, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7176 - accuracy: 0.7534 - val_loss: 0.7190 - val_accuracy: 0.7605\n",
      "Epoch 55/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.7196 - accuracy: 0.7579\n",
      "Epoch 55: val_loss improved from 0.71900 to 0.71725, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7195 - accuracy: 0.7576 - val_loss: 0.7173 - val_accuracy: 0.7605\n",
      "Epoch 56/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7042 - accuracy: 0.7673\n",
      "Epoch 56: val_loss improved from 0.71725 to 0.71404, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7039 - accuracy: 0.7676 - val_loss: 0.7140 - val_accuracy: 0.7584\n",
      "Epoch 57/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7007 - accuracy: 0.7595\n",
      "Epoch 57: val_loss improved from 0.71404 to 0.71084, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7005 - accuracy: 0.7597 - val_loss: 0.7108 - val_accuracy: 0.7626\n",
      "Epoch 58/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.7627\n",
      "Epoch 58: val_loss improved from 0.71084 to 0.70772, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6959 - accuracy: 0.7613 - val_loss: 0.7077 - val_accuracy: 0.7584\n",
      "Epoch 59/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6936 - accuracy: 0.7625\n",
      "Epoch 59: val_loss improved from 0.70772 to 0.70694, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6948 - accuracy: 0.7587 - val_loss: 0.7069 - val_accuracy: 0.7584\n",
      "Epoch 60/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6970 - accuracy: 0.7710\n",
      "Epoch 60: val_loss improved from 0.70694 to 0.70538, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6966 - accuracy: 0.7712 - val_loss: 0.7054 - val_accuracy: 0.7605\n",
      "Epoch 61/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6877 - accuracy: 0.7637\n",
      "Epoch 61: val_loss improved from 0.70538 to 0.70363, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6875 - accuracy: 0.7639 - val_loss: 0.7036 - val_accuracy: 0.7584\n",
      "Epoch 62/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6849 - accuracy: 0.7757\n",
      "Epoch 62: val_loss improved from 0.70363 to 0.70108, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6845 - accuracy: 0.7760 - val_loss: 0.7011 - val_accuracy: 0.7563\n",
      "Epoch 63/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.7644\n",
      "Epoch 63: val_loss improved from 0.70108 to 0.70000, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.7644 - val_loss: 0.7000 - val_accuracy: 0.7563\n",
      "Epoch 64/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.7564\n",
      "Epoch 64: val_loss improved from 0.70000 to 0.69908, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6914 - accuracy: 0.7581 - val_loss: 0.6991 - val_accuracy: 0.7563\n",
      "Epoch 65/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6784 - accuracy: 0.7722\n",
      "Epoch 65: val_loss improved from 0.69908 to 0.69773, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6790 - accuracy: 0.7718 - val_loss: 0.6977 - val_accuracy: 0.7563\n",
      "Epoch 66/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6790 - accuracy: 0.7724\n",
      "Epoch 66: val_loss improved from 0.69773 to 0.69578, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6786 - accuracy: 0.7712 - val_loss: 0.6958 - val_accuracy: 0.7563\n",
      "Epoch 67/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6785 - accuracy: 0.7714\n",
      "Epoch 67: val_loss improved from 0.69578 to 0.69454, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6780 - accuracy: 0.7718 - val_loss: 0.6945 - val_accuracy: 0.7584\n",
      "Epoch 68/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6832 - accuracy: 0.7712\n",
      "Epoch 68: val_loss improved from 0.69454 to 0.69307, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6832 - accuracy: 0.7712 - val_loss: 0.6931 - val_accuracy: 0.7626\n",
      "Epoch 69/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6833 - accuracy: 0.7728\n",
      "Epoch 69: val_loss improved from 0.69307 to 0.69109, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6829 - accuracy: 0.7733 - val_loss: 0.6911 - val_accuracy: 0.7605\n",
      "Epoch 70/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6624 - accuracy: 0.7786\n",
      "Epoch 70: val_loss improved from 0.69109 to 0.68971, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6640 - accuracy: 0.7770 - val_loss: 0.6897 - val_accuracy: 0.7542\n",
      "Epoch 71/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.7579\n",
      "Epoch 71: val_loss improved from 0.68971 to 0.68925, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6727 - accuracy: 0.7576 - val_loss: 0.6892 - val_accuracy: 0.7563\n",
      "Epoch 72/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6723 - accuracy: 0.7705\n",
      "Epoch 72: val_loss improved from 0.68925 to 0.68818, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6707 - accuracy: 0.7707 - val_loss: 0.6882 - val_accuracy: 0.7542\n",
      "Epoch 73/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6631 - accuracy: 0.7710\n",
      "Epoch 73: val_loss improved from 0.68818 to 0.68657, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6594 - accuracy: 0.7744 - val_loss: 0.6866 - val_accuracy: 0.7542\n",
      "Epoch 74/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6633 - accuracy: 0.7614\n",
      "Epoch 74: val_loss improved from 0.68657 to 0.68622, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6614 - accuracy: 0.7634 - val_loss: 0.6862 - val_accuracy: 0.7521\n",
      "Epoch 75/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6572 - accuracy: 0.7799\n",
      "Epoch 75: val_loss improved from 0.68622 to 0.68475, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6562 - accuracy: 0.7791 - val_loss: 0.6847 - val_accuracy: 0.7584\n",
      "Epoch 76/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6672 - accuracy: 0.7651\n",
      "Epoch 76: val_loss improved from 0.68475 to 0.68388, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6664 - accuracy: 0.7639 - val_loss: 0.6839 - val_accuracy: 0.7563\n",
      "Epoch 77/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6579 - accuracy: 0.7680\n",
      "Epoch 77: val_loss improved from 0.68388 to 0.68271, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6563 - accuracy: 0.7692 - val_loss: 0.6827 - val_accuracy: 0.7563\n",
      "Epoch 78/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6535 - accuracy: 0.7703\n",
      "Epoch 78: val_loss improved from 0.68271 to 0.68123, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6538 - accuracy: 0.7712 - val_loss: 0.6812 - val_accuracy: 0.7584\n",
      "Epoch 79/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6523 - accuracy: 0.7807\n",
      "Epoch 79: val_loss improved from 0.68123 to 0.67980, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6532 - accuracy: 0.7781 - val_loss: 0.6798 - val_accuracy: 0.7584\n",
      "Epoch 80/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6564 - accuracy: 0.7772\n",
      "Epoch 80: val_loss improved from 0.67980 to 0.67843, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6564 - accuracy: 0.7760 - val_loss: 0.6784 - val_accuracy: 0.7647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6631 - accuracy: 0.7701\n",
      "Epoch 81: val_loss improved from 0.67843 to 0.67829, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6599 - accuracy: 0.7718 - val_loss: 0.6783 - val_accuracy: 0.7626\n",
      "Epoch 82/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6431 - accuracy: 0.7772\n",
      "Epoch 82: val_loss improved from 0.67829 to 0.67749, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6441 - accuracy: 0.7770 - val_loss: 0.6775 - val_accuracy: 0.7584\n",
      "Epoch 83/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6474 - accuracy: 0.7749\n",
      "Epoch 83: val_loss improved from 0.67749 to 0.67661, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6465 - accuracy: 0.7760 - val_loss: 0.6766 - val_accuracy: 0.7605\n",
      "Epoch 84/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6393 - accuracy: 0.7812\n",
      "Epoch 84: val_loss improved from 0.67661 to 0.67517, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6416 - accuracy: 0.7791 - val_loss: 0.6752 - val_accuracy: 0.7647\n",
      "Epoch 85/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.6486 - accuracy: 0.7759\n",
      "Epoch 85: val_loss improved from 0.67517 to 0.67482, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6470 - accuracy: 0.7765 - val_loss: 0.6748 - val_accuracy: 0.7605\n",
      "Epoch 86/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6339 - accuracy: 0.7724\n",
      "Epoch 86: val_loss improved from 0.67482 to 0.67320, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6356 - accuracy: 0.7707 - val_loss: 0.6732 - val_accuracy: 0.7689\n",
      "Epoch 87/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.6338 - accuracy: 0.7840\n",
      "Epoch 87: val_loss improved from 0.67320 to 0.67220, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6318 - accuracy: 0.7833 - val_loss: 0.6722 - val_accuracy: 0.7647\n",
      "Epoch 88/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6382 - accuracy: 0.7872\n",
      "Epoch 88: val_loss improved from 0.67220 to 0.67107, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6374 - accuracy: 0.7891 - val_loss: 0.6711 - val_accuracy: 0.7668\n",
      "Epoch 89/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6291 - accuracy: 0.7870\n",
      "Epoch 89: val_loss did not improve from 0.67107\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6271 - accuracy: 0.7880 - val_loss: 0.6711 - val_accuracy: 0.7668\n",
      "Epoch 90/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6352 - accuracy: 0.7737\n",
      "Epoch 90: val_loss did not improve from 0.67107\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.7760 - val_loss: 0.6711 - val_accuracy: 0.7647\n",
      "Epoch 91/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.6281 - accuracy: 0.7904\n",
      "Epoch 91: val_loss improved from 0.67107 to 0.66923, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6307 - accuracy: 0.7886 - val_loss: 0.6692 - val_accuracy: 0.7626\n",
      "Epoch 92/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6359 - accuracy: 0.7745\n",
      "Epoch 92: val_loss improved from 0.66923 to 0.66887, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6360 - accuracy: 0.7749 - val_loss: 0.6689 - val_accuracy: 0.7668\n",
      "Epoch 93/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6160 - accuracy: 0.7896\n",
      "Epoch 93: val_loss improved from 0.66887 to 0.66682, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6160 - accuracy: 0.7896 - val_loss: 0.6668 - val_accuracy: 0.7647\n",
      "Epoch 94/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.6232 - accuracy: 0.7837\n",
      "Epoch 94: val_loss improved from 0.66682 to 0.66555, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6212 - accuracy: 0.7844 - val_loss: 0.6656 - val_accuracy: 0.7689\n",
      "Epoch 95/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.6177 - accuracy: 0.7856\n",
      "Epoch 95: val_loss improved from 0.66555 to 0.66437, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6159 - accuracy: 0.7865 - val_loss: 0.6644 - val_accuracy: 0.7689\n",
      "Epoch 96/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6214 - accuracy: 0.7828\n",
      "Epoch 96: val_loss improved from 0.66437 to 0.66334, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6214 - accuracy: 0.7828 - val_loss: 0.6633 - val_accuracy: 0.7647\n",
      "Epoch 97/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6244 - accuracy: 0.7821\n",
      "Epoch 97: val_loss did not improve from 0.66334\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.7838 - val_loss: 0.6636 - val_accuracy: 0.7731\n",
      "Epoch 98/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6195 - accuracy: 0.7844\n",
      "Epoch 98: val_loss improved from 0.66334 to 0.66312, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6189 - accuracy: 0.7849 - val_loss: 0.6631 - val_accuracy: 0.7710\n",
      "Epoch 99/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6197 - accuracy: 0.7889\n",
      "Epoch 99: val_loss improved from 0.66312 to 0.66101, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6192 - accuracy: 0.7891 - val_loss: 0.6610 - val_accuracy: 0.7668\n",
      "Epoch 100/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6188 - accuracy: 0.7934\n",
      "Epoch 100: val_loss improved from 0.66101 to 0.65996, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6180 - accuracy: 0.7933 - val_loss: 0.6600 - val_accuracy: 0.7647\n",
      "Epoch 101/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6153 - accuracy: 0.7770\n",
      "Epoch 101: val_loss improved from 0.65996 to 0.65988, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6148 - accuracy: 0.7775 - val_loss: 0.6599 - val_accuracy: 0.7668\n",
      "Epoch 102/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.6065 - accuracy: 0.7837\n",
      "Epoch 102: val_loss improved from 0.65988 to 0.65797, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6040 - accuracy: 0.7844 - val_loss: 0.6580 - val_accuracy: 0.7647\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/120 [============================>.] - ETA: 0s - loss: 0.6082 - accuracy: 0.7885\n",
      "Epoch 103: val_loss improved from 0.65797 to 0.65762, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6080 - accuracy: 0.7870 - val_loss: 0.6576 - val_accuracy: 0.7626\n",
      "Epoch 104/200\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.6008 - accuracy: 0.7900\n",
      "Epoch 104: val_loss improved from 0.65762 to 0.65594, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5945 - accuracy: 0.7959 - val_loss: 0.6559 - val_accuracy: 0.7647\n",
      "Epoch 105/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5940 - accuracy: 0.7899\n",
      "Epoch 105: val_loss improved from 0.65594 to 0.65556, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5931 - accuracy: 0.7917 - val_loss: 0.6556 - val_accuracy: 0.7563\n",
      "Epoch 106/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5948 - accuracy: 0.7941\n",
      "Epoch 106: val_loss did not improve from 0.65556\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7943 - val_loss: 0.6562 - val_accuracy: 0.7542\n",
      "Epoch 107/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5961 - accuracy: 0.7864\n",
      "Epoch 107: val_loss did not improve from 0.65556\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5966 - accuracy: 0.7875 - val_loss: 0.6563 - val_accuracy: 0.7542\n",
      "Epoch 108/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.6001 - accuracy: 0.7818\n",
      "Epoch 108: val_loss did not improve from 0.65556\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5993 - accuracy: 0.7828 - val_loss: 0.6558 - val_accuracy: 0.7563\n",
      "Epoch 109/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5838 - accuracy: 0.7925\n",
      "Epoch 109: val_loss did not improve from 0.65556\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.7928 - val_loss: 0.6565 - val_accuracy: 0.7563\n",
      "Epoch 110/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5851 - accuracy: 0.7966\n",
      "Epoch 110: val_loss did not improve from 0.65556\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7975 - val_loss: 0.6576 - val_accuracy: 0.7584\n",
      "Epoch 111/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5849 - accuracy: 0.7991\n",
      "Epoch 111: val_loss did not improve from 0.65556\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7970 - val_loss: 0.6561 - val_accuracy: 0.7500\n",
      "Epoch 112/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5876 - accuracy: 0.7855\n",
      "Epoch 112: val_loss did not improve from 0.65556\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.7859 - val_loss: 0.6560 - val_accuracy: 0.7542\n",
      "Epoch 113/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5802 - accuracy: 0.7933\n",
      "Epoch 113: val_loss improved from 0.65556 to 0.65509, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5806 - accuracy: 0.7943 - val_loss: 0.6551 - val_accuracy: 0.7563\n",
      "Epoch 114/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5839 - accuracy: 0.8001\n",
      "Epoch 114: val_loss improved from 0.65509 to 0.65424, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5830 - accuracy: 0.8012 - val_loss: 0.6542 - val_accuracy: 0.7500\n",
      "Epoch 115/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5898 - accuracy: 0.7922\n",
      "Epoch 115: val_loss improved from 0.65424 to 0.65385, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5869 - accuracy: 0.7949 - val_loss: 0.6539 - val_accuracy: 0.7500\n",
      "Epoch 116/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5807 - accuracy: 0.7977\n",
      "Epoch 116: val_loss improved from 0.65385 to 0.65362, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5814 - accuracy: 0.7959 - val_loss: 0.6536 - val_accuracy: 0.7500\n",
      "Epoch 117/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5839 - accuracy: 0.7946\n",
      "Epoch 117: val_loss did not improve from 0.65362\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.7949 - val_loss: 0.6537 - val_accuracy: 0.7521\n",
      "Epoch 118/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5767 - accuracy: 0.7960\n",
      "Epoch 118: val_loss did not improve from 0.65362\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7996 - val_loss: 0.6538 - val_accuracy: 0.7500\n",
      "Epoch 119/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5820 - accuracy: 0.7933\n",
      "Epoch 119: val_loss did not improve from 0.65362\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5808 - accuracy: 0.7949 - val_loss: 0.6549 - val_accuracy: 0.7542\n",
      "Epoch 120/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5817 - accuracy: 0.7913\n",
      "Epoch 120: val_loss improved from 0.65362 to 0.65227, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5803 - accuracy: 0.7922 - val_loss: 0.6523 - val_accuracy: 0.7521\n",
      "Epoch 121/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5578 - accuracy: 0.8055\n",
      "Epoch 121: val_loss improved from 0.65227 to 0.65144, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5590 - accuracy: 0.8054 - val_loss: 0.6514 - val_accuracy: 0.7521\n",
      "Epoch 122/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5741 - accuracy: 0.8045\n",
      "Epoch 122: val_loss improved from 0.65144 to 0.65034, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5742 - accuracy: 0.8059 - val_loss: 0.6503 - val_accuracy: 0.7521\n",
      "Epoch 123/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5684 - accuracy: 0.7917\n",
      "Epoch 123: val_loss improved from 0.65034 to 0.64960, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5687 - accuracy: 0.7922 - val_loss: 0.6496 - val_accuracy: 0.7542\n",
      "Epoch 124/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5651 - accuracy: 0.8045\n",
      "Epoch 124: val_loss did not improve from 0.64960\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5651 - accuracy: 0.8048 - val_loss: 0.6503 - val_accuracy: 0.7521\n",
      "Epoch 125/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5674 - accuracy: 0.7926\n",
      "Epoch 125: val_loss improved from 0.64960 to 0.64954, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5667 - accuracy: 0.7954 - val_loss: 0.6495 - val_accuracy: 0.7500\n",
      "Epoch 126/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5636 - accuracy: 0.7903\n",
      "Epoch 126: val_loss improved from 0.64954 to 0.64838, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5628 - accuracy: 0.7917 - val_loss: 0.6484 - val_accuracy: 0.7542\n",
      "Epoch 127/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5595 - accuracy: 0.8066\n",
      "Epoch 127: val_loss did not improve from 0.64838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.8075 - val_loss: 0.6484 - val_accuracy: 0.7563\n",
      "Epoch 128/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5564 - accuracy: 0.7993\n",
      "Epoch 128: val_loss did not improve from 0.64838\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7985 - val_loss: 0.6492 - val_accuracy: 0.7542\n",
      "Epoch 129/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5588 - accuracy: 0.7997\n",
      "Epoch 129: val_loss improved from 0.64838 to 0.64737, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5602 - accuracy: 0.7991 - val_loss: 0.6474 - val_accuracy: 0.7521\n",
      "Epoch 130/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5549 - accuracy: 0.8051\n",
      "Epoch 130: val_loss improved from 0.64737 to 0.64572, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5547 - accuracy: 0.8054 - val_loss: 0.6457 - val_accuracy: 0.7542\n",
      "Epoch 131/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5437 - accuracy: 0.8027\n",
      "Epoch 131: val_loss did not improve from 0.64572\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5440 - accuracy: 0.8017 - val_loss: 0.6471 - val_accuracy: 0.7458\n",
      "Epoch 132/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5510 - accuracy: 0.8082\n",
      "Epoch 132: val_loss did not improve from 0.64572\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5499 - accuracy: 0.8090 - val_loss: 0.6460 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5611 - accuracy: 0.8114\n",
      "Epoch 133: val_loss did not improve from 0.64572\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.8122 - val_loss: 0.6471 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5681 - accuracy: 0.7975\n",
      "Epoch 134: val_loss improved from 0.64572 to 0.64430, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5691 - accuracy: 0.7975 - val_loss: 0.6443 - val_accuracy: 0.7479\n",
      "Epoch 135/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5518 - accuracy: 0.8040\n",
      "Epoch 135: val_loss improved from 0.64430 to 0.64304, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\bestModel-fold4.hdf5\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5545 - accuracy: 0.8033 - val_loss: 0.6430 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5462 - accuracy: 0.8043\n",
      "Epoch 136: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5520 - accuracy: 0.8038 - val_loss: 0.6433 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5366 - accuracy: 0.8167\n",
      "Epoch 137: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.8158 - val_loss: 0.6440 - val_accuracy: 0.7479\n",
      "Epoch 138/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5486 - accuracy: 0.8141\n",
      "Epoch 138: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.8143 - val_loss: 0.6431 - val_accuracy: 0.7542\n",
      "Epoch 139/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.8178\n",
      "Epoch 139: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5399 - accuracy: 0.8164 - val_loss: 0.6453 - val_accuracy: 0.7521\n",
      "Epoch 140/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5570 - accuracy: 0.8066\n",
      "Epoch 140: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5534 - accuracy: 0.8095 - val_loss: 0.6440 - val_accuracy: 0.7563\n",
      "Epoch 141/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5380 - accuracy: 0.8077\n",
      "Epoch 141: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.8054 - val_loss: 0.6443 - val_accuracy: 0.7542\n",
      "Epoch 142/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.8157\n",
      "Epoch 142: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5383 - accuracy: 0.8158 - val_loss: 0.6439 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.5332 - accuracy: 0.8158\n",
      "Epoch 143: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5325 - accuracy: 0.8179 - val_loss: 0.6461 - val_accuracy: 0.7542\n",
      "Epoch 144/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5268 - accuracy: 0.8114\n",
      "Epoch 144: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5273 - accuracy: 0.8106 - val_loss: 0.6463 - val_accuracy: 0.7563\n",
      "Epoch 145/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5283 - accuracy: 0.8147\n",
      "Epoch 145: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5292 - accuracy: 0.8137 - val_loss: 0.6461 - val_accuracy: 0.7542\n",
      "Epoch 146/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5197 - accuracy: 0.8157\n",
      "Epoch 146: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5182 - accuracy: 0.8164 - val_loss: 0.6475 - val_accuracy: 0.7521\n",
      "Epoch 147/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5137 - accuracy: 0.8253\n",
      "Epoch 147: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.8237 - val_loss: 0.6484 - val_accuracy: 0.7605\n",
      "Epoch 148/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5474 - accuracy: 0.8033\n",
      "Epoch 148: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5460 - accuracy: 0.8038 - val_loss: 0.6446 - val_accuracy: 0.7647\n",
      "Epoch 149/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5254 - accuracy: 0.8120\n",
      "Epoch 149: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.8127 - val_loss: 0.6445 - val_accuracy: 0.7647\n",
      "Epoch 150/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5207 - accuracy: 0.8146\n",
      "Epoch 150: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.8148 - val_loss: 0.6458 - val_accuracy: 0.7605\n",
      "Epoch 151/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.5342 - accuracy: 0.8114\n",
      "Epoch 151: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5317 - accuracy: 0.8132 - val_loss: 0.6438 - val_accuracy: 0.7605\n",
      "Epoch 152/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.8248\n",
      "Epoch 152: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.8248 - val_loss: 0.6452 - val_accuracy: 0.7584\n",
      "Epoch 153/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5085 - accuracy: 0.8342\n",
      "Epoch 153: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5092 - accuracy: 0.8337 - val_loss: 0.6455 - val_accuracy: 0.7626\n",
      "Epoch 154/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.5225 - accuracy: 0.8190\n",
      "Epoch 154: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.8221 - val_loss: 0.6439 - val_accuracy: 0.7584\n",
      "Epoch 155/200\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.5137 - accuracy: 0.8354\n",
      "Epoch 155: val_loss did not improve from 0.64304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5122 - accuracy: 0.8353 - val_loss: 0.6439 - val_accuracy: 0.7542\n",
      "Epoch 156/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5108 - accuracy: 0.8220\n",
      "Epoch 156: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.8221 - val_loss: 0.6465 - val_accuracy: 0.7542\n",
      "Epoch 157/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5092 - accuracy: 0.8257\n",
      "Epoch 157: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.8248 - val_loss: 0.6462 - val_accuracy: 0.7584\n",
      "Epoch 158/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.5123 - accuracy: 0.8328\n",
      "Epoch 158: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.8326 - val_loss: 0.6460 - val_accuracy: 0.7584\n",
      "Epoch 159/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.5142 - accuracy: 0.8252\n",
      "Epoch 159: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5151 - accuracy: 0.8258 - val_loss: 0.6474 - val_accuracy: 0.7584\n",
      "Epoch 160/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5010 - accuracy: 0.8309\n",
      "Epoch 160: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.8305 - val_loss: 0.6460 - val_accuracy: 0.7605\n",
      "Epoch 161/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5013 - accuracy: 0.8293\n",
      "Epoch 161: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.8295 - val_loss: 0.6451 - val_accuracy: 0.7626\n",
      "Epoch 162/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.5112 - accuracy: 0.8316\n",
      "Epoch 162: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5107 - accuracy: 0.8305 - val_loss: 0.6435 - val_accuracy: 0.7584\n",
      "Epoch 163/200\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.5051 - accuracy: 0.8228\n",
      "Epoch 163: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5036 - accuracy: 0.8237 - val_loss: 0.6446 - val_accuracy: 0.7605\n",
      "Epoch 164/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5005 - accuracy: 0.8242\n",
      "Epoch 164: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.8242 - val_loss: 0.6469 - val_accuracy: 0.7605\n",
      "Epoch 165/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4934 - accuracy: 0.8308\n",
      "Epoch 165: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.8311 - val_loss: 0.6504 - val_accuracy: 0.7647\n",
      "Epoch 166/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4902 - accuracy: 0.8252\n",
      "Epoch 166: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.8258 - val_loss: 0.6483 - val_accuracy: 0.7626\n",
      "Epoch 167/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.8258\n",
      "Epoch 167: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.8258 - val_loss: 0.6484 - val_accuracy: 0.7626\n",
      "Epoch 168/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4776 - accuracy: 0.8392\n",
      "Epoch 168: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.8384 - val_loss: 0.6493 - val_accuracy: 0.7689\n",
      "Epoch 169/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4857 - accuracy: 0.8371\n",
      "Epoch 169: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.8353 - val_loss: 0.6487 - val_accuracy: 0.7710\n",
      "Epoch 170/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4819 - accuracy: 0.8356\n",
      "Epoch 170: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.8353 - val_loss: 0.6490 - val_accuracy: 0.7731\n",
      "Epoch 171/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4903 - accuracy: 0.8281\n",
      "Epoch 171: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4890 - accuracy: 0.8295 - val_loss: 0.6494 - val_accuracy: 0.7731\n",
      "Epoch 172/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4924 - accuracy: 0.8360\n",
      "Epoch 172: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.8363 - val_loss: 0.6491 - val_accuracy: 0.7668\n",
      "Epoch 173/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4756 - accuracy: 0.8493\n",
      "Epoch 173: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.8494 - val_loss: 0.6493 - val_accuracy: 0.7668\n",
      "Epoch 174/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.4754 - accuracy: 0.8407\n",
      "Epoch 174: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4805 - accuracy: 0.8400 - val_loss: 0.6529 - val_accuracy: 0.7752\n",
      "Epoch 175/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4864 - accuracy: 0.8276\n",
      "Epoch 175: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.8295 - val_loss: 0.6492 - val_accuracy: 0.7689\n",
      "Epoch 176/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4810 - accuracy: 0.8392\n",
      "Epoch 176: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.8405 - val_loss: 0.6494 - val_accuracy: 0.7752\n",
      "Epoch 177/200\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.4708 - accuracy: 0.8420\n",
      "Epoch 177: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.8358 - val_loss: 0.6518 - val_accuracy: 0.7752\n",
      "Epoch 178/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.8470\n",
      "Epoch 178: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4849 - accuracy: 0.8452 - val_loss: 0.6516 - val_accuracy: 0.7731\n",
      "Epoch 179/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4842 - accuracy: 0.8453\n",
      "Epoch 179: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.8458 - val_loss: 0.6521 - val_accuracy: 0.7710\n",
      "Epoch 180/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4760 - accuracy: 0.8389\n",
      "Epoch 180: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4735 - accuracy: 0.8410 - val_loss: 0.6522 - val_accuracy: 0.7731\n",
      "Epoch 181/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4647 - accuracy: 0.8466\n",
      "Epoch 181: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.8468 - val_loss: 0.6540 - val_accuracy: 0.7710\n",
      "Epoch 182/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.8448\n",
      "Epoch 182: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.8447 - val_loss: 0.6539 - val_accuracy: 0.7731\n",
      "Epoch 183/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4634 - accuracy: 0.8454\n",
      "Epoch 183: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4592 - accuracy: 0.8494 - val_loss: 0.6550 - val_accuracy: 0.7773\n",
      "Epoch 184/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4653 - accuracy: 0.8498\n",
      "Epoch 184: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.8499 - val_loss: 0.6555 - val_accuracy: 0.7752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4652 - accuracy: 0.8416\n",
      "Epoch 185: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.8421 - val_loss: 0.6522 - val_accuracy: 0.7773\n",
      "Epoch 186/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4629 - accuracy: 0.8478\n",
      "Epoch 186: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.8478 - val_loss: 0.6504 - val_accuracy: 0.7752\n",
      "Epoch 187/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.8416\n",
      "Epoch 187: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.8416 - val_loss: 0.6487 - val_accuracy: 0.7773\n",
      "Epoch 188/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4553 - accuracy: 0.8556\n",
      "Epoch 188: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.8541 - val_loss: 0.6491 - val_accuracy: 0.7752\n",
      "Epoch 189/200\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.4456 - accuracy: 0.8551\n",
      "Epoch 189: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4485 - accuracy: 0.8541 - val_loss: 0.6555 - val_accuracy: 0.7710\n",
      "Epoch 190/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4651 - accuracy: 0.8435\n",
      "Epoch 190: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.8437 - val_loss: 0.6564 - val_accuracy: 0.7731\n",
      "Epoch 191/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4396 - accuracy: 0.8628\n",
      "Epoch 191: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8631 - val_loss: 0.6601 - val_accuracy: 0.7731\n",
      "Epoch 192/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4467 - accuracy: 0.8631\n",
      "Epoch 192: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4481 - accuracy: 0.8615 - val_loss: 0.6610 - val_accuracy: 0.7710\n",
      "Epoch 193/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4401 - accuracy: 0.8518\n",
      "Epoch 193: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4388 - accuracy: 0.8531 - val_loss: 0.6638 - val_accuracy: 0.7752\n",
      "Epoch 194/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4519 - accuracy: 0.8551\n",
      "Epoch 194: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4521 - accuracy: 0.8547 - val_loss: 0.6631 - val_accuracy: 0.7752\n",
      "Epoch 195/200\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.4468 - accuracy: 0.8579\n",
      "Epoch 195: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.8578 - val_loss: 0.6619 - val_accuracy: 0.7773\n",
      "Epoch 196/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4336 - accuracy: 0.8648\n",
      "Epoch 196: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8662 - val_loss: 0.6613 - val_accuracy: 0.7689\n",
      "Epoch 197/200\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.4417 - accuracy: 0.8583\n",
      "Epoch 197: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.8578 - val_loss: 0.6619 - val_accuracy: 0.7752\n",
      "Epoch 198/200\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4411 - accuracy: 0.8598\n",
      "Epoch 198: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8599 - val_loss: 0.6596 - val_accuracy: 0.7731\n",
      "Epoch 199/200\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.4323 - accuracy: 0.8640\n",
      "Epoch 199: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.8604 - val_loss: 0.6623 - val_accuracy: 0.7689\n",
      "Epoch 200/200\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.4560 - accuracy: 0.8543\n",
      "Epoch 200: val_loss did not improve from 0.64304\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.8557 - val_loss: 0.6579 - val_accuracy: 0.7731\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Train/Test model on all folds, generate evaluations\n",
    "##################################################################################\n",
    "\n",
    "## Create and set directory to save model\n",
    "modelPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold), \"models\")\n",
    "if(not os.path.isdir(modelPath)):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "i = -1\n",
    "for fold in folds:\n",
    "    i += 1\n",
    "    \n",
    "    print(\"\\nTrain/Test model on Fold #\"+str(i)+\".\")\n",
    "    \n",
    "    model = DLNN_Classifier(input_vec_shape = input_vec_shape)\n",
    "    \n",
    "    ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    modelCallbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                           monitor = monitor, verbose = 1, save_best_only = True, \n",
    "                                           save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "    ]\n",
    "    \n",
    "    # adding random shuffling of the dataset for training purpose\n",
    "    index_arr = np.arange(fold[\"X_train\"].shape[0])\n",
    "    index_arr = np.random.permutation(index_arr)\n",
    "    \n",
    "    model.fit(x = fold[\"X_train\"][index_arr], y = fold[\"y_train\"][index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "              callbacks = modelCallbacks, validation_data = (fold[\"X_test\"], fold[\"y_test\"]))\n",
    "    \n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TRAIN dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_train\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "    mcc = matthews_corrcoef(fold[\"y_train\"], label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Train\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TEST dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_test\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "    mcc = matthews_corrcoef(fold[\"y_test\"], label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Test\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.739718</td>\n",
       "      <td>0.757655</td>\n",
       "      <td>0.810415</td>\n",
       "      <td>0.707795</td>\n",
       "      <td>0.771615</td>\n",
       "      <td>0.481568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.835643</td>\n",
       "      <td>0.856347</td>\n",
       "      <td>0.918553</td>\n",
       "      <td>0.806887</td>\n",
       "      <td>0.864397</td>\n",
       "      <td>0.672569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                   \n",
       "Test        0.739718   0.757655  0.810415     0.707795     0.771615  0.481568\n",
       "Train       0.835643   0.856347  0.918553     0.806887     0.864397  0.672569"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.725367</td>\n",
       "      <td>0.726891</td>\n",
       "      <td>[0.0, 0.0041841004184100415, 0.071129707112970...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.999749, 0.999749, 0.9904192, 0.98997295, 0....</td>\n",
       "      <td>0.796755</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.726891</td>\n",
       "      <td>0.450740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.746331</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0546218487394958...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0041841004184100415, 0.00418...</td>\n",
       "      <td>[1.9977884, 0.9977884, 0.9898033, 0.9857631, 0...</td>\n",
       "      <td>0.801009</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.493571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.733193</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0714285714285714...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9999557, 0.99995565, 0.9865463, 0.9865393, ...</td>\n",
       "      <td>0.808541</td>\n",
       "      <td>0.697479</td>\n",
       "      <td>0.768908</td>\n",
       "      <td>0.467581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.743697</td>\n",
       "      <td>0.798969</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0504201680672268...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9996699, 0.9996699, 0.99448156, 0.99418336,...</td>\n",
       "      <td>0.812937</td>\n",
       "      <td>0.651261</td>\n",
       "      <td>0.836134</td>\n",
       "      <td>0.495944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.748954</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0420168067226890...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9999757, 0.9999757, 0.9991516, 0.9982273, 0...</td>\n",
       "      <td>0.832833</td>\n",
       "      <td>0.752101</td>\n",
       "      <td>0.747899</td>\n",
       "      <td>0.500004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Train_Test  Accuracy  Precision  \\\n",
       "1     0       Test  0.725367   0.726891   \n",
       "3     1       Test  0.746331   0.762332   \n",
       "5     2       Test  0.733193   0.751131   \n",
       "7     3       Test  0.743697   0.798969   \n",
       "9     4       Test  0.750000   0.748954   \n",
       "\n",
       "                                                 TPR  \\\n",
       "1  [0.0, 0.0041841004184100415, 0.071129707112970...   \n",
       "3  [0.0, 0.004201680672268907, 0.0546218487394958...   \n",
       "5  [0.0, 0.004201680672268907, 0.0714285714285714...   \n",
       "7  [0.0, 0.004201680672268907, 0.0504201680672268...   \n",
       "9  [0.0, 0.004201680672268907, 0.0420168067226890...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "1  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "3  [0.0, 0.0, 0.0, 0.0041841004184100415, 0.00418...   \n",
       "5  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "7  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "9  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "1  [1.999749, 0.999749, 0.9904192, 0.98997295, 0....  0.796755     0.723849   \n",
       "3  [1.9977884, 0.9977884, 0.9898033, 0.9857631, 0...  0.801009     0.714286   \n",
       "5  [1.9999557, 0.99995565, 0.9865463, 0.9865393, ...  0.808541     0.697479   \n",
       "7  [1.9996699, 0.9996699, 0.99448156, 0.99418336,...  0.812937     0.651261   \n",
       "9  [1.9999757, 0.9999757, 0.9991516, 0.9982273, 0...  0.832833     0.752101   \n",
       "\n",
       "   Specificity       MCC  \n",
       "1     0.726891  0.450740  \n",
       "3     0.778243  0.493571  \n",
       "5     0.768908  0.467581  \n",
       "7     0.836134  0.495944  \n",
       "9     0.747899  0.500004  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df[evaluations_df[\"Train_Test\"] == 'Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.849344</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>[0.0, 0.0010504201680672268, 0.031512605042016...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.9999899, 0.99998987, 0.99802667, 0.9979911,...</td>\n",
       "      <td>0.928331</td>\n",
       "      <td>0.818277</td>\n",
       "      <td>0.880378</td>\n",
       "      <td>0.700022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.725367</td>\n",
       "      <td>0.726891</td>\n",
       "      <td>[0.0, 0.0041841004184100415, 0.071129707112970...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.999749, 0.999749, 0.9904192, 0.98997295, 0....</td>\n",
       "      <td>0.796755</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.726891</td>\n",
       "      <td>0.450740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.829396</td>\n",
       "      <td>0.846578</td>\n",
       "      <td>[0.0, 0.001049317943336831, 0.0136411332633788...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00105042...</td>\n",
       "      <td>[1.9999757, 0.9999757, 0.9973654, 0.99733377, ...</td>\n",
       "      <td>0.909746</td>\n",
       "      <td>0.804827</td>\n",
       "      <td>0.853992</td>\n",
       "      <td>0.659605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.746331</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0546218487394958...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0041841004184100415, 0.00418...</td>\n",
       "      <td>[1.9977884, 0.9977884, 0.9898033, 0.9857631, 0...</td>\n",
       "      <td>0.801009</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.493571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.815845</td>\n",
       "      <td>0.827174</td>\n",
       "      <td>[0.0, 0.001049317943336831, 0.0545645330535152...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.001049317943336831, 0.001049...</td>\n",
       "      <td>[1.9991243, 0.9991242, 0.98641765, 0.9861864, ...</td>\n",
       "      <td>0.904854</td>\n",
       "      <td>0.798531</td>\n",
       "      <td>0.833158</td>\n",
       "      <td>0.632068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.733193</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0714285714285714...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9999557, 0.99995565, 0.9865463, 0.9865393, ...</td>\n",
       "      <td>0.808541</td>\n",
       "      <td>0.697479</td>\n",
       "      <td>0.768908</td>\n",
       "      <td>0.467581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.830010</td>\n",
       "      <td>0.866123</td>\n",
       "      <td>[0.0, 0.001049317943336831, 0.0451206715634837...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00104931...</td>\n",
       "      <td>[1.9999998, 0.99999976, 0.99702615, 0.9970023,...</td>\n",
       "      <td>0.916085</td>\n",
       "      <td>0.780693</td>\n",
       "      <td>0.879328</td>\n",
       "      <td>0.663255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.743697</td>\n",
       "      <td>0.798969</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0504201680672268...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9996699, 0.9996699, 0.99448156, 0.99418336,...</td>\n",
       "      <td>0.812937</td>\n",
       "      <td>0.651261</td>\n",
       "      <td>0.836134</td>\n",
       "      <td>0.495944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.853620</td>\n",
       "      <td>0.869518</td>\n",
       "      <td>[0.0, 0.001049317943336831, 0.0430220356768100...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.9999977, 0.99999774, 0.9981901, 0.99815446,...</td>\n",
       "      <td>0.933750</td>\n",
       "      <td>0.832109</td>\n",
       "      <td>0.875131</td>\n",
       "      <td>0.707896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.748954</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0420168067226890...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9999757, 0.9999757, 0.9991516, 0.9982273, 0...</td>\n",
       "      <td>0.832833</td>\n",
       "      <td>0.752101</td>\n",
       "      <td>0.747899</td>\n",
       "      <td>0.500004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Train_Test  Accuracy  Precision  \\\n",
       "0     0      Train  0.849344   0.872340   \n",
       "1     0       Test  0.725367   0.726891   \n",
       "2     1      Train  0.829396   0.846578   \n",
       "3     1       Test  0.746331   0.762332   \n",
       "4     2      Train  0.815845   0.827174   \n",
       "5     2       Test  0.733193   0.751131   \n",
       "6     3      Train  0.830010   0.866123   \n",
       "7     3       Test  0.743697   0.798969   \n",
       "8     4      Train  0.853620   0.869518   \n",
       "9     4       Test  0.750000   0.748954   \n",
       "\n",
       "                                                 TPR  \\\n",
       "0  [0.0, 0.0010504201680672268, 0.031512605042016...   \n",
       "1  [0.0, 0.0041841004184100415, 0.071129707112970...   \n",
       "2  [0.0, 0.001049317943336831, 0.0136411332633788...   \n",
       "3  [0.0, 0.004201680672268907, 0.0546218487394958...   \n",
       "4  [0.0, 0.001049317943336831, 0.0545645330535152...   \n",
       "5  [0.0, 0.004201680672268907, 0.0714285714285714...   \n",
       "6  [0.0, 0.001049317943336831, 0.0451206715634837...   \n",
       "7  [0.0, 0.004201680672268907, 0.0504201680672268...   \n",
       "8  [0.0, 0.001049317943336831, 0.0430220356768100...   \n",
       "9  [0.0, 0.004201680672268907, 0.0420168067226890...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00105042...   \n",
       "3  [0.0, 0.0, 0.0, 0.0041841004184100415, 0.00418...   \n",
       "4  [0.0, 0.0, 0.0, 0.001049317943336831, 0.001049...   \n",
       "5  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00104931...   \n",
       "7  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0  [1.9999899, 0.99998987, 0.99802667, 0.9979911,...  0.928331     0.818277   \n",
       "1  [1.999749, 0.999749, 0.9904192, 0.98997295, 0....  0.796755     0.723849   \n",
       "2  [1.9999757, 0.9999757, 0.9973654, 0.99733377, ...  0.909746     0.804827   \n",
       "3  [1.9977884, 0.9977884, 0.9898033, 0.9857631, 0...  0.801009     0.714286   \n",
       "4  [1.9991243, 0.9991242, 0.98641765, 0.9861864, ...  0.904854     0.798531   \n",
       "5  [1.9999557, 0.99995565, 0.9865463, 0.9865393, ...  0.808541     0.697479   \n",
       "6  [1.9999998, 0.99999976, 0.99702615, 0.9970023,...  0.916085     0.780693   \n",
       "7  [1.9996699, 0.9996699, 0.99448156, 0.99418336,...  0.812937     0.651261   \n",
       "8  [1.9999977, 0.99999774, 0.9981901, 0.99815446,...  0.933750     0.832109   \n",
       "9  [1.9999757, 0.9999757, 0.9991516, 0.9982273, 0...  0.832833     0.752101   \n",
       "\n",
       "   Specificity       MCC  \n",
       "0     0.880378  0.700022  \n",
       "1     0.726891  0.450740  \n",
       "2     0.853992  0.659605  \n",
       "3     0.778243  0.493571  \n",
       "4     0.833158  0.632068  \n",
       "5     0.768908  0.467581  \n",
       "6     0.879328  0.663255  \n",
       "7     0.836134  0.495944  \n",
       "8     0.875131  0.707896  \n",
       "9     0.747899  0.500004  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent data evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using k-fold Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of each k-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.615837</td>\n",
       "      <td>0.236618</td>\n",
       "      <td>0.643466</td>\n",
       "      <td>0.592118</td>\n",
       "      <td>0.620548</td>\n",
       "      <td>0.160545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.615837   0.236618  0.643466     0.592118     0.620548  0.160545"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    label_pred = pred2label(y_pred)\n",
    "\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(indpe_labels, label_pred)\n",
    "    prec = precision_score(indpe_labels,label_pred)\n",
    "    mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "    conf = confusion_matrix(indpe_labels, label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "    auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.613878</td>\n",
       "      <td>0.242366</td>\n",
       "      <td>[0.0, 0.0, 0.009852216748768473, 0.00985221674...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.000978473581213...</td>\n",
       "      <td>[1.9999899, 0.99998987, 0.9995154, 0.999508, 0...</td>\n",
       "      <td>0.654114</td>\n",
       "      <td>0.625616</td>\n",
       "      <td>0.611546</td>\n",
       "      <td>0.178235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.604898</td>\n",
       "      <td>0.229287</td>\n",
       "      <td>[0.0, 0.0, 0.014778325123152709, 0.01477832512...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.000978473581213...</td>\n",
       "      <td>[1.9999757, 0.9999757, 0.9988452, 0.99510694, ...</td>\n",
       "      <td>0.642474</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.608611</td>\n",
       "      <td>0.146594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.613878</td>\n",
       "      <td>0.237354</td>\n",
       "      <td>[0.0, 0.0, 0.014778325123152709, 0.01477832512...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.000978473581213...</td>\n",
       "      <td>[1.9999557, 0.99995565, 0.9975981, 0.9972519, ...</td>\n",
       "      <td>0.639143</td>\n",
       "      <td>0.600985</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.163819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.630204</td>\n",
       "      <td>0.237395</td>\n",
       "      <td>[0.0, 0.0, 0.029556650246305417, 0.02955665024...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.000978473581213...</td>\n",
       "      <td>[1.9999998, 0.99999976, 0.99844724, 0.9980725,...</td>\n",
       "      <td>0.642296</td>\n",
       "      <td>0.556650</td>\n",
       "      <td>0.644814</td>\n",
       "      <td>0.153684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.616327</td>\n",
       "      <td>0.236686</td>\n",
       "      <td>[0.0, 0.0, 0.009852216748768473, 0.00985221674...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.000978473581213...</td>\n",
       "      <td>[1.9999977, 0.99999774, 0.99992156, 0.99951375...</td>\n",
       "      <td>0.639302</td>\n",
       "      <td>0.591133</td>\n",
       "      <td>0.621331</td>\n",
       "      <td>0.160395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold   Train_Test  Accuracy  Precision  \\\n",
       "0     0  Independent  0.613878   0.242366   \n",
       "1     1  Independent  0.604898   0.229287   \n",
       "2     2  Independent  0.613878   0.237354   \n",
       "3     3  Independent  0.630204   0.237395   \n",
       "4     4  Independent  0.616327   0.236686   \n",
       "\n",
       "                                                 TPR  \\\n",
       "0  [0.0, 0.0, 0.009852216748768473, 0.00985221674...   \n",
       "1  [0.0, 0.0, 0.014778325123152709, 0.01477832512...   \n",
       "2  [0.0, 0.0, 0.014778325123152709, 0.01477832512...   \n",
       "3  [0.0, 0.0, 0.029556650246305417, 0.02955665024...   \n",
       "4  [0.0, 0.0, 0.009852216748768473, 0.00985221674...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "0  [0.0, 0.0009784735812133072, 0.000978473581213...   \n",
       "1  [0.0, 0.0009784735812133072, 0.000978473581213...   \n",
       "2  [0.0, 0.0009784735812133072, 0.000978473581213...   \n",
       "3  [0.0, 0.0009784735812133072, 0.000978473581213...   \n",
       "4  [0.0, 0.0009784735812133072, 0.000978473581213...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0  [1.9999899, 0.99998987, 0.9995154, 0.999508, 0...  0.654114     0.625616   \n",
       "1  [1.9999757, 0.9999757, 0.9988452, 0.99510694, ...  0.642474     0.586207   \n",
       "2  [1.9999557, 0.99995565, 0.9975981, 0.9972519, ...  0.639143     0.600985   \n",
       "3  [1.9999998, 0.99999976, 0.99844724, 0.9980725,...  0.642296     0.556650   \n",
       "4  [1.9999977, 0.99999774, 0.99992156, 0.99951375...  0.639302     0.591133   \n",
       "\n",
       "   Specificity       MCC  \n",
       "0     0.611546  0.178235  \n",
       "1     0.608611  0.146594  \n",
       "2     0.616438  0.163819  \n",
       "3     0.644814  0.153684  \n",
       "4     0.621331  0.160395  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.618776</td>\n",
       "      <td>0.237052</td>\n",
       "      <td>0.648822</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.625245</td>\n",
       "      <td>0.159869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.618776   0.237052  0.648822     0.586207     0.625245  0.159869"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    total_pred += y_pred\n",
    "    all_preds.append(y_pred)\n",
    "    \n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.62449</td>\n",
       "      <td>0.242485</td>\n",
       "      <td>0.630773</td>\n",
       "      <td>0.596059</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.171175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent   0.62449   0.242485  0.630773     0.596059     0.630137  0.171175"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    vote_pred = pred2label(y_pred)\n",
    "    total_pred += vote_pred\n",
    "    all_preds.append(vote_pred)\n",
    "    \n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using New Model\n",
    "\n",
    "Train model on full data from training. Predict and evaluate on Independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "141/149 [===========================>..] - ETA: 0s - loss: 1.0671 - accuracy: 0.5106\n",
      "Epoch 1: val_loss improved from inf to 0.99425, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 1.0642 - accuracy: 0.5118 - val_loss: 0.9943 - val_accuracy: 0.4384\n",
      "Epoch 2/200\n",
      "140/149 [===========================>..] - ETA: 0s - loss: 1.0260 - accuracy: 0.5308\n",
      "Epoch 2: val_loss improved from 0.99425 to 0.95789, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 1.0270 - accuracy: 0.5281 - val_loss: 0.9579 - val_accuracy: 0.5927\n",
      "Epoch 3/200\n",
      "140/149 [===========================>..] - ETA: 0s - loss: 1.0159 - accuracy: 0.5214\n",
      "Epoch 3: val_loss improved from 0.95789 to 0.93536, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 1.0139 - accuracy: 0.5223 - val_loss: 0.9354 - val_accuracy: 0.6629\n",
      "Epoch 4/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.9927 - accuracy: 0.5283\n",
      "Epoch 4: val_loss did not improve from 0.93536\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.9916 - accuracy: 0.5294 - val_loss: 0.9359 - val_accuracy: 0.6506\n",
      "Epoch 5/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.9729 - accuracy: 0.5612\n",
      "Epoch 5: val_loss improved from 0.93536 to 0.92832, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.9748 - accuracy: 0.5584 - val_loss: 0.9283 - val_accuracy: 0.6767\n",
      "Epoch 6/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.9619 - accuracy: 0.5764\n",
      "Epoch 6: val_loss improved from 0.92832 to 0.92395, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.9603 - accuracy: 0.5764 - val_loss: 0.9239 - val_accuracy: 0.6849\n",
      "Epoch 7/200\n",
      "141/149 [===========================>..] - ETA: 0s - loss: 0.9514 - accuracy: 0.5705\n",
      "Epoch 7: val_loss did not improve from 0.92395\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.9537 - accuracy: 0.5684 - val_loss: 0.9258 - val_accuracy: 0.6686\n",
      "Epoch 8/200\n",
      "143/149 [===========================>..] - ETA: 0s - loss: 0.9550 - accuracy: 0.5691\n",
      "Epoch 8: val_loss improved from 0.92395 to 0.91962, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.9547 - accuracy: 0.5668 - val_loss: 0.9196 - val_accuracy: 0.6800\n",
      "Epoch 9/200\n",
      "142/149 [===========================>..] - ETA: 0s - loss: 0.9384 - accuracy: 0.5766\n",
      "Epoch 9: val_loss did not improve from 0.91962\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.9389 - accuracy: 0.5764 - val_loss: 0.9216 - val_accuracy: 0.6727\n",
      "Epoch 10/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.9260 - accuracy: 0.5890\n",
      "Epoch 10: val_loss improved from 0.91962 to 0.91766, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.9266 - accuracy: 0.5873 - val_loss: 0.9177 - val_accuracy: 0.6678\n",
      "Epoch 11/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.9179 - accuracy: 0.5995\n",
      "Epoch 11: val_loss did not improve from 0.91766\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.9173 - accuracy: 0.6033 - val_loss: 0.9182 - val_accuracy: 0.6645\n",
      "Epoch 12/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.9108 - accuracy: 0.6020\n",
      "Epoch 12: val_loss improved from 0.91766 to 0.91408, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.9099 - accuracy: 0.6041 - val_loss: 0.9141 - val_accuracy: 0.6653\n",
      "Epoch 13/200\n",
      "143/149 [===========================>..] - ETA: 0s - loss: 0.9027 - accuracy: 0.6359\n",
      "Epoch 13: val_loss improved from 0.91408 to 0.91009, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.9047 - accuracy: 0.6335 - val_loss: 0.9101 - val_accuracy: 0.6653\n",
      "Epoch 14/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.8985 - accuracy: 0.6124\n",
      "Epoch 14: val_loss did not improve from 0.91009\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.8976 - accuracy: 0.6138 - val_loss: 0.9112 - val_accuracy: 0.6588\n",
      "Epoch 15/200\n",
      "142/149 [===========================>..] - ETA: 0s - loss: 0.8744 - accuracy: 0.6607\n",
      "Epoch 15: val_loss improved from 0.91009 to 0.90661, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.8735 - accuracy: 0.6608 - val_loss: 0.9066 - val_accuracy: 0.6596\n",
      "Epoch 16/200\n",
      "143/149 [===========================>..] - ETA: 0s - loss: 0.8747 - accuracy: 0.6447\n",
      "Epoch 16: val_loss did not improve from 0.90661\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.8741 - accuracy: 0.6448 - val_loss: 0.9097 - val_accuracy: 0.6506\n",
      "Epoch 17/200\n",
      "143/149 [===========================>..] - ETA: 0s - loss: 0.8689 - accuracy: 0.6534\n",
      "Epoch 17: val_loss improved from 0.90661 to 0.90253, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_KgapRFE\\5fold\\models\\_fullModel.hdf5\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.8663 - accuracy: 0.6562 - val_loss: 0.9025 - val_accuracy: 0.6563\n",
      "Epoch 18/200\n",
      "139/149 [==========================>...] - ETA: 0s - loss: 0.8591 - accuracy: 0.6565\n",
      "Epoch 18: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.8571 - accuracy: 0.6574 - val_loss: 0.9044 - val_accuracy: 0.6482\n",
      "Epoch 19/200\n",
      "141/149 [===========================>..] - ETA: 0s - loss: 0.8453 - accuracy: 0.6645\n",
      "Epoch 19: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.8474 - accuracy: 0.6625 - val_loss: 0.9136 - val_accuracy: 0.6359\n",
      "Epoch 20/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.8379 - accuracy: 0.6771\n",
      "Epoch 20: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.8349 - accuracy: 0.6809 - val_loss: 0.9026 - val_accuracy: 0.6506\n",
      "Epoch 21/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.8257 - accuracy: 0.6958\n",
      "Epoch 21: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8257 - accuracy: 0.6914 - val_loss: 0.9134 - val_accuracy: 0.6416\n",
      "Epoch 22/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.8151 - accuracy: 0.6940\n",
      "Epoch 22: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.8201 - accuracy: 0.6952 - val_loss: 0.9177 - val_accuracy: 0.6400\n",
      "Epoch 23/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.8008 - accuracy: 0.7191\n",
      "Epoch 23: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8008 - accuracy: 0.7191 - val_loss: 0.9328 - val_accuracy: 0.6253\n",
      "Epoch 24/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.8004 - accuracy: 0.7106\n",
      "Epoch 24: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8021 - accuracy: 0.7078 - val_loss: 0.9154 - val_accuracy: 0.6441\n",
      "Epoch 25/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.8064 - accuracy: 0.7181\n",
      "Epoch 25: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.8064 - accuracy: 0.7170 - val_loss: 0.9155 - val_accuracy: 0.6392\n",
      "Epoch 26/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.7961 - accuracy: 0.7057\n",
      "Epoch 26: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7961 - accuracy: 0.7057 - val_loss: 0.9206 - val_accuracy: 0.6359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.7830 - accuracy: 0.7112\n",
      "Epoch 27: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7830 - accuracy: 0.7112 - val_loss: 0.9204 - val_accuracy: 0.6351\n",
      "Epoch 28/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.7749 - accuracy: 0.7292\n",
      "Epoch 28: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7749 - accuracy: 0.7292 - val_loss: 0.9225 - val_accuracy: 0.6318\n",
      "Epoch 29/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.7793 - accuracy: 0.7162\n",
      "Epoch 29: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7793 - accuracy: 0.7162 - val_loss: 0.9166 - val_accuracy: 0.6367\n",
      "Epoch 30/200\n",
      "140/149 [===========================>..] - ETA: 0s - loss: 0.7781 - accuracy: 0.7281\n",
      "Epoch 30: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.7765 - accuracy: 0.7288 - val_loss: 0.9070 - val_accuracy: 0.6376\n",
      "Epoch 31/200\n",
      "134/149 [=========================>....] - ETA: 0s - loss: 0.7694 - accuracy: 0.7369\n",
      "Epoch 31: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7651 - accuracy: 0.7410 - val_loss: 0.9137 - val_accuracy: 0.6343\n",
      "Epoch 32/200\n",
      "140/149 [===========================>..] - ETA: 0s - loss: 0.7602 - accuracy: 0.7299\n",
      "Epoch 32: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7623 - accuracy: 0.7280 - val_loss: 0.9146 - val_accuracy: 0.6310\n",
      "Epoch 33/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.7507 - accuracy: 0.7356\n",
      "Epoch 33: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7508 - accuracy: 0.7351 - val_loss: 0.9197 - val_accuracy: 0.6253\n",
      "Epoch 34/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.7396 - accuracy: 0.7394\n",
      "Epoch 34: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7403 - accuracy: 0.7393 - val_loss: 0.9283 - val_accuracy: 0.6147\n",
      "Epoch 35/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.7411 - accuracy: 0.7407\n",
      "Epoch 35: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7417 - accuracy: 0.7401 - val_loss: 0.9116 - val_accuracy: 0.6261\n",
      "Epoch 36/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.7445 - accuracy: 0.7457\n",
      "Epoch 36: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7456 - accuracy: 0.7448 - val_loss: 0.9149 - val_accuracy: 0.6310\n",
      "Epoch 37/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.7386 - accuracy: 0.7436\n",
      "Epoch 37: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7408 - accuracy: 0.7435 - val_loss: 0.9278 - val_accuracy: 0.6147\n",
      "Epoch 38/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.7334 - accuracy: 0.7458\n",
      "Epoch 38: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7329 - accuracy: 0.7427 - val_loss: 0.9165 - val_accuracy: 0.6318\n",
      "Epoch 39/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.7256 - accuracy: 0.7490\n",
      "Epoch 39: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7256 - accuracy: 0.7490 - val_loss: 0.9172 - val_accuracy: 0.6286\n",
      "Epoch 40/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.7594\n",
      "Epoch 40: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7238 - accuracy: 0.7594 - val_loss: 0.9260 - val_accuracy: 0.6212\n",
      "Epoch 41/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.7289 - accuracy: 0.7547\n",
      "Epoch 41: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7281 - accuracy: 0.7544 - val_loss: 0.9185 - val_accuracy: 0.6261\n",
      "Epoch 42/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.7226 - accuracy: 0.7509\n",
      "Epoch 42: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7206 - accuracy: 0.7557 - val_loss: 0.9362 - val_accuracy: 0.6196\n",
      "Epoch 43/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.7121 - accuracy: 0.7506\n",
      "Epoch 43: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7121 - accuracy: 0.7506 - val_loss: 0.9184 - val_accuracy: 0.6310\n",
      "Epoch 44/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.7129 - accuracy: 0.7470\n",
      "Epoch 44: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7118 - accuracy: 0.7469 - val_loss: 0.9351 - val_accuracy: 0.6196\n",
      "Epoch 45/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.7085 - accuracy: 0.7569\n",
      "Epoch 45: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7136 - accuracy: 0.7523 - val_loss: 0.9265 - val_accuracy: 0.6245\n",
      "Epoch 46/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.7530\n",
      "Epoch 46: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.7527 - val_loss: 0.9323 - val_accuracy: 0.6237\n",
      "Epoch 47/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.6954 - accuracy: 0.7595\n",
      "Epoch 47: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6948 - accuracy: 0.7611 - val_loss: 0.9357 - val_accuracy: 0.6188\n",
      "Epoch 48/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.7031 - accuracy: 0.7572\n",
      "Epoch 48: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.7023 - accuracy: 0.7582 - val_loss: 0.9279 - val_accuracy: 0.6237\n",
      "Epoch 49/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.6842 - accuracy: 0.7644\n",
      "Epoch 49: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6912 - accuracy: 0.7624 - val_loss: 0.9145 - val_accuracy: 0.6343\n",
      "Epoch 50/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6873 - accuracy: 0.7732\n",
      "Epoch 50: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6864 - accuracy: 0.7737 - val_loss: 0.9313 - val_accuracy: 0.6204\n",
      "Epoch 51/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.6880 - accuracy: 0.7721\n",
      "Epoch 51: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6890 - accuracy: 0.7720 - val_loss: 0.9221 - val_accuracy: 0.6261\n",
      "Epoch 52/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6920 - accuracy: 0.7639\n",
      "Epoch 52: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6918 - accuracy: 0.7636 - val_loss: 0.9259 - val_accuracy: 0.6261\n",
      "Epoch 53/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.6652 - accuracy: 0.7679\n",
      "Epoch 53: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6664 - accuracy: 0.7687 - val_loss: 0.9327 - val_accuracy: 0.6261\n",
      "Epoch 54/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.6774 - accuracy: 0.7647\n",
      "Epoch 54: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6779 - accuracy: 0.7628 - val_loss: 0.9441 - val_accuracy: 0.6155\n",
      "Epoch 55/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.6727 - accuracy: 0.7690\n",
      "Epoch 55: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6766 - accuracy: 0.7662 - val_loss: 0.9320 - val_accuracy: 0.6237\n",
      "Epoch 56/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.6684 - accuracy: 0.7606\n",
      "Epoch 56: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6694 - accuracy: 0.7615 - val_loss: 0.9283 - val_accuracy: 0.6294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6646 - accuracy: 0.7762\n",
      "Epoch 57: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6648 - accuracy: 0.7758 - val_loss: 0.9482 - val_accuracy: 0.6139\n",
      "Epoch 58/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6575 - accuracy: 0.7774\n",
      "Epoch 58: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6587 - accuracy: 0.7767 - val_loss: 0.9450 - val_accuracy: 0.6180\n",
      "Epoch 59/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.6554 - accuracy: 0.7776\n",
      "Epoch 59: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6569 - accuracy: 0.7767 - val_loss: 0.9460 - val_accuracy: 0.6171\n",
      "Epoch 60/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.6574 - accuracy: 0.7730\n",
      "Epoch 60: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6566 - accuracy: 0.7712 - val_loss: 0.9351 - val_accuracy: 0.6286\n",
      "Epoch 61/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.7729\n",
      "Epoch 61: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6651 - accuracy: 0.7729 - val_loss: 0.9276 - val_accuracy: 0.6335\n",
      "Epoch 62/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.6528 - accuracy: 0.7676\n",
      "Epoch 62: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6515 - accuracy: 0.7678 - val_loss: 0.9352 - val_accuracy: 0.6220\n",
      "Epoch 63/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6509 - accuracy: 0.7666\n",
      "Epoch 63: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6509 - accuracy: 0.7666 - val_loss: 0.9339 - val_accuracy: 0.6261\n",
      "Epoch 64/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.6485 - accuracy: 0.7742\n",
      "Epoch 64: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6507 - accuracy: 0.7741 - val_loss: 0.9396 - val_accuracy: 0.6220\n",
      "Epoch 65/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6515 - accuracy: 0.7808\n",
      "Epoch 65: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6507 - accuracy: 0.7809 - val_loss: 0.9144 - val_accuracy: 0.6376\n",
      "Epoch 66/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.6412 - accuracy: 0.7751\n",
      "Epoch 66: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6413 - accuracy: 0.7746 - val_loss: 0.9406 - val_accuracy: 0.6278\n",
      "Epoch 67/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6392 - accuracy: 0.7783\n",
      "Epoch 67: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6393 - accuracy: 0.7783 - val_loss: 0.9466 - val_accuracy: 0.6269\n",
      "Epoch 68/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.6421 - accuracy: 0.7773\n",
      "Epoch 68: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6416 - accuracy: 0.7783 - val_loss: 0.9229 - val_accuracy: 0.6367\n",
      "Epoch 69/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.6379 - accuracy: 0.7815\n",
      "Epoch 69: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6398 - accuracy: 0.7817 - val_loss: 0.9346 - val_accuracy: 0.6269\n",
      "Epoch 70/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6315 - accuracy: 0.7884\n",
      "Epoch 70: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6321 - accuracy: 0.7876 - val_loss: 0.9375 - val_accuracy: 0.6286\n",
      "Epoch 71/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.6337 - accuracy: 0.7787\n",
      "Epoch 71: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6332 - accuracy: 0.7796 - val_loss: 0.9484 - val_accuracy: 0.6261\n",
      "Epoch 72/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6358 - accuracy: 0.7774\n",
      "Epoch 72: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6370 - accuracy: 0.7767 - val_loss: 0.9383 - val_accuracy: 0.6318\n",
      "Epoch 73/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6290 - accuracy: 0.7834\n",
      "Epoch 73: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6287 - accuracy: 0.7834 - val_loss: 0.9274 - val_accuracy: 0.6351\n",
      "Epoch 74/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.6253 - accuracy: 0.7801\n",
      "Epoch 74: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6255 - accuracy: 0.7792 - val_loss: 0.9263 - val_accuracy: 0.6310\n",
      "Epoch 75/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6181 - accuracy: 0.7788\n",
      "Epoch 75: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6181 - accuracy: 0.7788 - val_loss: 0.9309 - val_accuracy: 0.6310\n",
      "Epoch 76/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.6200 - accuracy: 0.7921\n",
      "Epoch 76: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6228 - accuracy: 0.7905 - val_loss: 0.9313 - val_accuracy: 0.6343\n",
      "Epoch 77/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.6159 - accuracy: 0.7801\n",
      "Epoch 77: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6207 - accuracy: 0.7792 - val_loss: 0.9206 - val_accuracy: 0.6367\n",
      "Epoch 78/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.6145 - accuracy: 0.7841\n",
      "Epoch 78: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.7838 - val_loss: 0.9390 - val_accuracy: 0.6286\n",
      "Epoch 79/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.6191 - accuracy: 0.7853\n",
      "Epoch 79: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6186 - accuracy: 0.7863 - val_loss: 0.9364 - val_accuracy: 0.6278\n",
      "Epoch 80/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6149 - accuracy: 0.7901\n",
      "Epoch 80: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6144 - accuracy: 0.7905 - val_loss: 0.9427 - val_accuracy: 0.6261\n",
      "Epoch 81/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.6182 - accuracy: 0.7866\n",
      "Epoch 81: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6169 - accuracy: 0.7859 - val_loss: 0.9391 - val_accuracy: 0.6245\n",
      "Epoch 82/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.6136 - accuracy: 0.7812\n",
      "Epoch 82: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6114 - accuracy: 0.7817 - val_loss: 0.9337 - val_accuracy: 0.6310\n",
      "Epoch 83/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6023 - accuracy: 0.7817\n",
      "Epoch 83: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6021 - accuracy: 0.7821 - val_loss: 0.9520 - val_accuracy: 0.6253\n",
      "Epoch 84/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.6083 - accuracy: 0.7825\n",
      "Epoch 84: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6102 - accuracy: 0.7813 - val_loss: 0.9510 - val_accuracy: 0.6229\n",
      "Epoch 85/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6016 - accuracy: 0.7884\n",
      "Epoch 85: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6023 - accuracy: 0.7876 - val_loss: 0.9429 - val_accuracy: 0.6310\n",
      "Epoch 86/200\n",
      "143/149 [===========================>..] - ETA: 0s - loss: 0.6013 - accuracy: 0.8007\n",
      "Epoch 86: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6042 - accuracy: 0.7981 - val_loss: 0.9441 - val_accuracy: 0.6286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5988 - accuracy: 0.7897\n",
      "Epoch 87: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5987 - accuracy: 0.7893 - val_loss: 0.9421 - val_accuracy: 0.6310\n",
      "Epoch 88/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5991 - accuracy: 0.7880\n",
      "Epoch 88: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6013 - accuracy: 0.7880 - val_loss: 0.9530 - val_accuracy: 0.6269\n",
      "Epoch 89/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5893 - accuracy: 0.7901\n",
      "Epoch 89: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5893 - accuracy: 0.7909 - val_loss: 0.9554 - val_accuracy: 0.6327\n",
      "Epoch 90/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.6032 - accuracy: 0.7872\n",
      "Epoch 90: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6012 - accuracy: 0.7893 - val_loss: 0.9313 - val_accuracy: 0.6416\n",
      "Epoch 91/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.5851 - accuracy: 0.7912\n",
      "Epoch 91: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5837 - accuracy: 0.7939 - val_loss: 0.9472 - val_accuracy: 0.6286\n",
      "Epoch 92/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.5849 - accuracy: 0.7840\n",
      "Epoch 92: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5829 - accuracy: 0.7855 - val_loss: 0.9445 - val_accuracy: 0.6367\n",
      "Epoch 93/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5799 - accuracy: 0.8019\n",
      "Epoch 93: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5803 - accuracy: 0.8014 - val_loss: 0.9437 - val_accuracy: 0.6359\n",
      "Epoch 94/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.5884 - accuracy: 0.7960\n",
      "Epoch 94: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5881 - accuracy: 0.7981 - val_loss: 0.9404 - val_accuracy: 0.6367\n",
      "Epoch 95/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.5771 - accuracy: 0.7904\n",
      "Epoch 95: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5763 - accuracy: 0.7909 - val_loss: 0.9267 - val_accuracy: 0.6449\n",
      "Epoch 96/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 0.7990\n",
      "Epoch 96: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5759 - accuracy: 0.7985 - val_loss: 0.9459 - val_accuracy: 0.6343\n",
      "Epoch 97/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.7830\n",
      "Epoch 97: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5794 - accuracy: 0.7830 - val_loss: 0.9462 - val_accuracy: 0.6294\n",
      "Epoch 98/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.5730 - accuracy: 0.7940\n",
      "Epoch 98: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5725 - accuracy: 0.7930 - val_loss: 0.9306 - val_accuracy: 0.6384\n",
      "Epoch 99/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.5817 - accuracy: 0.7961\n",
      "Epoch 99: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5801 - accuracy: 0.7976 - val_loss: 0.9401 - val_accuracy: 0.6343\n",
      "Epoch 100/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.5731 - accuracy: 0.8010\n",
      "Epoch 100: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5728 - accuracy: 0.8002 - val_loss: 0.9664 - val_accuracy: 0.6286\n",
      "Epoch 101/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.5658 - accuracy: 0.7979\n",
      "Epoch 101: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5690 - accuracy: 0.7943 - val_loss: 0.9493 - val_accuracy: 0.6392\n",
      "Epoch 102/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.5722 - accuracy: 0.8056\n",
      "Epoch 102: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5709 - accuracy: 0.8065 - val_loss: 0.9695 - val_accuracy: 0.6245\n",
      "Epoch 103/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.5638 - accuracy: 0.8001\n",
      "Epoch 103: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5647 - accuracy: 0.7993 - val_loss: 0.9613 - val_accuracy: 0.6343\n",
      "Epoch 104/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.8024\n",
      "Epoch 104: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5573 - accuracy: 0.8018 - val_loss: 0.9427 - val_accuracy: 0.6465\n",
      "Epoch 105/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.5591 - accuracy: 0.8021\n",
      "Epoch 105: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5586 - accuracy: 0.8023 - val_loss: 0.9281 - val_accuracy: 0.6457\n",
      "Epoch 106/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.5579 - accuracy: 0.7966\n",
      "Epoch 106: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5557 - accuracy: 0.7985 - val_loss: 0.9431 - val_accuracy: 0.6441\n",
      "Epoch 107/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.5579 - accuracy: 0.7984\n",
      "Epoch 107: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5601 - accuracy: 0.7985 - val_loss: 0.9685 - val_accuracy: 0.6376\n",
      "Epoch 108/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.5665 - accuracy: 0.7958\n",
      "Epoch 108: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5661 - accuracy: 0.7943 - val_loss: 0.9382 - val_accuracy: 0.6433\n",
      "Epoch 109/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.5571 - accuracy: 0.7983\n",
      "Epoch 109: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5526 - accuracy: 0.8027 - val_loss: 0.9710 - val_accuracy: 0.6253\n",
      "Epoch 110/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.5588 - accuracy: 0.8031\n",
      "Epoch 110: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5594 - accuracy: 0.8023 - val_loss: 0.9898 - val_accuracy: 0.6204\n",
      "Epoch 111/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.5520 - accuracy: 0.7935\n",
      "Epoch 111: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5495 - accuracy: 0.7947 - val_loss: 0.9545 - val_accuracy: 0.6400\n",
      "Epoch 112/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5522 - accuracy: 0.8041\n",
      "Epoch 112: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5519 - accuracy: 0.8044 - val_loss: 0.9675 - val_accuracy: 0.6327\n",
      "Epoch 113/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5532 - accuracy: 0.8035\n",
      "Epoch 113: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5532 - accuracy: 0.8035 - val_loss: 0.9667 - val_accuracy: 0.6318\n",
      "Epoch 114/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5435 - accuracy: 0.8070\n",
      "Epoch 114: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.8073 - val_loss: 0.9798 - val_accuracy: 0.6278\n",
      "Epoch 115/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.5395 - accuracy: 0.8108\n",
      "Epoch 115: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.8077 - val_loss: 0.9727 - val_accuracy: 0.6359\n",
      "Epoch 116/200\n",
      "142/149 [===========================>..] - ETA: 0s - loss: 0.5455 - accuracy: 0.8085\n",
      "Epoch 116: val_loss did not improve from 0.90253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5455 - accuracy: 0.8090 - val_loss: 0.9580 - val_accuracy: 0.6335\n",
      "Epoch 117/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.8098\n",
      "Epoch 117: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5378 - accuracy: 0.8098 - val_loss: 0.9816 - val_accuracy: 0.6335\n",
      "Epoch 118/200\n",
      "140/149 [===========================>..] - ETA: 0s - loss: 0.5364 - accuracy: 0.8121\n",
      "Epoch 118: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5340 - accuracy: 0.8140 - val_loss: 0.9680 - val_accuracy: 0.6351\n",
      "Epoch 119/200\n",
      "144/149 [===========================>..] - ETA: 0s - loss: 0.5369 - accuracy: 0.8069\n",
      "Epoch 119: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5377 - accuracy: 0.8060 - val_loss: 0.9837 - val_accuracy: 0.6294\n",
      "Epoch 120/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.5401 - accuracy: 0.8121\n",
      "Epoch 120: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5376 - accuracy: 0.8136 - val_loss: 0.9767 - val_accuracy: 0.6294\n",
      "Epoch 121/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.5341 - accuracy: 0.8082\n",
      "Epoch 121: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5330 - accuracy: 0.8090 - val_loss: 0.9773 - val_accuracy: 0.6327\n",
      "Epoch 122/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.5319 - accuracy: 0.8078\n",
      "Epoch 122: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.8090 - val_loss: 0.9801 - val_accuracy: 0.6335\n",
      "Epoch 123/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.5299 - accuracy: 0.8134\n",
      "Epoch 123: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5292 - accuracy: 0.8136 - val_loss: 0.9826 - val_accuracy: 0.6343\n",
      "Epoch 124/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.5292 - accuracy: 0.8125\n",
      "Epoch 124: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.8123 - val_loss: 0.9609 - val_accuracy: 0.6400\n",
      "Epoch 125/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.5247 - accuracy: 0.8112\n",
      "Epoch 125: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5252 - accuracy: 0.8111 - val_loss: 0.9735 - val_accuracy: 0.6278\n",
      "Epoch 126/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.5283 - accuracy: 0.8074\n",
      "Epoch 126: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5266 - accuracy: 0.8102 - val_loss: 0.9735 - val_accuracy: 0.6359\n",
      "Epoch 127/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.8132\n",
      "Epoch 127: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5213 - accuracy: 0.8132 - val_loss: 0.9711 - val_accuracy: 0.6318\n",
      "Epoch 128/200\n",
      "139/149 [==========================>...] - ETA: 0s - loss: 0.5325 - accuracy: 0.7995\n",
      "Epoch 128: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.8018 - val_loss: 0.9888 - val_accuracy: 0.6188\n",
      "Epoch 129/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.5165 - accuracy: 0.8287\n",
      "Epoch 129: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5185 - accuracy: 0.8254 - val_loss: 1.0045 - val_accuracy: 0.6212\n",
      "Epoch 130/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.5124 - accuracy: 0.8216\n",
      "Epoch 130: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5201 - accuracy: 0.8178 - val_loss: 1.0211 - val_accuracy: 0.6155\n",
      "Epoch 131/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.8203\n",
      "Epoch 131: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5087 - accuracy: 0.8203 - val_loss: 1.0024 - val_accuracy: 0.6457\n",
      "Epoch 132/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.5203 - accuracy: 0.8181\n",
      "Epoch 132: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5210 - accuracy: 0.8170 - val_loss: 0.9806 - val_accuracy: 0.6416\n",
      "Epoch 133/200\n",
      "139/149 [==========================>...] - ETA: 0s - loss: 0.5085 - accuracy: 0.8309\n",
      "Epoch 133: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5102 - accuracy: 0.8270 - val_loss: 0.9965 - val_accuracy: 0.6335\n",
      "Epoch 134/200\n",
      "134/149 [=========================>....] - ETA: 0s - loss: 0.5068 - accuracy: 0.8204\n",
      "Epoch 134: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5070 - accuracy: 0.8207 - val_loss: 0.9849 - val_accuracy: 0.6367\n",
      "Epoch 135/200\n",
      "143/149 [===========================>..] - ETA: 0s - loss: 0.5182 - accuracy: 0.8177\n",
      "Epoch 135: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.8195 - val_loss: 0.9776 - val_accuracy: 0.6400\n",
      "Epoch 136/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.5166 - accuracy: 0.8172\n",
      "Epoch 136: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.8174 - val_loss: 0.9884 - val_accuracy: 0.6376\n",
      "Epoch 137/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.5119 - accuracy: 0.8263\n",
      "Epoch 137: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5109 - accuracy: 0.8254 - val_loss: 0.9805 - val_accuracy: 0.6416\n",
      "Epoch 138/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.5046 - accuracy: 0.8352\n",
      "Epoch 138: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.8333 - val_loss: 1.0032 - val_accuracy: 0.6376\n",
      "Epoch 139/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.5036 - accuracy: 0.8198\n",
      "Epoch 139: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5059 - accuracy: 0.8195 - val_loss: 1.0150 - val_accuracy: 0.6367\n",
      "Epoch 140/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.4954 - accuracy: 0.8329\n",
      "Epoch 140: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.8329 - val_loss: 0.9783 - val_accuracy: 0.6506\n",
      "Epoch 141/200\n",
      "138/149 [==========================>...] - ETA: 0s - loss: 0.5057 - accuracy: 0.8175\n",
      "Epoch 141: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5029 - accuracy: 0.8220 - val_loss: 0.9982 - val_accuracy: 0.6351\n",
      "Epoch 142/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4959 - accuracy: 0.8318\n",
      "Epoch 142: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4948 - accuracy: 0.8321 - val_loss: 0.9958 - val_accuracy: 0.6367\n",
      "Epoch 143/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5074 - accuracy: 0.8182\n",
      "Epoch 143: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5074 - accuracy: 0.8182 - val_loss: 0.9788 - val_accuracy: 0.6441\n",
      "Epoch 144/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.8296\n",
      "Epoch 144: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4955 - accuracy: 0.8296 - val_loss: 0.9940 - val_accuracy: 0.6392\n",
      "Epoch 145/200\n",
      "142/149 [===========================>..] - ETA: 0s - loss: 0.4954 - accuracy: 0.8248\n",
      "Epoch 145: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4952 - accuracy: 0.8245 - val_loss: 0.9970 - val_accuracy: 0.6384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.4893 - accuracy: 0.8250\n",
      "Epoch 146: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4819 - accuracy: 0.8300 - val_loss: 1.0304 - val_accuracy: 0.6392\n",
      "Epoch 147/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.4872 - accuracy: 0.8292\n",
      "Epoch 147: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4839 - accuracy: 0.8346 - val_loss: 1.0148 - val_accuracy: 0.6424\n",
      "Epoch 148/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.4888 - accuracy: 0.8315\n",
      "Epoch 148: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4901 - accuracy: 0.8296 - val_loss: 0.9997 - val_accuracy: 0.6449\n",
      "Epoch 149/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.4815 - accuracy: 0.8383\n",
      "Epoch 149: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4808 - accuracy: 0.8384 - val_loss: 1.0116 - val_accuracy: 0.6416\n",
      "Epoch 150/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.4722 - accuracy: 0.8408\n",
      "Epoch 150: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4712 - accuracy: 0.8413 - val_loss: 1.0285 - val_accuracy: 0.6327\n",
      "Epoch 151/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.8338\n",
      "Epoch 151: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4813 - accuracy: 0.8338 - val_loss: 1.0630 - val_accuracy: 0.6098\n",
      "Epoch 152/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.4833 - accuracy: 0.8396\n",
      "Epoch 152: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.8396 - val_loss: 1.0546 - val_accuracy: 0.6155\n",
      "Epoch 153/200\n",
      "140/149 [===========================>..] - ETA: 0s - loss: 0.4814 - accuracy: 0.8335\n",
      "Epoch 153: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4844 - accuracy: 0.8317 - val_loss: 1.0281 - val_accuracy: 0.6286\n",
      "Epoch 154/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.4779 - accuracy: 0.8298\n",
      "Epoch 154: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4760 - accuracy: 0.8333 - val_loss: 1.0061 - val_accuracy: 0.6506\n",
      "Epoch 155/200\n",
      "140/149 [===========================>..] - ETA: 0s - loss: 0.4825 - accuracy: 0.8384\n",
      "Epoch 155: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4796 - accuracy: 0.8413 - val_loss: 1.0074 - val_accuracy: 0.6547\n",
      "Epoch 156/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4747 - accuracy: 0.8474\n",
      "Epoch 156: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4716 - accuracy: 0.8514 - val_loss: 1.0477 - val_accuracy: 0.6318\n",
      "Epoch 157/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.4766 - accuracy: 0.8367\n",
      "Epoch 157: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4736 - accuracy: 0.8401 - val_loss: 1.0102 - val_accuracy: 0.6473\n",
      "Epoch 158/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.4591 - accuracy: 0.8532\n",
      "Epoch 158: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4585 - accuracy: 0.8531 - val_loss: 1.0453 - val_accuracy: 0.6408\n",
      "Epoch 159/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.4641 - accuracy: 0.8500\n",
      "Epoch 159: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4612 - accuracy: 0.8514 - val_loss: 1.0460 - val_accuracy: 0.6433\n",
      "Epoch 160/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4738 - accuracy: 0.8433\n",
      "Epoch 160: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4697 - accuracy: 0.8430 - val_loss: 1.0112 - val_accuracy: 0.6531\n",
      "Epoch 161/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.4661 - accuracy: 0.8536\n",
      "Epoch 161: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4649 - accuracy: 0.8543 - val_loss: 1.0203 - val_accuracy: 0.6506\n",
      "Epoch 162/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.4645 - accuracy: 0.8431\n",
      "Epoch 162: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.8430 - val_loss: 1.0660 - val_accuracy: 0.6351\n",
      "Epoch 163/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8531\n",
      "Epoch 163: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4506 - accuracy: 0.8531 - val_loss: 1.0716 - val_accuracy: 0.6384\n",
      "Epoch 164/200\n",
      "138/149 [==========================>...] - ETA: 0s - loss: 0.4449 - accuracy: 0.8591\n",
      "Epoch 164: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4497 - accuracy: 0.8568 - val_loss: 1.0795 - val_accuracy: 0.6441\n",
      "Epoch 165/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.4574 - accuracy: 0.8552\n",
      "Epoch 165: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4569 - accuracy: 0.8556 - val_loss: 1.0381 - val_accuracy: 0.6482\n",
      "Epoch 166/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4618 - accuracy: 0.8474\n",
      "Epoch 166: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4624 - accuracy: 0.8484 - val_loss: 1.0499 - val_accuracy: 0.6433\n",
      "Epoch 167/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4560 - accuracy: 0.8516\n",
      "Epoch 167: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4514 - accuracy: 0.8539 - val_loss: 1.0374 - val_accuracy: 0.6514\n",
      "Epoch 168/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4541 - accuracy: 0.8525\n",
      "Epoch 168: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4539 - accuracy: 0.8510 - val_loss: 1.0674 - val_accuracy: 0.6359\n",
      "Epoch 169/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.4501 - accuracy: 0.8577\n",
      "Epoch 169: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4523 - accuracy: 0.8552 - val_loss: 1.0724 - val_accuracy: 0.6335\n",
      "Epoch 170/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4539 - accuracy: 0.8511\n",
      "Epoch 170: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4539 - accuracy: 0.8497 - val_loss: 1.0717 - val_accuracy: 0.6400\n",
      "Epoch 171/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.4391 - accuracy: 0.8556\n",
      "Epoch 171: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4405 - accuracy: 0.8547 - val_loss: 1.0532 - val_accuracy: 0.6498\n",
      "Epoch 172/200\n",
      "142/149 [===========================>..] - ETA: 0s - loss: 0.4446 - accuracy: 0.8561\n",
      "Epoch 172: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4493 - accuracy: 0.8535 - val_loss: 1.0670 - val_accuracy: 0.6482\n",
      "Epoch 173/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.4420 - accuracy: 0.8634\n",
      "Epoch 173: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4366 - accuracy: 0.8636 - val_loss: 1.0936 - val_accuracy: 0.6506\n",
      "Epoch 174/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4365 - accuracy: 0.8575\n",
      "Epoch 174: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4398 - accuracy: 0.8552 - val_loss: 1.1110 - val_accuracy: 0.6449\n",
      "Epoch 175/200\n",
      "145/149 [============================>.] - ETA: 0s - loss: 0.4455 - accuracy: 0.8591\n",
      "Epoch 175: val_loss did not improve from 0.90253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4459 - accuracy: 0.8585 - val_loss: 1.0755 - val_accuracy: 0.6506\n",
      "Epoch 176/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4408 - accuracy: 0.8516\n",
      "Epoch 176: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4426 - accuracy: 0.8522 - val_loss: 1.0710 - val_accuracy: 0.6522\n",
      "Epoch 177/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.4382 - accuracy: 0.8618\n",
      "Epoch 177: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4392 - accuracy: 0.8615 - val_loss: 1.0872 - val_accuracy: 0.6482\n",
      "Epoch 178/200\n",
      "138/149 [==========================>...] - ETA: 0s - loss: 0.4319 - accuracy: 0.8614\n",
      "Epoch 178: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4292 - accuracy: 0.8623 - val_loss: 1.0884 - val_accuracy: 0.6490\n",
      "Epoch 179/200\n",
      "138/149 [==========================>...] - ETA: 0s - loss: 0.4361 - accuracy: 0.8619\n",
      "Epoch 179: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4347 - accuracy: 0.8636 - val_loss: 1.1081 - val_accuracy: 0.6457\n",
      "Epoch 180/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4383 - accuracy: 0.8598\n",
      "Epoch 180: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4346 - accuracy: 0.8636 - val_loss: 1.0909 - val_accuracy: 0.6547\n",
      "Epoch 181/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4274 - accuracy: 0.8676\n",
      "Epoch 181: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4305 - accuracy: 0.8665 - val_loss: 1.1302 - val_accuracy: 0.6376\n",
      "Epoch 182/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.4400 - accuracy: 0.8563\n",
      "Epoch 182: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4397 - accuracy: 0.8547 - val_loss: 1.0946 - val_accuracy: 0.6588\n",
      "Epoch 183/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.8682\n",
      "Epoch 183: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4154 - accuracy: 0.8682 - val_loss: 1.0986 - val_accuracy: 0.6588\n",
      "Epoch 184/200\n",
      "147/149 [============================>.] - ETA: 0s - loss: 0.4222 - accuracy: 0.8707\n",
      "Epoch 184: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.8711 - val_loss: 1.0987 - val_accuracy: 0.6588\n",
      "Epoch 185/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.4264 - accuracy: 0.8609\n",
      "Epoch 185: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4237 - accuracy: 0.8615 - val_loss: 1.1446 - val_accuracy: 0.6514\n",
      "Epoch 186/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.8606\n",
      "Epoch 186: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4291 - accuracy: 0.8606 - val_loss: 1.1277 - val_accuracy: 0.6531\n",
      "Epoch 187/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.4115 - accuracy: 0.8763\n",
      "Epoch 187: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8762 - val_loss: 1.1124 - val_accuracy: 0.6563\n",
      "Epoch 188/200\n",
      "138/149 [==========================>...] - ETA: 0s - loss: 0.4219 - accuracy: 0.8687\n",
      "Epoch 188: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4246 - accuracy: 0.8682 - val_loss: 1.0860 - val_accuracy: 0.6637\n",
      "Epoch 189/200\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.8661\n",
      "Epoch 189: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4088 - accuracy: 0.8661 - val_loss: 1.1441 - val_accuracy: 0.6506\n",
      "Epoch 190/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.4264 - accuracy: 0.8731\n",
      "Epoch 190: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4242 - accuracy: 0.8728 - val_loss: 1.1250 - val_accuracy: 0.6580\n",
      "Epoch 191/200\n",
      "137/149 [==========================>...] - ETA: 0s - loss: 0.4113 - accuracy: 0.8700\n",
      "Epoch 191: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4092 - accuracy: 0.8724 - val_loss: 1.1203 - val_accuracy: 0.6571\n",
      "Epoch 192/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.4171 - accuracy: 0.8682\n",
      "Epoch 192: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4184 - accuracy: 0.8682 - val_loss: 1.1369 - val_accuracy: 0.6563\n",
      "Epoch 193/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.4060 - accuracy: 0.8750\n",
      "Epoch 193: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4052 - accuracy: 0.8745 - val_loss: 1.1795 - val_accuracy: 0.6424\n",
      "Epoch 194/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.4249 - accuracy: 0.8713\n",
      "Epoch 194: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4240 - accuracy: 0.8720 - val_loss: 1.1465 - val_accuracy: 0.6637\n",
      "Epoch 195/200\n",
      "135/149 [==========================>...] - ETA: 0s - loss: 0.4071 - accuracy: 0.8778\n",
      "Epoch 195: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4046 - accuracy: 0.8778 - val_loss: 1.1453 - val_accuracy: 0.6563\n",
      "Epoch 196/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.8874\n",
      "Epoch 196: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.3969 - accuracy: 0.8875 - val_loss: 1.1548 - val_accuracy: 0.6588\n",
      "Epoch 197/200\n",
      "146/149 [============================>.] - ETA: 0s - loss: 0.4050 - accuracy: 0.8746\n",
      "Epoch 197: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4037 - accuracy: 0.8753 - val_loss: 1.1816 - val_accuracy: 0.6424\n",
      "Epoch 198/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.4089 - accuracy: 0.8737\n",
      "Epoch 198: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4080 - accuracy: 0.8745 - val_loss: 1.1708 - val_accuracy: 0.6449\n",
      "Epoch 199/200\n",
      "136/149 [==========================>...] - ETA: 0s - loss: 0.3927 - accuracy: 0.8805\n",
      "Epoch 199: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3965 - accuracy: 0.8770 - val_loss: 1.1779 - val_accuracy: 0.6531\n",
      "Epoch 200/200\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.3987 - accuracy: 0.8699\n",
      "Epoch 200: val_loss did not improve from 0.90253\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3986 - accuracy: 0.8699 - val_loss: 1.1468 - val_accuracy: 0.6563\n"
     ]
    }
   ],
   "source": [
    "model = DLNN_Classifier(input_vec_shape = input_vec_shape)\n",
    "    \n",
    "## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "current_model_path = os.path.join(modelPath, \"_fullModel.hdf5\")\n",
    "modelCallbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                       monitor = monitor, verbose = 1, save_best_only = True, \n",
    "                                       save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "]\n",
    "\n",
    "# adding random shuffling of the dataset for training purpose\n",
    "index_arr = np.arange(train_features.shape[0])\n",
    "index_arr = np.random.permutation(index_arr)\n",
    "\n",
    "model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "          callbacks = modelCallbacks, validation_data = (indpe_features, indpe_labels))\n",
    "# model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "#           callbacks = modelCallbacks, validation_split = 0.2)\n",
    "\n",
    "model = tf.keras.models.load_model(current_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.656327</td>\n",
       "      <td>0.247685</td>\n",
       "      <td>0.628192</td>\n",
       "      <td>0.527094</td>\n",
       "      <td>0.681996</td>\n",
       "      <td>0.162715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.656327   0.247685  0.628192     0.527094     0.681996  0.162715"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "y_pred = model.predict(indpe_features)\n",
    "label_pred = pred2label(y_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.77      1022\n",
      "           1       0.25      0.53      0.34       203\n",
      "\n",
      "    accuracy                           0.66      1225\n",
      "   macro avg       0.56      0.60      0.55      1225\n",
      "weighted avg       0.77      0.66      0.70      1225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(indpe_labels, np.round(y_pred).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
