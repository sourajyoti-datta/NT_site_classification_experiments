{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"NT_Site_iNitroY_Classification_DLNN_CORENup_v2\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "shuffle = True\n",
    "seed = None\n",
    "\n",
    "input_data_folder = \"Data\\\\iNitroY-Deep-Dataset\"\n",
    "pos_data_file = \"raw-nitrotyrosine-pos.fasta\"\n",
    "neg_data_file = \"cdhit70-nitrotyr-neg.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import math\n",
    "\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define all CUSTOM functions\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode_nt(sequence, char_dict):\n",
    "    \n",
    "    seq_encoded = np.zeros((len(sequence),len(char_dict)))\n",
    "    \n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in char_dict.keys()):\n",
    "            seq_encoded[i][char_dict[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in NT sequence: '+sequence)\n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Build k-fold functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "                 conv_filters_per_layer_1 = 10, kernel_length_1 = 10, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "                 max_pool_width_1 = 3, max_pool_stride_1 = 3, ## 1st Maxpool layer parameters\n",
    "                 lstm_decode_units = 10, ## LSTM layer parameters\n",
    "                 conv_filters_per_layer_2 = 10,  kernel_length_2 = 5, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "                 max_pool_width_2 = 3, max_pool_stride_2 = 3, ## 2nd Maxpool layer parameters\n",
    "                 dense_decode_units = 32, ## Dense layer parameters\n",
    "                 prob = 0.5, learn_rate = 0.0005, \n",
    "                 loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  SEQUENCE  ##################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1,\n",
    "                                strides = conv_strides_1, kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = \"same\")(input1)\n",
    "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta))(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    ## Conv Path\n",
    "\n",
    "    x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), padding = 'same')(x1)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "    x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "    \n",
    "    x4 = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  Classifier  ################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    y = tf.keras.layers.Dense(dense_decode_units, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'relu')(x4)\n",
    "    \n",
    "    y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(1, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'sigmoid')(y)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step in range(10):\n",
    "#     initial_learning_rate=1e-1\n",
    "#     decay_steps=10000\n",
    "#     decay_rate=0.9\n",
    "#     print(step, ':', initial_learning_rate * decay_rate ** (step / decay_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 41, 21)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 41, 10)       2110        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 41, 10)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 13, 10)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 13, 10)       0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 13, 10)       510         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 13, 10)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 13, 10)       840         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 4, 10)       0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 13, 10)       0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 10)        0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 130)          0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 40)           0           ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 170)          0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           5472        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 32)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            33          ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,965\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "DLNN_CORENup().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta_file(file_path):\n",
    "    \n",
    "    openFile = open(file_path)\n",
    "    fastaSequences = SeqIO.parse(openFile, \"fasta\")\n",
    "\n",
    "    name_list = []\n",
    "    seq_list = []\n",
    "\n",
    "    for fasta in fastaSequences: \n",
    "        name_list.append(fasta.id)\n",
    "        seq_list.append(str(fasta.seq))\n",
    "\n",
    "    openFile.close()\n",
    "    \n",
    "    return name_list, seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read positive and negative files\n",
    "##################################################################################\n",
    "\n",
    "pos_file_path = os.path.join(input_data_folder, pos_data_file)\n",
    "_, pos_seq_list = read_fasta_file(pos_file_path)\n",
    "\n",
    "neg_file_path = os.path.join(input_data_folder, neg_data_file)\n",
    "_, neg_seq_list = read_fasta_file(neg_file_path)\n",
    "\n",
    "pos_seq_list = [val.replace('X', '-') for val in pos_seq_list]\n",
    "neg_seq_list = [val.replace('X', '-') for val in neg_seq_list]\n",
    "\n",
    "# remove duplicates in data\n",
    "pos_seq_list = list(set(pos_seq_list))\n",
    "neg_seq_list = list(set(neg_seq_list))\n",
    "\n",
    "all_seq_list = pos_seq_list + neg_seq_list\n",
    "\n",
    "all_seq_label_list = ([1] * len(pos_seq_list)) + ([0] * len(neg_seq_list))\n",
    "\n",
    "##################################################################################\n",
    "##### Create dictionary of all characters in the NT sequence \n",
    "##################################################################################\n",
    "all_char_set = set({})\n",
    "for val in [set(val) for val in all_seq_list]:\n",
    "    all_char_set = all_char_set.union(val)\n",
    "all_char_list = list(all_char_set)\n",
    "all_char_list.sort()\n",
    "all_char_dict = {}\n",
    "for i in range(len(all_char_list)):\n",
    "    all_char_dict[all_char_list[i]] = i\n",
    "    \n",
    "##################################################################################\n",
    "##### Create OHE of all sequences\n",
    "##################################################################################\n",
    "all_seq_OHE_list = [one_hot_encode_nt(val, all_char_dict)\n",
    "                    for val in all_seq_list]\n",
    "\n",
    "##################################################################################\n",
    "##### Create numpy array of features and sequences\n",
    "##################################################################################\n",
    "\n",
    "## create the features and labels datasets for the training\n",
    "features = np.array(all_seq_OHE_list)\n",
    "labels = np.array(all_seq_label_list)\n",
    "labels = labels.reshape((labels.shape[0], 1))\n",
    "\n",
    "##################################################################################\n",
    "##### Divide into Train/Independent datasets\n",
    "##################################################################################\n",
    "\n",
    "train_features, indpe_features, train_labels, indpe_labels = train_test_split(features, labels, \n",
    "                                                                              stratify=labels, test_size=0.3, \n",
    "                                                                              random_state=seed, shuffle=shuffle)\n",
    "\n",
    "##################################################################################\n",
    "##### Generate Folds from training dataset, and store to file\n",
    "##################################################################################\n",
    "\n",
    "## Generate the k-fold dataset\n",
    "folds = build_kfold(train_features, train_labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "## Write the k-fold dataset to file\n",
    "foldPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(foldPath)):\n",
    "    os.makedirs(foldPath)\n",
    "pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "\n",
    "## Write the independent test dataset to file\n",
    "pickle.dump([indpe_features, indpe_labels], open(os.path.join(foldPath, 'independent_dataset.pickle'), \"wb\"))\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "input_seq_shape = features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test model on Fold #0.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - ETA: 0s - loss: 0.7798\n",
      "Epoch 1: val_loss improved from inf to 0.71121, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 5s 31ms/step - loss: 0.7798 - val_loss: 0.7112\n",
      "Epoch 2/100\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.7394\n",
      "Epoch 2: val_loss improved from 0.71121 to 0.67248, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7354 - val_loss: 0.6725\n",
      "Epoch 3/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6854\n",
      "Epoch 3: val_loss improved from 0.67248 to 0.65439, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6897 - val_loss: 0.6544\n",
      "Epoch 4/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6787\n",
      "Epoch 4: val_loss improved from 0.65439 to 0.64589, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6624 - val_loss: 0.6459\n",
      "Epoch 5/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6945\n",
      "Epoch 5: val_loss improved from 0.64589 to 0.64378, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7062 - val_loss: 0.6438\n",
      "Epoch 6/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6300\n",
      "Epoch 6: val_loss did not improve from 0.64378\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6526 - val_loss: 0.6445\n",
      "Epoch 7/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6515\n",
      "Epoch 7: val_loss improved from 0.64378 to 0.63961, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6683 - val_loss: 0.6396\n",
      "Epoch 8/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6752\n",
      "Epoch 8: val_loss improved from 0.63961 to 0.63467, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6491 - val_loss: 0.6347\n",
      "Epoch 9/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6438\n",
      "Epoch 9: val_loss improved from 0.63467 to 0.62618, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6471 - val_loss: 0.6262\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6639\n",
      "Epoch 10: val_loss improved from 0.62618 to 0.62342, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6639 - val_loss: 0.6234\n",
      "Epoch 11/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6460\n",
      "Epoch 11: val_loss did not improve from 0.62342\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6478 - val_loss: 0.6236\n",
      "Epoch 12/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.6407\n",
      "Epoch 12: val_loss improved from 0.62342 to 0.61498, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6386 - val_loss: 0.6150\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6361\n",
      "Epoch 13: val_loss improved from 0.61498 to 0.60819, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6361 - val_loss: 0.6082\n",
      "Epoch 14/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6387\n",
      "Epoch 14: val_loss did not improve from 0.60819\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6314 - val_loss: 0.6117\n",
      "Epoch 15/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6402\n",
      "Epoch 15: val_loss improved from 0.60819 to 0.60469, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6283 - val_loss: 0.6047\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6178\n",
      "Epoch 16: val_loss improved from 0.60469 to 0.59418, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6178 - val_loss: 0.5942\n",
      "Epoch 17/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.5891\n",
      "Epoch 17: val_loss improved from 0.59418 to 0.58991, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6007 - val_loss: 0.5899\n",
      "Epoch 18/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.6112\n",
      "Epoch 18: val_loss improved from 0.58991 to 0.58932, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6097 - val_loss: 0.5893\n",
      "Epoch 19/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5814\n",
      "Epoch 19: val_loss improved from 0.58932 to 0.57908, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5990 - val_loss: 0.5791\n",
      "Epoch 20/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6146\n",
      "Epoch 20: val_loss improved from 0.57908 to 0.57881, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6138 - val_loss: 0.5788\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5977\n",
      "Epoch 21: val_loss improved from 0.57881 to 0.57016, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5977 - val_loss: 0.5702\n",
      "Epoch 22/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6130\n",
      "Epoch 22: val_loss did not improve from 0.57016\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6111 - val_loss: 0.5765\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5771\n",
      "Epoch 23: val_loss improved from 0.57016 to 0.56064, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5771 - val_loss: 0.5606\n",
      "Epoch 24/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5575\n",
      "Epoch 24: val_loss improved from 0.56064 to 0.54505, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5626 - val_loss: 0.5451\n",
      "Epoch 25/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5657\n",
      "Epoch 25: val_loss did not improve from 0.54505\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5765 - val_loss: 0.5491\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5628\n",
      "Epoch 26: val_loss improved from 0.54505 to 0.53470, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5628 - val_loss: 0.5347\n",
      "Epoch 27/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.5422\n",
      "Epoch 27: val_loss improved from 0.53470 to 0.52073, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5459 - val_loss: 0.5207\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5590\n",
      "Epoch 28: val_loss improved from 0.52073 to 0.52012, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5590 - val_loss: 0.5201\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5392\n",
      "Epoch 29: val_loss improved from 0.52012 to 0.50262, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5392 - val_loss: 0.5026\n",
      "Epoch 30/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5432\n",
      "Epoch 30: val_loss improved from 0.50262 to 0.49422, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5389 - val_loss: 0.4942\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5313\n",
      "Epoch 31: val_loss improved from 0.49422 to 0.48183, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5313 - val_loss: 0.4818\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5047\n",
      "Epoch 32: val_loss improved from 0.48183 to 0.46858, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5047 - val_loss: 0.4686\n",
      "Epoch 33/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4983\n",
      "Epoch 33: val_loss improved from 0.46858 to 0.45464, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5031 - val_loss: 0.4546\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4542\n",
      "Epoch 34: val_loss improved from 0.45464 to 0.43070, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4542 - val_loss: 0.4307\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4566\n",
      "Epoch 35: val_loss improved from 0.43070 to 0.41100, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4566 - val_loss: 0.4110\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4589\n",
      "Epoch 36: val_loss improved from 0.41100 to 0.40173, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4589 - val_loss: 0.4017\n",
      "Epoch 37/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4627\n",
      "Epoch 37: val_loss did not improve from 0.40173\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4574 - val_loss: 0.4086\n",
      "Epoch 38/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4300\n",
      "Epoch 38: val_loss improved from 0.40173 to 0.38082, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4304 - val_loss: 0.3808\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4389\n",
      "Epoch 39: val_loss improved from 0.38082 to 0.37654, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4389 - val_loss: 0.3765\n",
      "Epoch 40/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3764\n",
      "Epoch 40: val_loss improved from 0.37654 to 0.35127, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3850 - val_loss: 0.3513\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3772\n",
      "Epoch 41: val_loss improved from 0.35127 to 0.32925, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3772 - val_loss: 0.3293\n",
      "Epoch 42/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3773\n",
      "Epoch 42: val_loss improved from 0.32925 to 0.32662, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3752 - val_loss: 0.3266\n",
      "Epoch 43/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3444\n",
      "Epoch 43: val_loss improved from 0.32662 to 0.30733, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3439 - val_loss: 0.3073\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3376\n",
      "Epoch 44: val_loss improved from 0.30733 to 0.29319, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3376 - val_loss: 0.2932\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3463\n",
      "Epoch 45: val_loss improved from 0.29319 to 0.27928, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3463 - val_loss: 0.2793\n",
      "Epoch 46/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3434\n",
      "Epoch 46: val_loss improved from 0.27928 to 0.26881, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3346 - val_loss: 0.2688\n",
      "Epoch 47/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3315\n",
      "Epoch 47: val_loss improved from 0.26881 to 0.26378, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3294 - val_loss: 0.2638\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3236\n",
      "Epoch 48: val_loss did not improve from 0.26378\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3236 - val_loss: 0.2884\n",
      "Epoch 49/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3078\n",
      "Epoch 49: val_loss did not improve from 0.26378\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3022 - val_loss: 0.2651\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2975\n",
      "Epoch 50: val_loss improved from 0.26378 to 0.26019, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2975 - val_loss: 0.2602\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2732\n",
      "Epoch 51: val_loss improved from 0.26019 to 0.24350, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2732 - val_loss: 0.2435\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2723\n",
      "Epoch 52: val_loss did not improve from 0.24350\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2723 - val_loss: 0.2530\n",
      "Epoch 53/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2764\n",
      "Epoch 53: val_loss did not improve from 0.24350\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2842 - val_loss: 0.2519\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2946\n",
      "Epoch 54: val_loss improved from 0.24350 to 0.24087, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2946 - val_loss: 0.2409\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - ETA: 0s - loss: 0.2451\n",
      "Epoch 55: val_loss improved from 0.24087 to 0.23567, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2451 - val_loss: 0.2357\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2664\n",
      "Epoch 56: val_loss improved from 0.23567 to 0.23192, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2664 - val_loss: 0.2319\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2423\n",
      "Epoch 57: val_loss improved from 0.23192 to 0.22291, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2423 - val_loss: 0.2229\n",
      "Epoch 58/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2399\n",
      "Epoch 58: val_loss improved from 0.22291 to 0.21470, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2410 - val_loss: 0.2147\n",
      "Epoch 59/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2082\n",
      "Epoch 59: val_loss improved from 0.21470 to 0.20453, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2216 - val_loss: 0.2045\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2161\n",
      "Epoch 60: val_loss improved from 0.20453 to 0.20106, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2161 - val_loss: 0.2011\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2351\n",
      "Epoch 61: val_loss did not improve from 0.20106\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2351 - val_loss: 0.2214\n",
      "Epoch 62/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2250\n",
      "Epoch 62: val_loss did not improve from 0.20106\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2026 - val_loss: 0.2263\n",
      "Epoch 63/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2232\n",
      "Epoch 63: val_loss did not improve from 0.20106\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2203 - val_loss: 0.2093\n",
      "Epoch 64/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1841\n",
      "Epoch 64: val_loss did not improve from 0.20106\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1790 - val_loss: 0.2098\n",
      "Epoch 65/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2175\n",
      "Epoch 65: val_loss did not improve from 0.20106\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2149 - val_loss: 0.2061\n",
      "Epoch 66/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1990\n",
      "Epoch 66: val_loss improved from 0.20106 to 0.19800, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1935 - val_loss: 0.1980\n",
      "Epoch 67/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1844\n",
      "Epoch 67: val_loss did not improve from 0.19800\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1821 - val_loss: 0.2006\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 68: val_loss improved from 0.19800 to 0.19537, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1573 - val_loss: 0.1954\n",
      "Epoch 69/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2279\n",
      "Epoch 69: val_loss did not improve from 0.19537\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2111 - val_loss: 0.2906\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2028\n",
      "Epoch 70: val_loss did not improve from 0.19537\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2028 - val_loss: 0.1975\n",
      "Epoch 71/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1962\n",
      "Epoch 71: val_loss did not improve from 0.19537\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2118 - val_loss: 0.2008\n",
      "Epoch 72/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1651\n",
      "Epoch 72: val_loss did not improve from 0.19537\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1737 - val_loss: 0.2109\n",
      "Epoch 73/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1601\n",
      "Epoch 73: val_loss improved from 0.19537 to 0.19214, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1704 - val_loss: 0.1921\n",
      "Epoch 74/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1554\n",
      "Epoch 74: val_loss did not improve from 0.19214\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1468 - val_loss: 0.2013\n",
      "Epoch 75/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1437\n",
      "Epoch 75: val_loss improved from 0.19214 to 0.18934, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1435 - val_loss: 0.1893\n",
      "Epoch 76/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1604\n",
      "Epoch 76: val_loss improved from 0.18934 to 0.18689, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1761 - val_loss: 0.1869\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1921\n",
      "Epoch 77: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1921 - val_loss: 0.2023\n",
      "Epoch 78/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1597\n",
      "Epoch 78: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1554 - val_loss: 0.1926\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1841\n",
      "Epoch 79: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1841 - val_loss: 0.1995\n",
      "Epoch 80/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1470\n",
      "Epoch 80: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1583 - val_loss: 0.1919\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1912\n",
      "Epoch 81: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1912 - val_loss: 0.1907\n",
      "Epoch 82/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1612\n",
      "Epoch 82: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1636 - val_loss: 0.1939\n",
      "Epoch 83/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1762\n",
      "Epoch 83: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1645 - val_loss: 0.2086\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1393\n",
      "Epoch 84: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1393 - val_loss: 0.1938\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1528\n",
      "Epoch 85: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1528 - val_loss: 0.2007\n",
      "Epoch 86/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1167\n",
      "Epoch 86: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1246 - val_loss: 0.2100\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1506\n",
      "Epoch 87: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1506 - val_loss: 0.2062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1418\n",
      "Epoch 88: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1572 - val_loss: 0.1918\n",
      "Epoch 89/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1439\n",
      "Epoch 89: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1278 - val_loss: 0.2050\n",
      "Epoch 90/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1439\n",
      "Epoch 90: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1440 - val_loss: 0.1882\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1488\n",
      "Epoch 91: val_loss did not improve from 0.18689\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1488 - val_loss: 0.1922\n",
      "Epoch 92/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1569\n",
      "Epoch 92: val_loss improved from 0.18689 to 0.18351, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1455 - val_loss: 0.1835\n",
      "Epoch 93/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1139\n",
      "Epoch 93: val_loss did not improve from 0.18351\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1263 - val_loss: 0.1983\n",
      "Epoch 94/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1615\n",
      "Epoch 94: val_loss improved from 0.18351 to 0.17938, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1705 - val_loss: 0.1794\n",
      "Epoch 95/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1094\n",
      "Epoch 95: val_loss did not improve from 0.17938\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1296 - val_loss: 0.1832\n",
      "Epoch 96/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1244\n",
      "Epoch 96: val_loss did not improve from 0.17938\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1158 - val_loss: 0.1795\n",
      "Epoch 97/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1084\n",
      "Epoch 97: val_loss did not improve from 0.17938\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1023 - val_loss: 0.1872\n",
      "Epoch 98/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1465\n",
      "Epoch 98: val_loss did not improve from 0.17938\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1306 - val_loss: 0.1806\n",
      "Epoch 99/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1199\n",
      "Epoch 99: val_loss did not improve from 0.17938\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1294 - val_loss: 0.2001\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1168\n",
      "Epoch 100: val_loss did not improve from 0.17938\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1168 - val_loss: 0.1828\n",
      "\n",
      "Train/Test model on Fold #1.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - ETA: 0s - loss: 0.8183\n",
      "Epoch 1: val_loss improved from inf to 0.70799, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 2s 32ms/step - loss: 0.8183 - val_loss: 0.7080\n",
      "Epoch 2/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.7151\n",
      "Epoch 2: val_loss improved from 0.70799 to 0.66623, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7200 - val_loss: 0.6662\n",
      "Epoch 3/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.6776\n",
      "Epoch 3: val_loss improved from 0.66623 to 0.65220, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6838 - val_loss: 0.6522\n",
      "Epoch 4/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6812\n",
      "Epoch 4: val_loss improved from 0.65220 to 0.64785, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6775 - val_loss: 0.6478\n",
      "Epoch 5/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6689\n",
      "Epoch 5: val_loss improved from 0.64785 to 0.64356, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6649 - val_loss: 0.6436\n",
      "Epoch 6/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6525\n",
      "Epoch 6: val_loss improved from 0.64356 to 0.64167, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6505 - val_loss: 0.6417\n",
      "Epoch 7/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6412\n",
      "Epoch 7: val_loss improved from 0.64167 to 0.63794, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6432 - val_loss: 0.6379\n",
      "Epoch 8/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6764\n",
      "Epoch 8: val_loss did not improve from 0.63794\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6800 - val_loss: 0.6396\n",
      "Epoch 9/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6493\n",
      "Epoch 9: val_loss improved from 0.63794 to 0.63506, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6638 - val_loss: 0.6351\n",
      "Epoch 10/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6584\n",
      "Epoch 10: val_loss improved from 0.63506 to 0.63175, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6523 - val_loss: 0.6318\n",
      "Epoch 11/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6353\n",
      "Epoch 11: val_loss improved from 0.63175 to 0.62580, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6343 - val_loss: 0.6258\n",
      "Epoch 12/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6363\n",
      "Epoch 12: val_loss improved from 0.62580 to 0.61989, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6247 - val_loss: 0.6199\n",
      "Epoch 13/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6752\n",
      "Epoch 13: val_loss improved from 0.61989 to 0.61972, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6428 - val_loss: 0.6197\n",
      "Epoch 14/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6279\n",
      "Epoch 14: val_loss improved from 0.61972 to 0.61113, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6107 - val_loss: 0.6111\n",
      "Epoch 15/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6585\n",
      "Epoch 15: val_loss improved from 0.61113 to 0.60897, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6335 - val_loss: 0.6090\n",
      "Epoch 16/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.6322\n",
      "Epoch 16: val_loss improved from 0.60897 to 0.60802, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6318 - val_loss: 0.6080\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6142\n",
      "Epoch 17: val_loss improved from 0.60802 to 0.59999, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6142 - val_loss: 0.6000\n",
      "Epoch 18/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6058\n",
      "Epoch 18: val_loss improved from 0.59999 to 0.59630, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6020 - val_loss: 0.5963\n",
      "Epoch 19/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.5992\n",
      "Epoch 19: val_loss improved from 0.59630 to 0.58856, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6025 - val_loss: 0.5886\n",
      "Epoch 20/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.5796\n",
      "Epoch 20: val_loss improved from 0.58856 to 0.58219, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5828 - val_loss: 0.5822\n",
      "Epoch 21/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6040\n",
      "Epoch 21: val_loss improved from 0.58219 to 0.57834, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5853 - val_loss: 0.5783\n",
      "Epoch 22/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5665\n",
      "Epoch 22: val_loss improved from 0.57834 to 0.56583, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5905 - val_loss: 0.5658\n",
      "Epoch 23/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5511\n",
      "Epoch 23: val_loss improved from 0.56583 to 0.55230, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5470 - val_loss: 0.5523\n",
      "Epoch 24/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5509\n",
      "Epoch 24: val_loss improved from 0.55230 to 0.54151, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5506 - val_loss: 0.5415\n",
      "Epoch 25/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5454\n",
      "Epoch 25: val_loss improved from 0.54151 to 0.52799, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5392 - val_loss: 0.5280\n",
      "Epoch 26/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4965\n",
      "Epoch 26: val_loss improved from 0.52799 to 0.51443, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5088 - val_loss: 0.5144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5021\n",
      "Epoch 27: val_loss improved from 0.51443 to 0.49564, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4907 - val_loss: 0.4956\n",
      "Epoch 28/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4649\n",
      "Epoch 28: val_loss improved from 0.49564 to 0.48287, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4784 - val_loss: 0.4829\n",
      "Epoch 29/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5009\n",
      "Epoch 29: val_loss improved from 0.48287 to 0.46939, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4672 - val_loss: 0.4694\n",
      "Epoch 30/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.4507\n",
      "Epoch 30: val_loss improved from 0.46939 to 0.45754, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.4355 - val_loss: 0.4575\n",
      "Epoch 31/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4490\n",
      "Epoch 31: val_loss did not improve from 0.45754\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4482 - val_loss: 0.5015\n",
      "Epoch 32/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4223\n",
      "Epoch 32: val_loss improved from 0.45754 to 0.44433, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4159 - val_loss: 0.4443\n",
      "Epoch 33/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3951\n",
      "Epoch 33: val_loss improved from 0.44433 to 0.43444, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3774 - val_loss: 0.4344\n",
      "Epoch 34/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3898\n",
      "Epoch 34: val_loss improved from 0.43444 to 0.42507, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3855 - val_loss: 0.4251\n",
      "Epoch 35/100\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.3475\n",
      "Epoch 35: val_loss did not improve from 0.42507\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3568 - val_loss: 0.4294\n",
      "Epoch 36/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3802\n",
      "Epoch 36: val_loss improved from 0.42507 to 0.41991, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3568 - val_loss: 0.4199\n",
      "Epoch 37/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3241\n",
      "Epoch 37: val_loss improved from 0.41991 to 0.41865, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3256 - val_loss: 0.4187\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2986\n",
      "Epoch 38: val_loss improved from 0.41865 to 0.41771, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2986 - val_loss: 0.4177\n",
      "Epoch 39/100\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.3147\n",
      "Epoch 39: val_loss improved from 0.41771 to 0.41436, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3032 - val_loss: 0.4144\n",
      "Epoch 40/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2710\n",
      "Epoch 40: val_loss did not improve from 0.41436\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2767 - val_loss: 0.4395\n",
      "Epoch 41/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2865\n",
      "Epoch 41: val_loss did not improve from 0.41436\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2806 - val_loss: 0.4190\n",
      "Epoch 42/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3145\n",
      "Epoch 42: val_loss did not improve from 0.41436\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2886 - val_loss: 0.4149\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2660\n",
      "Epoch 43: val_loss improved from 0.41436 to 0.41231, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2660 - val_loss: 0.4123\n",
      "Epoch 44/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3037\n",
      "Epoch 44: val_loss improved from 0.41231 to 0.40505, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2766 - val_loss: 0.4051\n",
      "Epoch 45/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2517\n",
      "Epoch 45: val_loss improved from 0.40505 to 0.39749, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2550 - val_loss: 0.3975\n",
      "Epoch 46/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2366\n",
      "Epoch 46: val_loss did not improve from 0.39749\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2346 - val_loss: 0.4039\n",
      "Epoch 47/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2305\n",
      "Epoch 47: val_loss improved from 0.39749 to 0.39352, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.2336 - val_loss: 0.3935\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2358\n",
      "Epoch 48: val_loss improved from 0.39352 to 0.38244, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2358 - val_loss: 0.3824\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2679\n",
      "Epoch 49: val_loss improved from 0.38244 to 0.36610, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2679 - val_loss: 0.3661\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1983\n",
      "Epoch 50: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1983 - val_loss: 0.3968\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2368\n",
      "Epoch 51: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2368 - val_loss: 0.3923\n",
      "Epoch 52/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2051\n",
      "Epoch 52: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2142 - val_loss: 0.3684\n",
      "Epoch 53/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1922\n",
      "Epoch 53: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2028 - val_loss: 0.3743\n",
      "Epoch 54/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1923\n",
      "Epoch 54: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1965 - val_loss: 0.3921\n",
      "Epoch 55/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1898\n",
      "Epoch 55: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1775 - val_loss: 0.3810\n",
      "Epoch 56/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1745\n",
      "Epoch 56: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1671 - val_loss: 0.3939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2212\n",
      "Epoch 57: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2334 - val_loss: 0.3889\n",
      "Epoch 58/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1760\n",
      "Epoch 58: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1670 - val_loss: 0.4048\n",
      "Epoch 59/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1269\n",
      "Epoch 59: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1392 - val_loss: 0.3995\n",
      "Epoch 60/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1767\n",
      "Epoch 60: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1747 - val_loss: 0.3984\n",
      "Epoch 61/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1877\n",
      "Epoch 61: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1728 - val_loss: 0.3979\n",
      "Epoch 62/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1770\n",
      "Epoch 62: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1919 - val_loss: 0.3946\n",
      "Epoch 63/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1851\n",
      "Epoch 63: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1696 - val_loss: 0.3955\n",
      "Epoch 64/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1484\n",
      "Epoch 64: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1466 - val_loss: 0.4002\n",
      "Epoch 65/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1701\n",
      "Epoch 65: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1836 - val_loss: 0.4259\n",
      "Epoch 66/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1733\n",
      "Epoch 66: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1723 - val_loss: 0.3912\n",
      "Epoch 67/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2021\n",
      "Epoch 67: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2064 - val_loss: 0.3797\n",
      "Epoch 68/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1527\n",
      "Epoch 68: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1477 - val_loss: 0.4196\n",
      "Epoch 69/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1579\n",
      "Epoch 69: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1610 - val_loss: 0.3944\n",
      "Epoch 70/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.1875\n",
      "Epoch 70: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1815 - val_loss: 0.3786\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1603\n",
      "Epoch 71: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1603 - val_loss: 0.3991\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1424\n",
      "Epoch 72: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1424 - val_loss: 0.3982\n",
      "Epoch 73/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1204\n",
      "Epoch 73: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1176 - val_loss: 0.4267\n",
      "Epoch 74/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1743\n",
      "Epoch 74: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1687 - val_loss: 0.4045\n",
      "Epoch 75/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1146\n",
      "Epoch 75: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1274 - val_loss: 0.4228\n",
      "Epoch 76/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1220\n",
      "Epoch 76: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1216 - val_loss: 0.5576\n",
      "Epoch 77/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1632\n",
      "Epoch 77: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1491 - val_loss: 0.4306\n",
      "Epoch 78/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1330\n",
      "Epoch 78: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1320 - val_loss: 0.4349\n",
      "Epoch 79/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1129\n",
      "Epoch 79: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1152 - val_loss: 0.4660\n",
      "Epoch 80/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1127\n",
      "Epoch 80: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1116 - val_loss: 0.4548\n",
      "Epoch 81/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1215\n",
      "Epoch 81: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1420 - val_loss: 0.5176\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1113\n",
      "Epoch 82: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1113 - val_loss: 0.4565\n",
      "Epoch 83/100\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.1292\n",
      "Epoch 83: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1355 - val_loss: 0.4670\n",
      "Epoch 84/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1654\n",
      "Epoch 84: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1554 - val_loss: 0.4177\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1291\n",
      "Epoch 85: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1291 - val_loss: 0.4271\n",
      "Epoch 86/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0994\n",
      "Epoch 86: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1007 - val_loss: 0.4781\n",
      "Epoch 87/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1176\n",
      "Epoch 87: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1283 - val_loss: 0.4769\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1214\n",
      "Epoch 88: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1214 - val_loss: 0.4388\n",
      "Epoch 89/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1149\n",
      "Epoch 89: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1195 - val_loss: 0.4281\n",
      "Epoch 90/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1547\n",
      "Epoch 90: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1601 - val_loss: 0.4355\n",
      "Epoch 91/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1355\n",
      "Epoch 91: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1317 - val_loss: 0.4131\n",
      "Epoch 92/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1075\n",
      "Epoch 92: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1194 - val_loss: 0.4199\n",
      "Epoch 93/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0919\n",
      "Epoch 93: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0858 - val_loss: 0.4574\n",
      "Epoch 94/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1013\n",
      "Epoch 94: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1070 - val_loss: 0.4289\n",
      "Epoch 95/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1249\n",
      "Epoch 95: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1200 - val_loss: 0.4257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0964\n",
      "Epoch 96: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0957 - val_loss: 0.4343\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1091\n",
      "Epoch 97: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1091 - val_loss: 0.4736\n",
      "Epoch 98/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0901\n",
      "Epoch 98: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0948 - val_loss: 0.4505\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1259\n",
      "Epoch 99: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1259 - val_loss: 0.4045\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1205\n",
      "Epoch 100: val_loss did not improve from 0.36610\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1205 - val_loss: 0.4177\n",
      "\n",
      "Train/Test model on Fold #2.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/24 [====================>.........] - ETA: 0s - loss: 0.7945\n",
      "Epoch 1: val_loss improved from inf to 0.68556, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 2s 26ms/step - loss: 0.7767 - val_loss: 0.6856\n",
      "Epoch 2/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6720\n",
      "Epoch 2: val_loss improved from 0.68556 to 0.65381, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6968 - val_loss: 0.6538\n",
      "Epoch 3/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6891\n",
      "Epoch 3: val_loss improved from 0.65381 to 0.64828, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6561 - val_loss: 0.6483\n",
      "Epoch 4/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6845\n",
      "Epoch 4: val_loss improved from 0.64828 to 0.64553, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6705 - val_loss: 0.6455\n",
      "Epoch 5/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6581\n",
      "Epoch 5: val_loss improved from 0.64553 to 0.64275, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6686 - val_loss: 0.6428\n",
      "Epoch 6/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6859\n",
      "Epoch 6: val_loss did not improve from 0.64275\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6814 - val_loss: 0.6456\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6465\n",
      "Epoch 7: val_loss improved from 0.64275 to 0.64093, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6465 - val_loss: 0.6409\n",
      "Epoch 8/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6590\n",
      "Epoch 8: val_loss improved from 0.64093 to 0.63711, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6563 - val_loss: 0.6371\n",
      "Epoch 9/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6569\n",
      "Epoch 9: val_loss improved from 0.63711 to 0.63499, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6563 - val_loss: 0.6350\n",
      "Epoch 10/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6298\n",
      "Epoch 10: val_loss improved from 0.63499 to 0.62982, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6297 - val_loss: 0.6298\n",
      "Epoch 11/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6511\n",
      "Epoch 11: val_loss improved from 0.62982 to 0.62907, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6536 - val_loss: 0.6291\n",
      "Epoch 12/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6373\n",
      "Epoch 12: val_loss improved from 0.62907 to 0.62753, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6373 - val_loss: 0.6275\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6235\n",
      "Epoch 13: val_loss improved from 0.62753 to 0.62147, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6235 - val_loss: 0.6215\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6411\n",
      "Epoch 14: val_loss did not improve from 0.62147\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6411 - val_loss: 0.6228\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6024\n",
      "Epoch 15: val_loss improved from 0.62147 to 0.61259, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6024 - val_loss: 0.6126\n",
      "Epoch 16/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.6117\n",
      "Epoch 16: val_loss improved from 0.61259 to 0.60864, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6141 - val_loss: 0.6086\n",
      "Epoch 17/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5989\n",
      "Epoch 17: val_loss improved from 0.60864 to 0.60351, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5945 - val_loss: 0.6035\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6112\n",
      "Epoch 18: val_loss improved from 0.60351 to 0.60091, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6112 - val_loss: 0.6009\n",
      "Epoch 19/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5820\n",
      "Epoch 19: val_loss improved from 0.60091 to 0.59616, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.5814 - val_loss: 0.5962\n",
      "Epoch 20/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5767\n",
      "Epoch 20: val_loss improved from 0.59616 to 0.59185, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5757 - val_loss: 0.5919\n",
      "Epoch 21/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5786\n",
      "Epoch 21: val_loss improved from 0.59185 to 0.58842, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.5774 - val_loss: 0.5884\n",
      "Epoch 22/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.5928\n",
      "Epoch 22: val_loss improved from 0.58842 to 0.58599, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5817 - val_loss: 0.5860\n",
      "Epoch 23/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.5568\n",
      "Epoch 23: val_loss improved from 0.58599 to 0.57638, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5560 - val_loss: 0.5764\n",
      "Epoch 24/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5353\n",
      "Epoch 24: val_loss improved from 0.57638 to 0.56986, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5344 - val_loss: 0.5699\n",
      "Epoch 25/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.5275\n",
      "Epoch 25: val_loss improved from 0.56986 to 0.55991, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5279 - val_loss: 0.5599\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5360\n",
      "Epoch 26: val_loss did not improve from 0.55991\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5360 - val_loss: 0.5600\n",
      "Epoch 27/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4778\n",
      "Epoch 27: val_loss improved from 0.55991 to 0.54567, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4745 - val_loss: 0.5457\n",
      "Epoch 28/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4941\n",
      "Epoch 28: val_loss improved from 0.54567 to 0.53280, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5082 - val_loss: 0.5328\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4614\n",
      "Epoch 29: val_loss improved from 0.53280 to 0.52663, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4614 - val_loss: 0.5266\n",
      "Epoch 30/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4735\n",
      "Epoch 30: val_loss improved from 0.52663 to 0.52435, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4779 - val_loss: 0.5243\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4876\n",
      "Epoch 31: val_loss improved from 0.52435 to 0.50449, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4876 - val_loss: 0.5045\n",
      "Epoch 32/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4386\n",
      "Epoch 32: val_loss did not improve from 0.50449\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4454 - val_loss: 0.5080\n",
      "Epoch 33/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4600\n",
      "Epoch 33: val_loss improved from 0.50449 to 0.49911, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4490 - val_loss: 0.4991\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4200\n",
      "Epoch 34: val_loss improved from 0.49911 to 0.49151, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.4200 - val_loss: 0.4915\n",
      "Epoch 35/100\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.4508\n",
      "Epoch 35: val_loss improved from 0.49151 to 0.47841, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4281 - val_loss: 0.4784\n",
      "Epoch 36/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3964\n",
      "Epoch 36: val_loss improved from 0.47841 to 0.46332, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4001 - val_loss: 0.4633\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3982\n",
      "Epoch 37: val_loss improved from 0.46332 to 0.45929, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3982 - val_loss: 0.4593\n",
      "Epoch 38/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3944\n",
      "Epoch 38: val_loss did not improve from 0.45929\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3896 - val_loss: 0.4604\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3622\n",
      "Epoch 39: val_loss improved from 0.45929 to 0.43307, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3622 - val_loss: 0.4331\n",
      "Epoch 40/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3438\n",
      "Epoch 40: val_loss did not improve from 0.43307\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3474 - val_loss: 0.4545\n",
      "Epoch 41/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3569\n",
      "Epoch 41: val_loss improved from 0.43307 to 0.42219, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3558 - val_loss: 0.4222\n",
      "Epoch 42/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3236\n",
      "Epoch 42: val_loss did not improve from 0.42219\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3280 - val_loss: 0.4712\n",
      "Epoch 43/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3680\n",
      "Epoch 43: val_loss improved from 0.42219 to 0.41897, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3575 - val_loss: 0.4190\n",
      "Epoch 44/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3233\n",
      "Epoch 44: val_loss improved from 0.41897 to 0.40974, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3233 - val_loss: 0.4097\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3327\n",
      "Epoch 45: val_loss improved from 0.40974 to 0.40235, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3327 - val_loss: 0.4024\n",
      "Epoch 46/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2933\n",
      "Epoch 46: val_loss did not improve from 0.40235\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2919 - val_loss: 0.4056\n",
      "Epoch 47/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3300\n",
      "Epoch 47: val_loss did not improve from 0.40235\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3070 - val_loss: 0.4283\n",
      "Epoch 48/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2802\n",
      "Epoch 48: val_loss improved from 0.40235 to 0.39289, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2686 - val_loss: 0.3929\n",
      "Epoch 49/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2945\n",
      "Epoch 49: val_loss did not improve from 0.39289\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2848 - val_loss: 0.4272\n",
      "Epoch 50/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.3014\n",
      "Epoch 50: val_loss did not improve from 0.39289\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3007 - val_loss: 0.4179\n",
      "Epoch 51/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2615\n",
      "Epoch 51: val_loss did not improve from 0.39289\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2671 - val_loss: 0.4362\n",
      "Epoch 52/100\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.2688\n",
      "Epoch 52: val_loss did not improve from 0.39289\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2537 - val_loss: 0.4041\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2762\n",
      "Epoch 53: val_loss did not improve from 0.39289\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2762 - val_loss: 0.3933\n",
      "Epoch 54/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2525\n",
      "Epoch 54: val_loss improved from 0.39289 to 0.38855, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2490 - val_loss: 0.3886\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2494\n",
      "Epoch 55: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2494 - val_loss: 0.3988\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2072\n",
      "Epoch 56: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2072 - val_loss: 0.4250\n",
      "Epoch 57/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1759\n",
      "Epoch 57: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1781 - val_loss: 0.4063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2161\n",
      "Epoch 58: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2358 - val_loss: 0.4012\n",
      "Epoch 59/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2226\n",
      "Epoch 59: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2280 - val_loss: 0.4014\n",
      "Epoch 60/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2119\n",
      "Epoch 60: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2242 - val_loss: 0.4514\n",
      "Epoch 61/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1880\n",
      "Epoch 61: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1985 - val_loss: 0.4734\n",
      "Epoch 62/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2087\n",
      "Epoch 62: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2265 - val_loss: 0.4347\n",
      "Epoch 63/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1835\n",
      "Epoch 63: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1773 - val_loss: 0.4224\n",
      "Epoch 64/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1835\n",
      "Epoch 64: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1880 - val_loss: 0.4107\n",
      "Epoch 65/100\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.2387\n",
      "Epoch 65: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2336 - val_loss: 0.4024\n",
      "Epoch 66/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1993\n",
      "Epoch 66: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1841 - val_loss: 0.4221\n",
      "Epoch 67/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1946\n",
      "Epoch 67: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1772 - val_loss: 0.4128\n",
      "Epoch 68/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1863\n",
      "Epoch 68: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1988 - val_loss: 0.4365\n",
      "Epoch 69/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1679\n",
      "Epoch 69: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1671 - val_loss: 0.4504\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2404\n",
      "Epoch 70: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2404 - val_loss: 0.4227\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1497\n",
      "Epoch 71: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1497 - val_loss: 0.4458\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1915\n",
      "Epoch 72: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1915 - val_loss: 0.4312\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1661\n",
      "Epoch 73: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1661 - val_loss: 0.4322\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1948\n",
      "Epoch 74: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1948 - val_loss: 0.4232\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1555\n",
      "Epoch 75: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1555 - val_loss: 0.4216\n",
      "Epoch 76/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1599\n",
      "Epoch 76: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1560 - val_loss: 0.4874\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1616\n",
      "Epoch 77: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1616 - val_loss: 0.4333\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1965\n",
      "Epoch 78: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1965 - val_loss: 0.4928\n",
      "Epoch 79/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1695\n",
      "Epoch 79: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1694 - val_loss: 0.4379\n",
      "Epoch 80/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1578\n",
      "Epoch 80: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1560 - val_loss: 0.4424\n",
      "Epoch 81/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1693\n",
      "Epoch 81: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1674 - val_loss: 0.4562\n",
      "Epoch 82/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1644\n",
      "Epoch 82: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1703 - val_loss: 0.4294\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1998\n",
      "Epoch 83: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1998 - val_loss: 0.5397\n",
      "Epoch 84/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1529\n",
      "Epoch 84: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1677 - val_loss: 0.4384\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1419\n",
      "Epoch 85: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1419 - val_loss: 0.4757\n",
      "Epoch 86/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1555\n",
      "Epoch 86: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1543 - val_loss: 0.4920\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1682\n",
      "Epoch 87: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1682 - val_loss: 0.5056\n",
      "Epoch 88/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1293\n",
      "Epoch 88: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1235 - val_loss: 0.4622\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1792\n",
      "Epoch 89: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1792 - val_loss: 0.4985\n",
      "Epoch 90/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1679\n",
      "Epoch 90: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1779 - val_loss: 0.5854\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1491\n",
      "Epoch 91: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1491 - val_loss: 0.4600\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1388\n",
      "Epoch 92: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1388 - val_loss: 0.5515\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1309\n",
      "Epoch 93: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1309 - val_loss: 0.4783\n",
      "Epoch 94/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1180\n",
      "Epoch 94: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1111 - val_loss: 0.6018\n",
      "Epoch 95/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1312\n",
      "Epoch 95: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1273 - val_loss: 0.5083\n",
      "Epoch 96/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1633\n",
      "Epoch 96: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1503 - val_loss: 0.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1287\n",
      "Epoch 97: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1286 - val_loss: 0.4886\n",
      "Epoch 98/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1092\n",
      "Epoch 98: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1165 - val_loss: 0.5650\n",
      "Epoch 99/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1526\n",
      "Epoch 99: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1497 - val_loss: 0.4820\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1203\n",
      "Epoch 100: val_loss did not improve from 0.38855\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1203 - val_loss: 0.4737\n",
      "\n",
      "Train/Test model on Fold #3.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/24 [=====================>........] - ETA: 0s - loss: 0.7802\n",
      "Epoch 1: val_loss improved from inf to 0.70174, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 2s 25ms/step - loss: 0.7793 - val_loss: 0.7017\n",
      "Epoch 2/100\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.7300\n",
      "Epoch 2: val_loss improved from 0.70174 to 0.66964, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7191 - val_loss: 0.6696\n",
      "Epoch 3/100\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.6633\n",
      "Epoch 3: val_loss improved from 0.66964 to 0.65594, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6798 - val_loss: 0.6559\n",
      "Epoch 4/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6798\n",
      "Epoch 4: val_loss improved from 0.65594 to 0.65110, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6926 - val_loss: 0.6511\n",
      "Epoch 5/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6483\n",
      "Epoch 5: val_loss improved from 0.65110 to 0.64711, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6604 - val_loss: 0.6471\n",
      "Epoch 6/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6409\n",
      "Epoch 6: val_loss improved from 0.64711 to 0.64556, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6665 - val_loss: 0.6456\n",
      "Epoch 7/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6401\n",
      "Epoch 7: val_loss improved from 0.64556 to 0.64364, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6616 - val_loss: 0.6436\n",
      "Epoch 8/100\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.6407\n",
      "Epoch 8: val_loss improved from 0.64364 to 0.63674, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6452 - val_loss: 0.6367\n",
      "Epoch 9/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5907\n",
      "Epoch 9: val_loss improved from 0.63674 to 0.63126, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6070 - val_loss: 0.6313\n",
      "Epoch 10/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6348\n",
      "Epoch 10: val_loss improved from 0.63126 to 0.62979, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6420 - val_loss: 0.6298\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6246\n",
      "Epoch 11: val_loss improved from 0.62979 to 0.62836, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6246 - val_loss: 0.6284\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6186\n",
      "Epoch 12: val_loss improved from 0.62836 to 0.62582, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6186 - val_loss: 0.6258\n",
      "Epoch 13/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6280\n",
      "Epoch 13: val_loss improved from 0.62582 to 0.62178, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6262 - val_loss: 0.6218\n",
      "Epoch 14/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.6215\n",
      "Epoch 14: val_loss improved from 0.62178 to 0.61952, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6136 - val_loss: 0.6195\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6089\n",
      "Epoch 15: val_loss improved from 0.61952 to 0.61440, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6089 - val_loss: 0.6144\n",
      "Epoch 16/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6222\n",
      "Epoch 16: val_loss improved from 0.61440 to 0.61217, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6111 - val_loss: 0.6122\n",
      "Epoch 17/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.5959\n",
      "Epoch 17: val_loss improved from 0.61217 to 0.60653, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6010 - val_loss: 0.6065\n",
      "Epoch 18/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5900\n",
      "Epoch 18: val_loss improved from 0.60653 to 0.60292, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5861 - val_loss: 0.6029\n",
      "Epoch 19/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5837\n",
      "Epoch 19: val_loss improved from 0.60292 to 0.59850, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5827 - val_loss: 0.5985\n",
      "Epoch 20/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6028\n",
      "Epoch 20: val_loss improved from 0.59850 to 0.59410, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5940 - val_loss: 0.5941\n",
      "Epoch 21/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5759\n",
      "Epoch 21: val_loss improved from 0.59410 to 0.58856, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5733 - val_loss: 0.5886\n",
      "Epoch 22/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5497\n",
      "Epoch 22: val_loss improved from 0.58856 to 0.58432, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5591 - val_loss: 0.5843\n",
      "Epoch 23/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5534\n",
      "Epoch 23: val_loss improved from 0.58432 to 0.57714, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5466 - val_loss: 0.5771\n",
      "Epoch 24/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5503\n",
      "Epoch 24: val_loss improved from 0.57714 to 0.57020, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5596 - val_loss: 0.5702\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5497\n",
      "Epoch 25: val_loss improved from 0.57020 to 0.56459, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5497 - val_loss: 0.5646\n",
      "Epoch 26/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5318\n",
      "Epoch 26: val_loss improved from 0.56459 to 0.56286, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5223 - val_loss: 0.5629\n",
      "Epoch 27/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4963\n",
      "Epoch 27: val_loss improved from 0.56286 to 0.55051, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5054 - val_loss: 0.5505\n",
      "Epoch 28/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5152\n",
      "Epoch 28: val_loss improved from 0.55051 to 0.54151, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5174 - val_loss: 0.5415\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4969\n",
      "Epoch 29: val_loss improved from 0.54151 to 0.53765, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4969 - val_loss: 0.5376\n",
      "Epoch 30/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4458\n",
      "Epoch 30: val_loss improved from 0.53765 to 0.53648, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.4581 - val_loss: 0.5365\n",
      "Epoch 31/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4599\n",
      "Epoch 31: val_loss improved from 0.53648 to 0.51945, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4563 - val_loss: 0.5195\n",
      "Epoch 32/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4346\n",
      "Epoch 32: val_loss did not improve from 0.51945\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4298 - val_loss: 0.5195\n",
      "Epoch 33/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4388\n",
      "Epoch 33: val_loss improved from 0.51945 to 0.51200, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4356 - val_loss: 0.5120\n",
      "Epoch 34/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3852\n",
      "Epoch 34: val_loss improved from 0.51200 to 0.49291, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4110 - val_loss: 0.4929\n",
      "Epoch 35/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4061\n",
      "Epoch 35: val_loss did not improve from 0.49291\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4084 - val_loss: 0.5286\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3760\n",
      "Epoch 36: val_loss did not improve from 0.49291\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3760 - val_loss: 0.5129\n",
      "Epoch 37/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3621\n",
      "Epoch 37: val_loss did not improve from 0.49291\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3612 - val_loss: 0.4988\n",
      "Epoch 38/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3246\n",
      "Epoch 38: val_loss did not improve from 0.49291\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3369 - val_loss: 0.5398\n",
      "Epoch 39/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3707\n",
      "Epoch 39: val_loss did not improve from 0.49291\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3653 - val_loss: 0.5009\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3522\n",
      "Epoch 40: val_loss improved from 0.49291 to 0.47633, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3522 - val_loss: 0.4763\n",
      "Epoch 41/100\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.3296\n",
      "Epoch 41: val_loss improved from 0.47633 to 0.46125, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3327 - val_loss: 0.4612\n",
      "Epoch 42/100\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.2814\n",
      "Epoch 42: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2909 - val_loss: 0.5019\n",
      "Epoch 43/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3208\n",
      "Epoch 43: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3105 - val_loss: 0.4741\n",
      "Epoch 44/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2962\n",
      "Epoch 44: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3237 - val_loss: 0.4898\n",
      "Epoch 45/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2710\n",
      "Epoch 45: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2744 - val_loss: 0.4969\n",
      "Epoch 46/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2495\n",
      "Epoch 46: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2597 - val_loss: 0.4826\n",
      "Epoch 47/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2874\n",
      "Epoch 47: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2594 - val_loss: 0.5678\n",
      "Epoch 48/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2547\n",
      "Epoch 48: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2596 - val_loss: 0.5318\n",
      "Epoch 49/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2476\n",
      "Epoch 49: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2283 - val_loss: 0.5570\n",
      "Epoch 50/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2123\n",
      "Epoch 50: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2115 - val_loss: 0.5905\n",
      "Epoch 51/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2425\n",
      "Epoch 51: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2363 - val_loss: 0.5541\n",
      "Epoch 52/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2256\n",
      "Epoch 52: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2352 - val_loss: 0.6543\n",
      "Epoch 53/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2115\n",
      "Epoch 53: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2213 - val_loss: 0.6009\n",
      "Epoch 54/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2034\n",
      "Epoch 54: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2020 - val_loss: 0.6087\n",
      "Epoch 55/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2189\n",
      "Epoch 55: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2057 - val_loss: 0.5812\n",
      "Epoch 56/100\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.1815\n",
      "Epoch 56: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1845 - val_loss: 0.5788\n",
      "Epoch 57/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1951\n",
      "Epoch 57: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1889 - val_loss: 0.5495\n",
      "Epoch 58/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2129\n",
      "Epoch 58: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1998 - val_loss: 0.6421\n",
      "Epoch 59/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1636\n",
      "Epoch 59: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1499 - val_loss: 0.5887\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1879\n",
      "Epoch 60: val_loss did not improve from 0.46125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1879 - val_loss: 0.6126\n",
      "Epoch 61/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1565\n",
      "Epoch 61: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1576 - val_loss: 0.6068\n",
      "Epoch 62/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1408\n",
      "Epoch 62: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1359 - val_loss: 0.6634\n",
      "Epoch 63/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1585\n",
      "Epoch 63: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1656 - val_loss: 0.5843\n",
      "Epoch 64/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1416\n",
      "Epoch 64: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1403 - val_loss: 0.6393\n",
      "Epoch 65/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1604\n",
      "Epoch 65: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1520 - val_loss: 0.6587\n",
      "Epoch 66/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1576\n",
      "Epoch 66: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1570 - val_loss: 0.6139\n",
      "Epoch 67/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1222\n",
      "Epoch 67: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1255 - val_loss: 0.7219\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1278\n",
      "Epoch 68: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1278 - val_loss: 0.7007\n",
      "Epoch 69/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1652\n",
      "Epoch 69: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1551 - val_loss: 0.7236\n",
      "Epoch 70/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1693\n",
      "Epoch 70: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1577 - val_loss: 0.7261\n",
      "Epoch 71/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1844\n",
      "Epoch 71: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1637 - val_loss: 0.6422\n",
      "Epoch 72/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1613\n",
      "Epoch 72: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1538 - val_loss: 0.6785\n",
      "Epoch 73/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1260\n",
      "Epoch 73: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1168 - val_loss: 0.7090\n",
      "Epoch 74/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1271\n",
      "Epoch 74: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1377 - val_loss: 0.7079\n",
      "Epoch 75/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1216\n",
      "Epoch 75: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1235 - val_loss: 0.7715\n",
      "Epoch 76/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1420\n",
      "Epoch 76: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1450 - val_loss: 0.7428\n",
      "Epoch 77/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1687\n",
      "Epoch 77: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1484 - val_loss: 0.7185\n",
      "Epoch 78/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1190\n",
      "Epoch 78: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1193 - val_loss: 0.7443\n",
      "Epoch 79/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1418\n",
      "Epoch 79: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1352 - val_loss: 0.7380\n",
      "Epoch 80/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1476\n",
      "Epoch 80: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1291 - val_loss: 0.7254\n",
      "Epoch 81/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1174\n",
      "Epoch 81: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1152 - val_loss: 0.7746\n",
      "Epoch 82/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1105\n",
      "Epoch 82: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1115 - val_loss: 0.7901\n",
      "Epoch 83/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1027\n",
      "Epoch 83: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1099 - val_loss: 0.7908\n",
      "Epoch 84/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1170\n",
      "Epoch 84: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1083 - val_loss: 0.7676\n",
      "Epoch 85/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1109\n",
      "Epoch 85: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1210 - val_loss: 0.7827\n",
      "Epoch 86/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1222\n",
      "Epoch 86: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1131 - val_loss: 0.7990\n",
      "Epoch 87/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0902\n",
      "Epoch 87: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0990 - val_loss: 0.7644\n",
      "Epoch 88/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1270\n",
      "Epoch 88: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1252 - val_loss: 0.8039\n",
      "Epoch 89/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1114\n",
      "Epoch 89: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1118 - val_loss: 0.7711\n",
      "Epoch 90/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1133\n",
      "Epoch 90: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1046 - val_loss: 0.7361\n",
      "Epoch 91/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1045\n",
      "Epoch 91: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1155 - val_loss: 0.7399\n",
      "Epoch 92/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0855\n",
      "Epoch 92: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0859 - val_loss: 0.8380\n",
      "Epoch 93/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1163\n",
      "Epoch 93: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1139 - val_loss: 0.8582\n",
      "Epoch 94/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1232\n",
      "Epoch 94: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1114 - val_loss: 0.8267\n",
      "Epoch 95/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1107\n",
      "Epoch 95: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1181 - val_loss: 0.8245\n",
      "Epoch 96/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0865\n",
      "Epoch 96: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0888 - val_loss: 0.8278\n",
      "Epoch 97/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1149\n",
      "Epoch 97: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1062 - val_loss: 0.8239\n",
      "Epoch 98/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1060\n",
      "Epoch 98: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1091 - val_loss: 0.9106\n",
      "Epoch 99/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1095\n",
      "Epoch 99: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1234 - val_loss: 0.7790\n",
      "Epoch 100/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1245\n",
      "Epoch 100: val_loss did not improve from 0.46125\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1114 - val_loss: 0.8048\n",
      "\n",
      "Train/Test model on Fold #4.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - ETA: 0s - loss: 0.8317\n",
      "Epoch 1: val_loss improved from inf to 0.68672, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 2s 26ms/step - loss: 0.8317 - val_loss: 0.6867\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.7261\n",
      "Epoch 2: val_loss improved from 0.68672 to 0.65247, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7261 - val_loss: 0.6525\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6774\n",
      "Epoch 3: val_loss improved from 0.65247 to 0.64416, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6774 - val_loss: 0.6442\n",
      "Epoch 4/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6717\n",
      "Epoch 4: val_loss improved from 0.64416 to 0.64000, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6709 - val_loss: 0.6400\n",
      "Epoch 5/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6825\n",
      "Epoch 5: val_loss improved from 0.64000 to 0.63748, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6669 - val_loss: 0.6375\n",
      "Epoch 6/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6746\n",
      "Epoch 6: val_loss improved from 0.63748 to 0.63564, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6939 - val_loss: 0.6356\n",
      "Epoch 7/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6592\n",
      "Epoch 7: val_loss improved from 0.63564 to 0.63391, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6703 - val_loss: 0.6339\n",
      "Epoch 8/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6505\n",
      "Epoch 8: val_loss improved from 0.63391 to 0.63057, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6560 - val_loss: 0.6306\n",
      "Epoch 9/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6550\n",
      "Epoch 9: val_loss improved from 0.63057 to 0.62811, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6375 - val_loss: 0.6281\n",
      "Epoch 10/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6516\n",
      "Epoch 10: val_loss improved from 0.62811 to 0.62417, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6416 - val_loss: 0.6242\n",
      "Epoch 11/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6144\n",
      "Epoch 11: val_loss improved from 0.62417 to 0.62059, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6318 - val_loss: 0.6206\n",
      "Epoch 12/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6366\n",
      "Epoch 12: val_loss improved from 0.62059 to 0.61829, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6332 - val_loss: 0.6183\n",
      "Epoch 13/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6100\n",
      "Epoch 13: val_loss improved from 0.61829 to 0.61664, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6148 - val_loss: 0.6166\n",
      "Epoch 14/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6271\n",
      "Epoch 14: val_loss improved from 0.61664 to 0.61439, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6187 - val_loss: 0.6144\n",
      "Epoch 15/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6110\n",
      "Epoch 15: val_loss improved from 0.61439 to 0.61067, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6144 - val_loss: 0.6107\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6332\n",
      "Epoch 16: val_loss improved from 0.61067 to 0.60864, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6332 - val_loss: 0.6086\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6150\n",
      "Epoch 17: val_loss improved from 0.60864 to 0.60485, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6150 - val_loss: 0.6048\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.6067\n",
      "Epoch 18: val_loss improved from 0.60485 to 0.60235, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6067 - val_loss: 0.6023\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5994\n",
      "Epoch 19: val_loss improved from 0.60235 to 0.59836, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5994 - val_loss: 0.5984\n",
      "Epoch 20/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.6040\n",
      "Epoch 20: val_loss improved from 0.59836 to 0.59575, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5958 - val_loss: 0.5957\n",
      "Epoch 21/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.5921\n",
      "Epoch 21: val_loss improved from 0.59575 to 0.59258, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5923 - val_loss: 0.5926\n",
      "Epoch 22/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5631\n",
      "Epoch 22: val_loss improved from 0.59258 to 0.58838, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5768 - val_loss: 0.5884\n",
      "Epoch 23/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5949\n",
      "Epoch 23: val_loss improved from 0.58838 to 0.58440, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5848 - val_loss: 0.5844\n",
      "Epoch 24/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5856\n",
      "Epoch 24: val_loss improved from 0.58440 to 0.57974, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5572 - val_loss: 0.5797\n",
      "Epoch 25/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5958\n",
      "Epoch 25: val_loss improved from 0.57974 to 0.57450, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5959 - val_loss: 0.5745\n",
      "Epoch 26/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.5784\n",
      "Epoch 26: val_loss improved from 0.57450 to 0.57258, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5787 - val_loss: 0.5726\n",
      "Epoch 27/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5860\n",
      "Epoch 27: val_loss improved from 0.57258 to 0.56535, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5477 - val_loss: 0.5653\n",
      "Epoch 28/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5335\n",
      "Epoch 28: val_loss improved from 0.56535 to 0.55661, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5367 - val_loss: 0.5566\n",
      "Epoch 29/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.5266\n",
      "Epoch 29: val_loss improved from 0.55661 to 0.55228, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5322 - val_loss: 0.5523\n",
      "Epoch 30/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.5396\n",
      "Epoch 30: val_loss improved from 0.55228 to 0.54228, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5349 - val_loss: 0.5423\n",
      "Epoch 31/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4863\n",
      "Epoch 31: val_loss improved from 0.54228 to 0.52999, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5005 - val_loss: 0.5300\n",
      "Epoch 32/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4577\n",
      "Epoch 32: val_loss improved from 0.52999 to 0.51689, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4679 - val_loss: 0.5169\n",
      "Epoch 33/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4987\n",
      "Epoch 33: val_loss improved from 0.51689 to 0.51037, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4882 - val_loss: 0.5104\n",
      "Epoch 34/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4370\n",
      "Epoch 34: val_loss improved from 0.51037 to 0.49620, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4184 - val_loss: 0.4962\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3954\n",
      "Epoch 35: val_loss did not improve from 0.49620\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3954 - val_loss: 0.5171\n",
      "Epoch 36/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.4616\n",
      "Epoch 36: val_loss improved from 0.49620 to 0.47507, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4280 - val_loss: 0.4751\n",
      "Epoch 37/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3795\n",
      "Epoch 37: val_loss did not improve from 0.47507\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3812 - val_loss: 0.4751\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3665\n",
      "Epoch 38: val_loss improved from 0.47507 to 0.45503, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3665 - val_loss: 0.4550\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3286\n",
      "Epoch 39: val_loss did not improve from 0.45503\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3286 - val_loss: 0.4646\n",
      "Epoch 40/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3235\n",
      "Epoch 40: val_loss improved from 0.45503 to 0.44604, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3146 - val_loss: 0.4460\n",
      "Epoch 41/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2975\n",
      "Epoch 41: val_loss did not improve from 0.44604\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2930 - val_loss: 0.4587\n",
      "Epoch 42/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2919\n",
      "Epoch 42: val_loss improved from 0.44604 to 0.43843, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2980 - val_loss: 0.4384\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2756\n",
      "Epoch 43: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2756 - val_loss: 0.4472\n",
      "Epoch 44/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2900\n",
      "Epoch 44: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2868 - val_loss: 0.4971\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2661\n",
      "Epoch 45: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2661 - val_loss: 0.4742\n",
      "Epoch 46/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2687\n",
      "Epoch 46: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2606 - val_loss: 0.4623\n",
      "Epoch 47/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.3034\n",
      "Epoch 47: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2873 - val_loss: 0.4465\n",
      "Epoch 48/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2613\n",
      "Epoch 48: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2523 - val_loss: 0.4503\n",
      "Epoch 49/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2299\n",
      "Epoch 49: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2163 - val_loss: 0.4736\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2748\n",
      "Epoch 50: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2748 - val_loss: 0.4653\n",
      "Epoch 51/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1959\n",
      "Epoch 51: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2138 - val_loss: 0.4515\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2255\n",
      "Epoch 52: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2255 - val_loss: 0.4627\n",
      "Epoch 53/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2152\n",
      "Epoch 53: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2268 - val_loss: 0.4512\n",
      "Epoch 54/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2184\n",
      "Epoch 54: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2275 - val_loss: 0.4548\n",
      "Epoch 55/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2161\n",
      "Epoch 55: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2150 - val_loss: 0.4404\n",
      "Epoch 56/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2003\n",
      "Epoch 56: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2186 - val_loss: 0.4474\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2072\n",
      "Epoch 57: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2072 - val_loss: 0.4787\n",
      "Epoch 58/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1677\n",
      "Epoch 58: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1660 - val_loss: 0.5030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1835\n",
      "Epoch 59: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1962 - val_loss: 0.4793\n",
      "Epoch 60/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1716\n",
      "Epoch 60: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1685 - val_loss: 0.5296\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1856\n",
      "Epoch 61: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1856 - val_loss: 0.5093\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1599\n",
      "Epoch 62: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1599 - val_loss: 0.5455\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1671\n",
      "Epoch 63: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1671 - val_loss: 0.4955\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1663\n",
      "Epoch 64: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1663 - val_loss: 0.4892\n",
      "Epoch 65/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1606\n",
      "Epoch 65: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1584 - val_loss: 0.5003\n",
      "Epoch 66/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1653\n",
      "Epoch 66: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1622 - val_loss: 0.5024\n",
      "Epoch 67/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1862\n",
      "Epoch 67: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1867 - val_loss: 0.5073\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1747\n",
      "Epoch 68: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1747 - val_loss: 0.5108\n",
      "Epoch 69/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1334\n",
      "Epoch 69: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1468 - val_loss: 0.4976\n",
      "Epoch 70/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1490\n",
      "Epoch 70: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1591 - val_loss: 0.4927\n",
      "Epoch 71/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1494\n",
      "Epoch 71: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1480 - val_loss: 0.4969\n",
      "Epoch 72/100\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.1235\n",
      "Epoch 72: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1265 - val_loss: 0.5293\n",
      "Epoch 73/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1480\n",
      "Epoch 73: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1463 - val_loss: 0.5173\n",
      "Epoch 74/100\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.1400\n",
      "Epoch 74: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1385 - val_loss: 0.5390\n",
      "Epoch 75/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1511\n",
      "Epoch 75: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1755 - val_loss: 0.6020\n",
      "Epoch 76/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1339\n",
      "Epoch 76: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1304 - val_loss: 0.5330\n",
      "Epoch 77/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1419\n",
      "Epoch 77: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1335 - val_loss: 0.5586\n",
      "Epoch 78/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1179\n",
      "Epoch 78: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1149 - val_loss: 0.5414\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1470\n",
      "Epoch 79: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1470 - val_loss: 0.5419\n",
      "Epoch 80/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1108\n",
      "Epoch 80: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1110 - val_loss: 0.5534\n",
      "Epoch 81/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0991\n",
      "Epoch 81: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0969 - val_loss: 0.5640\n",
      "Epoch 82/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1230\n",
      "Epoch 82: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1230 - val_loss: 0.5833\n",
      "Epoch 83/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1394\n",
      "Epoch 83: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1469 - val_loss: 0.5733\n",
      "Epoch 84/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1407\n",
      "Epoch 84: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1364 - val_loss: 0.5767\n",
      "Epoch 85/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1477\n",
      "Epoch 85: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1414 - val_loss: 0.5350\n",
      "Epoch 86/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1091\n",
      "Epoch 86: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1074 - val_loss: 0.5682\n",
      "Epoch 87/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1225\n",
      "Epoch 87: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1170 - val_loss: 0.5433\n",
      "Epoch 88/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1203\n",
      "Epoch 88: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1319 - val_loss: 0.5517\n",
      "Epoch 89/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1184\n",
      "Epoch 89: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1277 - val_loss: 0.5886\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1145\n",
      "Epoch 90: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1145 - val_loss: 0.5821\n",
      "Epoch 91/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0971\n",
      "Epoch 91: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0935 - val_loss: 0.5887\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1112\n",
      "Epoch 92: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1112 - val_loss: 0.5858\n",
      "Epoch 93/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0890\n",
      "Epoch 93: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0966 - val_loss: 0.6000\n",
      "Epoch 94/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0790\n",
      "Epoch 94: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0808 - val_loss: 0.6165\n",
      "Epoch 95/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1231\n",
      "Epoch 95: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1355 - val_loss: 0.6195\n",
      "Epoch 96/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1056\n",
      "Epoch 96: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1035 - val_loss: 0.6310\n",
      "Epoch 97/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1070\n",
      "Epoch 97: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1050 - val_loss: 0.6315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1095\n",
      "Epoch 98: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1095 - val_loss: 0.6432\n",
      "Epoch 99/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1258\n",
      "Epoch 99: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1286 - val_loss: 0.5910\n",
      "Epoch 100/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.0729\n",
      "Epoch 100: val_loss did not improve from 0.43843\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0896 - val_loss: 0.6293\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Train/Test model on all folds, generate evaluations\n",
    "##################################################################################\n",
    "\n",
    "## Create and set directory to save model\n",
    "modelPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold), \"models\")\n",
    "if(not os.path.isdir(modelPath)):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "i = -1\n",
    "for fold in folds:\n",
    "    i += 1\n",
    "    \n",
    "    print(\"\\nTrain/Test model on Fold #\"+str(i)+\".\")\n",
    "    \n",
    "    model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "    ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    modelCallbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                           monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                           save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "    ]\n",
    "    \n",
    "    # adding random shuffling of the dataset for training purpose\n",
    "    index_arr = np.arange(fold[\"X_train\"].shape[0])\n",
    "    index_arr = np.random.permutation(index_arr)\n",
    "    \n",
    "    model.fit(x = fold[\"X_train\"][index_arr], y = fold[\"y_train\"][index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "              callbacks = modelCallbacks, validation_data = (fold[\"X_test\"], fold[\"y_test\"]))\n",
    "    \n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TRAIN dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_train\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Train\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TEST dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_test\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Test\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.906428</td>\n",
       "      <td>0.862443</td>\n",
       "      <td>0.893417</td>\n",
       "      <td>0.919635</td>\n",
       "      <td>0.862443</td>\n",
       "      <td>0.739371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.984083</td>\n",
       "      <td>0.967855</td>\n",
       "      <td>0.995150</td>\n",
       "      <td>0.989553</td>\n",
       "      <td>0.967855</td>\n",
       "      <td>0.957221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                   \n",
       "Test        0.906428   0.862443  0.893417     0.919635     0.862443  0.739371\n",
       "Train       0.984083   0.967855  0.995150     0.989553     0.967855  0.957221"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 16\n",
    "# \tAccuracy\tPrecision\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# Train_Test\t\t\t\t\t\t\n",
    "# Test\t0.943310\t0.923092\t0.965850\t0.957041\t0.923092\t0.881812\n",
    "# Train\t0.997427\t0.995646\t0.999898\t0.998589\t0.995646\t0.994615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.041666666666666664, 0.9166666666666666...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.04225352112676056, 0.0422535...</td>\n",
       "      <td>[1.9875169, 0.9875168, 0.81538314, 0.08427684,...</td>\n",
       "      <td>0.975352</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>[0.0, 0.0, 0.13043478260869565, 0.130434782608...</td>\n",
       "      <td>[0.0, 0.014084507042253521, 0.0140845070422535...</td>\n",
       "      <td>[1.9530256, 0.95302564, 0.91644675, 0.9053425,...</td>\n",
       "      <td>0.913656</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.712186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>[0.0, 0.043478260869565216, 0.5217391304347826...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.014084507042253521, 0.014084...</td>\n",
       "      <td>[1.9249774, 0.9249774, 0.80512834, 0.8016588, ...</td>\n",
       "      <td>0.889161</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.699462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>[0.0, 0.0, 0.6521739130434783, 0.6521739130434...</td>\n",
       "      <td>[0.0, 0.014084507042253521, 0.0140845070422535...</td>\n",
       "      <td>[1.9252974, 0.9252974, 0.55983454, 0.30217847,...</td>\n",
       "      <td>0.831598</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.729907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[0.0, 0.043478260869565216, 0.1739130434782608...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.014084507042253521, 0.014084...</td>\n",
       "      <td>[1.9508462, 0.95084625, 0.8793011, 0.8486935, ...</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.611082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Train_Test  Accuracy  Precision  \\\n",
       "1     0       Test  0.978947   1.000000   \n",
       "3     1       Test  0.893617   0.782609   \n",
       "5     2       Test  0.893617   0.842105   \n",
       "7     3       Test  0.904255   0.937500   \n",
       "9     4       Test  0.861702   0.750000   \n",
       "\n",
       "                                                 TPR  \\\n",
       "1  [0.0, 0.041666666666666664, 0.9166666666666666...   \n",
       "3  [0.0, 0.0, 0.13043478260869565, 0.130434782608...   \n",
       "5  [0.0, 0.043478260869565216, 0.5217391304347826...   \n",
       "7  [0.0, 0.0, 0.6521739130434783, 0.6521739130434...   \n",
       "9  [0.0, 0.043478260869565216, 0.1739130434782608...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "1  [0.0, 0.0, 0.0, 0.04225352112676056, 0.0422535...   \n",
       "3  [0.0, 0.014084507042253521, 0.0140845070422535...   \n",
       "5  [0.0, 0.0, 0.0, 0.014084507042253521, 0.014084...   \n",
       "7  [0.0, 0.014084507042253521, 0.0140845070422535...   \n",
       "9  [0.0, 0.0, 0.0, 0.014084507042253521, 0.014084...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "1  [1.9875169, 0.9875168, 0.81538314, 0.08427684,...  0.975352     0.972603   \n",
       "3  [1.9530256, 0.95302564, 0.91644675, 0.9053425,...  0.913656     0.929577   \n",
       "5  [1.9249774, 0.9249774, 0.80512834, 0.8016588, ...  0.889161     0.906667   \n",
       "7  [1.9252974, 0.9252974, 0.55983454, 0.30217847,...  0.831598     0.897436   \n",
       "9  [1.9508462, 0.95084625, 0.8793011, 0.8486935, ...  0.857318     0.891892   \n",
       "\n",
       "   Specificity       MCC  \n",
       "1     1.000000  0.944221  \n",
       "3     0.782609  0.712186  \n",
       "5     0.842105  0.699462  \n",
       "7     0.937500  0.729907  \n",
       "9     0.750000  0.611082  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df[evaluations_df[\"Train_Test\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using k-fold Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of each k-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.875248</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.863026</td>\n",
       "      <td>0.893346</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.64846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity      MCC\n",
       "Train_Test                                                                   \n",
       "Independent  0.875248   0.809524  0.863026     0.893346     0.809524  0.64846"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    label_pred = pred2label(y_pred)\n",
    "\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(indpe_labels, label_pred)\n",
    "    prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "    conf = confusion_matrix(indpe_labels, label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "    auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>[0.0, 0.02, 0.52, 0.52, 0.54, 0.54, 0.6, 0.6, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...</td>\n",
       "      <td>[1.9910834, 0.9910834, 0.9048365, 0.9032092, 0...</td>\n",
       "      <td>0.888289</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.667183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.866337</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>[0.0, 0.02, 0.28, 0.28, 0.5, 0.5, 0.52, 0.52, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...</td>\n",
       "      <td>[1.969076, 0.96907604, 0.90845865, 0.90223265,...</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.618063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.886139</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>[0.0, 0.02, 0.22, 0.22, 0.56, 0.56, 0.58, 0.58...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...</td>\n",
       "      <td>[1.9743633, 0.97436327, 0.9182227, 0.9003077, ...</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.682536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>[0.0, 0.02, 0.3, 0.3, 0.42, 0.42, 0.44, 0.44, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...</td>\n",
       "      <td>[1.9477913, 0.9477914, 0.7897756, 0.7895232, 0...</td>\n",
       "      <td>0.793026</td>\n",
       "      <td>0.854651</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.566887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>[0.0, 0.02, 0.14, 0.14, 0.24, 0.24, 0.5, 0.5, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...</td>\n",
       "      <td>[1.9304771, 0.93047714, 0.9067157, 0.9054375, ...</td>\n",
       "      <td>0.893158</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.707632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold   Train_Test  Accuracy  Precision  \\\n",
       "0     0  Independent  0.881188   0.809524   \n",
       "1     1  Independent  0.866337   0.810811   \n",
       "2     2  Independent  0.886139   0.813953   \n",
       "3     3  Independent  0.851485   0.833333   \n",
       "4     4  Independent  0.891089   0.780000   \n",
       "\n",
       "                                                 TPR  \\\n",
       "0  [0.0, 0.02, 0.52, 0.52, 0.54, 0.54, 0.6, 0.6, ...   \n",
       "1  [0.0, 0.02, 0.28, 0.28, 0.5, 0.5, 0.52, 0.52, ...   \n",
       "2  [0.0, 0.02, 0.22, 0.22, 0.56, 0.56, 0.58, 0.58...   \n",
       "3  [0.0, 0.02, 0.3, 0.3, 0.42, 0.42, 0.44, 0.44, ...   \n",
       "4  [0.0, 0.02, 0.14, 0.14, 0.24, 0.24, 0.5, 0.5, ...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "0  [0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...   \n",
       "1  [0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...   \n",
       "2  [0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...   \n",
       "3  [0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...   \n",
       "4  [0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0  [1.9910834, 0.9910834, 0.9048365, 0.9032092, 0...  0.888289     0.900000   \n",
       "1  [1.969076, 0.96907604, 0.90845865, 0.90223265,...  0.863158     0.878788   \n",
       "2  [1.9743633, 0.97436327, 0.9182227, 0.9003077, ...  0.877500     0.905660   \n",
       "3  [1.9477913, 0.9477914, 0.7897756, 0.7895232, 0...  0.793026     0.854651   \n",
       "4  [1.9304771, 0.93047714, 0.9067157, 0.9054375, ...  0.893158     0.927632   \n",
       "\n",
       "   Specificity       MCC  \n",
       "0     0.809524  0.667183  \n",
       "1     0.810811  0.618063  \n",
       "2     0.813953  0.682536  \n",
       "3     0.833333  0.566887  \n",
       "4     0.780000  0.707632  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.930693</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.882368</td>\n",
       "      <td>0.93125</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.930693   0.928571  0.882368      0.93125     0.928571  0.808511"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    total_pred += y_pred\n",
    "    all_preds.append(y_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "if(conf[0][0]+conf[1][0]):\n",
    "    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "else:\n",
    "    sens = 0.0\n",
    "if(conf[1][1]+conf[0][1]):\n",
    "    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "else:\n",
    "    spec = 0.0\n",
    "if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "else:\n",
    "    mcc= 0.0\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.905941</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.884934</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.737268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.905941   0.878049  0.884934     0.913043     0.878049  0.737268"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    vote_pred = pred2label(y_pred)\n",
    "    total_pred += vote_pred\n",
    "    all_preds.append(vote_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "if(conf[0][0]+conf[1][0]):\n",
    "    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "else:\n",
    "    sens = 0.0\n",
    "if(conf[1][1]+conf[0][1]):\n",
    "    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "else:\n",
    "    spec = 0.0\n",
    "if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "else:\n",
    "    mcc= 0.0\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using New Model\n",
    "\n",
    "Train one model on full data from training. Predict and evaluate on Independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - ETA: 0s - loss: 0.7621\n",
      "Epoch 1: val_loss improved from inf to 0.70310, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 2s 29ms/step - loss: 0.7621 - val_loss: 0.7031\n",
      "Epoch 2/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.6919\n",
      "Epoch 2: val_loss improved from 0.70310 to 0.66304, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6896 - val_loss: 0.6630\n",
      "Epoch 3/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.6843\n",
      "Epoch 3: val_loss improved from 0.66304 to 0.65584, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6810 - val_loss: 0.6558\n",
      "Epoch 4/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.6791\n",
      "Epoch 4: val_loss improved from 0.65584 to 0.64872, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6728 - val_loss: 0.6487\n",
      "Epoch 5/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.6727\n",
      "Epoch 5: val_loss improved from 0.64872 to 0.64329, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6659 - val_loss: 0.6433\n",
      "Epoch 6/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.6525\n",
      "Epoch 6: val_loss improved from 0.64329 to 0.63862, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6553 - val_loss: 0.6386\n",
      "Epoch 7/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.6634\n",
      "Epoch 7: val_loss did not improve from 0.63862\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6559 - val_loss: 0.6408\n",
      "Epoch 8/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.6491\n",
      "Epoch 8: val_loss improved from 0.63862 to 0.63372, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6508 - val_loss: 0.6337\n",
      "Epoch 9/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.6682\n",
      "Epoch 9: val_loss improved from 0.63372 to 0.63323, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6603 - val_loss: 0.6332\n",
      "Epoch 10/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.6333\n",
      "Epoch 10: val_loss improved from 0.63323 to 0.62299, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6379 - val_loss: 0.6230\n",
      "Epoch 11/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.6427\n",
      "Epoch 11: val_loss improved from 0.62299 to 0.62061, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6317 - val_loss: 0.6206\n",
      "Epoch 12/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.6438\n",
      "Epoch 12: val_loss improved from 0.62061 to 0.61573, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6359 - val_loss: 0.6157\n",
      "Epoch 13/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.6189\n",
      "Epoch 13: val_loss improved from 0.61573 to 0.60926, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6232 - val_loss: 0.6093\n",
      "Epoch 14/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.6325\n",
      "Epoch 14: val_loss improved from 0.60926 to 0.60886, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6305 - val_loss: 0.6089\n",
      "Epoch 15/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.6122\n",
      "Epoch 15: val_loss improved from 0.60886 to 0.60423, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6221 - val_loss: 0.6042\n",
      "Epoch 16/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.6079\n",
      "Epoch 16: val_loss improved from 0.60423 to 0.59869, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6056 - val_loss: 0.5987\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6107\n",
      "Epoch 17: val_loss improved from 0.59869 to 0.59303, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6107 - val_loss: 0.5930\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5937\n",
      "Epoch 18: val_loss improved from 0.59303 to 0.58770, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5937 - val_loss: 0.5877\n",
      "Epoch 19/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5905\n",
      "Epoch 19: val_loss improved from 0.58770 to 0.57634, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.5904 - val_loss: 0.5763\n",
      "Epoch 20/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.5684\n",
      "Epoch 20: val_loss improved from 0.57634 to 0.56764, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5762 - val_loss: 0.5676\n",
      "Epoch 21/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.5679\n",
      "Epoch 21: val_loss improved from 0.56764 to 0.55971, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5750 - val_loss: 0.5597\n",
      "Epoch 22/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.5400\n",
      "Epoch 22: val_loss improved from 0.55971 to 0.54313, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5266 - val_loss: 0.5431\n",
      "Epoch 23/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5341\n",
      "Epoch 23: val_loss improved from 0.54313 to 0.53773, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5385 - val_loss: 0.5377\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5326\n",
      "Epoch 24: val_loss improved from 0.53773 to 0.52609, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5326 - val_loss: 0.5261\n",
      "Epoch 25/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.4808\n",
      "Epoch 25: val_loss improved from 0.52609 to 0.51253, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4959 - val_loss: 0.5125\n",
      "Epoch 26/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.5102\n",
      "Epoch 26: val_loss improved from 0.51253 to 0.50604, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5064 - val_loss: 0.5060\n",
      "Epoch 27/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4841\n",
      "Epoch 27: val_loss improved from 0.50604 to 0.49584, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4846 - val_loss: 0.4958\n",
      "Epoch 28/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4642\n",
      "Epoch 28: val_loss improved from 0.49584 to 0.48628, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4623 - val_loss: 0.4863\n",
      "Epoch 29/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4786\n",
      "Epoch 29: val_loss improved from 0.48628 to 0.47876, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4758 - val_loss: 0.4788\n",
      "Epoch 30/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.4508\n",
      "Epoch 30: val_loss improved from 0.47876 to 0.46067, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4554 - val_loss: 0.4607\n",
      "Epoch 31/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3842\n",
      "Epoch 31: val_loss did not improve from 0.46067\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3897 - val_loss: 0.4626\n",
      "Epoch 32/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4181\n",
      "Epoch 32: val_loss improved from 0.46067 to 0.44822, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4124 - val_loss: 0.4482\n",
      "Epoch 33/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3717\n",
      "Epoch 33: val_loss improved from 0.44822 to 0.44253, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3802 - val_loss: 0.4425\n",
      "Epoch 34/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3913\n",
      "Epoch 34: val_loss improved from 0.44253 to 0.43060, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3903 - val_loss: 0.4306\n",
      "Epoch 35/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.3534\n",
      "Epoch 35: val_loss did not improve from 0.43060\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3564 - val_loss: 0.4314\n",
      "Epoch 36/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.3716\n",
      "Epoch 36: val_loss improved from 0.43060 to 0.41809, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3625 - val_loss: 0.4181\n",
      "Epoch 37/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.3313\n",
      "Epoch 37: val_loss did not improve from 0.41809\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3121 - val_loss: 0.4329\n",
      "Epoch 38/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.3256\n",
      "Epoch 38: val_loss improved from 0.41809 to 0.41767, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3250 - val_loss: 0.4177\n",
      "Epoch 39/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.3100\n",
      "Epoch 39: val_loss improved from 0.41767 to 0.41055, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3198 - val_loss: 0.4105\n",
      "Epoch 40/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.3242\n",
      "Epoch 40: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3159 - val_loss: 0.4199\n",
      "Epoch 41/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2558\n",
      "Epoch 41: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2739 - val_loss: 0.4114\n",
      "Epoch 42/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2875\n",
      "Epoch 42: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2871 - val_loss: 0.4112\n",
      "Epoch 43/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2667\n",
      "Epoch 43: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3003 - val_loss: 0.4529\n",
      "Epoch 44/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2611\n",
      "Epoch 44: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2658 - val_loss: 0.4296\n",
      "Epoch 45/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2425\n",
      "Epoch 45: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2433 - val_loss: 0.4547\n",
      "Epoch 46/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2355\n",
      "Epoch 46: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2384 - val_loss: 0.4807\n",
      "Epoch 47/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2650\n",
      "Epoch 47: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2652 - val_loss: 0.4256\n",
      "Epoch 48/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.2170\n",
      "Epoch 48: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2306 - val_loss: 0.4602\n",
      "Epoch 49/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2500\n",
      "Epoch 49: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2454 - val_loss: 0.4247\n",
      "Epoch 50/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2071\n",
      "Epoch 50: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2160 - val_loss: 0.4257\n",
      "Epoch 51/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2049\n",
      "Epoch 51: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1969 - val_loss: 0.4457\n",
      "Epoch 52/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2050\n",
      "Epoch 52: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2058 - val_loss: 0.4610\n",
      "Epoch 53/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2194\n",
      "Epoch 53: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2223 - val_loss: 0.4565\n",
      "Epoch 54/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1843\n",
      "Epoch 54: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1786 - val_loss: 0.5153\n",
      "Epoch 55/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1643\n",
      "Epoch 55: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1752 - val_loss: 0.4724\n",
      "Epoch 56/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2047\n",
      "Epoch 56: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2113 - val_loss: 0.4596\n",
      "Epoch 57/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1905\n",
      "Epoch 57: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1788 - val_loss: 0.4560\n",
      "Epoch 58/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1719\n",
      "Epoch 58: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1744 - val_loss: 0.4859\n",
      "Epoch 59/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1769\n",
      "Epoch 59: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1799 - val_loss: 0.4698\n",
      "Epoch 60/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1656\n",
      "Epoch 60: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1589 - val_loss: 0.4858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1679\n",
      "Epoch 61: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1643 - val_loss: 0.4857\n",
      "Epoch 62/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1873\n",
      "Epoch 62: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1841 - val_loss: 0.4917\n",
      "Epoch 63/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1855\n",
      "Epoch 63: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1747 - val_loss: 0.5325\n",
      "Epoch 64/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1577\n",
      "Epoch 64: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1560 - val_loss: 0.4987\n",
      "Epoch 65/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1404\n",
      "Epoch 65: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1494 - val_loss: 0.5819\n",
      "Epoch 66/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1600\n",
      "Epoch 66: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1597 - val_loss: 0.5162\n",
      "Epoch 67/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.1862\n",
      "Epoch 67: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1791 - val_loss: 0.5031\n",
      "Epoch 68/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1801\n",
      "Epoch 68: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1732 - val_loss: 0.4749\n",
      "Epoch 69/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1857\n",
      "Epoch 69: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1752 - val_loss: 0.5702\n",
      "Epoch 70/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1499\n",
      "Epoch 70: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1595 - val_loss: 0.5545\n",
      "Epoch 71/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1522\n",
      "Epoch 71: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1518 - val_loss: 0.5244\n",
      "Epoch 72/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.1323\n",
      "Epoch 72: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1345 - val_loss: 0.5328\n",
      "Epoch 73/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1653\n",
      "Epoch 73: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1603 - val_loss: 0.5373\n",
      "Epoch 74/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1497\n",
      "Epoch 74: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1460 - val_loss: 0.5325\n",
      "Epoch 75/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.1326\n",
      "Epoch 75: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1306 - val_loss: 0.5169\n",
      "Epoch 76/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.1340\n",
      "Epoch 76: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1363 - val_loss: 0.5334\n",
      "Epoch 77/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1516\n",
      "Epoch 77: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1539 - val_loss: 0.4860\n",
      "Epoch 78/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1251\n",
      "Epoch 78: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1255 - val_loss: 0.6338\n",
      "Epoch 79/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1340\n",
      "Epoch 79: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1403 - val_loss: 0.4974\n",
      "Epoch 80/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1277\n",
      "Epoch 80: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1285 - val_loss: 0.6167\n",
      "Epoch 81/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1376\n",
      "Epoch 81: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1304 - val_loss: 0.6267\n",
      "Epoch 82/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1277\n",
      "Epoch 82: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1214 - val_loss: 0.5554\n",
      "Epoch 83/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1215\n",
      "Epoch 83: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1428 - val_loss: 0.5762\n",
      "Epoch 84/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1142\n",
      "Epoch 84: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1103 - val_loss: 0.5564\n",
      "Epoch 85/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1091\n",
      "Epoch 85: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1079 - val_loss: 0.6045\n",
      "Epoch 86/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.1152\n",
      "Epoch 86: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1201 - val_loss: 0.7130\n",
      "Epoch 87/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1229\n",
      "Epoch 87: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1280 - val_loss: 0.5982\n",
      "Epoch 88/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1137\n",
      "Epoch 88: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1112 - val_loss: 0.5842\n",
      "Epoch 89/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1401\n",
      "Epoch 89: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1374 - val_loss: 0.5520\n",
      "Epoch 90/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1146\n",
      "Epoch 90: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1114 - val_loss: 0.6170\n",
      "Epoch 91/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1589\n",
      "Epoch 91: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1618 - val_loss: 0.5830\n",
      "Epoch 92/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1012\n",
      "Epoch 92: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0987 - val_loss: 0.6048\n",
      "Epoch 93/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1283\n",
      "Epoch 93: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1365 - val_loss: 0.5917\n",
      "Epoch 94/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1259\n",
      "Epoch 94: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1249 - val_loss: 0.5767\n",
      "Epoch 95/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1359\n",
      "Epoch 95: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1265 - val_loss: 0.6741\n",
      "Epoch 96/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1095\n",
      "Epoch 96: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1097 - val_loss: 0.5404\n",
      "Epoch 97/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1359\n",
      "Epoch 97: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1350 - val_loss: 0.5863\n",
      "Epoch 98/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1038\n",
      "Epoch 98: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1026 - val_loss: 0.5958\n",
      "Epoch 99/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1122\n",
      "Epoch 99: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1085 - val_loss: 0.6281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.1098\n",
      "Epoch 100: val_loss did not improve from 0.41055\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1180 - val_loss: 0.7192\n"
     ]
    }
   ],
   "source": [
    "model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "current_model_path = os.path.join(modelPath, \"_fullModel.hdf5\")\n",
    "modelCallbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                       monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                       save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "]\n",
    "\n",
    "# adding random shuffling of the dataset for training purpose\n",
    "index_arr = np.arange(train_features.shape[0])\n",
    "index_arr = np.random.permutation(index_arr)\n",
    "\n",
    "model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "          callbacks = modelCallbacks, validation_data = (indpe_features, indpe_labels))\n",
    "# model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "#           callbacks = modelCallbacks, validation_split = 0.2)\n",
    "\n",
    "model = tf.keras.models.load_model(current_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.867763</td>\n",
       "      <td>0.905063</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.669988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.881188   0.795455  0.867763     0.905063     0.795455  0.669988"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "y_pred = model.predict(indpe_features)\n",
    "label_pred = pred2label(y_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "if(conf[0][0]+conf[1][0]):\n",
    "    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "else:\n",
    "    sens = 0.0\n",
    "if(conf[1][1]+conf[0][1]):\n",
    "    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "else:\n",
    "    spec = 0.0\n",
    "if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "else:\n",
    "    mcc= 0.0\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_fasta_file_name = '.'.join((training_data_file.split('.')[0], 'fasta'))\n",
    "# out_fasta_file_path = os.path.join(input_data_folder, out_fasta_file_name)\n",
    "\n",
    "# count = 0\n",
    "# list_seqs = list(train_data['Sequence'])\n",
    "\n",
    "# with open(out_fasta_file_path, \"w\") as out_file_obj:\n",
    "#     for strLine in list_seqs:\n",
    "        \n",
    "#         #Output the header\n",
    "#         out_file_obj.write(\">\" + str(count+1) + \"\\n\")\n",
    "#         out_file_obj.write(strLine + \"\\n\")\n",
    "        \n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
