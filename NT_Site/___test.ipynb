{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"NT_Site_PredNTS_Classification_DLNN_CORENup\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "seed = None\n",
    "\n",
    "input_data_folder = \"Data\"\n",
    "training_data_file = \"Training-datasets-PredNTS.txt\"\n",
    "independent_data_file = \"independent dataset-PredNTS.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# print(tf.test.is_gpu_available(cuda_only=True))\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# physical_devices = tf.config.experimental.list_physical_devices('GPU')\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m physical_devices \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(physical_devices)\n\u001b[0;32m      5\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mset_memory_growth(physical_devices[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define all CUSTOM functions\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode_nt(sequence, char_dict):\n",
    "    \n",
    "    seq_encoded = np.zeros((len(sequence),len(char_dict)))\n",
    "    \n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in char_dict.keys()):\n",
    "            seq_encoded[i][char_dict[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in NT sequence: '+sequence)\n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Build k-fold functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "                 conv_filters_per_layer_1 = 50, kernel_length_1 = 5, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "                 max_pool_width_1 = 2, max_pool_stride_1 = 2, ## 1st Maxpool layer parameters\n",
    "                 lstm_decode_units = 50, ## LSTM layer parameters\n",
    "                 conv_filters_per_layer_2 = 50,  kernel_length_2 = 10, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "                 max_pool_width_2 = 2, max_pool_stride_2 = 2, ## 2nd Maxpool layer parameters\n",
    "                 dense_decode_units = 370, ## Dense layer parameters\n",
    "                 prob = 0.5, learn_rate = 0.0003, loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  SEQUENCE  ##################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1,\n",
    "                                strides = conv_strides_1, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = \"same\")(input1)\n",
    "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta))(x1)\n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    ## Conv Path\n",
    "\n",
    "    x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, \n",
    "                                strides = conv_strides_2, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = 'same')(x1)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "    x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "    \n",
    "    x4 = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  Classifier  ################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    y = tf.keras.layers.Dense(dense_decode_units, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'relu')(x4)\n",
    "    \n",
    "    y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(1, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'sigmoid')(y)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), \n",
    "                      loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), \n",
    "                      loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mDLNN_CORENup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mDLNN_CORENup\u001b[1;34m(input_seq_shape, conv_filters_per_layer_1, kernel_length_1, conv_strides_1, max_pool_width_1, max_pool_stride_1, lstm_decode_units, conv_filters_per_layer_2, kernel_length_2, conv_strides_2, max_pool_width_2, max_pool_stride_2, dense_decode_units, prob, learn_rate, loss, metrics)\u001b[0m\n\u001b[0;32m     14\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m######################################################################################################\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m########  SEQUENCE  ##################################################################################\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m######################################################################################################\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m input1 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_seq_shape)\n\u001b[0;32m     22\u001b[0m x1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv1D(conv_filters_per_layer_1, kernel_length_1,\n\u001b[0;32m     23\u001b[0m                             strides \u001b[38;5;241m=\u001b[39m conv_strides_1, \n\u001b[0;32m     24\u001b[0m                             kernel_regularizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mregularizers\u001b[38;5;241m.\u001b[39ml2(beta), \n\u001b[0;32m     25\u001b[0m                             padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m)(input1)\n\u001b[0;32m     26\u001b[0m x1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mActivation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "DLNN_CORENup().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read training file\n",
    "##################################################################################\n",
    "train_file_path = os.path.join(input_data_folder, training_data_file)\n",
    "train_data = pd.read_csv(train_file_path, sep='\\t', header=None)\n",
    "train_data.columns = ['Sequence', 'name', 'id', 'flag', 'label_original', 'type']\n",
    "\n",
    "##################################################################################\n",
    "##### Create dictionary of all characters in the NT sequence \n",
    "##################################################################################\n",
    "all_char_set = set({})\n",
    "for val in [set(val) for val in train_data['Sequence']]:\n",
    "    all_char_set = all_char_set.union(val)\n",
    "all_char_list = list(all_char_set)\n",
    "all_char_list.sort()\n",
    "all_char_dict = {}\n",
    "for i in range(len(all_char_list)):\n",
    "    all_char_dict[all_char_list[i]] = i\n",
    "    \n",
    "##################################################################################\n",
    "##### Create OHE of sequence\n",
    "##################################################################################\n",
    "train_data['OHE_Sequence'] = pd.Series([one_hot_encode_nt(val, all_char_dict) \n",
    "                                        for val in train_data[\"Sequence\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Fix the labels\n",
    "##################################################################################\n",
    "train_data['label'] = pd.Series([1 if val == 1 else 0 \n",
    "                                 for val in train_data[\"label_original\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "features = np.array(list(train_data['OHE_Sequence']))\n",
    "labels = np.array(list(train_data['label']))\n",
    "labels = labels.reshape((labels.shape[0], 1))\n",
    "\n",
    "input_seq_shape = features[0].shape\n",
    "\n",
    "folds = build_kfold(features, labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "## Write the k-fold dataset to file\n",
    "foldPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(foldPath)):\n",
    "    os.makedirs(foldPath)\n",
    "pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_seq_list = []\n",
    "for val in train_data['Sequence']:\n",
    "    half_seq_list.append(val[:20])\n",
    "    half_seq_list.append(val[21:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4764"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(half_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4624"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dict.fromkeys(half_seq_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_seq_list = []\n",
    "for val, label in zip(train_data['Sequence'], train_data['label_original']):\n",
    "    half_seq_list.append((val[:20], label))\n",
    "    half_seq_list.append((val[21:], label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4764"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(half_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4652"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dict.fromkeys(half_seq_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_seq_list = []\n",
    "for val, label in zip(train_data['Sequence'], train_data['label_original']):\n",
    "    half_seq_list.append((val[:21], label))\n",
    "    half_seq_list.append((val[20:], label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4764"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(half_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4661"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dict.fromkeys(half_seq_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('-MCDAFVGTWKLVSSENFDDY', 1),\n",
       " ('ACFLDSMATLGLAAYGYGIRY', 1),\n",
       " ('AEKTKQGVAEAAGKTKEGVLY', 1),\n",
       " ('AIVGVWQERNAENAIEALKEY', -1),\n",
       " ('ALDFENEMATAASSSSLEKSY', 1),\n",
       " ('DEEDDSGKDKKKKTKKIKEKY', 1),\n",
       " ('EMIKSGMNVARLNFSHGTHEY', -1),\n",
       " ('FGGGTGSGFTSLLMERLSVDY', 1),\n",
       " ('GDYMNMSPVGDSNTSSPSECY', -1),\n",
       " ('GGSILASLSTFQQMWISKPEY', -1),\n",
       " ('GIALNDHFVKLISWYDNEFGY', 1),\n",
       " ('GRVTMRKTVAKPKGPSGSPWY', 1),\n",
       " ('GTAEVELKKGATLKITLDNAY', 1),\n",
       " ('IILNKGHDISADYWSLGILMY', 1),\n",
       " ('LDLAGRDLTDYLMKILTERGY', -1),\n",
       " ('LDLAGRDLTDYLMKILTERGY', 1),\n",
       " ('LNPDGSEKKDFYKDGKRLKNY', 1),\n",
       " ('NAVLDGADCIMLSGETAKGDY', -1),\n",
       " ('NIGHFNDPVHGGSWIRGAIYY', 1),\n",
       " ('NILWLDYKNICKVVEVGSKIY', -1),\n",
       " ('NYCYRCGNQAAIMELDDTLKY', 1),\n",
       " ('PRAPIIAVTRNPQTARQAHLY', -1),\n",
       " ('QKDSYVGDEAQSKRGILTLKY', -1),\n",
       " ('QLMKKEFTLEFSRDRKSMSVY', -1),\n",
       " ('QMSLLLRRPPGREAYPGDVFY', -1),\n",
       " ('RNAENAIEALKEYEPEMGKVY', -1),\n",
       " ('RSSASVSGSPSDGGFISSDEY', -1),\n",
       " ('SIVGRPRHQGVMVGMGQKDSY', -1),\n",
       " ('TEMMPAAYPPGGGSGGRLPGY', -1),\n",
       " ('TFDAGAGIALNDHFVKLISWY', 1),\n",
       " ('TPSQSSVVSIEEYTEMMPAAY', -1),\n",
       " ('VLADDNFSTIVAAVEEGRAIY', -1),\n",
       " ('Y--------------------', 1),\n",
       " ('YAAEEDNTDNNLSMDEISDAY', -1),\n",
       " ('YARGHYTIGKEIIDLVLDRIR', 1),\n",
       " ('YASFLQVVLYLHIIMLLSRSY', -1),\n",
       " ('YDEAGPSIVHRKCF-------', -1),\n",
       " ('YELLTGSPPFSGPDPMKTYNI', 1),\n",
       " ('YELPDGQVITIGNERFRCPET', 1),\n",
       " ('YFKIAVALAVAAIPEGLPAVI', 1),\n",
       " ('YFSKPDAPIYQCMGCCFSRAY', 1),\n",
       " ('YGIGANGIRGVALDWAAGNLY', -1),\n",
       " ('YGKKSKLEFSIYPAPQVSTAV', 1),\n",
       " ('YGSDRVKYLGPFSGESPSYLT', 1),\n",
       " ('YGSSPCDFRSSFRSVTPDSLG', -1),\n",
       " ('YIMADLTVSEPYCSSDDNSTY', -1),\n",
       " ('YKAEYFLVLAVLNSGTNPIIY', -1),\n",
       " ('YKVHINPNSLFDVQVKRIHEY', 1),\n",
       " ('YLEVRDGHSESSNLIGRYCGY', -1),\n",
       " ('YLMGWLRDYLWLNSSQLINGY', -1),\n",
       " ('YMEKCDENILWLDYKNICKVV', 1),\n",
       " ('YMKEVGVGFATRKVAGMAKPN', 1),\n",
       " ('YMPAGYFTAVCLTGYLTGMGY', -1),\n",
       " ('YMTAKNNVVINYKDMNHTNSY', -1),\n",
       " ('YNNMKQFIRYLISSNVGEVVC', -1),\n",
       " ('YPDHFHLLRGNHETDNMNQIY', -1),\n",
       " ('YPIEHGIITNWDDMEKIWHHS', -1),\n",
       " ('YPLEAVRMQHLIAREAEAAIY', -1),\n",
       " ('YPLKPSWWFCAFPYSFLIFVY', -1),\n",
       " ('YPNRLIYFMDAYLDYIEFCDY', -1),\n",
       " ('YPPGGGSGGRLPGYRHSAFVP', -1),\n",
       " ('YPRIHFPLATYAPVISAEKAY', 1),\n",
       " ('YPSPTGVLIAIDLAYNLHSAY', -1),\n",
       " ('YPTPARSKKTMLVPKNITSEA', 1),\n",
       " ('YQILFELCVGSFQGLVVAVLY', -1),\n",
       " ('YQMGIVSWGEGCDRDGKYGFY', -1),\n",
       " ('YQPPTVVPGGDLAKVQRAVCM', 1),\n",
       " ('YQQYAQQWNQYYQNQGQWPPY', -1),\n",
       " ('YRERITILRGNHESRQITQVY', -1),\n",
       " ('YRGIIQHAPNLENIELYWNSY', -1),\n",
       " ('YRHSAFVPTHSYPEEGLEMHH', -1),\n",
       " ('YRPRAPIIAVTRNPQTARQAH', -1),\n",
       " ('YRQLFHPEQLITGKEDAANNY', 1),\n",
       " ('YSFLQFDPAPRRGEPHVTRRT', 1),\n",
       " ('YSFVTTAEREIVRDIKEKLCY', -1),\n",
       " ('YSFVTTAEREIVRDIKEKLCY', 1),\n",
       " ('YSGPSREFFFLVSRELFNPYY', -1),\n",
       " ('YSLLYNTLLTFYAILLAIRTY', -1),\n",
       " ('YSQSSQVFGRSAYSGLQSSSY', -1),\n",
       " ('YSWWTDGAGDATYQNNGGGSY', -1),\n",
       " ('YVEAI----------------', 1),\n",
       " ('YVGDEAQSKRGILTLKYPIEH', -1),\n",
       " ('YVGGEIVTIAHLDRTMYLLGY', -1),\n",
       " ('YVNGSTYQRWQFTLPMMSTLY', -1),\n",
       " ('YVTPETVVRVPMMKQQDQFYY', -1),\n",
       " ('YYFKIAVALAVAAIPEGLPAV', 1),\n",
       " ('YYGPEDPQHKPVLSYYSLPRS', -1),\n",
       " ('YYTTPASRSIEVLTLKGDTRY', -1)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x for x in half_seq_list if half_seq_list.count(x) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_seq_list = []\n",
    "for val, label in zip(indpe_data['Sequence'], indpe_data['label_original']):\n",
    "    half_seq_list.append((val[:21], label))\n",
    "    half_seq_list.append((val[20:], label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2450"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(half_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2285"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dict.fromkeys(half_seq_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('AIVGVWQERNAENAIEALKEY', -1),\n",
       " ('ATICALCNDSALDYNEAKGVY', -1),\n",
       " ('DGSLVGDYGFDPFGLGKPAEY', -1),\n",
       " ('DPTGSYHGDSDLQLERINVYY', -1),\n",
       " ('EMEFTEAESNMNDLVSEYQQY', -1),\n",
       " ('ENIWLVGSICLSMSLHFLILY', -1),\n",
       " ('FKRISEQFTAMFRRKAFLHWY', -1),\n",
       " ('GGSILASLSTFQQMWISKPEY', -1),\n",
       " ('GKMGPGFTKALGHGVDLGHIY', -1),\n",
       " ('GMDEMEFTEAESNMNDLVSEY', -1),\n",
       " ('GQPLPFSISTLIWIEVLVIGY', -1),\n",
       " ('GTAEVELKKGATLKITLDNAY', -1),\n",
       " ('HDNPLRREEMHLEDSANFIKY', -1),\n",
       " ('IDNEALYDICFRTLKLTTPTY', -1),\n",
       " ('IDPTGSYHGDSDLQLERINVY', -1),\n",
       " ('IEHGIITNWDDMEKIWHHSFY', 1),\n",
       " ('IGAKFWEVISDEHGIDPTGSY', -1),\n",
       " ('ILIGETIKIVIEEYVQQLSGY', -1),\n",
       " ('IMNTFSVVPSPKVSDTVVEPY', -1),\n",
       " ('INIGHFNDPVHGGSWIRGAIY', -1),\n",
       " ('IVAAVEEGRAIYNNMKQFIRY', -1),\n",
       " ('KALGHGVDLGHIYGDNLERQY', -1),\n",
       " ('KANREKMTQIMFETFNVPAMY', -1),\n",
       " ('KITLDNAYMEKCDENILWLDY', -1),\n",
       " ('LGGGTGSGMGTLLISKIREEY', -1),\n",
       " ('MFETFNVPAMYVAIQAVLSLY', -1),\n",
       " ('MNKPPRNPKEPLISGWLFFRY', -1),\n",
       " ('NIGHFNDPVHGGSWIRGAIYY', -1),\n",
       " ('NILWLDYKNICKVVEVGSKIY', 1),\n",
       " ('NPKEPLISGWLFFRYLAIGCY', -1),\n",
       " ('PCCYYPCQHQGICVRFGLDRY', -1),\n",
       " ('PQSQMAVGQEVFGLLPGLMLY', -1),\n",
       " ('PRAPIIAVTRNPQTARQAHLY', -1),\n",
       " ('PRLHFFMPGFAPLTSRGSQQY', -1),\n",
       " ('PSDTDLGAKVPKDVKIQGVWY', 1),\n",
       " ('QCKEDNPDFEGVDCAIFESPY', -1),\n",
       " ('QGICVRFGLDRYQCDCTRTGY', -1),\n",
       " ('QKDSYVGDEAQSKRGILTLKY', -1),\n",
       " ('QLMKKEFTLEFSRDRKSMSVY', -1),\n",
       " ('RMSMKEVDEQMLNVQNKNSSY', -1),\n",
       " ('RNAENAIEALKEYEPEMGKVY', -1),\n",
       " ('RPDNFVFGQSGAGNNWAKGHY', 1),\n",
       " ('SIVGRPRHQGVMVGMGQKDSY', -1),\n",
       " ('SVHQLVENTDETYCIDNEALY', -1),\n",
       " ('TQQMFDSKNMMAACDPRHGRY', -1),\n",
       " ('TVGAAAWWFIAADGGPRVSFY', -1),\n",
       " ('VEPYNATLSVHQLVENTDETY', -1),\n",
       " ('VGSQEYSYEQFLFNTSMLVDY', -1),\n",
       " ('VLADDNFSTIVAAVEEGRAIY', -1),\n",
       " ('WLTGVTWQDAGKVELVDGSSY', -1),\n",
       " ('Y--------------------', -1),\n",
       " ('YAGISIGILGCYVSGVFYAFY', -1),\n",
       " ('YASGRTTGIVLDSGDGVTHNV', -1),\n",
       " ('YCIDNEALYDICFRTLKLTTP', -1),\n",
       " ('YCTPNKPSRTSMSKMFVKGAP', -1),\n",
       " ('YDEAGPSIVHRKCF-------', -1),\n",
       " ('YDGLVELATICALCNDSALDY', -1),\n",
       " ('YDICFRTLKLTTPTYGDLNHL', -1),\n",
       " ('YEKVGEATETALTCLVEKMNV', -1),\n",
       " ('YEQFLFNTSMLVDYGVEALVD', -1),\n",
       " ('YETNLTFVGCVGMLDPPRIEV', -1),\n",
       " ('YFKIAVALAVAAIPEGLPAVI', -1),\n",
       " ('YFVEWIPNNVKTAVCDIPPRG', -1),\n",
       " ('YFVSGVLHLISSAVLGFGGIY', -1),\n",
       " ('YGDLNHLVSATMSGVTTCLRF', -1),\n",
       " ('YGDNLERQYQLRLFKDGKLKY', -1),\n",
       " ('YGEYFPGTGDLRDIGAGKGKY', -1),\n",
       " ('YGVGFWKPGSGIIHQIILENY', -1),\n",
       " ('YHLFSCHRSEKTCRRWMALDY', -1),\n",
       " ('YHSDEYIKFLRSIRPDNMSEY', -1),\n",
       " ('YIEFQRNAELDSEKRLYPGGK', -1),\n",
       " ('YISWESFSNVSYYTRILPSVP', -1),\n",
       " ('YKDRVTILRGNHESRQITQVY', -1),\n",
       " ('YKFNGLAWLFLGVPTSSSLLY', -1),\n",
       " ('YKNICKVVEVGSKIYVDDGLI', -1),\n",
       " ('YLAIGCYVGAATVGAAAWWFI', -1),\n",
       " ('YLGQPLPFSISTLIWIEVLVI', -1),\n",
       " ('YLISSNVGEVVCIFLTAALGF', -1),\n",
       " ('YLITVLAMILAVFFAQIHPNY', -1),\n",
       " ('YLTVAAIFRGRMSMKEVDEQM', -1),\n",
       " ('YMEKCDENILWLDYKNICKVV', -1),\n",
       " ('YMESDGIKVAGLLVLNYSNDY', -1),\n",
       " ('YNATLSVHQLVENTDETYCID', -1),\n",
       " ('YNEAKGVYEKVGEATETALTC', -1),\n",
       " ('YNELRVAPEEHPTLLTEAPLN', 1),\n",
       " ('YNNMKQFIRYLISSNVGEVVC', -1),\n",
       " ('YPCQHQGICVRFGLDRYQCDC', -1),\n",
       " ('YPDRIMNTFSVMPSPKVSDTV', -1),\n",
       " ('YPDRIMNTFSVVPSPKVSDTV', -1),\n",
       " ('YPIEHGIITNWDDMEKIWHHS', -1),\n",
       " ('YPLEAVRMQHLIAREAEAAIY', -1),\n",
       " ('YPMTMALSVLVTIEMCNALNS', -1),\n",
       " ('YPPSVEEAPVLMHYPRGIPPQ', -1),\n",
       " ('YPRGIPPQSQMAVGQEVFGLL', -1),\n",
       " ('YQCDCTRTGYSGPNCTIPEIW', -1),\n",
       " ('YQDATADEQGEFEEEEGEDEA', -1),\n",
       " ('YQKALNEINQFYQKFPQYLQY', -1),\n",
       " ('YQLRLFKDGKLKYQMLNGEVY', -1),\n",
       " ('YQLRLFKDGKLKYQVLDGEMY', -1),\n",
       " ('YQLSHFLQCKEDNPDFEGVDC', -1),\n",
       " ('YQMNFETSKSRVTQSNFAVGY', -1),\n",
       " ('YQQYQDATADEQGEFEEEEGE', -1),\n",
       " ('YRALTVPELTQQMFDSKNMMA', -1),\n",
       " ('YRAQLDNKTDSTGTHSLYTTY', -1),\n",
       " ('YRGRAPRTLTISNPQGCRLFY', -1),\n",
       " ('YRPRAPIIAVTRNPQTARQAH', -1),\n",
       " ('YRPVAVALDTKGPEIRTGLIK', -1),\n",
       " ('YRQDRKSVQRIKAKDIVPGDI', -1),\n",
       " ('YRQMSLLLRRPPGREAYPGDV', -1),\n",
       " ('YSQGGGKKKVCYYYDGDIGNY', -1),\n",
       " ('YSTDTNFSDMFWS--------', -1),\n",
       " ('YSVNDGAQLYMIDPSGVSYGY', -1),\n",
       " ('YSYEQFLFNTSMLVDYGVEAL', -1),\n",
       " ('YTEGAELVDSVLDVVRKESES', 1),\n",
       " ('YTGAALAEYFMYREQHTLIIY', -1),\n",
       " ('YTGEGMDEMEFTEAESNMNDL', -1),\n",
       " ('YTHHLFIIVYALLIVHGIKLY', -1),\n",
       " ('YTIVVAETADSPATLQYLAPY', -1),\n",
       " ('YVAIQAVLSLYASGRTTGIVL', -1),\n",
       " ('YVGAATVGAAAWWFIAADGGP', -1),\n",
       " ('YVGDEAQSKRGILTLKYPIEH', -1),\n",
       " ('YVNDIVLAILELLKYHQRVLY', -1),\n",
       " ('YVPRAILVDLEPGTMDSVRSG', -1),\n",
       " ('YVQQLSGYFLQLKFDPELLFG', -1),\n",
       " ('YYFKIAVALAVAAIPEGLPAV', -1),\n",
       " ('YYPCQHQGICVRFGLDRYQCD', -1),\n",
       " ('YYTRILPSVPKDCPTPMGTKG', -1)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x for x in half_seq_list if half_seq_list.count(x) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test model on Fold #0.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - ETA: 0s - loss: 1.4067\n",
      "Epoch 1: val_loss improved from inf to 1.35372, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 5s 28ms/step - loss: 1.4067 - val_loss: 1.3537\n",
      "Epoch 2/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.3106\n",
      "Epoch 2: val_loss improved from 1.35372 to 1.26336, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.3096 - val_loss: 1.2634\n",
      "Epoch 3/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 1.2215\n",
      "Epoch 3: val_loss improved from 1.26336 to 1.16788, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.2173 - val_loss: 1.1679\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.1355\n",
      "Epoch 4: val_loss improved from 1.16788 to 1.06409, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1355 - val_loss: 1.0641\n",
      "Epoch 5/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.0591\n",
      "Epoch 5: val_loss improved from 1.06409 to 1.01193, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0606 - val_loss: 1.0119\n",
      "Epoch 6/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.0053\n",
      "Epoch 6: val_loss improved from 1.01193 to 0.97368, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0024 - val_loss: 0.9737\n",
      "Epoch 7/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.9653\n",
      "Epoch 7: val_loss improved from 0.97368 to 0.93033, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9633 - val_loss: 0.9303\n",
      "Epoch 8/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.9342\n",
      "Epoch 8: val_loss improved from 0.93033 to 0.88973, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.9347 - val_loss: 0.8897\n",
      "Epoch 9/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8909\n",
      "Epoch 9: val_loss improved from 0.88973 to 0.85672, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8931 - val_loss: 0.8567\n",
      "Epoch 10/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8554\n",
      "Epoch 10: val_loss improved from 0.85672 to 0.83089, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8553 - val_loss: 0.8309\n",
      "Epoch 11/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8335\n",
      "Epoch 11: val_loss improved from 0.83089 to 0.81192, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8317 - val_loss: 0.8119\n",
      "Epoch 12/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.8212\n",
      "Epoch 12: val_loss improved from 0.81192 to 0.79430, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.8206 - val_loss: 0.7943\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.8037\n",
      "Epoch 13: val_loss improved from 0.79430 to 0.77541, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8037 - val_loss: 0.7754\n",
      "Epoch 14/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.7754\n",
      "Epoch 14: val_loss improved from 0.77541 to 0.75961, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7759 - val_loss: 0.7596\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7547\n",
      "Epoch 15: val_loss improved from 0.75961 to 0.74868, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.7547 - val_loss: 0.7487\n",
      "Epoch 16/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.7379\n",
      "Epoch 16: val_loss improved from 0.74868 to 0.73165, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.7491 - val_loss: 0.7316\n",
      "Epoch 17/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7351\n",
      "Epoch 17: val_loss improved from 0.73165 to 0.72487, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7325 - val_loss: 0.7249\n",
      "Epoch 18/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7199\n",
      "Epoch 18: val_loss improved from 0.72487 to 0.71369, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7198 - val_loss: 0.7137\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7180\n",
      "Epoch 19: val_loss improved from 0.71369 to 0.70573, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7180 - val_loss: 0.7057\n",
      "Epoch 20/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6918\n",
      "Epoch 20: val_loss did not improve from 0.70573\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6910 - val_loss: 0.7181\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6625\n",
      "Epoch 21: val_loss improved from 0.70573 to 0.68958, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6625 - val_loss: 0.6896\n",
      "Epoch 22/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6662\n",
      "Epoch 22: val_loss improved from 0.68958 to 0.68144, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6689 - val_loss: 0.6814\n",
      "Epoch 23/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6669\n",
      "Epoch 23: val_loss improved from 0.68144 to 0.66725, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6675 - val_loss: 0.6673\n",
      "Epoch 24/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6487\n",
      "Epoch 24: val_loss improved from 0.66725 to 0.65914, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6472 - val_loss: 0.6591\n",
      "Epoch 25/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6308\n",
      "Epoch 25: val_loss improved from 0.65914 to 0.65235, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6299 - val_loss: 0.6524\n",
      "Epoch 26/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6300\n",
      "Epoch 26: val_loss improved from 0.65235 to 0.64776, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6299 - val_loss: 0.6478\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5993\n",
      "Epoch 27: val_loss improved from 0.64776 to 0.64252, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5993 - val_loss: 0.6425\n",
      "Epoch 28/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6089\n",
      "Epoch 28: val_loss did not improve from 0.64252\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6089 - val_loss: 0.6468\n",
      "Epoch 29/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5928\n",
      "Epoch 29: val_loss did not improve from 0.64252\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5930 - val_loss: 0.6557\n",
      "Epoch 30/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5845\n",
      "Epoch 30: val_loss improved from 0.64252 to 0.63274, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5864 - val_loss: 0.6327\n",
      "Epoch 31/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5953\n",
      "Epoch 31: val_loss improved from 0.63274 to 0.63173, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5944 - val_loss: 0.6317\n",
      "Epoch 32/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5844\n",
      "Epoch 32: val_loss improved from 0.63173 to 0.62271, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5851 - val_loss: 0.6227\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5612\n",
      "Epoch 33: val_loss improved from 0.62271 to 0.62190, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5612 - val_loss: 0.6219\n",
      "Epoch 34/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5611\n",
      "Epoch 34: val_loss did not improve from 0.62190\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5606 - val_loss: 0.6226\n",
      "Epoch 35/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5524\n",
      "Epoch 35: val_loss did not improve from 0.62190\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5502 - val_loss: 0.6276\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5563\n",
      "Epoch 36: val_loss improved from 0.62190 to 0.61579, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5563 - val_loss: 0.6158\n",
      "Epoch 37/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5486\n",
      "Epoch 37: val_loss improved from 0.61579 to 0.61018, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5487 - val_loss: 0.6102\n",
      "Epoch 38/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5362\n",
      "Epoch 38: val_loss improved from 0.61018 to 0.60404, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5365 - val_loss: 0.6040\n",
      "Epoch 39/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5190\n",
      "Epoch 39: val_loss did not improve from 0.60404\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5191 - val_loss: 0.6114\n",
      "Epoch 40/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5245\n",
      "Epoch 40: val_loss improved from 0.60404 to 0.59992, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5234 - val_loss: 0.5999\n",
      "Epoch 41/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5196\n",
      "Epoch 41: val_loss improved from 0.59992 to 0.59845, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5170 - val_loss: 0.5985\n",
      "Epoch 42/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5135\n",
      "Epoch 42: val_loss did not improve from 0.59845\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5112 - val_loss: 0.6039\n",
      "Epoch 43/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5188\n",
      "Epoch 43: val_loss improved from 0.59845 to 0.59586, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5157 - val_loss: 0.5959\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5118\n",
      "Epoch 44: val_loss did not improve from 0.59586\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5118 - val_loss: 0.5961\n",
      "Epoch 45/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5007\n",
      "Epoch 45: val_loss improved from 0.59586 to 0.59541, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5017 - val_loss: 0.5954\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5001\n",
      "Epoch 46: val_loss did not improve from 0.59541\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5001 - val_loss: 0.6024\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4846\n",
      "Epoch 47: val_loss did not improve from 0.59541\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4846 - val_loss: 0.5962\n",
      "Epoch 48/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4778\n",
      "Epoch 48: val_loss did not improve from 0.59541\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4824 - val_loss: 0.5957\n",
      "Epoch 49/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4881\n",
      "Epoch 49: val_loss improved from 0.59541 to 0.59061, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4856 - val_loss: 0.5906\n",
      "Epoch 50/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4794\n",
      "Epoch 50: val_loss did not improve from 0.59061\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4784 - val_loss: 0.6040\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4672\n",
      "Epoch 51: val_loss did not improve from 0.59061\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4672 - val_loss: 0.5931\n",
      "Epoch 52/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.4606\n",
      "Epoch 52: val_loss did not improve from 0.59061\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4525 - val_loss: 0.5982\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4546\n",
      "Epoch 53: val_loss did not improve from 0.59061\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4546 - val_loss: 0.5960\n",
      "Epoch 54/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4400\n",
      "Epoch 54: val_loss did not improve from 0.59061\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4428 - val_loss: 0.6130\n",
      "Epoch 55/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.4488\n",
      "Epoch 55: val_loss did not improve from 0.59061\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4550 - val_loss: 0.6076\n",
      "Epoch 56/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4432\n",
      "Epoch 56: val_loss improved from 0.59061 to 0.59015, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4431 - val_loss: 0.5901\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4434\n",
      "Epoch 57: val_loss improved from 0.59015 to 0.58855, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.4434 - val_loss: 0.5886\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/30 [=======================>......] - ETA: 0s - loss: 0.4335\n",
      "Epoch 58: val_loss did not improve from 0.58855\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4311 - val_loss: 0.6237\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4621\n",
      "Epoch 59: val_loss improved from 0.58855 to 0.58466, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4621 - val_loss: 0.5847\n",
      "Epoch 60/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4243\n",
      "Epoch 60: val_loss did not improve from 0.58466\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4228 - val_loss: 0.5941\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4163\n",
      "Epoch 61: val_loss did not improve from 0.58466\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4163 - val_loss: 0.5961\n",
      "Epoch 62/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.4056\n",
      "Epoch 62: val_loss did not improve from 0.58466\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4094 - val_loss: 0.6156\n",
      "Epoch 63/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.4203\n",
      "Epoch 63: val_loss did not improve from 0.58466\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4224 - val_loss: 0.6081\n",
      "Epoch 64/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.4364\n",
      "Epoch 64: val_loss did not improve from 0.58466\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4331 - val_loss: 0.5981\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4233\n",
      "Epoch 65: val_loss improved from 0.58466 to 0.58354, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4233 - val_loss: 0.5835\n",
      "Epoch 66/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4257\n",
      "Epoch 66: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4237 - val_loss: 0.5876\n",
      "Epoch 67/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3960\n",
      "Epoch 67: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3965 - val_loss: 0.5892\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4043\n",
      "Epoch 68: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4043 - val_loss: 0.6026\n",
      "Epoch 69/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3897\n",
      "Epoch 69: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3887 - val_loss: 0.6020\n",
      "Epoch 70/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3879\n",
      "Epoch 70: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3908 - val_loss: 0.5989\n",
      "Epoch 71/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3871\n",
      "Epoch 71: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3838 - val_loss: 0.5957\n",
      "Epoch 72/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3757\n",
      "Epoch 72: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3755 - val_loss: 0.5990\n",
      "Epoch 73/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3827\n",
      "Epoch 73: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3861 - val_loss: 0.6291\n",
      "Epoch 74/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3765\n",
      "Epoch 74: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3780 - val_loss: 0.5928\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3734\n",
      "Epoch 75: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3734 - val_loss: 0.6106\n",
      "Epoch 76/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3538\n",
      "Epoch 76: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3574 - val_loss: 0.6048\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3613\n",
      "Epoch 77: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3613 - val_loss: 0.6170\n",
      "Epoch 78/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3675\n",
      "Epoch 78: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3691 - val_loss: 0.5987\n",
      "Epoch 79/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3737\n",
      "Epoch 79: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3728 - val_loss: 0.6027\n",
      "Epoch 80/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.3598\n",
      "Epoch 80: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3698 - val_loss: 0.6021\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3657\n",
      "Epoch 81: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3657 - val_loss: 0.6005\n",
      "Epoch 82/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3605\n",
      "Epoch 82: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3599 - val_loss: 0.5973\n",
      "Epoch 83/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3486\n",
      "Epoch 83: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3497 - val_loss: 0.6096\n",
      "Epoch 84/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3570\n",
      "Epoch 84: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3557 - val_loss: 0.6128\n",
      "Epoch 85/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3419\n",
      "Epoch 85: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3411 - val_loss: 0.6032\n",
      "Epoch 86/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3473\n",
      "Epoch 86: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3450 - val_loss: 0.6100\n",
      "Epoch 87/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3506\n",
      "Epoch 87: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3530 - val_loss: 0.6050\n",
      "Epoch 88/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3462\n",
      "Epoch 88: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3431 - val_loss: 0.6072\n",
      "Epoch 89/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3417\n",
      "Epoch 89: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3441 - val_loss: 0.6181\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3367\n",
      "Epoch 90: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3367 - val_loss: 0.6236\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3442\n",
      "Epoch 91: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3442 - val_loss: 0.6082\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3380\n",
      "Epoch 92: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3380 - val_loss: 0.6005\n",
      "Epoch 93/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3346\n",
      "Epoch 93: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3347 - val_loss: 0.6022\n",
      "Epoch 94/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3257\n",
      "Epoch 94: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3261 - val_loss: 0.6032\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3424\n",
      "Epoch 95: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3424 - val_loss: 0.6026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3098\n",
      "Epoch 96: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3098 - val_loss: 0.6119\n",
      "Epoch 97/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.3266\n",
      "Epoch 97: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3248 - val_loss: 0.6320\n",
      "Epoch 98/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3247\n",
      "Epoch 98: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3253 - val_loss: 0.6036\n",
      "Epoch 99/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3181\n",
      "Epoch 99: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3240 - val_loss: 0.6052\n",
      "Epoch 100/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3101\n",
      "Epoch 100: val_loss did not improve from 0.58354\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3126 - val_loss: 0.6146\n",
      "\n",
      "Train/Test model on Fold #1.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/30 [=========================>....] - ETA: 0s - loss: 1.4154\n",
      "Epoch 1: val_loss improved from inf to 1.35359, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 2s 26ms/step - loss: 1.4091 - val_loss: 1.3536\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.3168\n",
      "Epoch 2: val_loss improved from 1.35359 to 1.27117, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.3168 - val_loss: 1.2712\n",
      "Epoch 3/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.2256\n",
      "Epoch 3: val_loss improved from 1.27117 to 1.16762, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.2258 - val_loss: 1.1676\n",
      "Epoch 4/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.1236\n",
      "Epoch 4: val_loss improved from 1.16762 to 1.07759, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1229 - val_loss: 1.0776\n",
      "Epoch 5/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 1.0771\n",
      "Epoch 5: val_loss improved from 1.07759 to 1.02858, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0638 - val_loss: 1.0286\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.9953\n",
      "Epoch 6: val_loss improved from 1.02858 to 0.97949, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9953 - val_loss: 0.9795\n",
      "Epoch 7/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.9710\n",
      "Epoch 7: val_loss improved from 0.97949 to 0.94560, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9623 - val_loss: 0.9456\n",
      "Epoch 8/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.9209\n",
      "Epoch 8: val_loss improved from 0.94560 to 0.93264, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9198 - val_loss: 0.9326\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.8843\n",
      "Epoch 9: val_loss improved from 0.93264 to 0.88219, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8843 - val_loss: 0.8822\n",
      "Epoch 10/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8629\n",
      "Epoch 10: val_loss improved from 0.88219 to 0.86037, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8623 - val_loss: 0.8604\n",
      "Epoch 11/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8245\n",
      "Epoch 11: val_loss improved from 0.86037 to 0.84648, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8222 - val_loss: 0.8465\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.8114\n",
      "Epoch 12: val_loss improved from 0.84648 to 0.81605, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8114 - val_loss: 0.8160\n",
      "Epoch 13/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.7844\n",
      "Epoch 13: val_loss improved from 0.81605 to 0.79739, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7829 - val_loss: 0.7974\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7735\n",
      "Epoch 14: val_loss improved from 0.79739 to 0.78851, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7735 - val_loss: 0.7885\n",
      "Epoch 15/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.7502\n",
      "Epoch 15: val_loss improved from 0.78851 to 0.77227, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7551 - val_loss: 0.7723\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7317\n",
      "Epoch 16: val_loss improved from 0.77227 to 0.75724, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.7317 - val_loss: 0.7572\n",
      "Epoch 17/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.7249\n",
      "Epoch 17: val_loss improved from 0.75724 to 0.75376, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.7164 - val_loss: 0.7538\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7123\n",
      "Epoch 18: val_loss improved from 0.75376 to 0.73272, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7123 - val_loss: 0.7327\n",
      "Epoch 19/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6957\n",
      "Epoch 19: val_loss improved from 0.73272 to 0.72155, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6958 - val_loss: 0.7216\n",
      "Epoch 20/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6886\n",
      "Epoch 20: val_loss improved from 0.72155 to 0.71359, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6873 - val_loss: 0.7136\n",
      "Epoch 21/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6734\n",
      "Epoch 21: val_loss improved from 0.71359 to 0.70468, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6732 - val_loss: 0.7047\n",
      "Epoch 22/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6557\n",
      "Epoch 22: val_loss improved from 0.70468 to 0.69701, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6544 - val_loss: 0.6970\n",
      "Epoch 23/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6499\n",
      "Epoch 23: val_loss improved from 0.69701 to 0.69189, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6475 - val_loss: 0.6919\n",
      "Epoch 24/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6358\n",
      "Epoch 24: val_loss improved from 0.69189 to 0.68227, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6351 - val_loss: 0.6823\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6385\n",
      "Epoch 25: val_loss improved from 0.68227 to 0.67486, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6385 - val_loss: 0.6749\n",
      "Epoch 26/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6204\n",
      "Epoch 26: val_loss improved from 0.67486 to 0.66972, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6223 - val_loss: 0.6697\n",
      "Epoch 27/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6137\n",
      "Epoch 27: val_loss improved from 0.66972 to 0.66918, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6110 - val_loss: 0.6692\n",
      "Epoch 28/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.5924\n",
      "Epoch 28: val_loss improved from 0.66918 to 0.66091, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5921 - val_loss: 0.6609\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5995\n",
      "Epoch 29: val_loss improved from 0.66091 to 0.65478, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5995 - val_loss: 0.6548\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5859\n",
      "Epoch 30: val_loss did not improve from 0.65478\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5859 - val_loss: 0.6612\n",
      "Epoch 31/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5854\n",
      "Epoch 31: val_loss improved from 0.65478 to 0.64693, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5840 - val_loss: 0.6469\n",
      "Epoch 32/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5707\n",
      "Epoch 32: val_loss improved from 0.64693 to 0.64135, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5744 - val_loss: 0.6414\n",
      "Epoch 33/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5677\n",
      "Epoch 33: val_loss did not improve from 0.64135\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5652 - val_loss: 0.6690\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5645\n",
      "Epoch 34: val_loss did not improve from 0.64135\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5645 - val_loss: 0.6536\n",
      "Epoch 35/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5627\n",
      "Epoch 35: val_loss improved from 0.64135 to 0.63239, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5659 - val_loss: 0.6324\n",
      "Epoch 36/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5453\n",
      "Epoch 36: val_loss did not improve from 0.63239\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5431 - val_loss: 0.6336\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5408\n",
      "Epoch 37: val_loss improved from 0.63239 to 0.62644, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5408 - val_loss: 0.6264\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5384\n",
      "Epoch 38: val_loss did not improve from 0.62644\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5384 - val_loss: 0.6419\n",
      "Epoch 39/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5372\n",
      "Epoch 39: val_loss improved from 0.62644 to 0.62422, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5371 - val_loss: 0.6242\n",
      "Epoch 40/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5220\n",
      "Epoch 40: val_loss improved from 0.62422 to 0.62019, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5270 - val_loss: 0.6202\n",
      "Epoch 41/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5157\n",
      "Epoch 41: val_loss improved from 0.62019 to 0.61754, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5163 - val_loss: 0.6175\n",
      "Epoch 42/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5145\n",
      "Epoch 42: val_loss improved from 0.61754 to 0.61234, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5124 - val_loss: 0.6123\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5002\n",
      "Epoch 43: val_loss did not improve from 0.61234\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5002 - val_loss: 0.6175\n",
      "Epoch 44/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5001\n",
      "Epoch 44: val_loss improved from 0.61234 to 0.61035, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5009 - val_loss: 0.6103\n",
      "Epoch 45/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4736\n",
      "Epoch 45: val_loss did not improve from 0.61035\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4740 - val_loss: 0.6275\n",
      "Epoch 46/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4862\n",
      "Epoch 46: val_loss did not improve from 0.61035\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4872 - val_loss: 0.6174\n",
      "Epoch 47/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4945\n",
      "Epoch 47: val_loss improved from 0.61035 to 0.60975, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4952 - val_loss: 0.6097\n",
      "Epoch 48/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4759\n",
      "Epoch 48: val_loss did not improve from 0.60975\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4746 - val_loss: 0.6132\n",
      "Epoch 49/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4687\n",
      "Epoch 49: val_loss did not improve from 0.60975\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4695 - val_loss: 0.6113\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4763\n",
      "Epoch 50: val_loss improved from 0.60975 to 0.60688, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4763 - val_loss: 0.6069\n",
      "Epoch 51/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.4525\n",
      "Epoch 51: val_loss did not improve from 0.60688\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4588 - val_loss: 0.6098\n",
      "Epoch 52/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4677\n",
      "Epoch 52: val_loss did not improve from 0.60688\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4699 - val_loss: 0.6132\n",
      "Epoch 53/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4557\n",
      "Epoch 53: val_loss did not improve from 0.60688\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4611 - val_loss: 0.6108\n",
      "Epoch 54/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4501\n",
      "Epoch 54: val_loss did not improve from 0.60688\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4512 - val_loss: 0.6097\n",
      "Epoch 55/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4404\n",
      "Epoch 55: val_loss did not improve from 0.60688\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4395 - val_loss: 0.6136\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4461\n",
      "Epoch 56: val_loss did not improve from 0.60688\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4461 - val_loss: 0.6113\n",
      "Epoch 57/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4287\n",
      "Epoch 57: val_loss did not improve from 0.60688\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4277 - val_loss: 0.6117\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4276\n",
      "Epoch 58: val_loss did not improve from 0.60688\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4276 - val_loss: 0.6179\n",
      "Epoch 59/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.4226\n",
      "Epoch 59: val_loss did not improve from 0.60688\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4286 - val_loss: 0.6088\n",
      "Epoch 60/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4325\n",
      "Epoch 60: val_loss did not improve from 0.60688\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4327 - val_loss: 0.6190\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4288\n",
      "Epoch 61: val_loss improved from 0.60688 to 0.60348, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4288 - val_loss: 0.6035\n",
      "Epoch 62/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4054\n",
      "Epoch 62: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4097 - val_loss: 0.6080\n",
      "Epoch 63/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4094\n",
      "Epoch 63: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4127 - val_loss: 0.6083\n",
      "Epoch 64/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4116\n",
      "Epoch 64: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4122 - val_loss: 0.6129\n",
      "Epoch 65/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4116\n",
      "Epoch 65: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4099 - val_loss: 0.6221\n",
      "Epoch 66/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.4043\n",
      "Epoch 66: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4068 - val_loss: 0.6212\n",
      "Epoch 67/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3965\n",
      "Epoch 67: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4007 - val_loss: 0.6506\n",
      "Epoch 68/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3847\n",
      "Epoch 68: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3842 - val_loss: 0.6295\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3959\n",
      "Epoch 69: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3959 - val_loss: 0.6180\n",
      "Epoch 70/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3861\n",
      "Epoch 70: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3830 - val_loss: 0.6396\n",
      "Epoch 71/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4043\n",
      "Epoch 71: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4012 - val_loss: 0.6111\n",
      "Epoch 72/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3729\n",
      "Epoch 72: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3768 - val_loss: 0.6209\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3892\n",
      "Epoch 73: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3892 - val_loss: 0.6147\n",
      "Epoch 74/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3802\n",
      "Epoch 74: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3841 - val_loss: 0.6173\n",
      "Epoch 75/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3675\n",
      "Epoch 75: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3663 - val_loss: 0.6262\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3712\n",
      "Epoch 76: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3712 - val_loss: 0.6291\n",
      "Epoch 77/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3632\n",
      "Epoch 77: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3632 - val_loss: 0.6303\n",
      "Epoch 78/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3729\n",
      "Epoch 78: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3710 - val_loss: 0.6336\n",
      "Epoch 79/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.3650\n",
      "Epoch 79: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3605 - val_loss: 0.6283\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3704\n",
      "Epoch 80: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3704 - val_loss: 0.6199\n",
      "Epoch 81/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3620\n",
      "Epoch 81: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3611 - val_loss: 0.6277\n",
      "Epoch 82/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3512\n",
      "Epoch 82: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3511 - val_loss: 0.6235\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3458\n",
      "Epoch 83: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3458 - val_loss: 0.6355\n",
      "Epoch 84/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.3688\n",
      "Epoch 84: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3683 - val_loss: 0.6242\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3535\n",
      "Epoch 85: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3535 - val_loss: 0.6227\n",
      "Epoch 86/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.3617\n",
      "Epoch 86: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3625 - val_loss: 0.6364\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3364\n",
      "Epoch 87: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3364 - val_loss: 0.6326\n",
      "Epoch 88/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3395\n",
      "Epoch 88: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3436 - val_loss: 0.6555\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3587\n",
      "Epoch 89: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3587 - val_loss: 0.6196\n",
      "Epoch 90/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3558\n",
      "Epoch 90: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3481 - val_loss: 0.6464\n",
      "Epoch 91/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3490\n",
      "Epoch 91: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3497 - val_loss: 0.6172\n",
      "Epoch 92/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.3338\n",
      "Epoch 92: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3304 - val_loss: 0.6392\n",
      "Epoch 93/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3416\n",
      "Epoch 93: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3354 - val_loss: 0.6278\n",
      "Epoch 94/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3149\n",
      "Epoch 94: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3172 - val_loss: 0.6740\n",
      "Epoch 95/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3262\n",
      "Epoch 95: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3284 - val_loss: 0.6396\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3296\n",
      "Epoch 96: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3310 - val_loss: 0.6391\n",
      "Epoch 97/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.3177\n",
      "Epoch 97: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3108 - val_loss: 0.6578\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3200\n",
      "Epoch 98: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3200 - val_loss: 0.6735\n",
      "Epoch 99/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3006\n",
      "Epoch 99: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3033 - val_loss: 0.6562\n",
      "Epoch 100/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3075\n",
      "Epoch 100: val_loss did not improve from 0.60348\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3115 - val_loss: 0.6750\n",
      "\n",
      "Train/Test model on Fold #2.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - ETA: 0s - loss: 1.4097\n",
      "Epoch 1: val_loss improved from inf to 1.35066, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 3s 30ms/step - loss: 1.4097 - val_loss: 1.3507\n",
      "Epoch 2/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 1.3263\n",
      "Epoch 2: val_loss improved from 1.35066 to 1.25712, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.3187 - val_loss: 1.2571\n",
      "Epoch 3/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 1.2348\n",
      "Epoch 3: val_loss improved from 1.25712 to 1.14898, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.2268 - val_loss: 1.1490\n",
      "Epoch 4/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 1.1332\n",
      "Epoch 4: val_loss improved from 1.14898 to 1.05440, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.1222 - val_loss: 1.0544\n",
      "Epoch 5/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 1.0449\n",
      "Epoch 5: val_loss improved from 1.05440 to 1.00320, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.0429 - val_loss: 1.0032\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.9921\n",
      "Epoch 6: val_loss improved from 1.00320 to 0.95284, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9921 - val_loss: 0.9528\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.9554\n",
      "Epoch 7: val_loss improved from 0.95284 to 0.92120, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.9554 - val_loss: 0.9212\n",
      "Epoch 8/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.9162\n",
      "Epoch 8: val_loss improved from 0.92120 to 0.89619, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.9111 - val_loss: 0.8962\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.8728\n",
      "Epoch 9: val_loss improved from 0.89619 to 0.86414, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8728 - val_loss: 0.8641\n",
      "Epoch 10/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8460\n",
      "Epoch 10: val_loss improved from 0.86414 to 0.83859, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8462 - val_loss: 0.8386\n",
      "Epoch 11/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.8231\n",
      "Epoch 11: val_loss improved from 0.83859 to 0.81971, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.8239 - val_loss: 0.8197\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.8117\n",
      "Epoch 12: val_loss improved from 0.81971 to 0.80025, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8117 - val_loss: 0.8002\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7814\n",
      "Epoch 13: val_loss improved from 0.80025 to 0.79636, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7814 - val_loss: 0.7964\n",
      "Epoch 14/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7719\n",
      "Epoch 14: val_loss improved from 0.79636 to 0.77262, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7724 - val_loss: 0.7726\n",
      "Epoch 15/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7499\n",
      "Epoch 15: val_loss improved from 0.77262 to 0.75990, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7481 - val_loss: 0.7599\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7373\n",
      "Epoch 16: val_loss improved from 0.75990 to 0.74808, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7373 - val_loss: 0.7481\n",
      "Epoch 17/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.7251\n",
      "Epoch 17: val_loss did not improve from 0.74808\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7278 - val_loss: 0.7619\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6979\n",
      "Epoch 18: val_loss improved from 0.74808 to 0.72182, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6979 - val_loss: 0.7218\n",
      "Epoch 19/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6932\n",
      "Epoch 19: val_loss improved from 0.72182 to 0.71327, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6904 - val_loss: 0.7133\n",
      "Epoch 20/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6732\n",
      "Epoch 20: val_loss improved from 0.71327 to 0.70791, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6705 - val_loss: 0.7079\n",
      "Epoch 21/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6640\n",
      "Epoch 21: val_loss improved from 0.70791 to 0.69930, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6624 - val_loss: 0.6993\n",
      "Epoch 22/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6425\n",
      "Epoch 22: val_loss did not improve from 0.69930\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6444 - val_loss: 0.7029\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6437\n",
      "Epoch 23: val_loss improved from 0.69930 to 0.67873, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6437 - val_loss: 0.6787\n",
      "Epoch 24/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6238\n",
      "Epoch 24: val_loss improved from 0.67873 to 0.67046, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6246 - val_loss: 0.6705\n",
      "Epoch 25/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.6190\n",
      "Epoch 25: val_loss improved from 0.67046 to 0.66509, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.6256 - val_loss: 0.6651\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6268\n",
      "Epoch 26: val_loss improved from 0.66509 to 0.66461, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6268 - val_loss: 0.6646\n",
      "Epoch 27/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6102\n",
      "Epoch 27: val_loss improved from 0.66461 to 0.65273, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6101 - val_loss: 0.6527\n",
      "Epoch 28/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5966\n",
      "Epoch 28: val_loss improved from 0.65273 to 0.64957, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5965 - val_loss: 0.6496\n",
      "Epoch 29/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5787\n",
      "Epoch 29: val_loss did not improve from 0.64957\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5809 - val_loss: 0.6498\n",
      "Epoch 30/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5804\n",
      "Epoch 30: val_loss did not improve from 0.64957\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5823 - val_loss: 0.6517\n",
      "Epoch 31/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5838\n",
      "Epoch 31: val_loss improved from 0.64957 to 0.63919, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5834 - val_loss: 0.6392\n",
      "Epoch 32/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5632\n",
      "Epoch 32: val_loss improved from 0.63919 to 0.63583, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5629 - val_loss: 0.6358\n",
      "Epoch 33/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5506\n",
      "Epoch 33: val_loss improved from 0.63583 to 0.63483, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5529 - val_loss: 0.6348\n",
      "Epoch 34/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5581\n",
      "Epoch 34: val_loss improved from 0.63483 to 0.63434, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5575 - val_loss: 0.6343\n",
      "Epoch 35/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5495\n",
      "Epoch 35: val_loss improved from 0.63434 to 0.62739, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5522 - val_loss: 0.6274\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5338\n",
      "Epoch 36: val_loss improved from 0.62739 to 0.62704, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5338 - val_loss: 0.6270\n",
      "Epoch 37/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5404\n",
      "Epoch 37: val_loss improved from 0.62704 to 0.62624, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5375 - val_loss: 0.6262\n",
      "Epoch 38/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5303\n",
      "Epoch 38: val_loss improved from 0.62624 to 0.61992, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5316 - val_loss: 0.6199\n",
      "Epoch 39/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5215\n",
      "Epoch 39: val_loss did not improve from 0.61992\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5223 - val_loss: 0.6441\n",
      "Epoch 40/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5063\n",
      "Epoch 40: val_loss did not improve from 0.61992\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5053 - val_loss: 0.6245\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5148\n",
      "Epoch 41: val_loss improved from 0.61992 to 0.61746, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5148 - val_loss: 0.6175\n",
      "Epoch 42/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5053\n",
      "Epoch 42: val_loss improved from 0.61746 to 0.61677, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5029 - val_loss: 0.6168\n",
      "Epoch 43/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5083\n",
      "Epoch 43: val_loss did not improve from 0.61677\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5078 - val_loss: 0.6249\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4936\n",
      "Epoch 44: val_loss did not improve from 0.61677\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4936 - val_loss: 0.6191\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4978\n",
      "Epoch 45: val_loss improved from 0.61677 to 0.61530, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4978 - val_loss: 0.6153\n",
      "Epoch 46/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4829\n",
      "Epoch 46: val_loss improved from 0.61530 to 0.60916, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4811 - val_loss: 0.6092\n",
      "Epoch 47/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4902\n",
      "Epoch 47: val_loss did not improve from 0.60916\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4888 - val_loss: 0.6171\n",
      "Epoch 48/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4616\n",
      "Epoch 48: val_loss did not improve from 0.60916\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4645 - val_loss: 0.6137\n",
      "Epoch 49/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4630\n",
      "Epoch 49: val_loss did not improve from 0.60916\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4624 - val_loss: 0.6141\n",
      "Epoch 50/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4595\n",
      "Epoch 50: val_loss did not improve from 0.60916\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4606 - val_loss: 0.6352\n",
      "Epoch 51/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.4543\n",
      "Epoch 51: val_loss did not improve from 0.60916\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4426 - val_loss: 0.6120\n",
      "Epoch 52/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4609\n",
      "Epoch 52: val_loss improved from 0.60916 to 0.60911, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4630 - val_loss: 0.6091\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4595\n",
      "Epoch 53: val_loss did not improve from 0.60911\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4595 - val_loss: 0.6155\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4518\n",
      "Epoch 54: val_loss did not improve from 0.60911\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4518 - val_loss: 0.6118\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4407\n",
      "Epoch 55: val_loss did not improve from 0.60911\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4407 - val_loss: 0.6133\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4468\n",
      "Epoch 56: val_loss improved from 0.60911 to 0.60385, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4468 - val_loss: 0.6039\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4502\n",
      "Epoch 57: val_loss did not improve from 0.60385\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4502 - val_loss: 0.6475\n",
      "Epoch 58/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.4385\n",
      "Epoch 58: val_loss improved from 0.60385 to 0.60312, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4321 - val_loss: 0.6031\n",
      "Epoch 59/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4404\n",
      "Epoch 59: val_loss improved from 0.60312 to 0.60177, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4401 - val_loss: 0.6018\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4116\n",
      "Epoch 60: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4116 - val_loss: 0.6174\n",
      "Epoch 61/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4090\n",
      "Epoch 61: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4109 - val_loss: 0.6141\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4191\n",
      "Epoch 62: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4191 - val_loss: 0.6439\n",
      "Epoch 63/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4199\n",
      "Epoch 63: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4166 - val_loss: 0.6261\n",
      "Epoch 64/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4042\n",
      "Epoch 64: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4028 - val_loss: 0.6160\n",
      "Epoch 65/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.3956\n",
      "Epoch 65: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3908 - val_loss: 0.6175\n",
      "Epoch 66/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4083\n",
      "Epoch 66: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4129 - val_loss: 0.6191\n",
      "Epoch 67/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3724\n",
      "Epoch 67: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3746 - val_loss: 0.6344\n",
      "Epoch 68/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3997\n",
      "Epoch 68: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4020 - val_loss: 0.6243\n",
      "Epoch 69/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3953\n",
      "Epoch 69: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3954 - val_loss: 0.6107\n",
      "Epoch 70/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3813\n",
      "Epoch 70: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3893 - val_loss: 0.7057\n",
      "Epoch 71/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3976\n",
      "Epoch 71: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3935 - val_loss: 0.6150\n",
      "Epoch 72/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.3815\n",
      "Epoch 72: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3862 - val_loss: 0.6200\n",
      "Epoch 73/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3677\n",
      "Epoch 73: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3651 - val_loss: 0.6323\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3813\n",
      "Epoch 74: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3813 - val_loss: 0.6358\n",
      "Epoch 75/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3836\n",
      "Epoch 75: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3818 - val_loss: 0.6289\n",
      "Epoch 76/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3782\n",
      "Epoch 76: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3761 - val_loss: 0.6239\n",
      "Epoch 77/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3677\n",
      "Epoch 77: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3683 - val_loss: 0.6477\n",
      "Epoch 78/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3712\n",
      "Epoch 78: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3625 - val_loss: 0.6265\n",
      "Epoch 79/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3591\n",
      "Epoch 79: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3642 - val_loss: 0.6313\n",
      "Epoch 80/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3604\n",
      "Epoch 80: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3588 - val_loss: 0.6311\n",
      "Epoch 81/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3538\n",
      "Epoch 81: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3539 - val_loss: 0.6201\n",
      "Epoch 82/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3832\n",
      "Epoch 82: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3853 - val_loss: 0.6141\n",
      "Epoch 83/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3634\n",
      "Epoch 83: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3695 - val_loss: 0.6208\n",
      "Epoch 84/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.3513\n",
      "Epoch 84: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3491 - val_loss: 0.6358\n",
      "Epoch 85/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3656\n",
      "Epoch 85: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3674 - val_loss: 0.6220\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3589\n",
      "Epoch 86: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3589 - val_loss: 0.6336\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3523\n",
      "Epoch 87: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3523 - val_loss: 0.6179\n",
      "Epoch 88/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.3397\n",
      "Epoch 88: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3438 - val_loss: 0.6284\n",
      "Epoch 89/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3393\n",
      "Epoch 89: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3393 - val_loss: 0.6334\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3220\n",
      "Epoch 90: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3220 - val_loss: 0.6376\n",
      "Epoch 91/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3495\n",
      "Epoch 91: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3470 - val_loss: 0.6459\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3357\n",
      "Epoch 92: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3357 - val_loss: 0.6844\n",
      "Epoch 93/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3227\n",
      "Epoch 93: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3207 - val_loss: 0.6331\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3269\n",
      "Epoch 94: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3269 - val_loss: 0.6318\n",
      "Epoch 95/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3433\n",
      "Epoch 95: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3442 - val_loss: 0.6401\n",
      "Epoch 96/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3141\n",
      "Epoch 96: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3121 - val_loss: 0.6652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3193\n",
      "Epoch 97: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3216 - val_loss: 0.6486\n",
      "Epoch 98/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3155\n",
      "Epoch 98: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3166 - val_loss: 0.6495\n",
      "Epoch 99/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3304\n",
      "Epoch 99: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3294 - val_loss: 0.6537\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3256\n",
      "Epoch 100: val_loss did not improve from 0.60177\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3256 - val_loss: 0.6645\n",
      "\n",
      "Train/Test model on Fold #3.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/30 [==========================>...] - ETA: 0s - loss: 1.4178\n",
      "Epoch 1: val_loss improved from inf to 1.35251, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 2s 26ms/step - loss: 1.4118 - val_loss: 1.3525\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.3199\n",
      "Epoch 2: val_loss improved from 1.35251 to 1.25605, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.3199 - val_loss: 1.2560\n",
      "Epoch 3/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.2113\n",
      "Epoch 3: val_loss improved from 1.25605 to 1.14280, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.2084 - val_loss: 1.1428\n",
      "Epoch 4/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.1316\n",
      "Epoch 4: val_loss improved from 1.14280 to 1.08230, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1288 - val_loss: 1.0823\n",
      "Epoch 5/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.0596\n",
      "Epoch 5: val_loss improved from 1.08230 to 1.01895, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0615 - val_loss: 1.0189\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.0124\n",
      "Epoch 6: val_loss improved from 1.01895 to 0.98678, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0124 - val_loss: 0.9868\n",
      "Epoch 7/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.9721\n",
      "Epoch 7: val_loss improved from 0.98678 to 0.94856, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9681 - val_loss: 0.9486\n",
      "Epoch 8/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.9359\n",
      "Epoch 8: val_loss improved from 0.94856 to 0.93234, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9390 - val_loss: 0.9323\n",
      "Epoch 9/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.9029\n",
      "Epoch 9: val_loss improved from 0.93234 to 0.89210, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9020 - val_loss: 0.8921\n",
      "Epoch 10/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8719\n",
      "Epoch 10: val_loss improved from 0.89210 to 0.86635, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8716 - val_loss: 0.8663\n",
      "Epoch 11/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8467\n",
      "Epoch 11: val_loss improved from 0.86635 to 0.85465, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8450 - val_loss: 0.8546\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.8154\n",
      "Epoch 12: val_loss improved from 0.85465 to 0.82334, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8154 - val_loss: 0.8233\n",
      "Epoch 13/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7949\n",
      "Epoch 13: val_loss improved from 0.82334 to 0.81618, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7958 - val_loss: 0.8162\n",
      "Epoch 14/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7807\n",
      "Epoch 14: val_loss did not improve from 0.81618\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7818 - val_loss: 0.8333\n",
      "Epoch 15/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7675\n",
      "Epoch 15: val_loss improved from 0.81618 to 0.77922, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7675 - val_loss: 0.7792\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7619\n",
      "Epoch 16: val_loss improved from 0.77922 to 0.76517, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7619 - val_loss: 0.7652\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7376\n",
      "Epoch 17: val_loss improved from 0.76517 to 0.75935, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7376 - val_loss: 0.7594\n",
      "Epoch 18/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.7172\n",
      "Epoch 18: val_loss improved from 0.75935 to 0.75491, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.7155 - val_loss: 0.7549\n",
      "Epoch 19/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.7184\n",
      "Epoch 19: val_loss improved from 0.75491 to 0.73505, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7130 - val_loss: 0.7351\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6896\n",
      "Epoch 20: val_loss improved from 0.73505 to 0.73406, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6896 - val_loss: 0.7341\n",
      "Epoch 21/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6704\n",
      "Epoch 21: val_loss improved from 0.73406 to 0.72254, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6752 - val_loss: 0.7225\n",
      "Epoch 22/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6698\n",
      "Epoch 22: val_loss improved from 0.72254 to 0.70769, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6660 - val_loss: 0.7077\n",
      "Epoch 23/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6568\n",
      "Epoch 23: val_loss did not improve from 0.70769\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6575 - val_loss: 0.7152\n",
      "Epoch 24/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6522\n",
      "Epoch 24: val_loss improved from 0.70769 to 0.69456, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6541 - val_loss: 0.6946\n",
      "Epoch 25/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6473\n",
      "Epoch 25: val_loss improved from 0.69456 to 0.68681, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6489 - val_loss: 0.6868\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6202\n",
      "Epoch 26: val_loss improved from 0.68681 to 0.68675, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6202 - val_loss: 0.6867\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6332\n",
      "Epoch 27: val_loss improved from 0.68675 to 0.67749, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6332 - val_loss: 0.6775\n",
      "Epoch 28/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5973\n",
      "Epoch 28: val_loss did not improve from 0.67749\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6004 - val_loss: 0.6786\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5922\n",
      "Epoch 29: val_loss improved from 0.67749 to 0.66845, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5922 - val_loss: 0.6685\n",
      "Epoch 30/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5851\n",
      "Epoch 30: val_loss improved from 0.66845 to 0.66784, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5870 - val_loss: 0.6678\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5816\n",
      "Epoch 31: val_loss improved from 0.66784 to 0.66105, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5816 - val_loss: 0.6611\n",
      "Epoch 32/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5691\n",
      "Epoch 32: val_loss improved from 0.66105 to 0.65859, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5683 - val_loss: 0.6586\n",
      "Epoch 33/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5661\n",
      "Epoch 33: val_loss did not improve from 0.65859\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5635 - val_loss: 0.6598\n",
      "Epoch 34/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.5520\n",
      "Epoch 34: val_loss did not improve from 0.65859\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5672 - val_loss: 0.6699\n",
      "Epoch 35/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5643\n",
      "Epoch 35: val_loss improved from 0.65859 to 0.65093, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5598 - val_loss: 0.6509\n",
      "Epoch 36/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5460\n",
      "Epoch 36: val_loss improved from 0.65093 to 0.65000, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5457 - val_loss: 0.6500\n",
      "Epoch 37/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5545\n",
      "Epoch 37: val_loss improved from 0.65000 to 0.64142, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5523 - val_loss: 0.6414\n",
      "Epoch 38/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.5233\n",
      "Epoch 38: val_loss improved from 0.64142 to 0.64100, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5375 - val_loss: 0.6410\n",
      "Epoch 39/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.5295\n",
      "Epoch 39: val_loss improved from 0.64100 to 0.63905, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5397 - val_loss: 0.6391\n",
      "Epoch 40/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5263\n",
      "Epoch 40: val_loss did not improve from 0.63905\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5285 - val_loss: 0.6404\n",
      "Epoch 41/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5059\n",
      "Epoch 41: val_loss did not improve from 0.63905\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5078 - val_loss: 0.6483\n",
      "Epoch 42/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4938\n",
      "Epoch 42: val_loss did not improve from 0.63905\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4950 - val_loss: 0.6403\n",
      "Epoch 43/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5084\n",
      "Epoch 43: val_loss did not improve from 0.63905\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5098 - val_loss: 0.6541\n",
      "Epoch 44/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4876\n",
      "Epoch 44: val_loss improved from 0.63905 to 0.63501, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4876 - val_loss: 0.6350\n",
      "Epoch 45/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4846\n",
      "Epoch 45: val_loss did not improve from 0.63501\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4868 - val_loss: 0.6352\n",
      "Epoch 46/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4885\n",
      "Epoch 46: val_loss improved from 0.63501 to 0.63251, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4865 - val_loss: 0.6325\n",
      "Epoch 47/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4749\n",
      "Epoch 47: val_loss did not improve from 0.63251\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4739 - val_loss: 0.6411\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4721\n",
      "Epoch 48: val_loss improved from 0.63251 to 0.63200, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4721 - val_loss: 0.6320\n",
      "Epoch 49/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.4552\n",
      "Epoch 49: val_loss did not improve from 0.63200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4630 - val_loss: 0.6522\n",
      "Epoch 50/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4675\n",
      "Epoch 50: val_loss did not improve from 0.63200\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4683 - val_loss: 0.6524\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4668\n",
      "Epoch 51: val_loss did not improve from 0.63200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4668 - val_loss: 0.6365\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4320\n",
      "Epoch 52: val_loss did not improve from 0.63200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4320 - val_loss: 0.6452\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4509\n",
      "Epoch 53: val_loss did not improve from 0.63200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4509 - val_loss: 0.6322\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4458\n",
      "Epoch 54: val_loss did not improve from 0.63200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4458 - val_loss: 0.6388\n",
      "Epoch 55/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4242\n",
      "Epoch 55: val_loss did not improve from 0.63200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4236 - val_loss: 0.6346\n",
      "Epoch 56/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4520\n",
      "Epoch 56: val_loss did not improve from 0.63200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4505 - val_loss: 0.6327\n",
      "Epoch 57/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4272\n",
      "Epoch 57: val_loss improved from 0.63200 to 0.63081, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4267 - val_loss: 0.6308\n",
      "Epoch 58/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4177\n",
      "Epoch 58: val_loss did not improve from 0.63081\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4177 - val_loss: 0.6519\n",
      "Epoch 59/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.4252\n",
      "Epoch 59: val_loss did not improve from 0.63081\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4310 - val_loss: 0.6489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4184\n",
      "Epoch 60: val_loss did not improve from 0.63081\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4184 - val_loss: 0.6403\n",
      "Epoch 61/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4062\n",
      "Epoch 61: val_loss did not improve from 0.63081\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4065 - val_loss: 0.6456\n",
      "Epoch 62/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4096\n",
      "Epoch 62: val_loss did not improve from 0.63081\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4157 - val_loss: 0.6356\n",
      "Epoch 63/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4006\n",
      "Epoch 63: val_loss improved from 0.63081 to 0.63063, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3997 - val_loss: 0.6306\n",
      "Epoch 64/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.3836\n",
      "Epoch 64: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3979 - val_loss: 0.6426\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3983\n",
      "Epoch 65: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3983 - val_loss: 0.6623\n",
      "Epoch 66/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3972\n",
      "Epoch 66: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3999 - val_loss: 0.6335\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3934\n",
      "Epoch 67: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3934 - val_loss: 0.6550\n",
      "Epoch 68/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3995\n",
      "Epoch 68: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4007 - val_loss: 0.6338\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3815\n",
      "Epoch 69: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3815 - val_loss: 0.6430\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3959\n",
      "Epoch 70: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3959 - val_loss: 0.6358\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3812\n",
      "Epoch 71: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3812 - val_loss: 0.6454\n",
      "Epoch 72/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3722\n",
      "Epoch 72: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3743 - val_loss: 0.6372\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3862\n",
      "Epoch 73: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3862 - val_loss: 0.6449\n",
      "Epoch 74/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3731\n",
      "Epoch 74: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3746 - val_loss: 0.6328\n",
      "Epoch 75/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3677\n",
      "Epoch 75: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3703 - val_loss: 0.6419\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3740\n",
      "Epoch 76: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3740 - val_loss: 0.6380\n",
      "Epoch 77/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3590\n",
      "Epoch 77: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3603 - val_loss: 0.6407\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3729\n",
      "Epoch 78: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3729 - val_loss: 0.6363\n",
      "Epoch 79/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.3530\n",
      "Epoch 79: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3541 - val_loss: 0.6492\n",
      "Epoch 80/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.3627\n",
      "Epoch 80: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3630 - val_loss: 0.6397\n",
      "Epoch 81/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3662\n",
      "Epoch 81: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3639 - val_loss: 0.6476\n",
      "Epoch 82/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3505\n",
      "Epoch 82: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3488 - val_loss: 0.6345\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3415\n",
      "Epoch 83: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3415 - val_loss: 0.6571\n",
      "Epoch 84/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3443\n",
      "Epoch 84: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3449 - val_loss: 0.6539\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3495\n",
      "Epoch 85: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3495 - val_loss: 0.6525\n",
      "Epoch 86/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3567\n",
      "Epoch 86: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3575 - val_loss: 0.6525\n",
      "Epoch 87/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3198\n",
      "Epoch 87: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3206 - val_loss: 0.6644\n",
      "Epoch 88/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.3413\n",
      "Epoch 88: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3383 - val_loss: 0.6657\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3273\n",
      "Epoch 89: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3273 - val_loss: 0.6742\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3211\n",
      "Epoch 90: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3211 - val_loss: 0.6661\n",
      "Epoch 91/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3179\n",
      "Epoch 91: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3164 - val_loss: 0.6959\n",
      "Epoch 92/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.3275\n",
      "Epoch 92: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3235 - val_loss: 0.6674\n",
      "Epoch 93/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3366\n",
      "Epoch 93: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3346 - val_loss: 0.7128\n",
      "Epoch 94/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3440\n",
      "Epoch 94: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3419 - val_loss: 0.6635\n",
      "Epoch 95/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3265\n",
      "Epoch 95: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3276 - val_loss: 0.6698\n",
      "Epoch 96/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3160\n",
      "Epoch 96: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3190 - val_loss: 0.6904\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3329\n",
      "Epoch 97: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3329 - val_loss: 0.6662\n",
      "Epoch 98/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.3063\n",
      "Epoch 98: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3105 - val_loss: 0.6622\n",
      "Epoch 99/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.3080\n",
      "Epoch 99: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3079 - val_loss: 0.6751\n",
      "Epoch 100/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.3157\n",
      "Epoch 100: val_loss did not improve from 0.63063\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3138 - val_loss: 0.7119\n",
      "\n",
      "Train/Test model on Fold #4.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/30 [===========================>..] - ETA: 0s - loss: 1.4185\n",
      "Epoch 1: val_loss improved from inf to 1.35383, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 2s 28ms/step - loss: 1.4152 - val_loss: 1.3538\n",
      "Epoch 2/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.3241\n",
      "Epoch 2: val_loss improved from 1.35383 to 1.26453, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.3223 - val_loss: 1.2645\n",
      "Epoch 3/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 1.2313\n",
      "Epoch 3: val_loss improved from 1.26453 to 1.16240, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.2251 - val_loss: 1.1624\n",
      "Epoch 4/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 1.1296\n",
      "Epoch 4: val_loss improved from 1.16240 to 1.06209, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1264 - val_loss: 1.0621\n",
      "Epoch 5/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 1.0643\n",
      "Epoch 5: val_loss improved from 1.06209 to 1.01679, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.0643 - val_loss: 1.0168\n",
      "Epoch 6/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.0072\n",
      "Epoch 6: val_loss improved from 1.01679 to 0.97213, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0058 - val_loss: 0.9721\n",
      "Epoch 7/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.9644\n",
      "Epoch 7: val_loss improved from 0.97213 to 0.95388, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.9600 - val_loss: 0.9539\n",
      "Epoch 8/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.9170\n",
      "Epoch 8: val_loss improved from 0.95388 to 0.91271, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9123 - val_loss: 0.9127\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.8969\n",
      "Epoch 9: val_loss improved from 0.91271 to 0.88807, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8969 - val_loss: 0.8881\n",
      "Epoch 10/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.8590\n",
      "Epoch 10: val_loss improved from 0.88807 to 0.86636, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8608 - val_loss: 0.8664\n",
      "Epoch 11/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.8399\n",
      "Epoch 11: val_loss improved from 0.86636 to 0.84799, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.8381 - val_loss: 0.8480\n",
      "Epoch 12/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8012\n",
      "Epoch 12: val_loss improved from 0.84799 to 0.83319, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8026 - val_loss: 0.8332\n",
      "Epoch 13/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.8087\n",
      "Epoch 13: val_loss improved from 0.83319 to 0.82682, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.8072 - val_loss: 0.8268\n",
      "Epoch 14/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7730\n",
      "Epoch 14: val_loss improved from 0.82682 to 0.80928, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7721 - val_loss: 0.8093\n",
      "Epoch 15/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.7537\n",
      "Epoch 15: val_loss improved from 0.80928 to 0.79347, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7574 - val_loss: 0.7935\n",
      "Epoch 16/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.7298\n",
      "Epoch 16: val_loss improved from 0.79347 to 0.77767, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.7258 - val_loss: 0.7777\n",
      "Epoch 17/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.7164\n",
      "Epoch 17: val_loss improved from 0.77767 to 0.76662, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.7218 - val_loss: 0.7666\n",
      "Epoch 18/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7127\n",
      "Epoch 18: val_loss improved from 0.76662 to 0.75434, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7111 - val_loss: 0.7543\n",
      "Epoch 19/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6934\n",
      "Epoch 19: val_loss improved from 0.75434 to 0.74791, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6948 - val_loss: 0.7479\n",
      "Epoch 20/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7000\n",
      "Epoch 20: val_loss improved from 0.74791 to 0.73979, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7006 - val_loss: 0.7398\n",
      "Epoch 21/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6849\n",
      "Epoch 21: val_loss improved from 0.73979 to 0.73767, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6862 - val_loss: 0.7377\n",
      "Epoch 22/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.6659\n",
      "Epoch 22: val_loss improved from 0.73767 to 0.72026, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6716 - val_loss: 0.7203\n",
      "Epoch 23/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6518\n",
      "Epoch 23: val_loss did not improve from 0.72026\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6543 - val_loss: 0.7276\n",
      "Epoch 24/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6577\n",
      "Epoch 24: val_loss improved from 0.72026 to 0.71195, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6574 - val_loss: 0.7120\n",
      "Epoch 25/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6348\n",
      "Epoch 25: val_loss did not improve from 0.71195\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6359 - val_loss: 0.7158\n",
      "Epoch 26/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6144\n",
      "Epoch 26: val_loss improved from 0.71195 to 0.69936, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6120 - val_loss: 0.6994\n",
      "Epoch 27/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6228\n",
      "Epoch 27: val_loss improved from 0.69936 to 0.69683, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6237 - val_loss: 0.6968\n",
      "Epoch 28/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.6094\n",
      "Epoch 28: val_loss improved from 0.69683 to 0.69048, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.6127 - val_loss: 0.6905\n",
      "Epoch 29/100\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.5894\n",
      "Epoch 29: val_loss did not improve from 0.69048\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5857 - val_loss: 0.6970\n",
      "Epoch 30/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5857\n",
      "Epoch 30: val_loss did not improve from 0.69048\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5861 - val_loss: 0.7085\n",
      "Epoch 31/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5934\n",
      "Epoch 31: val_loss improved from 0.69048 to 0.67780, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5885 - val_loss: 0.6778\n",
      "Epoch 32/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5758\n",
      "Epoch 32: val_loss improved from 0.67780 to 0.67505, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5779 - val_loss: 0.6750\n",
      "Epoch 33/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5728\n",
      "Epoch 33: val_loss improved from 0.67505 to 0.67160, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5728 - val_loss: 0.6716\n",
      "Epoch 34/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5641\n",
      "Epoch 34: val_loss did not improve from 0.67160\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5633 - val_loss: 0.6759\n",
      "Epoch 35/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5538\n",
      "Epoch 35: val_loss did not improve from 0.67160\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5574 - val_loss: 0.6728\n",
      "Epoch 36/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5575\n",
      "Epoch 36: val_loss improved from 0.67160 to 0.66743, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5617 - val_loss: 0.6674\n",
      "Epoch 37/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5485\n",
      "Epoch 37: val_loss improved from 0.66743 to 0.66467, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5494 - val_loss: 0.6647\n",
      "Epoch 38/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5340\n",
      "Epoch 38: val_loss improved from 0.66467 to 0.66192, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5324 - val_loss: 0.6619\n",
      "Epoch 39/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5345\n",
      "Epoch 39: val_loss did not improve from 0.66192\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5374 - val_loss: 0.6632\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5398\n",
      "Epoch 40: val_loss improved from 0.66192 to 0.65638, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5398 - val_loss: 0.6564\n",
      "Epoch 41/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5170\n",
      "Epoch 41: val_loss did not improve from 0.65638\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5226 - val_loss: 0.6568\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5236\n",
      "Epoch 42: val_loss did not improve from 0.65638\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5236 - val_loss: 0.6569\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5022\n",
      "Epoch 43: val_loss did not improve from 0.65638\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5022 - val_loss: 0.6666\n",
      "Epoch 44/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5001\n",
      "Epoch 44: val_loss improved from 0.65638 to 0.65455, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5004 - val_loss: 0.6546\n",
      "Epoch 45/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4971\n",
      "Epoch 45: val_loss did not improve from 0.65455\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4972 - val_loss: 0.6617\n",
      "Epoch 46/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4936\n",
      "Epoch 46: val_loss improved from 0.65455 to 0.65431, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4931 - val_loss: 0.6543\n",
      "Epoch 47/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4868\n",
      "Epoch 47: val_loss did not improve from 0.65431\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4880 - val_loss: 0.6688\n",
      "Epoch 48/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4768\n",
      "Epoch 48: val_loss did not improve from 0.65431\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4786 - val_loss: 0.6604\n",
      "Epoch 49/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4861\n",
      "Epoch 49: val_loss did not improve from 0.65431\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4845 - val_loss: 0.6554\n",
      "Epoch 50/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4847\n",
      "Epoch 50: val_loss improved from 0.65431 to 0.64469, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4900 - val_loss: 0.6447\n",
      "Epoch 51/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4800\n",
      "Epoch 51: val_loss did not improve from 0.64469\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4788 - val_loss: 0.6559\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4745\n",
      "Epoch 52: val_loss did not improve from 0.64469\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4745 - val_loss: 0.6556\n",
      "Epoch 53/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4621\n",
      "Epoch 53: val_loss improved from 0.64469 to 0.64211, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4699 - val_loss: 0.6421\n",
      "Epoch 54/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4755\n",
      "Epoch 54: val_loss did not improve from 0.64211\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4753 - val_loss: 0.6462\n",
      "Epoch 55/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4422\n",
      "Epoch 55: val_loss did not improve from 0.64211\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4383 - val_loss: 0.6476\n",
      "Epoch 56/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4509\n",
      "Epoch 56: val_loss did not improve from 0.64211\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4473 - val_loss: 0.6509\n",
      "Epoch 57/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4553\n",
      "Epoch 57: val_loss improved from 0.64211 to 0.63908, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4563 - val_loss: 0.6391\n",
      "Epoch 58/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4422\n",
      "Epoch 58: val_loss did not improve from 0.63908\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4393 - val_loss: 0.6709\n",
      "Epoch 59/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4544\n",
      "Epoch 59: val_loss improved from 0.63908 to 0.63815, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4562 - val_loss: 0.6382\n",
      "Epoch 60/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4278\n",
      "Epoch 60: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4282 - val_loss: 0.6561\n",
      "Epoch 61/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.4494\n",
      "Epoch 61: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4488 - val_loss: 0.6492\n",
      "Epoch 62/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4357\n",
      "Epoch 62: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4367 - val_loss: 0.6406\n",
      "Epoch 63/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4180\n",
      "Epoch 63: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4122 - val_loss: 0.6620\n",
      "Epoch 64/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4016\n",
      "Epoch 64: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4020 - val_loss: 0.6740\n",
      "Epoch 65/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4145\n",
      "Epoch 65: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4159 - val_loss: 0.6536\n",
      "Epoch 66/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4254\n",
      "Epoch 66: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4220 - val_loss: 0.6518\n",
      "Epoch 67/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4090\n",
      "Epoch 67: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4077 - val_loss: 0.6562\n",
      "Epoch 68/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4092\n",
      "Epoch 68: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4096 - val_loss: 0.6513\n",
      "Epoch 69/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3969\n",
      "Epoch 69: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3955 - val_loss: 0.6758\n",
      "Epoch 70/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4170\n",
      "Epoch 70: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4162 - val_loss: 0.6506\n",
      "Epoch 71/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3877\n",
      "Epoch 71: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3882 - val_loss: 0.6629\n",
      "Epoch 72/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4235\n",
      "Epoch 72: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4214 - val_loss: 0.6442\n",
      "Epoch 73/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3956\n",
      "Epoch 73: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3924 - val_loss: 0.6538\n",
      "Epoch 74/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3912\n",
      "Epoch 74: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3896 - val_loss: 0.6557\n",
      "Epoch 75/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3650\n",
      "Epoch 75: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3683 - val_loss: 0.6743\n",
      "Epoch 76/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.3873\n",
      "Epoch 76: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3820 - val_loss: 0.6640\n",
      "Epoch 77/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3911\n",
      "Epoch 77: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3897 - val_loss: 0.6539\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3847\n",
      "Epoch 78: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3847 - val_loss: 0.6568\n",
      "Epoch 79/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3797\n",
      "Epoch 79: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3837 - val_loss: 0.6600\n",
      "Epoch 80/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.3804\n",
      "Epoch 80: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3812 - val_loss: 0.6475\n",
      "Epoch 81/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.3745\n",
      "Epoch 81: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3727 - val_loss: 0.6588\n",
      "Epoch 82/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.3800\n",
      "Epoch 82: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3871 - val_loss: 0.6560\n",
      "Epoch 83/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3608\n",
      "Epoch 83: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3658 - val_loss: 0.6553\n",
      "Epoch 84/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.3688\n",
      "Epoch 84: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3767 - val_loss: 0.6521\n",
      "Epoch 85/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3548\n",
      "Epoch 85: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3600 - val_loss: 0.6695\n",
      "Epoch 86/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3829\n",
      "Epoch 86: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3835 - val_loss: 0.6563\n",
      "Epoch 87/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3666\n",
      "Epoch 87: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3678 - val_loss: 0.6684\n",
      "Epoch 88/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3481\n",
      "Epoch 88: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3446 - val_loss: 0.6958\n",
      "Epoch 89/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3545\n",
      "Epoch 89: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3529 - val_loss: 0.6630\n",
      "Epoch 90/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.3444\n",
      "Epoch 90: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3456 - val_loss: 0.6825\n",
      "Epoch 91/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3434\n",
      "Epoch 91: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3432 - val_loss: 0.6802\n",
      "Epoch 92/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3646\n",
      "Epoch 92: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3678 - val_loss: 0.6690\n",
      "Epoch 93/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3390\n",
      "Epoch 93: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3395 - val_loss: 0.6663\n",
      "Epoch 94/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.3540\n",
      "Epoch 94: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3499 - val_loss: 0.6651\n",
      "Epoch 95/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3347\n",
      "Epoch 95: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3354 - val_loss: 0.6703\n",
      "Epoch 96/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3288\n",
      "Epoch 96: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3285 - val_loss: 0.6809\n",
      "Epoch 97/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.3288\n",
      "Epoch 97: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3346 - val_loss: 0.7132\n",
      "Epoch 98/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.3417\n",
      "Epoch 98: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3430 - val_loss: 0.6630\n",
      "Epoch 99/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.3258\n",
      "Epoch 99: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3321 - val_loss: 0.6666\n",
      "Epoch 100/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3250\n",
      "Epoch 100: val_loss did not improve from 0.63815\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3255 - val_loss: 0.6740\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Train/Test model on all folds, generate evaluations\n",
    "##################################################################################\n",
    "\n",
    "## Create and set directory to save model\n",
    "modelPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold), \"models\")\n",
    "if(not os.path.isdir(modelPath)):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "i = -1\n",
    "for fold in folds:\n",
    "    i += 1\n",
    "    \n",
    "    print(\"\\nTrain/Test model on Fold #\"+str(i)+\".\")\n",
    "    \n",
    "    model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "    ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    modelCallbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                           monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                           save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "    ]\n",
    "    \n",
    "    # adding random shuffling of the dataset for training purpose\n",
    "    index_arr = np.arange(fold[\"X_train\"].shape[0])\n",
    "    index_arr = np.random.permutation(index_arr)\n",
    "    \n",
    "    model.fit(x = fold[\"X_train\"][index_arr], y = fold[\"y_train\"][index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "              callbacks = modelCallbacks, validation_data = (fold[\"X_test\"], fold[\"y_test\"]))\n",
    "    \n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TRAIN dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_train\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "    mcc = matthews_corrcoef(fold[\"y_train\"], label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Train\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TEST dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_test\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "    mcc = matthews_corrcoef(fold[\"y_test\"], label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Test\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.759065</td>\n",
       "      <td>0.840120</td>\n",
       "      <td>0.761556</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.519347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.942906</td>\n",
       "      <td>0.941296</td>\n",
       "      <td>0.983703</td>\n",
       "      <td>0.945213</td>\n",
       "      <td>0.940597</td>\n",
       "      <td>0.886248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                   \n",
       "Test        0.759434   0.759065  0.840120     0.761556     0.757322  0.519347\n",
       "Train       0.942906   0.941296  0.983703     0.945213     0.940597  0.886248"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.775681</td>\n",
       "      <td>0.792035</td>\n",
       "      <td>[0.0, 0.0041841004184100415, 0.104602510460251...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9960138, 0.99601376, 0.9573596, 0.9553007, ...</td>\n",
       "      <td>0.856194</td>\n",
       "      <td>0.748954</td>\n",
       "      <td>0.802521</td>\n",
       "      <td>0.552233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0756302521008403...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0041841004184100415, 0.00418...</td>\n",
       "      <td>[1.995278, 0.995278, 0.97472954, 0.97269803, 0...</td>\n",
       "      <td>0.840494</td>\n",
       "      <td>0.756303</td>\n",
       "      <td>0.786611</td>\n",
       "      <td>0.543181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>0.746939</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.1302521008403361...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9920356, 0.9920357, 0.95690477, 0.95638555,...</td>\n",
       "      <td>0.845209</td>\n",
       "      <td>0.768908</td>\n",
       "      <td>0.739496</td>\n",
       "      <td>0.508623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.766807</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0504201680672268...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9928411, 0.9928411, 0.97938436, 0.97892886,...</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.534676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.728992</td>\n",
       "      <td>0.726141</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0882352941176470...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9935296, 0.9935295, 0.9597013, 0.9574193, 0...</td>\n",
       "      <td>0.819804</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.722689</td>\n",
       "      <td>0.458020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Train_Test  Accuracy  Precision  \\\n",
       "1     0       Test  0.775681   0.792035   \n",
       "3     1       Test  0.771488   0.779221   \n",
       "5     2       Test  0.754202   0.746939   \n",
       "7     3       Test  0.766807   0.750988   \n",
       "9     4       Test  0.728992   0.726141   \n",
       "\n",
       "                                                 TPR  \\\n",
       "1  [0.0, 0.0041841004184100415, 0.104602510460251...   \n",
       "3  [0.0, 0.004201680672268907, 0.0756302521008403...   \n",
       "5  [0.0, 0.004201680672268907, 0.1302521008403361...   \n",
       "7  [0.0, 0.004201680672268907, 0.0504201680672268...   \n",
       "9  [0.0, 0.004201680672268907, 0.0882352941176470...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "1  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "3  [0.0, 0.0, 0.0, 0.0041841004184100415, 0.00418...   \n",
       "5  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "7  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "9  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "1  [1.9960138, 0.99601376, 0.9573596, 0.9553007, ...  0.856194     0.748954   \n",
       "3  [1.995278, 0.995278, 0.97472954, 0.97269803, 0...  0.840494     0.756303   \n",
       "5  [1.9920356, 0.9920357, 0.95690477, 0.95638555,...  0.845209     0.768908   \n",
       "7  [1.9928411, 0.9928411, 0.97938436, 0.97892886,...  0.838897     0.798319   \n",
       "9  [1.9935296, 0.9935295, 0.9597013, 0.9574193, 0...  0.819804     0.735294   \n",
       "\n",
       "   Specificity       MCC  \n",
       "1     0.802521  0.552233  \n",
       "3     0.786611  0.543181  \n",
       "5     0.739496  0.508623  \n",
       "7     0.735294  0.534676  \n",
       "9     0.722689  0.458020  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df[evaluations_df[\"Train_Test\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features\n",
    "train_labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read independent data file\n",
    "##################################################################################\n",
    "indpe_file_path = os.path.join(input_data_folder, independent_data_file)\n",
    "indpe_data = pd.read_csv(indpe_file_path, sep='\\t', header=None)\n",
    "indpe_data.columns = ['Sequence', 'name', 'id', 'flag', 'label_original', 'type']\n",
    "indpe_data.head()\n",
    "    \n",
    "##################################################################################\n",
    "##### Create OHE of sequence\n",
    "##################################################################################\n",
    "indpe_data['OHE_Sequence'] = pd.Series([one_hot_encode_nt(val, all_char_dict) \n",
    "                                        for val in indpe_data[\"Sequence\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Fix the labels\n",
    "##################################################################################\n",
    "indpe_data['label'] = pd.Series([1 if val == 1 else 0 \n",
    "                                 for val in indpe_data[\"label_original\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "indpe_features = np.array(list(indpe_data['OHE_Sequence']))\n",
    "indpe_labels = np.array(list(indpe_data['label']))\n",
    "indpe_labels = indpe_labels.reshape((indpe_labels.shape[0], 1))\n",
    "\n",
    "input_seq_shape = indpe_features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using k-fold Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of each k-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.626776</td>\n",
       "      <td>0.246891</td>\n",
       "      <td>0.667723</td>\n",
       "      <td>0.608867</td>\n",
       "      <td>0.630333</td>\n",
       "      <td>0.181104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.626776   0.246891  0.667723     0.608867     0.630333  0.181104"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    label_pred = pred2label(y_pred)\n",
    "\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(indpe_labels, label_pred)\n",
    "    prec = precision_score(indpe_labels,label_pred)\n",
    "    mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "    conf = confusion_matrix(indpe_labels, label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "    auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.262821</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.0019569471624266144, 0.0019569471...</td>\n",
       "      <td>[1.9960555, 0.9960555, 0.9889481, 0.9862916, 0...</td>\n",
       "      <td>0.675735</td>\n",
       "      <td>0.605911</td>\n",
       "      <td>0.662427</td>\n",
       "      <td>0.205345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.631020</td>\n",
       "      <td>0.245399</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.0009784735812133072, 0.0009784735...</td>\n",
       "      <td>[1.9972394, 0.99723935, 0.995284, 0.99477816, ...</td>\n",
       "      <td>0.665998</td>\n",
       "      <td>0.591133</td>\n",
       "      <td>0.638943</td>\n",
       "      <td>0.174684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.614694</td>\n",
       "      <td>0.237817</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.0019569471624266144, 0.0019569471...</td>\n",
       "      <td>[1.9965749, 0.9965749, 0.99159884, 0.9882587, ...</td>\n",
       "      <td>0.665299</td>\n",
       "      <td>0.600985</td>\n",
       "      <td>0.617417</td>\n",
       "      <td>0.164601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.604082</td>\n",
       "      <td>0.237918</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.0009784735812133072, 0.0009784735...</td>\n",
       "      <td>[1.9974382, 0.9974382, 0.9929658, 0.99229115, ...</td>\n",
       "      <td>0.657168</td>\n",
       "      <td>0.630542</td>\n",
       "      <td>0.598826</td>\n",
       "      <td>0.171845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.631020</td>\n",
       "      <td>0.250501</td>\n",
       "      <td>[0.0, 0.0, 0.009852216748768473, 0.00985221674...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.000978473581213...</td>\n",
       "      <td>[1.9954288, 0.9954288, 0.9944258, 0.99050903, ...</td>\n",
       "      <td>0.674414</td>\n",
       "      <td>0.615764</td>\n",
       "      <td>0.634051</td>\n",
       "      <td>0.189048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold   Train_Test  Accuracy  Precision  \\\n",
       "0     0  Independent  0.653061   0.262821   \n",
       "1     1  Independent  0.631020   0.245399   \n",
       "2     2  Independent  0.614694   0.237817   \n",
       "3     3  Independent  0.604082   0.237918   \n",
       "4     4  Independent  0.631020   0.250501   \n",
       "\n",
       "                                                 TPR  \\\n",
       "0  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "1  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "2  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "3  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "4  [0.0, 0.0, 0.009852216748768473, 0.00985221674...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "0  [0.0, 0.0, 0.0019569471624266144, 0.0019569471...   \n",
       "1  [0.0, 0.0, 0.0009784735812133072, 0.0009784735...   \n",
       "2  [0.0, 0.0, 0.0019569471624266144, 0.0019569471...   \n",
       "3  [0.0, 0.0, 0.0009784735812133072, 0.0009784735...   \n",
       "4  [0.0, 0.0009784735812133072, 0.000978473581213...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0  [1.9960555, 0.9960555, 0.9889481, 0.9862916, 0...  0.675735     0.605911   \n",
       "1  [1.9972394, 0.99723935, 0.995284, 0.99477816, ...  0.665998     0.591133   \n",
       "2  [1.9965749, 0.9965749, 0.99159884, 0.9882587, ...  0.665299     0.600985   \n",
       "3  [1.9974382, 0.9974382, 0.9929658, 0.99229115, ...  0.657168     0.630542   \n",
       "4  [1.9954288, 0.9954288, 0.9944258, 0.99050903, ...  0.674414     0.615764   \n",
       "\n",
       "   Specificity       MCC  \n",
       "0     0.662427  0.205345  \n",
       "1     0.638943  0.174684  \n",
       "2     0.617417  0.164601  \n",
       "3     0.598826  0.171845  \n",
       "4     0.634051  0.189048  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.639184</td>\n",
       "      <td>0.250522</td>\n",
       "      <td>0.676178</td>\n",
       "      <td>0.591133</td>\n",
       "      <td>0.648728</td>\n",
       "      <td>0.182766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.639184   0.250522  0.676178     0.591133     0.648728  0.182766"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    total_pred += y_pred\n",
    "    all_preds.append(y_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.246407</td>\n",
       "      <td>0.661496</td>\n",
       "      <td>0.591133</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.176291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.632653   0.246407  0.661496     0.591133       0.6409  0.176291"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    vote_pred = pred2label(y_pred)\n",
    "    total_pred += vote_pred\n",
    "    all_preds.append(vote_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using New Model\n",
    "\n",
    "Train model on full data from training. Predict and evaluate on Independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 1.4069\n",
      "Epoch 1: val_loss improved from inf to 1.34049, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 3s 26ms/step - loss: 1.4069 - val_loss: 1.3405\n",
      "Epoch 2/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 1.2986\n",
      "Epoch 2: val_loss improved from 1.34049 to 1.27402, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.2961 - val_loss: 1.2740\n",
      "Epoch 3/100\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 1.2049\n",
      "Epoch 3: val_loss improved from 1.27402 to 1.26119, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.1961 - val_loss: 1.2612\n",
      "Epoch 4/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 1.0978\n",
      "Epoch 4: val_loss improved from 1.26119 to 1.08604, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.0955 - val_loss: 1.0860\n",
      "Epoch 5/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 1.0195\n",
      "Epoch 5: val_loss did not improve from 1.08604\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 1.0131 - val_loss: 1.2025\n",
      "Epoch 6/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.9660\n",
      "Epoch 6: val_loss did not improve from 1.08604\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.9654 - val_loss: 1.2143\n",
      "Epoch 7/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.9223\n",
      "Epoch 7: val_loss did not improve from 1.08604\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.9230 - val_loss: 1.2459\n",
      "Epoch 8/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.8803\n",
      "Epoch 8: val_loss improved from 1.08604 to 1.01971, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8750 - val_loss: 1.0197\n",
      "Epoch 9/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.8543\n",
      "Epoch 9: val_loss did not improve from 1.01971\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.8564 - val_loss: 1.0370\n",
      "Epoch 10/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.8076\n",
      "Epoch 10: val_loss did not improve from 1.01971\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.8067 - val_loss: 1.0456\n",
      "Epoch 11/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.7977\n",
      "Epoch 11: val_loss did not improve from 1.01971\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.8002 - val_loss: 1.0288\n",
      "Epoch 12/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.7807\n",
      "Epoch 12: val_loss did not improve from 1.01971\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.7769 - val_loss: 1.0445\n",
      "Epoch 13/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.7484\n",
      "Epoch 13: val_loss did not improve from 1.01971\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.7478 - val_loss: 1.0728\n",
      "Epoch 14/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.7427\n",
      "Epoch 14: val_loss improved from 1.01971 to 0.88543, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.7418 - val_loss: 0.8854\n",
      "Epoch 15/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.7208\n",
      "Epoch 15: val_loss did not improve from 0.88543\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.7209 - val_loss: 0.9122\n",
      "Epoch 16/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.6898\n",
      "Epoch 16: val_loss did not improve from 0.88543\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6888 - val_loss: 0.9231\n",
      "Epoch 17/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.6892\n",
      "Epoch 17: val_loss improved from 0.88543 to 0.84730, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.6878 - val_loss: 0.8473\n",
      "Epoch 18/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.6688\n",
      "Epoch 18: val_loss did not improve from 0.84730\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6696 - val_loss: 0.9576\n",
      "Epoch 19/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.6554\n",
      "Epoch 19: val_loss did not improve from 0.84730\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6537 - val_loss: 0.9794\n",
      "Epoch 20/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.6485\n",
      "Epoch 20: val_loss did not improve from 0.84730\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6525 - val_loss: 0.9395\n",
      "Epoch 21/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.6344\n",
      "Epoch 21: val_loss did not improve from 0.84730\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6340 - val_loss: 1.0303\n",
      "Epoch 22/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.6380\n",
      "Epoch 22: val_loss did not improve from 0.84730\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6378 - val_loss: 0.9975\n",
      "Epoch 23/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.6280\n",
      "Epoch 23: val_loss did not improve from 0.84730\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6294 - val_loss: 0.9334\n",
      "Epoch 24/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.6175\n",
      "Epoch 24: val_loss did not improve from 0.84730\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6165 - val_loss: 0.9377\n",
      "Epoch 25/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.5937\n",
      "Epoch 25: val_loss did not improve from 0.84730\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5971 - val_loss: 0.8979\n",
      "Epoch 26/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.5904\n",
      "Epoch 26: val_loss did not improve from 0.84730\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5923 - val_loss: 0.9505\n",
      "Epoch 27/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.5864\n",
      "Epoch 27: val_loss improved from 0.84730 to 0.83491, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.5827 - val_loss: 0.8349\n",
      "Epoch 28/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.5746\n",
      "Epoch 28: val_loss did not improve from 0.83491\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.5710 - val_loss: 0.8631\n",
      "Epoch 29/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.5713\n",
      "Epoch 29: val_loss did not improve from 0.83491\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5671 - val_loss: 0.9528\n",
      "Epoch 30/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.5609\n",
      "Epoch 30: val_loss did not improve from 0.83491\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.5579 - val_loss: 0.9178\n",
      "Epoch 31/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.5517\n",
      "Epoch 31: val_loss did not improve from 0.83491\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5529 - val_loss: 0.8953\n",
      "Epoch 32/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.5519\n",
      "Epoch 32: val_loss did not improve from 0.83491\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5507 - val_loss: 0.9061\n",
      "Epoch 33/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.5341\n",
      "Epoch 33: val_loss improved from 0.83491 to 0.77372, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.5362 - val_loss: 0.7737\n",
      "Epoch 34/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.5450\n",
      "Epoch 34: val_loss did not improve from 0.77372\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.5414 - val_loss: 0.7895\n",
      "Epoch 35/100\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.5416\n",
      "Epoch 35: val_loss did not improve from 0.77372\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.5385 - val_loss: 0.8783\n",
      "Epoch 36/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.5340\n",
      "Epoch 36: val_loss did not improve from 0.77372\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5338 - val_loss: 1.0496\n",
      "Epoch 37/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.5435\n",
      "Epoch 37: val_loss did not improve from 0.77372\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.5371 - val_loss: 0.8413\n",
      "Epoch 38/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.5275\n",
      "Epoch 38: val_loss did not improve from 0.77372\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5246 - val_loss: 0.8804\n",
      "Epoch 39/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.4991\n",
      "Epoch 39: val_loss did not improve from 0.77372\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4986 - val_loss: 0.7781\n",
      "Epoch 40/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.4920\n",
      "Epoch 40: val_loss did not improve from 0.77372\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4933 - val_loss: 0.8265\n",
      "Epoch 41/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.5043\n",
      "Epoch 41: val_loss did not improve from 0.77372\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5043 - val_loss: 0.8906\n",
      "Epoch 42/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.4823\n",
      "Epoch 42: val_loss did not improve from 0.77372\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4789 - val_loss: 0.8437\n",
      "Epoch 43/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.4844\n",
      "Epoch 43: val_loss did not improve from 0.77372\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4911 - val_loss: 0.8696\n",
      "Epoch 44/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4896\n",
      "Epoch 44: val_loss improved from 0.77372 to 0.76789, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4913 - val_loss: 0.7679\n",
      "Epoch 45/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4769\n",
      "Epoch 45: val_loss did not improve from 0.76789\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4752 - val_loss: 0.8104\n",
      "Epoch 46/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4796\n",
      "Epoch 46: val_loss did not improve from 0.76789\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4800 - val_loss: 0.8332\n",
      "Epoch 47/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.4640\n",
      "Epoch 47: val_loss did not improve from 0.76789\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4654 - val_loss: 0.8504\n",
      "Epoch 48/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4562\n",
      "Epoch 48: val_loss did not improve from 0.76789\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4558 - val_loss: 0.8461\n",
      "Epoch 49/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4407\n",
      "Epoch 49: val_loss did not improve from 0.76789\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4435 - val_loss: 1.0035\n",
      "Epoch 50/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4495\n",
      "Epoch 50: val_loss improved from 0.76789 to 0.75899, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.4503 - val_loss: 0.7590\n",
      "Epoch 51/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4501\n",
      "Epoch 51: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4516 - val_loss: 0.8048\n",
      "Epoch 52/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4591\n",
      "Epoch 52: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4563 - val_loss: 0.7804\n",
      "Epoch 53/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4492\n",
      "Epoch 53: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4483 - val_loss: 0.9121\n",
      "Epoch 54/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.4546\n",
      "Epoch 54: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4539 - val_loss: 0.8203\n",
      "Epoch 55/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4358\n",
      "Epoch 55: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4357 - val_loss: 0.8387\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4358\n",
      "Epoch 56: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4358 - val_loss: 0.8327\n",
      "Epoch 57/100\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.4335\n",
      "Epoch 57: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4387 - val_loss: 0.8808\n",
      "Epoch 58/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.4132\n",
      "Epoch 58: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4123 - val_loss: 0.8580\n",
      "Epoch 59/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.4247\n",
      "Epoch 59: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4318 - val_loss: 0.7941\n",
      "Epoch 60/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.4236\n",
      "Epoch 60: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4226 - val_loss: 0.9381\n",
      "Epoch 61/100\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 0.4137\n",
      "Epoch 61: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4123 - val_loss: 0.9885\n",
      "Epoch 62/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.4124\n",
      "Epoch 62: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4142 - val_loss: 0.7940\n",
      "Epoch 63/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.4070\n",
      "Epoch 63: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4062 - val_loss: 0.9384\n",
      "Epoch 64/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.4094\n",
      "Epoch 64: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4072 - val_loss: 0.9333\n",
      "Epoch 65/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3935\n",
      "Epoch 65: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3942 - val_loss: 0.8890\n",
      "Epoch 66/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.4098\n",
      "Epoch 66: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4092 - val_loss: 1.0117\n",
      "Epoch 67/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.4067\n",
      "Epoch 67: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4068 - val_loss: 1.0363\n",
      "Epoch 68/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3913\n",
      "Epoch 68: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3923 - val_loss: 0.9457\n",
      "Epoch 69/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3854\n",
      "Epoch 69: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3880 - val_loss: 0.9684\n",
      "Epoch 70/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3889\n",
      "Epoch 70: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3866 - val_loss: 0.9878\n",
      "Epoch 71/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3855\n",
      "Epoch 71: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3813 - val_loss: 0.9016\n",
      "Epoch 72/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3951\n",
      "Epoch 72: val_loss did not improve from 0.75899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3949 - val_loss: 0.8445\n",
      "Epoch 73/100\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.3842\n",
      "Epoch 73: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3863 - val_loss: 0.8752\n",
      "Epoch 74/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.3868\n",
      "Epoch 74: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3871 - val_loss: 1.1182\n",
      "Epoch 75/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.3702\n",
      "Epoch 75: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3779 - val_loss: 1.0481\n",
      "Epoch 76/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3896\n",
      "Epoch 76: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3899 - val_loss: 1.0467\n",
      "Epoch 77/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3636\n",
      "Epoch 77: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3662 - val_loss: 1.0004\n",
      "Epoch 78/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3706\n",
      "Epoch 78: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3688 - val_loss: 0.9923\n",
      "Epoch 79/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.3686\n",
      "Epoch 79: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3716 - val_loss: 0.9702\n",
      "Epoch 80/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3787\n",
      "Epoch 80: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3771 - val_loss: 0.9466\n",
      "Epoch 81/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3600\n",
      "Epoch 81: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3602 - val_loss: 0.9351\n",
      "Epoch 82/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3680\n",
      "Epoch 82: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3664 - val_loss: 1.0122\n",
      "Epoch 83/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3564\n",
      "Epoch 83: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3562 - val_loss: 0.8673\n",
      "Epoch 84/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3575\n",
      "Epoch 84: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3592 - val_loss: 0.9065\n",
      "Epoch 85/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3550\n",
      "Epoch 85: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3587 - val_loss: 0.9124\n",
      "Epoch 86/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3404\n",
      "Epoch 86: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3402 - val_loss: 1.0607\n",
      "Epoch 87/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.3500\n",
      "Epoch 87: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3513 - val_loss: 0.8576\n",
      "Epoch 88/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3273\n",
      "Epoch 88: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3260 - val_loss: 0.8888\n",
      "Epoch 89/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3456\n",
      "Epoch 89: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3451 - val_loss: 0.8610\n",
      "Epoch 90/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3348\n",
      "Epoch 90: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3337 - val_loss: 0.8686\n",
      "Epoch 91/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3487\n",
      "Epoch 91: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3484 - val_loss: 0.9109\n",
      "Epoch 92/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3523\n",
      "Epoch 92: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3520 - val_loss: 0.8933\n",
      "Epoch 93/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.3454\n",
      "Epoch 93: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3408 - val_loss: 0.9228\n",
      "Epoch 94/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3303\n",
      "Epoch 94: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3299 - val_loss: 1.1211\n",
      "Epoch 95/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3291\n",
      "Epoch 95: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3282 - val_loss: 0.8394\n",
      "Epoch 96/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3311\n",
      "Epoch 96: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3317 - val_loss: 0.9561\n",
      "Epoch 97/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3305\n",
      "Epoch 97: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3339 - val_loss: 0.9612\n",
      "Epoch 98/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.3294\n",
      "Epoch 98: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3309 - val_loss: 0.9487\n",
      "Epoch 99/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.3392\n",
      "Epoch 99: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3354 - val_loss: 1.0344\n",
      "Epoch 100/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.3318\n",
      "Epoch 100: val_loss did not improve from 0.75899\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3324 - val_loss: 1.0044\n"
     ]
    }
   ],
   "source": [
    "model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "current_model_path = os.path.join(modelPath, \"_fullModel.hdf5\")\n",
    "modelCallbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                       monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                       save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "]\n",
    "\n",
    "# adding random shuffling of the dataset for training purpose\n",
    "index_arr = np.arange(train_features.shape[0])\n",
    "index_arr = np.random.permutation(index_arr)\n",
    "\n",
    "model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "          callbacks = modelCallbacks, validation_data = (indpe_features, indpe_labels))\n",
    "# model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "#           callbacks = modelCallbacks, validation_split = 0.2)\n",
    "\n",
    "model = tf.keras.models.load_model(current_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.67102</td>\n",
       "      <td>0.256098</td>\n",
       "      <td>0.666437</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.701566</td>\n",
       "      <td>0.172411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent   0.67102   0.256098  0.666437     0.517241     0.701566  0.172411"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "y_pred = model.predict(indpe_features)\n",
    "label_pred = pred2label(y_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
