{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"NT_Site_PredNTS_Classification_DLNN_CORENup_v2\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "seed = None\n",
    "\n",
    "input_data_folder = \"Data\"\n",
    "training_data_file = \"Training-datasets-PredNTS.txt\"\n",
    "independent_data_file = \"independent dataset-PredNTS.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define all CUSTOM functions\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode_nt(sequence, char_dict):\n",
    "    \n",
    "    seq_encoded = np.zeros((len(sequence),len(char_dict)))\n",
    "    \n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in char_dict.keys()):\n",
    "            seq_encoded[i][char_dict[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in NT sequence: '+sequence)\n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Build k-fold functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "                 conv_filters_per_layer_1 = 10, kernel_length_1 = 10, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "                 max_pool_width_1 = 3, max_pool_stride_1 = 3, ## 1st Maxpool layer parameters\n",
    "                 lstm_decode_units = 25, ## LSTM layer parameters\n",
    "                 conv_filters_per_layer_2 = 10,  kernel_length_2 = 5, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "                 max_pool_width_2 = 3, max_pool_stride_2 = 3, ## 2nd Maxpool layer parameters\n",
    "                 dense_decode_units = 128, ## Dense layer parameters\n",
    "                 prob = 0.5, learn_rate = 0.0005, \n",
    "                 loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  SEQUENCE  ##################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1,\n",
    "                                strides = conv_strides_1, kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = \"same\")(input1)\n",
    "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta))(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    ## Conv Path\n",
    "\n",
    "    x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), padding = 'same')(x1)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "    x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "    \n",
    "    x4 = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  Classifier  ################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    y = tf.keras.layers.Dense(dense_decode_units, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'relu'\n",
    "                             )(x4)\n",
    "    \n",
    "    y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(1, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'sigmoid')(y)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Function to customize the DLNN architecture with parameters\n",
    "# ##################################################################################\n",
    "\n",
    "# def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "#                  conv_filters_per_layer_1 = 10, kernel_length_1 = 10, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "#                  max_pool_width_1 = 3, max_pool_stride_1 = 3, ## 1st Maxpool layer parameters\n",
    "#                  lstm_decode_units = 15, ## LSTM layer parameters\n",
    "#                  conv_filters_per_layer_2 = 10,  kernel_length_2 = 5, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "#                  max_pool_width_2 = 3, max_pool_stride_2 = 3, ## 2nd Maxpool layer parameters\n",
    "#                  dense_decode_units = 32, ## Dense layer parameters\n",
    "#                  prob = 0.5, learn_rate = 0.0005, \n",
    "#                  loss = 'binary_crossentropy', metrics = None):\n",
    "\n",
    "# # def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "# #                  conv_filters_per_layer_1 = 10, kernel_length_1 = 10, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "# #                  max_pool_width_1 = 3, max_pool_stride_1 = 3, ## 1st Maxpool layer parameters\n",
    "# #                  lstm_decode_units = 15, ## LSTM layer parameters\n",
    "# #                  conv_filters_per_layer_2 = 10,  kernel_length_2 = 5, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "# #                  max_pool_width_2 = 3, max_pool_stride_2 = 3, ## 2nd Maxpool layer parameters\n",
    "# #                  dense_decode_units = 128, ## Dense layer parameters\n",
    "# #                  prob = 0.75, learn_rate = 0.0005, \n",
    "# #                  loss = 'binary_crossentropy', metrics = None):\n",
    "\n",
    "#     beta = 0.001\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  SEQUENCE  ##################################################################################\n",
    "#     ######################################################################################################\n",
    "    \n",
    "#     input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "\n",
    "#     x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1,\n",
    "#                                 strides = conv_strides_1, kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "#                                )(input1)\n",
    "#     x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "#     x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "#     x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "#     ## LSTM Path\n",
    "    \n",
    "# #     x2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_decode_units, \n",
    "# #                                                             return_sequences = True, \n",
    "# #                                                             kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "# #                                                            )\n",
    "# #                                       )(x1)\n",
    "\n",
    "#     x2 = tf.keras.layers.GRU(lstm_decode_units, \n",
    "#                              kernel_regularizer = tf.keras.regularizers.l2(beta))(x1)\n",
    "    \n",
    "#     x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "#     x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "#     ## Conv Path\n",
    "\n",
    "#     x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "#                                 kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "#                                )(x1)\n",
    "#     x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "#     x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "#     x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "#     x3 = tf.keras.layers.Flatten()(x3)\n",
    "    \n",
    "#     x4 = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  Classifier  ################################################################################\n",
    "#     ######################################################################################################\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(dense_decode_units, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'relu')(x4)\n",
    "    \n",
    "#     y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(1, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'sigmoid')(y)\n",
    "\n",
    "#     ## Generate Model from input and output\n",
    "#     model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "# #     initial_learning_rate = 0.1\n",
    "# #     decay_steps = 1.0\n",
    "# #     decay_rate = 0.5\n",
    "# #     learning_rate_fn = tf.keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate, decay_steps, decay_rate)\n",
    "\n",
    "#     learning_rate_fn = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate=1e-1,\n",
    "#         decay_steps=10000,\n",
    "#         decay_rate=0.9\n",
    "#     )\n",
    "\n",
    "#     opt = tf.keras.optimizers.SGD(learning_rate=learning_rate_fn)\n",
    "    \n",
    "#     ## Compile model\n",
    "#     if(metrics != None):\n",
    "# #         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss, metrics = metrics)\n",
    "# #         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss = loss, metrics = metrics)\n",
    "#         model.compile(optimizer = opt, loss = loss, metrics = metrics)\n",
    "#     else:\n",
    "# #         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss)\n",
    "#         model.compile(optimizer = opt, loss = loss)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step in range(10):\n",
    "#     initial_learning_rate=1e-1\n",
    "#     decay_steps=10000\n",
    "#     decay_rate=0.9\n",
    "#     print(step, ':', initial_learning_rate * decay_rate ** (step / decay_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 41, 21)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 41, 10)       2110        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 41, 10)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 13, 10)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 13, 10)       0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 13, 10)       510         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 13, 10)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 13, 25)       3600        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 4, 10)       0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 13, 25)       0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 10)        0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 325)          0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 40)           0           ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 365)          0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          46848       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            129         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 53,197\n",
      "Trainable params: 53,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DLNN_CORENup().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read training file\n",
    "##################################################################################\n",
    "train_file_path = os.path.join(input_data_folder, training_data_file)\n",
    "train_data = pd.read_csv(train_file_path, sep='\\t', header=None)\n",
    "train_data.columns = ['Sequence', 'name', 'id', 'flag', 'label_original', 'type']\n",
    "train_data.head()\n",
    "\n",
    "##################################################################################\n",
    "##### Create dictionary of all characters in the NT sequence \n",
    "##################################################################################\n",
    "all_char_set = set({})\n",
    "for val in [set(val) for val in train_data['Sequence']]:\n",
    "    all_char_set = all_char_set.union(val)\n",
    "all_char_list = list(all_char_set)\n",
    "all_char_list.sort()\n",
    "all_char_dict = {}\n",
    "for i in range(len(all_char_list)):\n",
    "    all_char_dict[all_char_list[i]] = i\n",
    "    \n",
    "##################################################################################\n",
    "##### Create OHE of sequence\n",
    "##################################################################################\n",
    "train_data['OHE_Sequence'] = pd.Series([one_hot_encode_nt(val, all_char_dict) \n",
    "                                        for val in train_data[\"Sequence\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Fix the labels\n",
    "##################################################################################\n",
    "train_data['label'] = pd.Series([1 if val == 1 else 0 \n",
    "                                 for val in train_data[\"label_original\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "features = np.array(list(train_data['OHE_Sequence']))\n",
    "labels = np.array(list(train_data['label']))\n",
    "labels = labels.reshape((labels.shape[0], 1))\n",
    "\n",
    "input_seq_shape = features[0].shape\n",
    "\n",
    "folds = build_kfold(features, labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "## Write the k-fold dataset to file\n",
    "foldPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(foldPath)):\n",
    "    os.makedirs(foldPath)\n",
    "pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test model on Fold #0.\n",
      "Epoch 1/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9125\n",
      "Epoch 1: val_loss improved from inf to 0.88334, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 13s 18ms/step - loss: 0.9125 - val_loss: 0.8833\n",
      "Epoch 2/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.8689\n",
      "Epoch 2: val_loss improved from 0.88334 to 0.84539, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.8685 - val_loss: 0.8454\n",
      "Epoch 3/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.8349\n",
      "Epoch 3: val_loss improved from 0.84539 to 0.80098, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.8319 - val_loss: 0.8010\n",
      "Epoch 4/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.7836\n",
      "Epoch 4: val_loss improved from 0.80098 to 0.73637, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.7830 - val_loss: 0.7364\n",
      "Epoch 5/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.7118\n",
      "Epoch 5: val_loss improved from 0.73637 to 0.68929, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.7099 - val_loss: 0.6893\n",
      "Epoch 6/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.6950\n",
      "Epoch 6: val_loss improved from 0.68929 to 0.67367, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.6932 - val_loss: 0.6737\n",
      "Epoch 7/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.6573\n",
      "Epoch 7: val_loss improved from 0.67367 to 0.64799, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.6593 - val_loss: 0.6480\n",
      "Epoch 8/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.6438\n",
      "Epoch 8: val_loss improved from 0.64799 to 0.63144, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 12ms/step - loss: 0.6418 - val_loss: 0.6314\n",
      "Epoch 9/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.6257\n",
      "Epoch 9: val_loss improved from 0.63144 to 0.61601, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.6254 - val_loss: 0.6160\n",
      "Epoch 10/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.6027\n",
      "Epoch 10: val_loss improved from 0.61601 to 0.60410, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.6021 - val_loss: 0.6041\n",
      "Epoch 11/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.6042\n",
      "Epoch 11: val_loss improved from 0.60410 to 0.59468, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.6002 - val_loss: 0.5947\n",
      "Epoch 12/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5889\n",
      "Epoch 12: val_loss improved from 0.59468 to 0.58996, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5878 - val_loss: 0.5900\n",
      "Epoch 13/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5779\n",
      "Epoch 13: val_loss improved from 0.58996 to 0.58129, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5778 - val_loss: 0.5813\n",
      "Epoch 14/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5716\n",
      "Epoch 14: val_loss improved from 0.58129 to 0.57191, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.5712 - val_loss: 0.5719\n",
      "Epoch 15/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5790\n",
      "Epoch 15: val_loss improved from 0.57191 to 0.56534, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5757 - val_loss: 0.5653\n",
      "Epoch 16/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5467\n",
      "Epoch 16: val_loss improved from 0.56534 to 0.55877, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5461 - val_loss: 0.5588\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5433\n",
      "Epoch 17: val_loss improved from 0.55877 to 0.55141, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5433 - val_loss: 0.5514\n",
      "Epoch 18/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5440\n",
      "Epoch 18: val_loss improved from 0.55141 to 0.54739, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5420 - val_loss: 0.5474\n",
      "Epoch 19/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5281\n",
      "Epoch 19: val_loss improved from 0.54739 to 0.54307, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5295 - val_loss: 0.5431\n",
      "Epoch 20/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5187\n",
      "Epoch 20: val_loss improved from 0.54307 to 0.54128, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5210 - val_loss: 0.5413\n",
      "Epoch 21/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5176\n",
      "Epoch 21: val_loss improved from 0.54128 to 0.53341, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5173 - val_loss: 0.5334\n",
      "Epoch 22/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5097\n",
      "Epoch 22: val_loss improved from 0.53341 to 0.52956, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5126 - val_loss: 0.5296\n",
      "Epoch 23/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5242\n",
      "Epoch 23: val_loss improved from 0.52956 to 0.52798, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5276 - val_loss: 0.5280\n",
      "Epoch 24/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.4990\n",
      "Epoch 24: val_loss did not improve from 0.52798\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5005 - val_loss: 0.5286\n",
      "Epoch 25/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.4907\n",
      "Epoch 25: val_loss improved from 0.52798 to 0.52504, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4908 - val_loss: 0.5250\n",
      "Epoch 26/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.4862\n",
      "Epoch 26: val_loss improved from 0.52504 to 0.51608, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4861 - val_loss: 0.5161\n",
      "Epoch 27/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.4862\n",
      "Epoch 27: val_loss improved from 0.51608 to 0.51548, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4850 - val_loss: 0.5155\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4768\n",
      "Epoch 28: val_loss did not improve from 0.51548\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4768 - val_loss: 0.5221\n",
      "Epoch 29/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4579\n",
      "Epoch 29: val_loss did not improve from 0.51548\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4591 - val_loss: 0.5239\n",
      "Epoch 30/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4757\n",
      "Epoch 30: val_loss improved from 0.51548 to 0.50969, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4751 - val_loss: 0.5097\n",
      "Epoch 31/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.4686\n",
      "Epoch 31: val_loss did not improve from 0.50969\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4687 - val_loss: 0.5123\n",
      "Epoch 32/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4419\n",
      "Epoch 32: val_loss did not improve from 0.50969\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4417 - val_loss: 0.5127\n",
      "Epoch 33/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4401\n",
      "Epoch 33: val_loss improved from 0.50969 to 0.49949, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4441 - val_loss: 0.4995\n",
      "Epoch 34/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.4550\n",
      "Epoch 34: val_loss did not improve from 0.49949\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4570 - val_loss: 0.5368\n",
      "Epoch 35/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4468\n",
      "Epoch 35: val_loss did not improve from 0.49949\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4465 - val_loss: 0.5027\n",
      "Epoch 36/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4519\n",
      "Epoch 36: val_loss improved from 0.49949 to 0.49462, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4525 - val_loss: 0.4946\n",
      "Epoch 37/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4422\n",
      "Epoch 37: val_loss improved from 0.49462 to 0.49257, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4411 - val_loss: 0.4926\n",
      "Epoch 38/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4352\n",
      "Epoch 38: val_loss improved from 0.49257 to 0.48885, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4353 - val_loss: 0.4889\n",
      "Epoch 39/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.4265\n",
      "Epoch 39: val_loss improved from 0.48885 to 0.48856, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4287 - val_loss: 0.4886\n",
      "Epoch 40/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4166\n",
      "Epoch 40: val_loss improved from 0.48856 to 0.48799, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4147 - val_loss: 0.4880\n",
      "Epoch 41/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4267\n",
      "Epoch 41: val_loss improved from 0.48799 to 0.48159, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4300 - val_loss: 0.4816\n",
      "Epoch 42/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.4081\n",
      "Epoch 42: val_loss did not improve from 0.48159\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4148 - val_loss: 0.4836\n",
      "Epoch 43/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4020\n",
      "Epoch 43: val_loss did not improve from 0.48159\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4019 - val_loss: 0.4827\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4056\n",
      "Epoch 44: val_loss did not improve from 0.48159\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4056 - val_loss: 0.4902\n",
      "Epoch 45/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4294\n",
      "Epoch 45: val_loss did not improve from 0.48159\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4298 - val_loss: 0.5006\n",
      "Epoch 46/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4128\n",
      "Epoch 46: val_loss improved from 0.48159 to 0.48103, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4128 - val_loss: 0.4810\n",
      "Epoch 47/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4189\n",
      "Epoch 47: val_loss did not improve from 0.48103\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4173 - val_loss: 0.4998\n",
      "Epoch 48/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3869\n",
      "Epoch 48: val_loss did not improve from 0.48103\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3872 - val_loss: 0.4889\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3962\n",
      "Epoch 49: val_loss did not improve from 0.48103\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3962 - val_loss: 0.4841\n",
      "Epoch 50/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3968\n",
      "Epoch 50: val_loss improved from 0.48103 to 0.47547, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3968 - val_loss: 0.4755\n",
      "Epoch 51/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3974\n",
      "Epoch 51: val_loss did not improve from 0.47547\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3957 - val_loss: 0.4799\n",
      "Epoch 52/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3850\n",
      "Epoch 52: val_loss did not improve from 0.47547\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3842 - val_loss: 0.4869\n",
      "Epoch 53/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3839\n",
      "Epoch 53: val_loss did not improve from 0.47547\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3804 - val_loss: 0.4888\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3823\n",
      "Epoch 54: val_loss did not improve from 0.47547\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3823 - val_loss: 0.4797\n",
      "Epoch 55/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3866\n",
      "Epoch 55: val_loss did not improve from 0.47547\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3876 - val_loss: 0.4832\n",
      "Epoch 56/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3899\n",
      "Epoch 56: val_loss did not improve from 0.47547\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3879 - val_loss: 0.4909\n",
      "Epoch 57/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3743\n",
      "Epoch 57: val_loss did not improve from 0.47547\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3729 - val_loss: 0.4899\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3768\n",
      "Epoch 58: val_loss improved from 0.47547 to 0.46941, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3768 - val_loss: 0.4694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3806\n",
      "Epoch 59: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3806 - val_loss: 0.4736\n",
      "Epoch 60/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3624\n",
      "Epoch 60: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3622 - val_loss: 0.4777\n",
      "Epoch 61/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3691\n",
      "Epoch 61: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3686 - val_loss: 0.4784\n",
      "Epoch 62/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3613\n",
      "Epoch 62: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3639 - val_loss: 0.4815\n",
      "Epoch 63/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3514\n",
      "Epoch 63: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3504 - val_loss: 0.4709\n",
      "Epoch 64/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3553\n",
      "Epoch 64: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3549 - val_loss: 0.4830\n",
      "Epoch 65/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3513\n",
      "Epoch 65: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3518 - val_loss: 0.4889\n",
      "Epoch 66/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3497\n",
      "Epoch 66: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3485 - val_loss: 0.4794\n",
      "Epoch 67/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3343\n",
      "Epoch 67: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3396 - val_loss: 0.4947\n",
      "Epoch 68/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.3297\n",
      "Epoch 68: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3309 - val_loss: 0.4908\n",
      "Epoch 69/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3519\n",
      "Epoch 69: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3517 - val_loss: 0.4838\n",
      "Epoch 70/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3392\n",
      "Epoch 70: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3394 - val_loss: 0.4831\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3504\n",
      "Epoch 71: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3504 - val_loss: 0.4774\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3558\n",
      "Epoch 72: val_loss did not improve from 0.46941\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3558 - val_loss: 0.4718\n",
      "Epoch 73/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3405\n",
      "Epoch 73: val_loss improved from 0.46941 to 0.46420, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold0.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3397 - val_loss: 0.4642\n",
      "Epoch 74/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3420\n",
      "Epoch 74: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3368 - val_loss: 0.4668\n",
      "Epoch 75/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3300\n",
      "Epoch 75: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3309 - val_loss: 0.4652\n",
      "Epoch 76/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3274\n",
      "Epoch 76: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3286 - val_loss: 0.4744\n",
      "Epoch 77/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3349\n",
      "Epoch 77: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3345 - val_loss: 0.4663\n",
      "Epoch 78/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3417\n",
      "Epoch 78: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3407 - val_loss: 0.4777\n",
      "Epoch 79/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3280\n",
      "Epoch 79: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3308 - val_loss: 0.4731\n",
      "Epoch 80/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3398\n",
      "Epoch 80: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3366 - val_loss: 0.4719\n",
      "Epoch 81/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.3083\n",
      "Epoch 81: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3024 - val_loss: 0.4987\n",
      "Epoch 82/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3375\n",
      "Epoch 82: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3346 - val_loss: 0.4837\n",
      "Epoch 83/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3221\n",
      "Epoch 83: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3200 - val_loss: 0.4978\n",
      "Epoch 84/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3387\n",
      "Epoch 84: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3363 - val_loss: 0.4869\n",
      "Epoch 85/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.2971\n",
      "Epoch 85: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3000 - val_loss: 0.4918\n",
      "Epoch 86/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3288\n",
      "Epoch 86: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3252 - val_loss: 0.4837\n",
      "Epoch 87/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3269\n",
      "Epoch 87: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3251 - val_loss: 0.4728\n",
      "Epoch 88/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3124\n",
      "Epoch 88: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3120 - val_loss: 0.5181\n",
      "Epoch 89/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3167\n",
      "Epoch 89: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3173 - val_loss: 0.4886\n",
      "Epoch 90/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3158\n",
      "Epoch 90: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3131 - val_loss: 0.4844\n",
      "Epoch 91/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3250\n",
      "Epoch 91: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3214 - val_loss: 0.4919\n",
      "Epoch 92/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3085\n",
      "Epoch 92: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3147 - val_loss: 0.4990\n",
      "Epoch 93/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3158\n",
      "Epoch 93: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3163 - val_loss: 0.4808\n",
      "Epoch 94/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3041\n",
      "Epoch 94: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3027 - val_loss: 0.4833\n",
      "Epoch 95/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3139\n",
      "Epoch 95: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3117 - val_loss: 0.4840\n",
      "Epoch 96/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3073\n",
      "Epoch 96: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3033 - val_loss: 0.4913\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3055\n",
      "Epoch 97: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3024 - val_loss: 0.4850\n",
      "Epoch 98/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.2990\n",
      "Epoch 98: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.2950 - val_loss: 0.4825\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3214\n",
      "Epoch 99: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3214 - val_loss: 0.5142\n",
      "Epoch 100/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3099\n",
      "Epoch 100: val_loss did not improve from 0.46420\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3051 - val_loss: 0.5012\n",
      "\n",
      "Train/Test model on Fold #1.\n",
      "Epoch 1/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.9221\n",
      "Epoch 1: val_loss improved from inf to 0.89171, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 2s 16ms/step - loss: 0.9208 - val_loss: 0.8917\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8790\n",
      "Epoch 2: val_loss improved from 0.89171 to 0.86348, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.8790 - val_loss: 0.8635\n",
      "Epoch 3/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.8560\n",
      "Epoch 3: val_loss improved from 0.86348 to 0.83580, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.8548 - val_loss: 0.8358\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8254\n",
      "Epoch 4: val_loss improved from 0.83580 to 0.79885, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.8254 - val_loss: 0.7988\n",
      "Epoch 5/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.7888\n",
      "Epoch 5: val_loss improved from 0.79885 to 0.73475, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.7899 - val_loss: 0.7348\n",
      "Epoch 6/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.7302\n",
      "Epoch 6: val_loss improved from 0.73475 to 0.67231, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.7284 - val_loss: 0.6723\n",
      "Epoch 7/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.6975\n",
      "Epoch 7: val_loss improved from 0.67231 to 0.64109, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6969 - val_loss: 0.6411\n",
      "Epoch 8/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.6726\n",
      "Epoch 8: val_loss improved from 0.64109 to 0.61772, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6717 - val_loss: 0.6177\n",
      "Epoch 9/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.6417\n",
      "Epoch 9: val_loss improved from 0.61772 to 0.60374, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6464 - val_loss: 0.6037\n",
      "Epoch 10/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.6393\n",
      "Epoch 10: val_loss improved from 0.60374 to 0.59814, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6365 - val_loss: 0.5981\n",
      "Epoch 11/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.6107\n",
      "Epoch 11: val_loss improved from 0.59814 to 0.58130, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6107 - val_loss: 0.5813\n",
      "Epoch 12/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.6003\n",
      "Epoch 12: val_loss improved from 0.58130 to 0.56994, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6041 - val_loss: 0.5699\n",
      "Epoch 13/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5870\n",
      "Epoch 13: val_loss improved from 0.56994 to 0.56311, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5860 - val_loss: 0.5631\n",
      "Epoch 14/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5867\n",
      "Epoch 14: val_loss improved from 0.56311 to 0.56045, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5902 - val_loss: 0.5605\n",
      "Epoch 15/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5684\n",
      "Epoch 15: val_loss improved from 0.56045 to 0.55593, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5705 - val_loss: 0.5559\n",
      "Epoch 16/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5608\n",
      "Epoch 16: val_loss improved from 0.55593 to 0.54455, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5593 - val_loss: 0.5445\n",
      "Epoch 17/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5527\n",
      "Epoch 17: val_loss improved from 0.54455 to 0.54235, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5556 - val_loss: 0.5423\n",
      "Epoch 18/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.5493\n",
      "Epoch 18: val_loss improved from 0.54235 to 0.53393, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5400 - val_loss: 0.5339\n",
      "Epoch 19/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5375\n",
      "Epoch 19: val_loss improved from 0.53393 to 0.53311, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.5357 - val_loss: 0.5331\n",
      "Epoch 20/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5345\n",
      "Epoch 20: val_loss improved from 0.53311 to 0.53028, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5319 - val_loss: 0.5303\n",
      "Epoch 21/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5149\n",
      "Epoch 21: val_loss improved from 0.53028 to 0.52783, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5149 - val_loss: 0.5278\n",
      "Epoch 22/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5157\n",
      "Epoch 22: val_loss did not improve from 0.52783\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.5162 - val_loss: 0.5294\n",
      "Epoch 23/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5111\n",
      "Epoch 23: val_loss did not improve from 0.52783\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.5118 - val_loss: 0.5295\n",
      "Epoch 24/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5006\n",
      "Epoch 24: val_loss improved from 0.52783 to 0.52213, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5014 - val_loss: 0.5221\n",
      "Epoch 25/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4914\n",
      "Epoch 25: val_loss improved from 0.52213 to 0.51631, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4892 - val_loss: 0.5163\n",
      "Epoch 26/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4755\n",
      "Epoch 26: val_loss improved from 0.51631 to 0.51487, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4763 - val_loss: 0.5149\n",
      "Epoch 27/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.4830\n",
      "Epoch 27: val_loss improved from 0.51487 to 0.51307, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4870 - val_loss: 0.5131\n",
      "Epoch 28/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4821\n",
      "Epoch 28: val_loss did not improve from 0.51307\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4821 - val_loss: 0.5253\n",
      "Epoch 29/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4786\n",
      "Epoch 29: val_loss improved from 0.51307 to 0.51084, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4778 - val_loss: 0.5108\n",
      "Epoch 30/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4710\n",
      "Epoch 30: val_loss improved from 0.51084 to 0.50714, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4705 - val_loss: 0.5071\n",
      "Epoch 31/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4556\n",
      "Epoch 31: val_loss improved from 0.50714 to 0.50543, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4568 - val_loss: 0.5054\n",
      "Epoch 32/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4619\n",
      "Epoch 32: val_loss did not improve from 0.50543\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4622 - val_loss: 0.5089\n",
      "Epoch 33/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4409\n",
      "Epoch 33: val_loss improved from 0.50543 to 0.49839, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4426 - val_loss: 0.4984\n",
      "Epoch 34/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4460\n",
      "Epoch 34: val_loss did not improve from 0.49839\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4473 - val_loss: 0.5390\n",
      "Epoch 35/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.4550\n",
      "Epoch 35: val_loss did not improve from 0.49839\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4479 - val_loss: 0.5044\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4419\n",
      "Epoch 36: val_loss did not improve from 0.49839\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4419 - val_loss: 0.5153\n",
      "Epoch 37/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4266\n",
      "Epoch 37: val_loss did not improve from 0.49839\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4261 - val_loss: 0.5079\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4120\n",
      "Epoch 38: val_loss did not improve from 0.49839\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4120 - val_loss: 0.5131\n",
      "Epoch 39/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4233\n",
      "Epoch 39: val_loss improved from 0.49839 to 0.49666, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4183 - val_loss: 0.4967\n",
      "Epoch 40/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4174\n",
      "Epoch 40: val_loss did not improve from 0.49666\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4168 - val_loss: 0.5020\n",
      "Epoch 41/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4226\n",
      "Epoch 41: val_loss improved from 0.49666 to 0.49423, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4214 - val_loss: 0.4942\n",
      "Epoch 42/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4202\n",
      "Epoch 42: val_loss improved from 0.49423 to 0.49365, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4194 - val_loss: 0.4936\n",
      "Epoch 43/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4041\n",
      "Epoch 43: val_loss did not improve from 0.49365\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4062 - val_loss: 0.4958\n",
      "Epoch 44/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4173\n",
      "Epoch 44: val_loss did not improve from 0.49365\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4157 - val_loss: 0.4942\n",
      "Epoch 45/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3963\n",
      "Epoch 45: val_loss did not improve from 0.49365\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3931 - val_loss: 0.4969\n",
      "Epoch 46/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4103\n",
      "Epoch 46: val_loss improved from 0.49365 to 0.49311, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4109 - val_loss: 0.4931\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4010\n",
      "Epoch 47: val_loss did not improve from 0.49311\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4010 - val_loss: 0.4999\n",
      "Epoch 48/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3871\n",
      "Epoch 48: val_loss improved from 0.49311 to 0.49226, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold1.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3859 - val_loss: 0.4923\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3770\n",
      "Epoch 49: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3770 - val_loss: 0.4945\n",
      "Epoch 50/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3868\n",
      "Epoch 50: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3887 - val_loss: 0.5010\n",
      "Epoch 51/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3843\n",
      "Epoch 51: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3877 - val_loss: 0.4949\n",
      "Epoch 52/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3855\n",
      "Epoch 52: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3845 - val_loss: 0.4951\n",
      "Epoch 53/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3826\n",
      "Epoch 53: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3781 - val_loss: 0.4999\n",
      "Epoch 54/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3749\n",
      "Epoch 54: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3729 - val_loss: 0.4946\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3776\n",
      "Epoch 55: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3776 - val_loss: 0.4961\n",
      "Epoch 56/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3746\n",
      "Epoch 56: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3750 - val_loss: 0.5042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3776\n",
      "Epoch 57: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3779 - val_loss: 0.4976\n",
      "Epoch 58/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3590\n",
      "Epoch 58: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3678 - val_loss: 0.5002\n",
      "Epoch 59/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3523\n",
      "Epoch 59: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3542 - val_loss: 0.5086\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3549\n",
      "Epoch 60: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3549 - val_loss: 0.5014\n",
      "Epoch 61/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3474\n",
      "Epoch 61: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3444 - val_loss: 0.5078\n",
      "Epoch 62/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3681\n",
      "Epoch 62: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3689 - val_loss: 0.5164\n",
      "Epoch 63/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3642\n",
      "Epoch 63: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3611 - val_loss: 0.5017\n",
      "Epoch 64/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3464\n",
      "Epoch 64: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3486 - val_loss: 0.5241\n",
      "Epoch 65/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3528\n",
      "Epoch 65: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3527 - val_loss: 0.5291\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3444\n",
      "Epoch 66: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3444 - val_loss: 0.5094\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3350\n",
      "Epoch 67: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3350 - val_loss: 0.5123\n",
      "Epoch 68/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3337\n",
      "Epoch 68: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3323 - val_loss: 0.5300\n",
      "Epoch 69/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3359\n",
      "Epoch 69: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3336 - val_loss: 0.5172\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3157\n",
      "Epoch 70: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3157 - val_loss: 0.5305\n",
      "Epoch 71/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3292\n",
      "Epoch 71: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3278 - val_loss: 0.5158\n",
      "Epoch 72/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3323\n",
      "Epoch 72: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3334 - val_loss: 0.5294\n",
      "Epoch 73/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3442\n",
      "Epoch 73: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3425 - val_loss: 0.5306\n",
      "Epoch 74/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3346\n",
      "Epoch 74: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3362 - val_loss: 0.5151\n",
      "Epoch 75/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3381\n",
      "Epoch 75: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3369 - val_loss: 0.5120\n",
      "Epoch 76/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3351\n",
      "Epoch 76: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3330 - val_loss: 0.5125\n",
      "Epoch 77/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3211\n",
      "Epoch 77: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3201 - val_loss: 0.5121\n",
      "Epoch 78/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3310\n",
      "Epoch 78: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3302 - val_loss: 0.4976\n",
      "Epoch 79/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3202\n",
      "Epoch 79: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3211 - val_loss: 0.5054\n",
      "Epoch 80/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3159\n",
      "Epoch 80: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3186 - val_loss: 0.5109\n",
      "Epoch 81/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3154\n",
      "Epoch 81: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3125 - val_loss: 0.5135\n",
      "Epoch 82/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3200\n",
      "Epoch 82: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3165 - val_loss: 0.5277\n",
      "Epoch 83/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3324\n",
      "Epoch 83: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3323 - val_loss: 0.5272\n",
      "Epoch 84/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.3257\n",
      "Epoch 84: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3245 - val_loss: 0.5433\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3120\n",
      "Epoch 85: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3120 - val_loss: 0.5189\n",
      "Epoch 86/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3040\n",
      "Epoch 86: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3085 - val_loss: 0.5269\n",
      "Epoch 87/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3097\n",
      "Epoch 87: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3059 - val_loss: 0.5287\n",
      "Epoch 88/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3119\n",
      "Epoch 88: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3099 - val_loss: 0.5260\n",
      "Epoch 89/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3066\n",
      "Epoch 89: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3143 - val_loss: 0.5104\n",
      "Epoch 90/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2955\n",
      "Epoch 90: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2961 - val_loss: 0.5291\n",
      "Epoch 91/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3020\n",
      "Epoch 91: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3033 - val_loss: 0.5230\n",
      "Epoch 92/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3210\n",
      "Epoch 92: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3185 - val_loss: 0.5118\n",
      "Epoch 93/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3057\n",
      "Epoch 93: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3087 - val_loss: 0.5211\n",
      "Epoch 94/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.2870\n",
      "Epoch 94: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2849 - val_loss: 0.5533\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3082\n",
      "Epoch 95: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3082 - val_loss: 0.4948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3116\n",
      "Epoch 96: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3101 - val_loss: 0.5199\n",
      "Epoch 97/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3126\n",
      "Epoch 97: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3110 - val_loss: 0.5172\n",
      "Epoch 98/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.2954\n",
      "Epoch 98: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2979 - val_loss: 0.5520\n",
      "Epoch 99/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3006\n",
      "Epoch 99: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3015 - val_loss: 0.5341\n",
      "Epoch 100/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3110\n",
      "Epoch 100: val_loss did not improve from 0.49226\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3117 - val_loss: 0.5144\n",
      "\n",
      "Train/Test model on Fold #2.\n",
      "Epoch 1/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9145\n",
      "Epoch 1: val_loss improved from inf to 0.88763, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 3s 20ms/step - loss: 0.9145 - val_loss: 0.8876\n",
      "Epoch 2/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.8785\n",
      "Epoch 2: val_loss improved from 0.88763 to 0.85467, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.8771 - val_loss: 0.8547\n",
      "Epoch 3/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.8494\n",
      "Epoch 3: val_loss improved from 0.85467 to 0.82383, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.8486 - val_loss: 0.8238\n",
      "Epoch 4/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.7998\n",
      "Epoch 4: val_loss improved from 0.82383 to 0.75217, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.7987 - val_loss: 0.7522\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7429\n",
      "Epoch 5: val_loss improved from 0.75217 to 0.70968, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.7429 - val_loss: 0.7097\n",
      "Epoch 6/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.6852\n",
      "Epoch 6: val_loss improved from 0.70968 to 0.65891, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6860 - val_loss: 0.6589\n",
      "Epoch 7/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.6706\n",
      "Epoch 7: val_loss improved from 0.65891 to 0.64909, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.6679 - val_loss: 0.6491\n",
      "Epoch 8/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.6426\n",
      "Epoch 8: val_loss improved from 0.64909 to 0.62592, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6443 - val_loss: 0.6259\n",
      "Epoch 9/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.6192\n",
      "Epoch 9: val_loss improved from 0.62592 to 0.61931, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6196 - val_loss: 0.6193\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6123\n",
      "Epoch 10: val_loss improved from 0.61931 to 0.60570, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6123 - val_loss: 0.6057\n",
      "Epoch 11/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5932\n",
      "Epoch 11: val_loss improved from 0.60570 to 0.59521, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5927 - val_loss: 0.5952\n",
      "Epoch 12/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5668\n",
      "Epoch 12: val_loss improved from 0.59521 to 0.59352, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5696 - val_loss: 0.5935\n",
      "Epoch 13/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5623\n",
      "Epoch 13: val_loss improved from 0.59352 to 0.58260, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5633 - val_loss: 0.5826\n",
      "Epoch 14/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5602\n",
      "Epoch 14: val_loss improved from 0.58260 to 0.57750, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5619 - val_loss: 0.5775\n",
      "Epoch 15/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5422\n",
      "Epoch 15: val_loss improved from 0.57750 to 0.57437, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5409 - val_loss: 0.5744\n",
      "Epoch 16/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5394\n",
      "Epoch 16: val_loss improved from 0.57437 to 0.57096, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5394 - val_loss: 0.5710\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5262\n",
      "Epoch 17: val_loss did not improve from 0.57096\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5262 - val_loss: 0.5784\n",
      "Epoch 18/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.5251\n",
      "Epoch 18: val_loss improved from 0.57096 to 0.56751, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5348 - val_loss: 0.5675\n",
      "Epoch 19/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5169\n",
      "Epoch 19: val_loss improved from 0.56751 to 0.55859, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5148 - val_loss: 0.5586\n",
      "Epoch 20/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5012\n",
      "Epoch 20: val_loss improved from 0.55859 to 0.55844, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5042 - val_loss: 0.5584\n",
      "Epoch 21/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5120\n",
      "Epoch 21: val_loss improved from 0.55844 to 0.54884, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5111 - val_loss: 0.5488\n",
      "Epoch 22/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4906\n",
      "Epoch 22: val_loss did not improve from 0.54884\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4942 - val_loss: 0.5505\n",
      "Epoch 23/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4937\n",
      "Epoch 23: val_loss did not improve from 0.54884\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4948 - val_loss: 0.5517\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4844\n",
      "Epoch 24: val_loss improved from 0.54884 to 0.54075, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4850 - val_loss: 0.5408\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4679\n",
      "Epoch 25: val_loss did not improve from 0.54075\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4679 - val_loss: 0.5415\n",
      "Epoch 26/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.4698\n",
      "Epoch 26: val_loss improved from 0.54075 to 0.53755, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4719 - val_loss: 0.5375\n",
      "Epoch 27/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4544\n",
      "Epoch 27: val_loss improved from 0.53755 to 0.53108, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4531 - val_loss: 0.5311\n",
      "Epoch 28/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4555\n",
      "Epoch 28: val_loss did not improve from 0.53108\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4551 - val_loss: 0.5365\n",
      "Epoch 29/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4349\n",
      "Epoch 29: val_loss improved from 0.53108 to 0.52716, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4380 - val_loss: 0.5272\n",
      "Epoch 30/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.4356\n",
      "Epoch 30: val_loss did not improve from 0.52716\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4405 - val_loss: 0.5280\n",
      "Epoch 31/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4504\n",
      "Epoch 31: val_loss improved from 0.52716 to 0.52362, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4524 - val_loss: 0.5236\n",
      "Epoch 32/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.4289\n",
      "Epoch 32: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4373 - val_loss: 0.5266\n",
      "Epoch 33/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.4354\n",
      "Epoch 33: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4329 - val_loss: 0.5263\n",
      "Epoch 34/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4200\n",
      "Epoch 34: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4258 - val_loss: 0.5255\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4130\n",
      "Epoch 35: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4130 - val_loss: 0.5284\n",
      "Epoch 36/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4120\n",
      "Epoch 36: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4117 - val_loss: 0.5310\n",
      "Epoch 37/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4163\n",
      "Epoch 37: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4149 - val_loss: 0.5322\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4096\n",
      "Epoch 38: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4096 - val_loss: 0.5264\n",
      "Epoch 39/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3962\n",
      "Epoch 39: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3938 - val_loss: 0.5506\n",
      "Epoch 40/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3995\n",
      "Epoch 40: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3973 - val_loss: 0.5265\n",
      "Epoch 41/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3878\n",
      "Epoch 41: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3860 - val_loss: 0.5400\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3702\n",
      "Epoch 42: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3702 - val_loss: 0.5322\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3813\n",
      "Epoch 43: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3813 - val_loss: 0.5281\n",
      "Epoch 44/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3743\n",
      "Epoch 44: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3748 - val_loss: 0.5388\n",
      "Epoch 45/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3751\n",
      "Epoch 45: val_loss did not improve from 0.52362\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3740 - val_loss: 0.5264\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3869\n",
      "Epoch 46: val_loss improved from 0.52362 to 0.52147, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3869 - val_loss: 0.5215\n",
      "Epoch 47/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3776\n",
      "Epoch 47: val_loss improved from 0.52147 to 0.51488, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3788 - val_loss: 0.5149\n",
      "Epoch 48/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3792\n",
      "Epoch 48: val_loss did not improve from 0.51488\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3780 - val_loss: 0.5161\n",
      "Epoch 49/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3761\n",
      "Epoch 49: val_loss did not improve from 0.51488\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3778 - val_loss: 0.5244\n",
      "Epoch 50/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3585\n",
      "Epoch 50: val_loss did not improve from 0.51488\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3573 - val_loss: 0.5295\n",
      "Epoch 51/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3539\n",
      "Epoch 51: val_loss did not improve from 0.51488\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3536 - val_loss: 0.5219\n",
      "Epoch 52/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3528\n",
      "Epoch 52: val_loss did not improve from 0.51488\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3509 - val_loss: 0.5382\n",
      "Epoch 53/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3405\n",
      "Epoch 53: val_loss did not improve from 0.51488\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3401 - val_loss: 0.5164\n",
      "Epoch 54/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3581\n",
      "Epoch 54: val_loss did not improve from 0.51488\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3578 - val_loss: 0.5233\n",
      "Epoch 55/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3547\n",
      "Epoch 55: val_loss did not improve from 0.51488\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3577 - val_loss: 0.5241\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3575\n",
      "Epoch 56: val_loss improved from 0.51488 to 0.51008, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold2.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3575 - val_loss: 0.5101\n",
      "Epoch 57/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3428\n",
      "Epoch 57: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3409 - val_loss: 0.5365\n",
      "Epoch 58/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3530\n",
      "Epoch 58: val_loss did not improve from 0.51008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3499 - val_loss: 0.5124\n",
      "Epoch 59/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3230\n",
      "Epoch 59: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3227 - val_loss: 0.5258\n",
      "Epoch 60/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3313\n",
      "Epoch 60: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3362 - val_loss: 0.5139\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3323\n",
      "Epoch 61: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3323 - val_loss: 0.5311\n",
      "Epoch 62/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3258\n",
      "Epoch 62: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3277 - val_loss: 0.5161\n",
      "Epoch 63/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3356\n",
      "Epoch 63: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3336 - val_loss: 0.5266\n",
      "Epoch 64/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3581\n",
      "Epoch 64: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3579 - val_loss: 0.5107\n",
      "Epoch 65/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3242\n",
      "Epoch 65: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3241 - val_loss: 0.5252\n",
      "Epoch 66/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3229\n",
      "Epoch 66: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3213 - val_loss: 0.5105\n",
      "Epoch 67/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3412\n",
      "Epoch 67: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3432 - val_loss: 0.5109\n",
      "Epoch 68/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.3168\n",
      "Epoch 68: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3204 - val_loss: 0.5407\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3098\n",
      "Epoch 69: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3098 - val_loss: 0.5202\n",
      "Epoch 70/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.3298\n",
      "Epoch 70: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3333 - val_loss: 0.5232\n",
      "Epoch 71/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3101\n",
      "Epoch 71: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3104 - val_loss: 0.5200\n",
      "Epoch 72/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3358\n",
      "Epoch 72: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3316 - val_loss: 0.5264\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3307\n",
      "Epoch 73: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3307 - val_loss: 0.5132\n",
      "Epoch 74/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3248\n",
      "Epoch 74: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3288 - val_loss: 0.5192\n",
      "Epoch 75/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3282\n",
      "Epoch 75: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3274 - val_loss: 0.5139\n",
      "Epoch 76/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3165\n",
      "Epoch 76: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3149 - val_loss: 0.5252\n",
      "Epoch 77/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3048\n",
      "Epoch 77: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3016 - val_loss: 0.5362\n",
      "Epoch 78/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3043\n",
      "Epoch 78: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3111 - val_loss: 0.5251\n",
      "Epoch 79/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3187\n",
      "Epoch 79: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3181 - val_loss: 0.5193\n",
      "Epoch 80/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3221\n",
      "Epoch 80: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3200 - val_loss: 0.5255\n",
      "Epoch 81/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3166\n",
      "Epoch 81: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3142 - val_loss: 0.5193\n",
      "Epoch 82/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.2990\n",
      "Epoch 82: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.2980 - val_loss: 0.5226\n",
      "Epoch 83/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3076\n",
      "Epoch 83: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3069 - val_loss: 0.5148\n",
      "Epoch 84/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.2967\n",
      "Epoch 84: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.2951 - val_loss: 0.5248\n",
      "Epoch 85/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2944\n",
      "Epoch 85: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.2948 - val_loss: 0.5448\n",
      "Epoch 86/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3049\n",
      "Epoch 86: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3044 - val_loss: 0.5373\n",
      "Epoch 87/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3056\n",
      "Epoch 87: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3057 - val_loss: 0.5267\n",
      "Epoch 88/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3061\n",
      "Epoch 88: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3066 - val_loss: 0.5144\n",
      "Epoch 89/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.2907\n",
      "Epoch 89: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2906 - val_loss: 0.5305\n",
      "Epoch 90/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2872\n",
      "Epoch 90: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2858 - val_loss: 0.5407\n",
      "Epoch 91/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3102\n",
      "Epoch 91: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3089 - val_loss: 0.5283\n",
      "Epoch 92/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.2979\n",
      "Epoch 92: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2995 - val_loss: 0.5554\n",
      "Epoch 93/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.2918\n",
      "Epoch 93: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2946 - val_loss: 0.5237\n",
      "Epoch 94/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.2886\n",
      "Epoch 94: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2884 - val_loss: 0.5456\n",
      "Epoch 95/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3333\n",
      "Epoch 95: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3310 - val_loss: 0.5302\n",
      "Epoch 96/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.2873\n",
      "Epoch 96: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2839 - val_loss: 0.5374\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.2915\n",
      "Epoch 97: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2915 - val_loss: 0.5488\n",
      "Epoch 98/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2933\n",
      "Epoch 98: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2929 - val_loss: 0.5379\n",
      "Epoch 99/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2893\n",
      "Epoch 99: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2877 - val_loss: 0.5684\n",
      "Epoch 100/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2868\n",
      "Epoch 100: val_loss did not improve from 0.51008\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2867 - val_loss: 0.5240\n",
      "\n",
      "Train/Test model on Fold #3.\n",
      "Epoch 1/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.9179\n",
      "Epoch 1: val_loss improved from inf to 0.88299, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 3s 16ms/step - loss: 0.9175 - val_loss: 0.8830\n",
      "Epoch 2/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.8723\n",
      "Epoch 2: val_loss improved from 0.88299 to 0.84997, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.8715 - val_loss: 0.8500\n",
      "Epoch 3/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.8387\n",
      "Epoch 3: val_loss improved from 0.84997 to 0.80650, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.8364 - val_loss: 0.8065\n",
      "Epoch 4/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.7824\n",
      "Epoch 4: val_loss improved from 0.80650 to 0.72810, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.7810 - val_loss: 0.7281\n",
      "Epoch 5/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.7323\n",
      "Epoch 5: val_loss improved from 0.72810 to 0.69444, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.7335 - val_loss: 0.6944\n",
      "Epoch 6/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.6994\n",
      "Epoch 6: val_loss improved from 0.69444 to 0.66043, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.6987 - val_loss: 0.6604\n",
      "Epoch 7/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.6713\n",
      "Epoch 7: val_loss improved from 0.66043 to 0.63990, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6714 - val_loss: 0.6399\n",
      "Epoch 8/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.6546\n",
      "Epoch 8: val_loss improved from 0.63990 to 0.63297, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6552 - val_loss: 0.6330\n",
      "Epoch 9/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.6309\n",
      "Epoch 9: val_loss improved from 0.63297 to 0.61561, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6306 - val_loss: 0.6156\n",
      "Epoch 10/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.6297\n",
      "Epoch 10: val_loss did not improve from 0.61561\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6267 - val_loss: 0.6159\n",
      "Epoch 11/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.6081\n",
      "Epoch 11: val_loss improved from 0.61561 to 0.60023, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.6034 - val_loss: 0.6002\n",
      "Epoch 12/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.5786\n",
      "Epoch 12: val_loss improved from 0.60023 to 0.59074, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5880 - val_loss: 0.5907\n",
      "Epoch 13/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5833\n",
      "Epoch 13: val_loss improved from 0.59074 to 0.58662, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5827 - val_loss: 0.5866\n",
      "Epoch 14/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5735\n",
      "Epoch 14: val_loss improved from 0.58662 to 0.58509, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5772 - val_loss: 0.5851\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5613\n",
      "Epoch 15: val_loss improved from 0.58509 to 0.57358, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5613 - val_loss: 0.5736\n",
      "Epoch 16/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5482\n",
      "Epoch 16: val_loss improved from 0.57358 to 0.57106, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5471 - val_loss: 0.5711\n",
      "Epoch 17/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5482\n",
      "Epoch 17: val_loss improved from 0.57106 to 0.56815, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5480 - val_loss: 0.5681\n",
      "Epoch 18/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5363\n",
      "Epoch 18: val_loss improved from 0.56815 to 0.56778, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.5368 - val_loss: 0.5678\n",
      "Epoch 19/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5383\n",
      "Epoch 19: val_loss improved from 0.56778 to 0.56379, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.5371 - val_loss: 0.5638\n",
      "Epoch 20/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5287\n",
      "Epoch 20: val_loss improved from 0.56379 to 0.55898, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5293 - val_loss: 0.5590\n",
      "Epoch 21/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5123\n",
      "Epoch 21: val_loss did not improve from 0.55898\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.5132 - val_loss: 0.5593\n",
      "Epoch 22/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5043\n",
      "Epoch 22: val_loss improved from 0.55898 to 0.55427, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4992 - val_loss: 0.5543\n",
      "Epoch 23/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5159\n",
      "Epoch 23: val_loss improved from 0.55427 to 0.55142, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5118 - val_loss: 0.5514\n",
      "Epoch 24/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.4916\n",
      "Epoch 24: val_loss improved from 0.55142 to 0.54828, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4907 - val_loss: 0.5483\n",
      "Epoch 25/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4889\n",
      "Epoch 25: val_loss improved from 0.54828 to 0.54756, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4892 - val_loss: 0.5476\n",
      "Epoch 26/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.4878\n",
      "Epoch 26: val_loss improved from 0.54756 to 0.54516, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4886 - val_loss: 0.5452\n",
      "Epoch 27/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4871\n",
      "Epoch 27: val_loss improved from 0.54516 to 0.54045, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4834 - val_loss: 0.5405\n",
      "Epoch 28/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4794\n",
      "Epoch 28: val_loss improved from 0.54045 to 0.53550, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4788 - val_loss: 0.5355\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4754\n",
      "Epoch 29: val_loss improved from 0.53550 to 0.53266, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4754 - val_loss: 0.5327\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4774\n",
      "Epoch 30: val_loss did not improve from 0.53266\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4774 - val_loss: 0.5504\n",
      "Epoch 31/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4693\n",
      "Epoch 31: val_loss did not improve from 0.53266\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4672 - val_loss: 0.5460\n",
      "Epoch 32/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4479\n",
      "Epoch 32: val_loss improved from 0.53266 to 0.52953, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4494 - val_loss: 0.5295\n",
      "Epoch 33/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4555\n",
      "Epoch 33: val_loss did not improve from 0.52953\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4524 - val_loss: 0.5311\n",
      "Epoch 34/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4425\n",
      "Epoch 34: val_loss improved from 0.52953 to 0.52857, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4414 - val_loss: 0.5286\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4472\n",
      "Epoch 35: val_loss improved from 0.52857 to 0.52516, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4472 - val_loss: 0.5252\n",
      "Epoch 36/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4145\n",
      "Epoch 36: val_loss did not improve from 0.52516\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4162 - val_loss: 0.5351\n",
      "Epoch 37/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4242\n",
      "Epoch 37: val_loss improved from 0.52516 to 0.52343, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4238 - val_loss: 0.5234\n",
      "Epoch 38/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4378\n",
      "Epoch 38: val_loss improved from 0.52343 to 0.52132, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4377 - val_loss: 0.5213\n",
      "Epoch 39/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4249\n",
      "Epoch 39: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4239 - val_loss: 0.5255\n",
      "Epoch 40/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4131\n",
      "Epoch 40: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4129 - val_loss: 0.5220\n",
      "Epoch 41/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4154\n",
      "Epoch 41: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4156 - val_loss: 0.5295\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3948\n",
      "Epoch 42: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3948 - val_loss: 0.5383\n",
      "Epoch 43/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4110\n",
      "Epoch 43: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4105 - val_loss: 0.5214\n",
      "Epoch 44/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4074\n",
      "Epoch 44: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4077 - val_loss: 0.5243\n",
      "Epoch 45/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3913\n",
      "Epoch 45: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3933 - val_loss: 0.5264\n",
      "Epoch 46/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4093\n",
      "Epoch 46: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4064 - val_loss: 0.5326\n",
      "Epoch 47/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.3957\n",
      "Epoch 47: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3942 - val_loss: 0.5313\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3732\n",
      "Epoch 48: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3732 - val_loss: 0.5340\n",
      "Epoch 49/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3853\n",
      "Epoch 49: val_loss did not improve from 0.52132\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3896 - val_loss: 0.5229\n",
      "Epoch 50/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3891\n",
      "Epoch 50: val_loss improved from 0.52132 to 0.51486, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3905 - val_loss: 0.5149\n",
      "Epoch 51/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3745\n",
      "Epoch 51: val_loss did not improve from 0.51486\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3754 - val_loss: 0.5439\n",
      "Epoch 52/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3737\n",
      "Epoch 52: val_loss did not improve from 0.51486\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3778 - val_loss: 0.5183\n",
      "Epoch 53/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3817\n",
      "Epoch 53: val_loss improved from 0.51486 to 0.50655, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold3.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3783 - val_loss: 0.5065\n",
      "Epoch 54/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3626\n",
      "Epoch 54: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3661 - val_loss: 0.5217\n",
      "Epoch 55/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3640\n",
      "Epoch 55: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3704 - val_loss: 0.5208\n",
      "Epoch 56/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3720\n",
      "Epoch 56: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3679 - val_loss: 0.5231\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3658\n",
      "Epoch 57: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3623 - val_loss: 0.5169\n",
      "Epoch 58/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3523\n",
      "Epoch 58: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3540 - val_loss: 0.5198\n",
      "Epoch 59/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3539\n",
      "Epoch 59: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3563 - val_loss: 0.5112\n",
      "Epoch 60/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3581\n",
      "Epoch 60: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3516 - val_loss: 0.5258\n",
      "Epoch 61/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3621\n",
      "Epoch 61: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3643 - val_loss: 0.5336\n",
      "Epoch 62/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3521\n",
      "Epoch 62: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3474 - val_loss: 0.5217\n",
      "Epoch 63/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3683\n",
      "Epoch 63: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3678 - val_loss: 0.5151\n",
      "Epoch 64/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3401\n",
      "Epoch 64: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3414 - val_loss: 0.5209\n",
      "Epoch 65/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3401\n",
      "Epoch 65: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3445 - val_loss: 0.5369\n",
      "Epoch 66/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3425\n",
      "Epoch 66: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3413 - val_loss: 0.5153\n",
      "Epoch 67/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3428\n",
      "Epoch 67: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3433 - val_loss: 0.5233\n",
      "Epoch 68/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3451\n",
      "Epoch 68: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3443 - val_loss: 0.5344\n",
      "Epoch 69/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3456\n",
      "Epoch 69: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3459 - val_loss: 0.5429\n",
      "Epoch 70/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3337\n",
      "Epoch 70: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3350 - val_loss: 0.5289\n",
      "Epoch 71/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3570\n",
      "Epoch 71: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3565 - val_loss: 0.5268\n",
      "Epoch 72/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3279\n",
      "Epoch 72: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3285 - val_loss: 0.5303\n",
      "Epoch 73/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3451\n",
      "Epoch 73: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3480 - val_loss: 0.5076\n",
      "Epoch 74/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3312\n",
      "Epoch 74: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3317 - val_loss: 0.5134\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3339\n",
      "Epoch 75: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3339 - val_loss: 0.5323\n",
      "Epoch 76/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3140\n",
      "Epoch 76: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3134 - val_loss: 0.5447\n",
      "Epoch 77/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3402\n",
      "Epoch 77: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3420 - val_loss: 0.5206\n",
      "Epoch 78/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3371\n",
      "Epoch 78: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3325 - val_loss: 0.5237\n",
      "Epoch 79/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3183\n",
      "Epoch 79: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3196 - val_loss: 0.5171\n",
      "Epoch 80/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3361\n",
      "Epoch 80: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3365 - val_loss: 0.5169\n",
      "Epoch 81/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3184\n",
      "Epoch 81: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3205 - val_loss: 0.5248\n",
      "Epoch 82/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3184\n",
      "Epoch 82: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3184 - val_loss: 0.5486\n",
      "Epoch 83/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3279\n",
      "Epoch 83: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3282 - val_loss: 0.5216\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3073\n",
      "Epoch 84: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3073 - val_loss: 0.5301\n",
      "Epoch 85/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3109\n",
      "Epoch 85: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3131 - val_loss: 0.5321\n",
      "Epoch 86/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3249\n",
      "Epoch 86: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3231 - val_loss: 0.5175\n",
      "Epoch 87/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3249\n",
      "Epoch 87: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3243 - val_loss: 0.5243\n",
      "Epoch 88/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3153\n",
      "Epoch 88: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3137 - val_loss: 0.5264\n",
      "Epoch 89/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3171\n",
      "Epoch 89: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3196 - val_loss: 0.5249\n",
      "Epoch 90/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3077\n",
      "Epoch 90: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3071 - val_loss: 0.5406\n",
      "Epoch 91/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3143\n",
      "Epoch 91: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3131 - val_loss: 0.5178\n",
      "Epoch 92/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.2943\n",
      "Epoch 92: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2916 - val_loss: 0.5318\n",
      "Epoch 93/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3277\n",
      "Epoch 93: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3286 - val_loss: 0.5163\n",
      "Epoch 94/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3232\n",
      "Epoch 94: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3233 - val_loss: 0.5170\n",
      "Epoch 95/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3176\n",
      "Epoch 95: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3212 - val_loss: 0.5204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3083\n",
      "Epoch 96: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3090 - val_loss: 0.5269\n",
      "Epoch 97/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.2948\n",
      "Epoch 97: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2985 - val_loss: 0.5147\n",
      "Epoch 98/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3119\n",
      "Epoch 98: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3125 - val_loss: 0.5247\n",
      "Epoch 99/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3050\n",
      "Epoch 99: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3041 - val_loss: 0.5441\n",
      "Epoch 100/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3106\n",
      "Epoch 100: val_loss did not improve from 0.50655\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3150 - val_loss: 0.5308\n",
      "\n",
      "Train/Test model on Fold #4.\n",
      "Epoch 1/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.9237\n",
      "Epoch 1: val_loss improved from inf to 0.88459, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 3s 17ms/step - loss: 0.9211 - val_loss: 0.8846\n",
      "Epoch 2/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.8694\n",
      "Epoch 2: val_loss improved from 0.88459 to 0.84899, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.8682 - val_loss: 0.8490\n",
      "Epoch 3/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.8317\n",
      "Epoch 3: val_loss improved from 0.84899 to 0.81375, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.8296 - val_loss: 0.8138\n",
      "Epoch 4/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.7757\n",
      "Epoch 4: val_loss improved from 0.81375 to 0.74136, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.7767 - val_loss: 0.7414\n",
      "Epoch 5/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.7064\n",
      "Epoch 5: val_loss improved from 0.74136 to 0.70015, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.7053 - val_loss: 0.7002\n",
      "Epoch 6/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.6752\n",
      "Epoch 6: val_loss improved from 0.70015 to 0.67845, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6749 - val_loss: 0.6785\n",
      "Epoch 7/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.6516\n",
      "Epoch 7: val_loss improved from 0.67845 to 0.66506, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6506 - val_loss: 0.6651\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6288\n",
      "Epoch 8: val_loss improved from 0.66506 to 0.65217, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6288 - val_loss: 0.6522\n",
      "Epoch 9/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.6048\n",
      "Epoch 9: val_loss improved from 0.65217 to 0.64172, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.6047 - val_loss: 0.6417\n",
      "Epoch 10/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5896\n",
      "Epoch 10: val_loss improved from 0.64172 to 0.63454, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5881 - val_loss: 0.6345\n",
      "Epoch 11/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5759\n",
      "Epoch 11: val_loss improved from 0.63454 to 0.62640, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5804 - val_loss: 0.6264\n",
      "Epoch 12/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5642\n",
      "Epoch 12: val_loss improved from 0.62640 to 0.62327, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5629 - val_loss: 0.6233\n",
      "Epoch 13/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5544\n",
      "Epoch 13: val_loss improved from 0.62327 to 0.61357, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5506 - val_loss: 0.6136\n",
      "Epoch 14/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5386\n",
      "Epoch 14: val_loss improved from 0.61357 to 0.60908, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5383 - val_loss: 0.6091\n",
      "Epoch 15/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5418\n",
      "Epoch 15: val_loss improved from 0.60908 to 0.60320, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5449 - val_loss: 0.6032\n",
      "Epoch 16/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5213\n",
      "Epoch 16: val_loss did not improve from 0.60320\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5211 - val_loss: 0.6038\n",
      "Epoch 17/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5250\n",
      "Epoch 17: val_loss improved from 0.60320 to 0.59828, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5223 - val_loss: 0.5983\n",
      "Epoch 18/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5134\n",
      "Epoch 18: val_loss improved from 0.59828 to 0.58723, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.5110 - val_loss: 0.5872\n",
      "Epoch 19/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5139\n",
      "Epoch 19: val_loss did not improve from 0.58723\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5104 - val_loss: 0.5878\n",
      "Epoch 20/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4907\n",
      "Epoch 20: val_loss improved from 0.58723 to 0.58548, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4913 - val_loss: 0.5855\n",
      "Epoch 21/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4880\n",
      "Epoch 21: val_loss improved from 0.58548 to 0.57961, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4880 - val_loss: 0.5796\n",
      "Epoch 22/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4683\n",
      "Epoch 22: val_loss improved from 0.57961 to 0.57894, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4718 - val_loss: 0.5789\n",
      "Epoch 23/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.4751\n",
      "Epoch 23: val_loss did not improve from 0.57894\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4778 - val_loss: 0.5965\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4647\n",
      "Epoch 24: val_loss improved from 0.57894 to 0.57537, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4629 - val_loss: 0.5754\n",
      "Epoch 25/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4543\n",
      "Epoch 25: val_loss improved from 0.57537 to 0.57282, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4539 - val_loss: 0.5728\n",
      "Epoch 26/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4622\n",
      "Epoch 26: val_loss improved from 0.57282 to 0.57099, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4622 - val_loss: 0.5710\n",
      "Epoch 27/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.4417\n",
      "Epoch 27: val_loss did not improve from 0.57099\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4406 - val_loss: 0.6059\n",
      "Epoch 28/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.4435\n",
      "Epoch 28: val_loss did not improve from 0.57099\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.4422 - val_loss: 0.5757\n",
      "Epoch 29/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4343\n",
      "Epoch 29: val_loss improved from 0.57099 to 0.56260, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.4341 - val_loss: 0.5626\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4307\n",
      "Epoch 30: val_loss did not improve from 0.56260\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.4307 - val_loss: 0.5786\n",
      "Epoch 31/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4247\n",
      "Epoch 31: val_loss did not improve from 0.56260\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4282 - val_loss: 0.5638\n",
      "Epoch 32/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4215\n",
      "Epoch 32: val_loss did not improve from 0.56260\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4222 - val_loss: 0.5629\n",
      "Epoch 33/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4154\n",
      "Epoch 33: val_loss did not improve from 0.56260\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4138 - val_loss: 0.5654\n",
      "Epoch 34/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4193\n",
      "Epoch 34: val_loss did not improve from 0.56260\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4197 - val_loss: 0.5630\n",
      "Epoch 35/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4115\n",
      "Epoch 35: val_loss improved from 0.56260 to 0.55725, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4101 - val_loss: 0.5573\n",
      "Epoch 36/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.4143\n",
      "Epoch 36: val_loss improved from 0.55725 to 0.54953, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4153 - val_loss: 0.5495\n",
      "Epoch 37/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.4020\n",
      "Epoch 37: val_loss did not improve from 0.54953\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4016 - val_loss: 0.5573\n",
      "Epoch 38/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4134\n",
      "Epoch 38: val_loss did not improve from 0.54953\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4127 - val_loss: 0.5509\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4151\n",
      "Epoch 39: val_loss improved from 0.54953 to 0.54892, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4151 - val_loss: 0.5489\n",
      "Epoch 40/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4011\n",
      "Epoch 40: val_loss improved from 0.54892 to 0.54719, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3994 - val_loss: 0.5472\n",
      "Epoch 41/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3942\n",
      "Epoch 41: val_loss did not improve from 0.54719\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3955 - val_loss: 0.5505\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3861\n",
      "Epoch 42: val_loss did not improve from 0.54719\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3861 - val_loss: 0.5577\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3719\n",
      "Epoch 43: val_loss did not improve from 0.54719\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3719 - val_loss: 0.5622\n",
      "Epoch 44/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3944\n",
      "Epoch 44: val_loss did not improve from 0.54719\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3900 - val_loss: 0.5590\n",
      "Epoch 45/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3767\n",
      "Epoch 45: val_loss did not improve from 0.54719\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3756 - val_loss: 0.5548\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3770\n",
      "Epoch 46: val_loss improved from 0.54719 to 0.54262, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\bestModel-fold4.hdf5\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3770 - val_loss: 0.5426\n",
      "Epoch 47/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3699\n",
      "Epoch 47: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3711 - val_loss: 0.5486\n",
      "Epoch 48/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3675\n",
      "Epoch 48: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3656 - val_loss: 0.5509\n",
      "Epoch 49/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3688\n",
      "Epoch 49: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3688 - val_loss: 0.5515\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3713\n",
      "Epoch 50: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3713 - val_loss: 0.5552\n",
      "Epoch 51/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3605\n",
      "Epoch 51: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3608 - val_loss: 0.5540\n",
      "Epoch 52/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3707\n",
      "Epoch 52: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3709 - val_loss: 0.5699\n",
      "Epoch 53/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3492\n",
      "Epoch 53: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3487 - val_loss: 0.5573\n",
      "Epoch 54/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3508\n",
      "Epoch 54: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3500 - val_loss: 0.5578\n",
      "Epoch 55/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3492\n",
      "Epoch 55: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3531 - val_loss: 0.5541\n",
      "Epoch 56/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3541\n",
      "Epoch 56: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3537 - val_loss: 0.5541\n",
      "Epoch 57/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3511\n",
      "Epoch 57: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3532 - val_loss: 0.5593\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/60 [============================>.] - ETA: 0s - loss: 0.3443\n",
      "Epoch 58: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3511 - val_loss: 0.5633\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3416\n",
      "Epoch 59: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3416 - val_loss: 0.5686\n",
      "Epoch 60/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3330\n",
      "Epoch 60: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3423 - val_loss: 0.5612\n",
      "Epoch 61/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3440\n",
      "Epoch 61: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3466 - val_loss: 0.5725\n",
      "Epoch 62/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3490\n",
      "Epoch 62: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3472 - val_loss: 0.5577\n",
      "Epoch 63/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3173\n",
      "Epoch 63: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3203 - val_loss: 0.5856\n",
      "Epoch 64/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3251\n",
      "Epoch 64: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3301 - val_loss: 0.5707\n",
      "Epoch 65/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3342\n",
      "Epoch 65: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3390 - val_loss: 0.5717\n",
      "Epoch 66/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3261\n",
      "Epoch 66: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3246 - val_loss: 0.5645\n",
      "Epoch 67/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.3555\n",
      "Epoch 67: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3487 - val_loss: 0.5654\n",
      "Epoch 68/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3074\n",
      "Epoch 68: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3058 - val_loss: 0.5784\n",
      "Epoch 69/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3260\n",
      "Epoch 69: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3275 - val_loss: 0.5691\n",
      "Epoch 70/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3092\n",
      "Epoch 70: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3079 - val_loss: 0.5812\n",
      "Epoch 71/100\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.3125\n",
      "Epoch 71: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3228 - val_loss: 0.5641\n",
      "Epoch 72/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.3184\n",
      "Epoch 72: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3183 - val_loss: 0.5702\n",
      "Epoch 73/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3072\n",
      "Epoch 73: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3064 - val_loss: 0.5799\n",
      "Epoch 74/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3136\n",
      "Epoch 74: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3136 - val_loss: 0.5975\n",
      "Epoch 75/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3012\n",
      "Epoch 75: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3010 - val_loss: 0.5909\n",
      "Epoch 76/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3033\n",
      "Epoch 76: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3036 - val_loss: 0.6015\n",
      "Epoch 77/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3056\n",
      "Epoch 77: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3018 - val_loss: 0.6221\n",
      "Epoch 78/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3010\n",
      "Epoch 78: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3003 - val_loss: 0.5943\n",
      "Epoch 79/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3260\n",
      "Epoch 79: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3240 - val_loss: 0.5786\n",
      "Epoch 80/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.2965\n",
      "Epoch 80: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3007 - val_loss: 0.6000\n",
      "Epoch 81/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.3031\n",
      "Epoch 81: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2987 - val_loss: 0.6128\n",
      "Epoch 82/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.3052\n",
      "Epoch 82: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3078 - val_loss: 0.5946\n",
      "Epoch 83/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.2952\n",
      "Epoch 83: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2930 - val_loss: 0.6036\n",
      "Epoch 84/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.3083\n",
      "Epoch 84: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3094 - val_loss: 0.6032\n",
      "Epoch 85/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.2931\n",
      "Epoch 85: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3041 - val_loss: 0.6050\n",
      "Epoch 86/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.2870\n",
      "Epoch 86: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2860 - val_loss: 0.6542\n",
      "Epoch 87/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.2895\n",
      "Epoch 87: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2862 - val_loss: 0.6262\n",
      "Epoch 88/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2886\n",
      "Epoch 88: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.2876 - val_loss: 0.6088\n",
      "Epoch 89/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.2974\n",
      "Epoch 89: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3026 - val_loss: 0.6070\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2833\n",
      "Epoch 90: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2833 - val_loss: 0.6097\n",
      "Epoch 91/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.2807\n",
      "Epoch 91: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2787 - val_loss: 0.6273\n",
      "Epoch 92/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.2668\n",
      "Epoch 92: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2658 - val_loss: 0.6347\n",
      "Epoch 93/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2762\n",
      "Epoch 93: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2747 - val_loss: 0.6066\n",
      "Epoch 94/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.2656\n",
      "Epoch 94: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2671 - val_loss: 0.6351\n",
      "Epoch 95/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2823\n",
      "Epoch 95: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2813 - val_loss: 0.6344\n",
      "Epoch 96/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.2924\n",
      "Epoch 96: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2897 - val_loss: 0.6235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2944\n",
      "Epoch 97: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.2944 - val_loss: 0.5929\n",
      "Epoch 98/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2924\n",
      "Epoch 98: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2924 - val_loss: 0.5919\n",
      "Epoch 99/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.2950\n",
      "Epoch 99: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2953 - val_loss: 0.6213\n",
      "Epoch 100/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.2725\n",
      "Epoch 100: val_loss did not improve from 0.54262\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.2734 - val_loss: 0.6202\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Train/Test model on all folds, generate evaluations\n",
    "##################################################################################\n",
    "\n",
    "## Create and set directory to save model\n",
    "modelPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold), \"models\")\n",
    "if(not os.path.isdir(modelPath)):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "i = -1\n",
    "for fold in folds:\n",
    "    i += 1\n",
    "    \n",
    "    print(\"\\nTrain/Test model on Fold #\"+str(i)+\".\")\n",
    "    \n",
    "    model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "    ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    modelCallbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                           monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                           save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "    ]\n",
    "    \n",
    "    # adding random shuffling of the dataset for training purpose\n",
    "    index_arr = np.arange(fold[\"X_train\"].shape[0])\n",
    "    index_arr = np.random.permutation(index_arr)\n",
    "    \n",
    "    model.fit(x = fold[\"X_train\"][index_arr], y = fold[\"y_train\"][index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "              callbacks = modelCallbacks, validation_data = (fold[\"X_test\"], fold[\"y_test\"]))\n",
    "    \n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TRAIN dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_train\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "    mcc = matthews_corrcoef(fold[\"y_train\"], label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Train\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TEST dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_test\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "    mcc = matthews_corrcoef(fold[\"y_test\"], label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Test\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.787562</td>\n",
       "      <td>0.789572</td>\n",
       "      <td>0.864722</td>\n",
       "      <td>0.784192</td>\n",
       "      <td>0.790915</td>\n",
       "      <td>0.575198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.936398</td>\n",
       "      <td>0.937209</td>\n",
       "      <td>0.978268</td>\n",
       "      <td>0.935566</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>0.873133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                   \n",
       "Test        0.787562   0.789572  0.864722     0.784192     0.790915  0.575198\n",
       "Train       0.936398   0.937209  0.978268     0.935566     0.937238  0.873133"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.807128</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>[0.0, 0.0041841004184100415, 0.121338912133891...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9957843, 0.9957842, 0.9765404, 0.97560775, ...</td>\n",
       "      <td>0.886555</td>\n",
       "      <td>0.811715</td>\n",
       "      <td>0.802521</td>\n",
       "      <td>0.614269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.1050420168067226...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0041841004184100415, 0.00418...</td>\n",
       "      <td>[1.993231, 0.99323106, 0.963058, 0.9627936, 0....</td>\n",
       "      <td>0.869018</td>\n",
       "      <td>0.777311</td>\n",
       "      <td>0.811715</td>\n",
       "      <td>0.589400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.792017</td>\n",
       "      <td>0.790795</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0546218487394958...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9980549, 0.99805486, 0.98709166, 0.98684794...</td>\n",
       "      <td>0.866720</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.789916</td>\n",
       "      <td>0.584039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.783613</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0378151260504201...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9956019, 0.9956019, 0.98058367, 0.97834504,...</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.777311</td>\n",
       "      <td>0.789916</td>\n",
       "      <td>0.567272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>[0.0, 0.004201680672268907, 0.0420168067226890...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...</td>\n",
       "      <td>[1.9967597, 0.9967596, 0.9828541, 0.9804451, 0...</td>\n",
       "      <td>0.840318</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.521008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Train_Test  Accuracy  Precision  \\\n",
       "1     0       Test  0.807128   0.804979   \n",
       "3     1       Test  0.794549   0.804348   \n",
       "5     2       Test  0.792017   0.790795   \n",
       "7     3       Test  0.783613   0.787234   \n",
       "9     4       Test  0.760504   0.760504   \n",
       "\n",
       "                                                 TPR  \\\n",
       "1  [0.0, 0.0041841004184100415, 0.121338912133891...   \n",
       "3  [0.0, 0.004201680672268907, 0.1050420168067226...   \n",
       "5  [0.0, 0.004201680672268907, 0.0546218487394958...   \n",
       "7  [0.0, 0.004201680672268907, 0.0378151260504201...   \n",
       "9  [0.0, 0.004201680672268907, 0.0420168067226890...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "1  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "3  [0.0, 0.0, 0.0, 0.0041841004184100415, 0.00418...   \n",
       "5  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "7  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "9  [0.0, 0.0, 0.0, 0.004201680672268907, 0.004201...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "1  [1.9957843, 0.9957842, 0.9765404, 0.97560775, ...  0.886555     0.811715   \n",
       "3  [1.993231, 0.99323106, 0.963058, 0.9627936, 0....  0.869018     0.777311   \n",
       "5  [1.9980549, 0.99805486, 0.98709166, 0.98684794...  0.866720     0.794118   \n",
       "7  [1.9956019, 0.9956019, 0.98058367, 0.97834504,...  0.861000     0.777311   \n",
       "9  [1.9967597, 0.9967596, 0.9828541, 0.9804451, 0...  0.840318     0.760504   \n",
       "\n",
       "   Specificity       MCC  \n",
       "1     0.802521  0.614269  \n",
       "3     0.811715  0.589400  \n",
       "5     0.789916  0.584039  \n",
       "7     0.789916  0.567272  \n",
       "9     0.760504  0.521008  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df[evaluations_df[\"Train_Test\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features\n",
    "train_labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read independent data file\n",
    "##################################################################################\n",
    "indpe_file_path = os.path.join(input_data_folder, independent_data_file)\n",
    "indpe_data = pd.read_csv(indpe_file_path, sep='\\t', header=None)\n",
    "indpe_data.columns = ['Sequence', 'name', 'id', 'flag', 'label_original', 'type']\n",
    "indpe_data.head()\n",
    "    \n",
    "##################################################################################\n",
    "##### Create OHE of sequence\n",
    "##################################################################################\n",
    "indpe_data['OHE_Sequence'] = pd.Series([one_hot_encode_nt(val, all_char_dict) \n",
    "                                        for val in indpe_data[\"Sequence\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Fix the labels\n",
    "##################################################################################\n",
    "indpe_data['label'] = pd.Series([1 if val == 1 else 0 \n",
    "                                 for val in indpe_data[\"label_original\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "indpe_features = np.array(list(indpe_data['OHE_Sequence']))\n",
    "indpe_labels = np.array(list(indpe_data['label']))\n",
    "indpe_labels = indpe_labels.reshape((indpe_labels.shape[0], 1))\n",
    "\n",
    "input_seq_shape = indpe_features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using k-fold Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of each k-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.62498</td>\n",
       "      <td>0.247755</td>\n",
       "      <td>0.673073</td>\n",
       "      <td>0.618719</td>\n",
       "      <td>0.626223</td>\n",
       "      <td>0.18509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity      MCC\n",
       "Train_Test                                                                   \n",
       "Independent   0.62498   0.247755  0.673073     0.618719     0.626223  0.18509"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    label_pred = pred2label(y_pred)\n",
    "\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(indpe_labels, label_pred)\n",
    "    prec = precision_score(indpe_labels,label_pred)\n",
    "    mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "    conf = confusion_matrix(indpe_labels, label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "    auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.603265</td>\n",
       "      <td>0.238447</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.00684931506849315, 0.006849315068...</td>\n",
       "      <td>[1.9970311, 0.9970311, 0.9890131, 0.9860087, 0...</td>\n",
       "      <td>0.680063</td>\n",
       "      <td>0.635468</td>\n",
       "      <td>0.596869</td>\n",
       "      <td>0.173966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.003913894324853229, 0.00391389432...</td>\n",
       "      <td>[1.9967053, 0.99670523, 0.98629075, 0.98195994...</td>\n",
       "      <td>0.666307</td>\n",
       "      <td>0.596059</td>\n",
       "      <td>0.655577</td>\n",
       "      <td>0.192180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.635102</td>\n",
       "      <td>0.251020</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.004892367906066536, 0.00489236790...</td>\n",
       "      <td>[1.9972383, 0.9972383, 0.98955977, 0.98942286,...</td>\n",
       "      <td>0.678598</td>\n",
       "      <td>0.605911</td>\n",
       "      <td>0.640900</td>\n",
       "      <td>0.187326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.610612</td>\n",
       "      <td>0.240530</td>\n",
       "      <td>[0.0, 0.0, 0.014778325123152709, 0.01477832512...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.000978473581213...</td>\n",
       "      <td>[1.9968368, 0.9968368, 0.9932454, 0.9921646, 0...</td>\n",
       "      <td>0.667483</td>\n",
       "      <td>0.625616</td>\n",
       "      <td>0.607632</td>\n",
       "      <td>0.175129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.630204</td>\n",
       "      <td>0.252964</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.009852216748768...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.005870841487279843, 0.005870...</td>\n",
       "      <td>[1.996693, 0.996693, 0.9912998, 0.98451334, 0....</td>\n",
       "      <td>0.672915</td>\n",
       "      <td>0.630542</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.196852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold   Train_Test  Accuracy  Precision  \\\n",
       "0     0  Independent  0.603265   0.238447   \n",
       "1     1  Independent  0.645714   0.255814   \n",
       "2     2  Independent  0.635102   0.251020   \n",
       "3     3  Independent  0.610612   0.240530   \n",
       "4     4  Independent  0.630204   0.252964   \n",
       "\n",
       "                                                 TPR  \\\n",
       "0  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "1  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "2  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "3  [0.0, 0.0, 0.014778325123152709, 0.01477832512...   \n",
       "4  [0.0, 0.0049261083743842365, 0.009852216748768...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "0  [0.0, 0.0, 0.00684931506849315, 0.006849315068...   \n",
       "1  [0.0, 0.0, 0.003913894324853229, 0.00391389432...   \n",
       "2  [0.0, 0.0, 0.004892367906066536, 0.00489236790...   \n",
       "3  [0.0, 0.0009784735812133072, 0.000978473581213...   \n",
       "4  [0.0, 0.0, 0.0, 0.005870841487279843, 0.005870...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0  [1.9970311, 0.9970311, 0.9890131, 0.9860087, 0...  0.680063     0.635468   \n",
       "1  [1.9967053, 0.99670523, 0.98629075, 0.98195994...  0.666307     0.596059   \n",
       "2  [1.9972383, 0.9972383, 0.98955977, 0.98942286,...  0.678598     0.605911   \n",
       "3  [1.9968368, 0.9968368, 0.9932454, 0.9921646, 0...  0.667483     0.625616   \n",
       "4  [1.996693, 0.996693, 0.9912998, 0.98451334, 0....  0.672915     0.630542   \n",
       "\n",
       "   Specificity       MCC  \n",
       "0     0.596869  0.173966  \n",
       "1     0.655577  0.192180  \n",
       "2     0.640900  0.187326  \n",
       "3     0.607632  0.175129  \n",
       "4     0.630137  0.196852  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.636735</td>\n",
       "      <td>0.256048</td>\n",
       "      <td>0.685515</td>\n",
       "      <td>0.625616</td>\n",
       "      <td>0.638943</td>\n",
       "      <td>0.200397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.636735   0.256048  0.685515     0.625616     0.638943  0.200397"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    total_pred += y_pred\n",
    "    all_preds.append(y_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.636735</td>\n",
       "      <td>0.254065</td>\n",
       "      <td>0.662832</td>\n",
       "      <td>0.615764</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.194672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.636735   0.254065  0.662832     0.615764       0.6409  0.194672"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    vote_pred = pred2label(y_pred)\n",
    "    total_pred += vote_pred\n",
    "    all_preds.append(vote_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using New Model\n",
    "\n",
    "Train model on full data from training. Predict and evaluate on Independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_indexes = np.where(indpe_labels==1)[0]\n",
    "neg_indexes = np.random.permutation(np.where(indpe_labels==0)[0])[0:pos_indexes.shape[0]]\n",
    "indpe_val_indexes = np.concatenate((pos_indexes, neg_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.9183\n",
      "Epoch 1: val_loss improved from inf to 0.88429, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 3s 16ms/step - loss: 0.9183 - val_loss: 0.8843\n",
      "Epoch 2/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 0.8732\n",
      "Epoch 2: val_loss improved from 0.88429 to 0.84942, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.8722 - val_loss: 0.8494\n",
      "Epoch 3/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.8316\n",
      "Epoch 3: val_loss improved from 0.84942 to 0.81245, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.8303 - val_loss: 0.8124\n",
      "Epoch 4/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.7674\n",
      "Epoch 4: val_loss improved from 0.81245 to 0.78526, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.7660 - val_loss: 0.7853\n",
      "Epoch 5/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.7042\n",
      "Epoch 5: val_loss improved from 0.78526 to 0.78417, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.7041 - val_loss: 0.7842\n",
      "Epoch 6/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.6665\n",
      "Epoch 6: val_loss improved from 0.78417 to 0.77507, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.6682 - val_loss: 0.7751\n",
      "Epoch 7/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.6449\n",
      "Epoch 7: val_loss did not improve from 0.77507\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.6470 - val_loss: 0.7822\n",
      "Epoch 8/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.6317\n",
      "Epoch 8: val_loss improved from 0.77507 to 0.77289, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.6273 - val_loss: 0.7729\n",
      "Epoch 9/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 0.6071\n",
      "Epoch 9: val_loss improved from 0.77289 to 0.75312, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.6072 - val_loss: 0.7531\n",
      "Epoch 10/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.5959\n",
      "Epoch 10: val_loss did not improve from 0.75312\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5976 - val_loss: 0.7677\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.5822\n",
      "Epoch 11: val_loss did not improve from 0.75312\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.5822 - val_loss: 0.7555\n",
      "Epoch 12/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.5711\n",
      "Epoch 12: val_loss did not improve from 0.75312\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5698 - val_loss: 0.7564\n",
      "Epoch 13/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.5675\n",
      "Epoch 13: val_loss did not improve from 0.75312\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5689 - val_loss: 0.7579\n",
      "Epoch 14/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.5552\n",
      "Epoch 14: val_loss improved from 0.75312 to 0.75308, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.5557 - val_loss: 0.7531\n",
      "Epoch 15/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.5525\n",
      "Epoch 15: val_loss improved from 0.75308 to 0.75039, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5519 - val_loss: 0.7504\n",
      "Epoch 16/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.5364\n",
      "Epoch 16: val_loss improved from 0.75039 to 0.74586, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5341 - val_loss: 0.7459\n",
      "Epoch 17/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.5273\n",
      "Epoch 17: val_loss improved from 0.74586 to 0.74450, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5269 - val_loss: 0.7445\n",
      "Epoch 18/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.5219\n",
      "Epoch 18: val_loss improved from 0.74450 to 0.73647, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5233 - val_loss: 0.7365\n",
      "Epoch 19/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.5246\n",
      "Epoch 19: val_loss did not improve from 0.73647\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 0.5225 - val_loss: 0.7525\n",
      "Epoch 20/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.5023\n",
      "Epoch 20: val_loss improved from 0.73647 to 0.73560, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5022 - val_loss: 0.7356\n",
      "Epoch 21/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.4937\n",
      "Epoch 21: val_loss did not improve from 0.73560\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.4929 - val_loss: 0.7625\n",
      "Epoch 22/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.4968\n",
      "Epoch 22: val_loss did not improve from 0.73560\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.4951 - val_loss: 0.7608\n",
      "Epoch 23/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.4832\n",
      "Epoch 23: val_loss did not improve from 0.73560\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4847 - val_loss: 0.7443\n",
      "Epoch 24/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 0.4872\n",
      "Epoch 24: val_loss did not improve from 0.73560\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4870 - val_loss: 0.7418\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4775\n",
      "Epoch 25: val_loss did not improve from 0.73560\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4775 - val_loss: 0.7485\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4805\n",
      "Epoch 26: val_loss improved from 0.73560 to 0.73247, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.4805 - val_loss: 0.7325\n",
      "Epoch 27/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 0.4671\n",
      "Epoch 27: val_loss improved from 0.73247 to 0.72798, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.4686 - val_loss: 0.7280\n",
      "Epoch 28/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.4530\n",
      "Epoch 28: val_loss did not improve from 0.72798\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4523 - val_loss: 0.7663\n",
      "Epoch 29/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.4532\n",
      "Epoch 29: val_loss did not improve from 0.72798\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.4470 - val_loss: 0.7465\n",
      "Epoch 30/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.4599\n",
      "Epoch 30: val_loss did not improve from 0.72798\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4580 - val_loss: 0.7440\n",
      "Epoch 31/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.4541\n",
      "Epoch 31: val_loss improved from 0.72798 to 0.72039, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2\\5fold\\models\\_fullModel.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4551 - val_loss: 0.7204\n",
      "Epoch 32/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.4365\n",
      "Epoch 32: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4433 - val_loss: 0.7662\n",
      "Epoch 33/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.4391\n",
      "Epoch 33: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4388 - val_loss: 0.7781\n",
      "Epoch 34/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.4285\n",
      "Epoch 34: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4334 - val_loss: 0.7712\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4261\n",
      "Epoch 35: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4261 - val_loss: 0.7760\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4128\n",
      "Epoch 36: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4128 - val_loss: 0.7625\n",
      "Epoch 37/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.4197\n",
      "Epoch 37: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4183 - val_loss: 0.7608\n",
      "Epoch 38/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.4174\n",
      "Epoch 38: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4162 - val_loss: 0.7901\n",
      "Epoch 39/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 0.4004\n",
      "Epoch 39: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4101 - val_loss: 0.7758\n",
      "Epoch 40/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 0.4122\n",
      "Epoch 40: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4110 - val_loss: 0.7849\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4114\n",
      "Epoch 41: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.4114 - val_loss: 0.7689\n",
      "Epoch 42/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.4042\n",
      "Epoch 42: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.4031 - val_loss: 0.7891\n",
      "Epoch 43/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.4038\n",
      "Epoch 43: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.4039 - val_loss: 0.7687\n",
      "Epoch 44/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 0.3883\n",
      "Epoch 44: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3854 - val_loss: 0.7936\n",
      "Epoch 45/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3947\n",
      "Epoch 45: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3974 - val_loss: 0.7993\n",
      "Epoch 46/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.3946\n",
      "Epoch 46: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3931 - val_loss: 0.8379\n",
      "Epoch 47/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3708\n",
      "Epoch 47: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3738 - val_loss: 0.8783\n",
      "Epoch 48/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.3779\n",
      "Epoch 48: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3764 - val_loss: 0.8179\n",
      "Epoch 49/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 0.3968\n",
      "Epoch 49: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3970 - val_loss: 0.7546\n",
      "Epoch 50/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 0.3869\n",
      "Epoch 50: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3859 - val_loss: 0.8077\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4003\n",
      "Epoch 51: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4003 - val_loss: 0.7797\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3609\n",
      "Epoch 52: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3609 - val_loss: 0.8364\n",
      "Epoch 53/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3825\n",
      "Epoch 53: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3839 - val_loss: 0.8322\n",
      "Epoch 54/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.3700\n",
      "Epoch 54: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3651 - val_loss: 0.8219\n",
      "Epoch 55/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3608\n",
      "Epoch 55: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3589 - val_loss: 0.8769\n",
      "Epoch 56/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 0.3708\n",
      "Epoch 56: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3715 - val_loss: 0.8338\n",
      "Epoch 57/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3485\n",
      "Epoch 57: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3481 - val_loss: 0.8463\n",
      "Epoch 58/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 0.3485\n",
      "Epoch 58: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3469 - val_loss: 0.9013\n",
      "Epoch 59/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 0.3487\n",
      "Epoch 59: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3573 - val_loss: 0.8555\n",
      "Epoch 60/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 0.3630\n",
      "Epoch 60: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3624 - val_loss: 0.7656\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3554\n",
      "Epoch 61: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3554 - val_loss: 0.8431\n",
      "Epoch 62/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.3589\n",
      "Epoch 62: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3612 - val_loss: 0.8336\n",
      "Epoch 63/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 0.3511\n",
      "Epoch 63: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3489 - val_loss: 0.8915\n",
      "Epoch 64/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3434\n",
      "Epoch 64: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3425 - val_loss: 0.8969\n",
      "Epoch 65/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.3609\n",
      "Epoch 65: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3591 - val_loss: 0.8431\n",
      "Epoch 66/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3429\n",
      "Epoch 66: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3438 - val_loss: 0.8506\n",
      "Epoch 67/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.3435\n",
      "Epoch 67: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3437 - val_loss: 0.8754\n",
      "Epoch 68/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 0.3508\n",
      "Epoch 68: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3512 - val_loss: 0.8492\n",
      "Epoch 69/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 0.3374\n",
      "Epoch 69: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3394 - val_loss: 0.8601\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - ETA: 0s - loss: 0.3644\n",
      "Epoch 70: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3644 - val_loss: 0.8551\n",
      "Epoch 71/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.3393\n",
      "Epoch 71: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3386 - val_loss: 0.8710\n",
      "Epoch 72/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 0.3583\n",
      "Epoch 72: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3539 - val_loss: 0.8985\n",
      "Epoch 73/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 0.3579\n",
      "Epoch 73: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3573 - val_loss: 0.8515\n",
      "Epoch 74/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.3352\n",
      "Epoch 74: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3345 - val_loss: 0.8435\n",
      "Epoch 75/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.3411\n",
      "Epoch 75: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3391 - val_loss: 0.8842\n",
      "Epoch 76/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.3426\n",
      "Epoch 76: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3438 - val_loss: 0.8557\n",
      "Epoch 77/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.3197\n",
      "Epoch 77: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3158 - val_loss: 0.9074\n",
      "Epoch 78/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3389\n",
      "Epoch 78: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3403 - val_loss: 0.9040\n",
      "Epoch 79/100\n",
      "69/75 [==========================>...] - ETA: 0s - loss: 0.3398\n",
      "Epoch 79: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3400 - val_loss: 0.9125\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3450\n",
      "Epoch 80: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3450 - val_loss: 0.8525\n",
      "Epoch 81/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 0.3211\n",
      "Epoch 81: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3203 - val_loss: 0.8706\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3260\n",
      "Epoch 82: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3260 - val_loss: 0.8850\n",
      "Epoch 83/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.3360\n",
      "Epoch 83: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3379 - val_loss: 0.8587\n",
      "Epoch 84/100\n",
      "74/75 [============================>.] - ETA: 0s - loss: 0.3236\n",
      "Epoch 84: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3232 - val_loss: 0.8906\n",
      "Epoch 85/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.3187\n",
      "Epoch 85: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3173 - val_loss: 0.9060\n",
      "Epoch 86/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.3335\n",
      "Epoch 86: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3334 - val_loss: 0.9114\n",
      "Epoch 87/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 0.3339\n",
      "Epoch 87: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3286 - val_loss: 0.9265\n",
      "Epoch 88/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.3303\n",
      "Epoch 88: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3285 - val_loss: 0.9213\n",
      "Epoch 89/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3129\n",
      "Epoch 89: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3145 - val_loss: 0.9542\n",
      "Epoch 90/100\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 0.3185\n",
      "Epoch 90: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3173 - val_loss: 0.9043\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3165\n",
      "Epoch 91: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3165 - val_loss: 0.9057\n",
      "Epoch 92/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.3294\n",
      "Epoch 92: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3292 - val_loss: 0.9147\n",
      "Epoch 93/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3165\n",
      "Epoch 93: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3164 - val_loss: 0.9239\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3141\n",
      "Epoch 94: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3141 - val_loss: 0.9443\n",
      "Epoch 95/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3177\n",
      "Epoch 95: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3163 - val_loss: 0.9292\n",
      "Epoch 96/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.3025\n",
      "Epoch 96: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3018 - val_loss: 0.8709\n",
      "Epoch 97/100\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 0.3000\n",
      "Epoch 97: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3097 - val_loss: 0.9129\n",
      "Epoch 98/100\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.3187\n",
      "Epoch 98: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3170 - val_loss: 0.9442\n",
      "Epoch 99/100\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 0.3228\n",
      "Epoch 99: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3209 - val_loss: 0.9151\n",
      "Epoch 100/100\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 0.3135\n",
      "Epoch 100: val_loss did not improve from 0.72039\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.3211 - val_loss: 0.8693\n"
     ]
    }
   ],
   "source": [
    "model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "current_model_path = os.path.join(modelPath, \"_fullModel.hdf5\")\n",
    "modelCallbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                       monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                       save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "]\n",
    "\n",
    "# adding random shuffling of the dataset for training purpose\n",
    "index_arr = np.arange(train_features.shape[0])\n",
    "index_arr = np.random.permutation(index_arr)\n",
    "\n",
    "model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "          callbacks = modelCallbacks, validation_data = (indpe_features[indpe_val_indexes], indpe_labels[indpe_val_indexes]))\n",
    "# model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "#           callbacks = modelCallbacks, validation_split = 0.2)\n",
    "\n",
    "model = tf.keras.models.load_model(current_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.607347</td>\n",
       "      <td>0.24635</td>\n",
       "      <td>0.676631</td>\n",
       "      <td>0.665025</td>\n",
       "      <td>0.59589</td>\n",
       "      <td>0.195114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.607347    0.24635  0.676631     0.665025      0.59589  0.195114"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "y_pred = model.predict(indpe_features)\n",
    "label_pred = pred2label(y_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
