{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "seed = None\n",
    "\n",
    "input_data_folder = \"Data\"\n",
    "training_data_file = \"Training-datasets-PredNTS.txt\"\n",
    "independent_data_file = \"independent dataset-PredNTS.txt\"\n",
    "\n",
    "iNitroY_input_data_folder = \"Data\\\\iNitroY-Deep-Dataset\"\n",
    "iNitroY_pos_data_file = \"raw-nitrotyrosine-pos.fasta\"\n",
    "iNitroY_neg_data_file = \"cdhit70-nitrotyr-neg.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import math\n",
    "\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define all CUSTOM functions\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode_nt(sequence, char_dict):\n",
    "    \n",
    "    seq_encoded = np.zeros((len(sequence),len(char_dict)))\n",
    "    \n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in char_dict.keys()):\n",
    "            seq_encoded[i][char_dict[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in NT sequence: '+sequence)\n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Build k-fold functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "                 conv_filters_per_layer_1 = 10, kernel_length_1 = 5, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "                 max_pool_width_1 = 3, max_pool_stride_1 = 3, ## 1st Maxpool layer parameters\n",
    "                 lstm_decode_units = 10, ## LSTM layer parameters\n",
    "                 conv_filters_per_layer_2 = 10,  kernel_length_2 = 3, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "                 max_pool_width_2 = 3, max_pool_stride_2 = 3, ## 2nd Maxpool layer parameters\n",
    "                 dense_decode_units = 64, ## Dense layer parameters\n",
    "                 prob = 0.5, learn_rate = 0.0005, \n",
    "                 loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  SEQUENCE  ##################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1,\n",
    "                                strides = conv_strides_1, kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = \"same\")(input1)\n",
    "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta))(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    ## Conv Path\n",
    "\n",
    "    x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), padding = 'same')(x1)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "    x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "    \n",
    "    x4 = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  Classifier  ################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    y = tf.keras.layers.Dense(dense_decode_units, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'relu')(x4)\n",
    "    \n",
    "    y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(1, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'sigmoid')(y)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 41, 21)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 41, 10)       1060        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 41, 10)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 13, 10)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 13, 10)       0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 13, 10)       310         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 13, 10)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 13, 10)       840         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 4, 10)       0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 13, 10)       0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 10)        0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 130)          0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 40)           0           ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 170)          0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           10944       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            65          ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,219\n",
      "Trainable params: 13,219\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DLNN_CORENup().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta_file(file_path):\n",
    "    \n",
    "    openFile = open(file_path)\n",
    "    fastaSequences = SeqIO.parse(openFile, \"fasta\")\n",
    "\n",
    "    name_list = []\n",
    "    seq_list = []\n",
    "\n",
    "    for fasta in fastaSequences: \n",
    "        name_list.append(fasta.id)\n",
    "        seq_list.append(str(fasta.seq))\n",
    "\n",
    "    openFile.close()\n",
    "    \n",
    "    return name_list, seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read PredNTS training file\n",
    "##################################################################################\n",
    "train_file_path = os.path.join(input_data_folder, training_data_file)\n",
    "train_data = pd.read_csv(train_file_path, sep='\\t', header=None)\n",
    "train_data.columns = ['Sequence', 'name', 'id', 'flag', 'label_original', 'type']\n",
    "train_data.head()\n",
    "\n",
    "train_seq_list = list(train_data['Sequence'])\n",
    "train_seq_label = [1 if val == 1 else 0 \n",
    "                   for val in train_data[\"label_original\"]]\n",
    "\n",
    "##################################################################################\n",
    "##### read iNitroY file\n",
    "##################################################################################\n",
    "\n",
    "iNitroY_pos_file_path = os.path.join(iNitroY_input_data_folder, iNitroY_pos_data_file)\n",
    "_, iNitroY_pos_seq_list = read_fasta_file(iNitroY_pos_file_path)\n",
    "\n",
    "iNitroY_neg_file_path = os.path.join(iNitroY_input_data_folder, iNitroY_neg_data_file)\n",
    "_, iNitroY_neg_seq_list = read_fasta_file(iNitroY_neg_file_path)\n",
    "\n",
    "iNitroY_pos_seq_list = [val.replace('X', '-') for val in iNitroY_pos_seq_list]\n",
    "iNitroY_neg_seq_list = [val.replace('X', '-') for val in iNitroY_neg_seq_list]\n",
    "\n",
    "# remove duplicates in data\n",
    "iNitroY_pos_seq_list = list(set(iNitroY_pos_seq_list))\n",
    "iNitroY_neg_seq_list = list(set(iNitroY_neg_seq_list))\n",
    "\n",
    "iNitroY_seq_list = iNitroY_pos_seq_list + iNitroY_neg_seq_list\n",
    "\n",
    "iNitroY_seq_label_list = ([1] * len(iNitroY_pos_seq_list)) + ([0] * len(iNitroY_neg_seq_list))\n",
    "\n",
    "##################################################################################\n",
    "##### merge both for training\n",
    "##################################################################################\n",
    "\n",
    "seq_list = train_seq_list + iNitroY_seq_list\n",
    "label_list = train_seq_label + iNitroY_seq_label_list\n",
    "\n",
    "all_train_data = pd.DataFrame({'Sequence':seq_list, 'label':label_list})\n",
    "all_train_data = all_train_data.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "##################################################################################\n",
    "##### Create dictionary of all characters in the NT sequence \n",
    "##################################################################################\n",
    "all_char_set = set({})\n",
    "for val in [set(val) for val in all_train_data['Sequence']]:\n",
    "    all_char_set = all_char_set.union(val)\n",
    "all_char_list = list(all_char_set)\n",
    "all_char_list.sort()\n",
    "all_char_dict = {}\n",
    "for i in range(len(all_char_list)):\n",
    "    all_char_dict[all_char_list[i]] = i\n",
    "\n",
    "##################################################################################\n",
    "##### Create OHE of sequence\n",
    "##################################################################################\n",
    "all_train_data['OHE_Sequence'] = pd.Series([one_hot_encode_nt(val, all_char_dict) \n",
    "                                            for val in all_train_data[\"Sequence\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "features = np.array(list(all_train_data['OHE_Sequence']))\n",
    "labels = np.array(list(all_train_data['label']))\n",
    "labels = labels.reshape((labels.shape[0], 1))\n",
    "\n",
    "input_seq_shape = features[0].shape\n",
    "\n",
    "folds = build_kfold(features, labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "## Write the k-fold dataset to file\n",
    "foldPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(foldPath)):\n",
    "    os.makedirs(foldPath)\n",
    "pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test model on Fold #0.\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8301\n",
      "Epoch 1: val_loss improved from inf to 0.80717, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 5s 15ms/step - loss: 0.8301 - val_loss: 0.8072\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8100\n",
      "Epoch 2: val_loss improved from 0.80717 to 0.79460, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.8100 - val_loss: 0.7946\n",
      "Epoch 3/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7967\n",
      "Epoch 3: val_loss improved from 0.79460 to 0.78396, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7969 - val_loss: 0.7840\n",
      "Epoch 4/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.7838\n",
      "Epoch 4: val_loss improved from 0.78396 to 0.77477, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7844 - val_loss: 0.7748\n",
      "Epoch 5/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7751\n",
      "Epoch 5: val_loss improved from 0.77477 to 0.76745, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7750 - val_loss: 0.7675\n",
      "Epoch 6/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7654\n",
      "Epoch 6: val_loss improved from 0.76745 to 0.75868, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7657 - val_loss: 0.7587\n",
      "Epoch 7/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7554\n",
      "Epoch 7: val_loss improved from 0.75868 to 0.75128, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7557 - val_loss: 0.7513\n",
      "Epoch 8/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7457\n",
      "Epoch 8: val_loss improved from 0.75128 to 0.74072, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7452 - val_loss: 0.7407\n",
      "Epoch 9/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.7377\n",
      "Epoch 9: val_loss improved from 0.74072 to 0.72552, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7364 - val_loss: 0.7255\n",
      "Epoch 10/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7205\n",
      "Epoch 10: val_loss improved from 0.72552 to 0.70370, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7208 - val_loss: 0.7037\n",
      "Epoch 11/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7058\n",
      "Epoch 11: val_loss improved from 0.70370 to 0.69192, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7059 - val_loss: 0.6919\n",
      "Epoch 12/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6898\n",
      "Epoch 12: val_loss improved from 0.69192 to 0.68135, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6906 - val_loss: 0.6814\n",
      "Epoch 13/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6734\n",
      "Epoch 13: val_loss improved from 0.68135 to 0.67165, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6737 - val_loss: 0.6717\n",
      "Epoch 14/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6669\n",
      "Epoch 14: val_loss improved from 0.67165 to 0.66584, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6671 - val_loss: 0.6658\n",
      "Epoch 15/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6617\n",
      "Epoch 15: val_loss improved from 0.66584 to 0.66277, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6617 - val_loss: 0.6628\n",
      "Epoch 16/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6550\n",
      "Epoch 16: val_loss improved from 0.66277 to 0.65896, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6555 - val_loss: 0.6590\n",
      "Epoch 17/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6401\n",
      "Epoch 17: val_loss improved from 0.65896 to 0.65127, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6393 - val_loss: 0.6513\n",
      "Epoch 18/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6406\n",
      "Epoch 18: val_loss improved from 0.65127 to 0.65102, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6396 - val_loss: 0.6510\n",
      "Epoch 19/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6342\n",
      "Epoch 19: val_loss improved from 0.65102 to 0.64783, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6338 - val_loss: 0.6478\n",
      "Epoch 20/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6364\n",
      "Epoch 20: val_loss improved from 0.64783 to 0.64208, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6357 - val_loss: 0.6421\n",
      "Epoch 21/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6286\n",
      "Epoch 21: val_loss improved from 0.64208 to 0.63783, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6285 - val_loss: 0.6378\n",
      "Epoch 22/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6273\n",
      "Epoch 22: val_loss improved from 0.63783 to 0.63629, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6286 - val_loss: 0.6363\n",
      "Epoch 23/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6161\n",
      "Epoch 23: val_loss improved from 0.63629 to 0.63600, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6169 - val_loss: 0.6360\n",
      "Epoch 24/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6100\n",
      "Epoch 24: val_loss improved from 0.63600 to 0.63160, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6129 - val_loss: 0.6316\n",
      "Epoch 25/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.6141\n",
      "Epoch 25: val_loss improved from 0.63160 to 0.63036, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6131 - val_loss: 0.6304\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 0.6043\n",
      "Epoch 26: val_loss did not improve from 0.63036\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6043 - val_loss: 0.6309\n",
      "Epoch 27/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6028\n",
      "Epoch 27: val_loss improved from 0.63036 to 0.62693, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6028 - val_loss: 0.6269\n",
      "Epoch 28/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5978\n",
      "Epoch 28: val_loss did not improve from 0.62693\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5959 - val_loss: 0.6272\n",
      "Epoch 29/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6069\n",
      "Epoch 29: val_loss improved from 0.62693 to 0.62234, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6072 - val_loss: 0.6223\n",
      "Epoch 30/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5990\n",
      "Epoch 30: val_loss improved from 0.62234 to 0.61804, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5994 - val_loss: 0.6180\n",
      "Epoch 31/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5952\n",
      "Epoch 31: val_loss improved from 0.61804 to 0.61719, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5937 - val_loss: 0.6172\n",
      "Epoch 32/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5945\n",
      "Epoch 32: val_loss improved from 0.61719 to 0.61640, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5945 - val_loss: 0.6164\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5914\n",
      "Epoch 33: val_loss improved from 0.61640 to 0.61401, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5914 - val_loss: 0.6140\n",
      "Epoch 34/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5918\n",
      "Epoch 34: val_loss did not improve from 0.61401\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5925 - val_loss: 0.6188\n",
      "Epoch 35/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5792\n",
      "Epoch 35: val_loss improved from 0.61401 to 0.61371, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5800 - val_loss: 0.6137\n",
      "Epoch 36/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5779\n",
      "Epoch 36: val_loss did not improve from 0.61371\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5774 - val_loss: 0.6142\n",
      "Epoch 37/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5765\n",
      "Epoch 37: val_loss improved from 0.61371 to 0.60946, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5769 - val_loss: 0.6095\n",
      "Epoch 38/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5785\n",
      "Epoch 38: val_loss improved from 0.60946 to 0.60931, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5796 - val_loss: 0.6093\n",
      "Epoch 39/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5704\n",
      "Epoch 39: val_loss did not improve from 0.60931\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5699 - val_loss: 0.6102\n",
      "Epoch 40/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5754\n",
      "Epoch 40: val_loss improved from 0.60931 to 0.60654, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5767 - val_loss: 0.6065\n",
      "Epoch 41/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5717\n",
      "Epoch 41: val_loss did not improve from 0.60654\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5714 - val_loss: 0.6088\n",
      "Epoch 42/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5669\n",
      "Epoch 42: val_loss did not improve from 0.60654\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5670 - val_loss: 0.6114\n",
      "Epoch 43/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5686\n",
      "Epoch 43: val_loss improved from 0.60654 to 0.60330, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5694 - val_loss: 0.6033\n",
      "Epoch 44/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5753\n",
      "Epoch 44: val_loss did not improve from 0.60330\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5754 - val_loss: 0.6088\n",
      "Epoch 45/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5635\n",
      "Epoch 45: val_loss improved from 0.60330 to 0.60176, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5624 - val_loss: 0.6018\n",
      "Epoch 46/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5691\n",
      "Epoch 46: val_loss improved from 0.60176 to 0.60161, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5707 - val_loss: 0.6016\n",
      "Epoch 47/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5549\n",
      "Epoch 47: val_loss did not improve from 0.60161\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5551 - val_loss: 0.6036\n",
      "Epoch 48/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5596\n",
      "Epoch 48: val_loss did not improve from 0.60161\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5598 - val_loss: 0.6036\n",
      "Epoch 49/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5573\n",
      "Epoch 49: val_loss improved from 0.60161 to 0.59936, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5596 - val_loss: 0.5994\n",
      "Epoch 50/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5688\n",
      "Epoch 50: val_loss did not improve from 0.59936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5673 - val_loss: 0.6105\n",
      "Epoch 51/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5528\n",
      "Epoch 51: val_loss did not improve from 0.59936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5535 - val_loss: 0.6031\n",
      "Epoch 52/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5587\n",
      "Epoch 52: val_loss did not improve from 0.59936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5596 - val_loss: 0.6000\n",
      "Epoch 53/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5469\n",
      "Epoch 53: val_loss improved from 0.59936 to 0.59909, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5475 - val_loss: 0.5991\n",
      "Epoch 54/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5451\n",
      "Epoch 54: val_loss improved from 0.59909 to 0.59749, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5484 - val_loss: 0.5975\n",
      "Epoch 55/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5533\n",
      "Epoch 55: val_loss improved from 0.59749 to 0.59716, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5531 - val_loss: 0.5972\n",
      "Epoch 56/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5599\n",
      "Epoch 56: val_loss did not improve from 0.59716\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5590 - val_loss: 0.6002\n",
      "Epoch 57/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5499\n",
      "Epoch 57: val_loss improved from 0.59716 to 0.59500, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5491 - val_loss: 0.5950\n",
      "Epoch 58/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5571\n",
      "Epoch 58: val_loss did not improve from 0.59500\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5555 - val_loss: 0.5976\n",
      "Epoch 59/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5415\n",
      "Epoch 59: val_loss did not improve from 0.59500\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5406 - val_loss: 0.6017\n",
      "Epoch 60/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5539\n",
      "Epoch 60: val_loss did not improve from 0.59500\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5537 - val_loss: 0.5956\n",
      "Epoch 61/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5554\n",
      "Epoch 61: val_loss did not improve from 0.59500\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5551 - val_loss: 0.5962\n",
      "Epoch 62/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5423\n",
      "Epoch 62: val_loss improved from 0.59500 to 0.59281, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5428 - val_loss: 0.5928\n",
      "Epoch 63/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5331\n",
      "Epoch 63: val_loss improved from 0.59281 to 0.59098, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5345 - val_loss: 0.5910\n",
      "Epoch 64/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5492\n",
      "Epoch 64: val_loss improved from 0.59098 to 0.59073, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5510 - val_loss: 0.5907\n",
      "Epoch 65/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5365\n",
      "Epoch 65: val_loss did not improve from 0.59073\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5355 - val_loss: 0.5919\n",
      "Epoch 66/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5486\n",
      "Epoch 66: val_loss improved from 0.59073 to 0.58932, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5487 - val_loss: 0.5893\n",
      "Epoch 67/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.5420\n",
      "Epoch 67: val_loss did not improve from 0.58932\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5412 - val_loss: 0.5940\n",
      "Epoch 68/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5437\n",
      "Epoch 68: val_loss did not improve from 0.58932\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5440 - val_loss: 0.5958\n",
      "Epoch 69/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5382\n",
      "Epoch 69: val_loss did not improve from 0.58932\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5414 - val_loss: 0.5894\n",
      "Epoch 70/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5268\n",
      "Epoch 70: val_loss did not improve from 0.58932\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5283 - val_loss: 0.5924\n",
      "Epoch 71/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5445\n",
      "Epoch 71: val_loss did not improve from 0.58932\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5418 - val_loss: 0.5899\n",
      "Epoch 72/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5261\n",
      "Epoch 72: val_loss did not improve from 0.58932\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5272 - val_loss: 0.5906\n",
      "Epoch 73/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5256\n",
      "Epoch 73: val_loss improved from 0.58932 to 0.58806, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5260 - val_loss: 0.5881\n",
      "Epoch 74/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5330\n",
      "Epoch 74: val_loss improved from 0.58806 to 0.58568, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5330 - val_loss: 0.5857\n",
      "Epoch 75/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5298\n",
      "Epoch 75: val_loss did not improve from 0.58568\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5285 - val_loss: 0.5871\n",
      "Epoch 76/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.5298\n",
      "Epoch 76: val_loss did not improve from 0.58568\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5291 - val_loss: 0.5864\n",
      "Epoch 77/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5171\n",
      "Epoch 77: val_loss did not improve from 0.58568\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5180 - val_loss: 0.5874\n",
      "Epoch 78/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5393\n",
      "Epoch 78: val_loss did not improve from 0.58568\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5399 - val_loss: 0.5876\n",
      "Epoch 79/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5329\n",
      "Epoch 79: val_loss did not improve from 0.58568\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5316 - val_loss: 0.5857\n",
      "Epoch 80/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5279\n",
      "Epoch 80: val_loss improved from 0.58568 to 0.58510, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5278 - val_loss: 0.5851\n",
      "Epoch 81/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5208\n",
      "Epoch 81: val_loss improved from 0.58510 to 0.58419, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5214 - val_loss: 0.5842\n",
      "Epoch 82/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5215\n",
      "Epoch 82: val_loss did not improve from 0.58419\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5239 - val_loss: 0.5853\n",
      "Epoch 83/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5213\n",
      "Epoch 83: val_loss improved from 0.58419 to 0.58366, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5215 - val_loss: 0.5837\n",
      "Epoch 84/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5235\n",
      "Epoch 84: val_loss did not improve from 0.58366\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5214 - val_loss: 0.6010\n",
      "Epoch 85/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5181\n",
      "Epoch 85: val_loss improved from 0.58366 to 0.58203, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5181 - val_loss: 0.5820\n",
      "Epoch 86/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.5168\n",
      "Epoch 86: val_loss did not improve from 0.58203\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5182 - val_loss: 0.5821\n",
      "Epoch 87/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5121\n",
      "Epoch 87: val_loss improved from 0.58203 to 0.57691, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5124 - val_loss: 0.5769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5089\n",
      "Epoch 88: val_loss did not improve from 0.57691\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5083 - val_loss: 0.5843\n",
      "Epoch 89/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5096\n",
      "Epoch 89: val_loss did not improve from 0.57691\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5103 - val_loss: 0.5802\n",
      "Epoch 90/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5235\n",
      "Epoch 90: val_loss did not improve from 0.57691\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5232 - val_loss: 0.5815\n",
      "Epoch 91/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5211\n",
      "Epoch 91: val_loss did not improve from 0.57691\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5206 - val_loss: 0.5784\n",
      "Epoch 92/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5128\n",
      "Epoch 92: val_loss did not improve from 0.57691\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5142 - val_loss: 0.5788\n",
      "Epoch 93/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5105\n",
      "Epoch 93: val_loss did not improve from 0.57691\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5107 - val_loss: 0.5774\n",
      "Epoch 94/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.5131\n",
      "Epoch 94: val_loss did not improve from 0.57691\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5164 - val_loss: 0.5831\n",
      "Epoch 95/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5019\n",
      "Epoch 95: val_loss did not improve from 0.57691\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5044 - val_loss: 0.5772\n",
      "Epoch 96/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5157\n",
      "Epoch 96: val_loss did not improve from 0.57691\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5146 - val_loss: 0.5771\n",
      "Epoch 97/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5135\n",
      "Epoch 97: val_loss improved from 0.57691 to 0.57597, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5139 - val_loss: 0.5760\n",
      "Epoch 98/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5162\n",
      "Epoch 98: val_loss did not improve from 0.57597\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5169 - val_loss: 0.5917\n",
      "Epoch 99/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5031\n",
      "Epoch 99: val_loss did not improve from 0.57597\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5051 - val_loss: 0.5767\n",
      "Epoch 100/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5222\n",
      "Epoch 100: val_loss did not improve from 0.57597\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5217 - val_loss: 0.5844\n",
      "\n",
      "Train/Test model on Fold #1.\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8354\n",
      "Epoch 1: val_loss improved from inf to 0.80963, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 3s 16ms/step - loss: 0.8354 - val_loss: 0.8096\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8118\n",
      "Epoch 2: val_loss improved from 0.80963 to 0.79835, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.8118 - val_loss: 0.7984\n",
      "Epoch 3/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7942\n",
      "Epoch 3: val_loss improved from 0.79835 to 0.78643, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7939 - val_loss: 0.7864\n",
      "Epoch 4/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7855\n",
      "Epoch 4: val_loss improved from 0.78643 to 0.77541, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7857 - val_loss: 0.7754\n",
      "Epoch 5/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.7755\n",
      "Epoch 5: val_loss improved from 0.77541 to 0.76336, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7753 - val_loss: 0.7634\n",
      "Epoch 6/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7543\n",
      "Epoch 6: val_loss improved from 0.76336 to 0.74500, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7542 - val_loss: 0.7450\n",
      "Epoch 7/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.7346\n",
      "Epoch 7: val_loss improved from 0.74500 to 0.72397, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7361 - val_loss: 0.7240\n",
      "Epoch 8/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.7235\n",
      "Epoch 8: val_loss improved from 0.72397 to 0.70951, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7239 - val_loss: 0.7095\n",
      "Epoch 9/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.7087\n",
      "Epoch 9: val_loss improved from 0.70951 to 0.69919, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7074 - val_loss: 0.6992\n",
      "Epoch 10/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6889\n",
      "Epoch 10: val_loss improved from 0.69919 to 0.68982, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6898\n",
      "Epoch 11/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6894\n",
      "Epoch 11: val_loss improved from 0.68982 to 0.68230, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6892 - val_loss: 0.6823\n",
      "Epoch 12/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6776\n",
      "Epoch 12: val_loss improved from 0.68230 to 0.67407, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6764 - val_loss: 0.6741\n",
      "Epoch 13/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.6673\n",
      "Epoch 13: val_loss improved from 0.67407 to 0.66978, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6666 - val_loss: 0.6698\n",
      "Epoch 14/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6659\n",
      "Epoch 14: val_loss improved from 0.66978 to 0.66321, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6675 - val_loss: 0.6632\n",
      "Epoch 15/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6523\n",
      "Epoch 15: val_loss improved from 0.66321 to 0.65837, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6533 - val_loss: 0.6584\n",
      "Epoch 16/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6534\n",
      "Epoch 16: val_loss improved from 0.65837 to 0.65460, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6527 - val_loss: 0.6546\n",
      "Epoch 17/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6352\n",
      "Epoch 17: val_loss improved from 0.65460 to 0.65440, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6350 - val_loss: 0.6544\n",
      "Epoch 18/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6384\n",
      "Epoch 18: val_loss improved from 0.65440 to 0.64450, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6386 - val_loss: 0.6445\n",
      "Epoch 19/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6288\n",
      "Epoch 19: val_loss improved from 0.64450 to 0.64219, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6307 - val_loss: 0.6422\n",
      "Epoch 20/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6281\n",
      "Epoch 20: val_loss improved from 0.64219 to 0.63681, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6275 - val_loss: 0.6368\n",
      "Epoch 21/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6163\n",
      "Epoch 21: val_loss improved from 0.63681 to 0.63329, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6176 - val_loss: 0.6333\n",
      "Epoch 22/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6250\n",
      "Epoch 22: val_loss did not improve from 0.63329\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6253 - val_loss: 0.6371\n",
      "Epoch 23/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6184\n",
      "Epoch 23: val_loss improved from 0.63329 to 0.62983, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6186 - val_loss: 0.6298\n",
      "Epoch 24/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6204\n",
      "Epoch 24: val_loss improved from 0.62983 to 0.62718, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6209 - val_loss: 0.6272\n",
      "Epoch 25/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6108\n",
      "Epoch 25: val_loss did not improve from 0.62718\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6116 - val_loss: 0.6284\n",
      "Epoch 26/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6110\n",
      "Epoch 26: val_loss improved from 0.62718 to 0.62372, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6119 - val_loss: 0.6237\n",
      "Epoch 27/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5962\n",
      "Epoch 27: val_loss improved from 0.62372 to 0.62292, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5961 - val_loss: 0.6229\n",
      "Epoch 28/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5950\n",
      "Epoch 28: val_loss improved from 0.62292 to 0.62160, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5945 - val_loss: 0.6216\n",
      "Epoch 29/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5862\n",
      "Epoch 29: val_loss did not improve from 0.62160\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5863 - val_loss: 0.6223\n",
      "Epoch 30/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5904\n",
      "Epoch 30: val_loss did not improve from 0.62160\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5893 - val_loss: 0.6226\n",
      "Epoch 31/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6032\n",
      "Epoch 31: val_loss improved from 0.62160 to 0.61862, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6015 - val_loss: 0.6186\n",
      "Epoch 32/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5943\n",
      "Epoch 32: val_loss improved from 0.61862 to 0.61652, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5953 - val_loss: 0.6165\n",
      "Epoch 33/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5874\n",
      "Epoch 33: val_loss improved from 0.61652 to 0.61371, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5866 - val_loss: 0.6137\n",
      "Epoch 34/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5813\n",
      "Epoch 34: val_loss improved from 0.61371 to 0.61328, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5806 - val_loss: 0.6133\n",
      "Epoch 35/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5860\n",
      "Epoch 35: val_loss did not improve from 0.61328\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5845 - val_loss: 0.6190\n",
      "Epoch 36/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5812\n",
      "Epoch 36: val_loss improved from 0.61328 to 0.61180, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5798 - val_loss: 0.6118\n",
      "Epoch 37/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5781\n",
      "Epoch 37: val_loss improved from 0.61180 to 0.60938, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5776 - val_loss: 0.6094\n",
      "Epoch 38/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5817\n",
      "Epoch 38: val_loss did not improve from 0.60938\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5814 - val_loss: 0.6100\n",
      "Epoch 39/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5685\n",
      "Epoch 39: val_loss did not improve from 0.60938\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5693 - val_loss: 0.6107\n",
      "Epoch 40/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5726\n",
      "Epoch 40: val_loss improved from 0.60938 to 0.60817, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5711 - val_loss: 0.6082\n",
      "Epoch 41/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5741\n",
      "Epoch 41: val_loss did not improve from 0.60817\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5741 - val_loss: 0.6103\n",
      "Epoch 42/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5696\n",
      "Epoch 42: val_loss improved from 0.60817 to 0.60517, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5721 - val_loss: 0.6052\n",
      "Epoch 43/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5607\n",
      "Epoch 43: val_loss did not improve from 0.60517\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5634 - val_loss: 0.6056\n",
      "Epoch 44/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5693\n",
      "Epoch 44: val_loss improved from 0.60517 to 0.60435, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5663 - val_loss: 0.6043\n",
      "Epoch 45/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5603\n",
      "Epoch 45: val_loss improved from 0.60435 to 0.60253, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5573 - val_loss: 0.6025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5604\n",
      "Epoch 46: val_loss did not improve from 0.60253\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5611 - val_loss: 0.6074\n",
      "Epoch 47/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5677\n",
      "Epoch 47: val_loss did not improve from 0.60253\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5689 - val_loss: 0.6058\n",
      "Epoch 48/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5628\n",
      "Epoch 48: val_loss did not improve from 0.60253\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5635 - val_loss: 0.6041\n",
      "Epoch 49/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5700\n",
      "Epoch 49: val_loss did not improve from 0.60253\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5702 - val_loss: 0.6056\n",
      "Epoch 50/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5559\n",
      "Epoch 50: val_loss did not improve from 0.60253\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5546 - val_loss: 0.6062\n",
      "Epoch 51/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5614\n",
      "Epoch 51: val_loss did not improve from 0.60253\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5597 - val_loss: 0.6027\n",
      "Epoch 52/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5541\n",
      "Epoch 52: val_loss did not improve from 0.60253\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5543 - val_loss: 0.6025\n",
      "Epoch 53/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5583\n",
      "Epoch 53: val_loss improved from 0.60253 to 0.59896, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5574 - val_loss: 0.5990\n",
      "Epoch 54/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5474\n",
      "Epoch 54: val_loss did not improve from 0.59896\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5463 - val_loss: 0.6015\n",
      "Epoch 55/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5512\n",
      "Epoch 55: val_loss did not improve from 0.59896\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5486 - val_loss: 0.6006\n",
      "Epoch 56/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5510\n",
      "Epoch 56: val_loss did not improve from 0.59896\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5514 - val_loss: 0.6017\n",
      "Epoch 57/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5421\n",
      "Epoch 57: val_loss did not improve from 0.59896\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5391 - val_loss: 0.6035\n",
      "Epoch 58/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5480\n",
      "Epoch 58: val_loss did not improve from 0.59896\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5481 - val_loss: 0.6083\n",
      "Epoch 59/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5408\n",
      "Epoch 59: val_loss did not improve from 0.59896\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5422 - val_loss: 0.6031\n",
      "Epoch 60/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5411\n",
      "Epoch 60: val_loss did not improve from 0.59896\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5419 - val_loss: 0.6087\n",
      "Epoch 61/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5409\n",
      "Epoch 61: val_loss improved from 0.59896 to 0.59891, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5404 - val_loss: 0.5989\n",
      "Epoch 62/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5343\n",
      "Epoch 62: val_loss did not improve from 0.59891\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5325 - val_loss: 0.6021\n",
      "Epoch 63/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5527\n",
      "Epoch 63: val_loss did not improve from 0.59891\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5533 - val_loss: 0.6008\n",
      "Epoch 64/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5409\n",
      "Epoch 64: val_loss did not improve from 0.59891\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5405 - val_loss: 0.6029\n",
      "Epoch 65/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5507\n",
      "Epoch 65: val_loss did not improve from 0.59891\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5499 - val_loss: 0.5991\n",
      "Epoch 66/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5320\n",
      "Epoch 66: val_loss did not improve from 0.59891\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5322 - val_loss: 0.5998\n",
      "Epoch 67/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5352\n",
      "Epoch 67: val_loss did not improve from 0.59891\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5340 - val_loss: 0.6010\n",
      "Epoch 68/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5359\n",
      "Epoch 68: val_loss did not improve from 0.59891\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5340 - val_loss: 0.6005\n",
      "Epoch 69/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5400\n",
      "Epoch 69: val_loss improved from 0.59891 to 0.59825, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5406 - val_loss: 0.5982\n",
      "Epoch 70/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5332\n",
      "Epoch 70: val_loss did not improve from 0.59825\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5320 - val_loss: 0.5993\n",
      "Epoch 71/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5248\n",
      "Epoch 71: val_loss did not improve from 0.59825\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5263 - val_loss: 0.6014\n",
      "Epoch 72/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5269\n",
      "Epoch 72: val_loss did not improve from 0.59825\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5262 - val_loss: 0.6005\n",
      "Epoch 73/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5456\n",
      "Epoch 73: val_loss did not improve from 0.59825\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5461 - val_loss: 0.5992\n",
      "Epoch 74/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5315\n",
      "Epoch 74: val_loss did not improve from 0.59825\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5331 - val_loss: 0.5992\n",
      "Epoch 75/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5376\n",
      "Epoch 75: val_loss did not improve from 0.59825\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5370 - val_loss: 0.6010\n",
      "Epoch 76/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5218\n",
      "Epoch 76: val_loss did not improve from 0.59825\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5263 - val_loss: 0.6001\n",
      "Epoch 77/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5249\n",
      "Epoch 77: val_loss did not improve from 0.59825\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5254 - val_loss: 0.6008\n",
      "Epoch 78/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5348\n",
      "Epoch 78: val_loss improved from 0.59825 to 0.59771, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5347 - val_loss: 0.5977\n",
      "Epoch 79/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5315\n",
      "Epoch 79: val_loss did not improve from 0.59771\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5316 - val_loss: 0.5990\n",
      "Epoch 80/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5362\n",
      "Epoch 80: val_loss did not improve from 0.59771\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5378 - val_loss: 0.5999\n",
      "Epoch 81/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5238\n",
      "Epoch 81: val_loss did not improve from 0.59771\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5250 - val_loss: 0.6028\n",
      "Epoch 82/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5330\n",
      "Epoch 82: val_loss improved from 0.59771 to 0.59413, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5324 - val_loss: 0.5941\n",
      "Epoch 83/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5217\n",
      "Epoch 83: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5200 - val_loss: 0.5992\n",
      "Epoch 84/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5197\n",
      "Epoch 84: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5188 - val_loss: 0.6032\n",
      "Epoch 85/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5272\n",
      "Epoch 85: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5274 - val_loss: 0.5997\n",
      "Epoch 86/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5198\n",
      "Epoch 86: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5197 - val_loss: 0.6007\n",
      "Epoch 87/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5200\n",
      "Epoch 87: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5228 - val_loss: 0.6039\n",
      "Epoch 88/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5187\n",
      "Epoch 88: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5181 - val_loss: 0.6031\n",
      "Epoch 89/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5226\n",
      "Epoch 89: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5226 - val_loss: 0.6048\n",
      "Epoch 90/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5268\n",
      "Epoch 90: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5265 - val_loss: 0.6021\n",
      "Epoch 91/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5309\n",
      "Epoch 91: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5321 - val_loss: 0.5980\n",
      "Epoch 92/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5134\n",
      "Epoch 92: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5141 - val_loss: 0.6011\n",
      "Epoch 93/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5076\n",
      "Epoch 93: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5066 - val_loss: 0.6037\n",
      "Epoch 94/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5243\n",
      "Epoch 94: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5247 - val_loss: 0.5997\n",
      "Epoch 95/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5202\n",
      "Epoch 95: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5196 - val_loss: 0.5989\n",
      "Epoch 96/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5183\n",
      "Epoch 96: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5190 - val_loss: 0.6012\n",
      "Epoch 97/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5101\n",
      "Epoch 97: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5123 - val_loss: 0.6024\n",
      "Epoch 98/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5262\n",
      "Epoch 98: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5262 - val_loss: 0.6002\n",
      "Epoch 99/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5280\n",
      "Epoch 99: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5289 - val_loss: 0.6017\n",
      "Epoch 100/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5125\n",
      "Epoch 100: val_loss did not improve from 0.59413\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5120 - val_loss: 0.5989\n",
      "\n",
      "Train/Test model on Fold #2.\n",
      "Epoch 1/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.8374\n",
      "Epoch 1: val_loss improved from inf to 0.80367, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 3s 14ms/step - loss: 0.8365 - val_loss: 0.8037\n",
      "Epoch 2/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.8054\n",
      "Epoch 2: val_loss improved from 0.80367 to 0.79228, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.8051 - val_loss: 0.7923\n",
      "Epoch 3/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.7921\n",
      "Epoch 3: val_loss improved from 0.79228 to 0.78290, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7918 - val_loss: 0.7829\n",
      "Epoch 4/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.7829\n",
      "Epoch 4: val_loss improved from 0.78290 to 0.77352, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7820 - val_loss: 0.7735\n",
      "Epoch 5/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7722\n",
      "Epoch 5: val_loss improved from 0.77352 to 0.76625, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7725 - val_loss: 0.7662\n",
      "Epoch 6/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.7642\n",
      "Epoch 6: val_loss improved from 0.76625 to 0.75859, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7645 - val_loss: 0.7586\n",
      "Epoch 7/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7567\n",
      "Epoch 7: val_loss improved from 0.75859 to 0.75159, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7571 - val_loss: 0.7516\n",
      "Epoch 8/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.7547\n",
      "Epoch 8: val_loss improved from 0.75159 to 0.74501, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7548 - val_loss: 0.7450\n",
      "Epoch 9/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.7442\n",
      "Epoch 9: val_loss improved from 0.74501 to 0.73590, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7454 - val_loss: 0.7359\n",
      "Epoch 10/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7338\n",
      "Epoch 10: val_loss improved from 0.73590 to 0.72169, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7336 - val_loss: 0.7217\n",
      "Epoch 11/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7164\n",
      "Epoch 11: val_loss improved from 0.72169 to 0.69594, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7160 - val_loss: 0.6959\n",
      "Epoch 12/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.7007\n",
      "Epoch 12: val_loss improved from 0.69594 to 0.67815, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7013 - val_loss: 0.6781\n",
      "Epoch 13/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6861\n",
      "Epoch 13: val_loss improved from 0.67815 to 0.66195, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6865 - val_loss: 0.6619\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6773\n",
      "Epoch 14: val_loss improved from 0.66195 to 0.65185, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6765 - val_loss: 0.6518\n",
      "Epoch 15/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6596\n",
      "Epoch 15: val_loss improved from 0.65185 to 0.64986, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6599 - val_loss: 0.6499\n",
      "Epoch 16/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6542\n",
      "Epoch 16: val_loss improved from 0.64986 to 0.64683, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6537 - val_loss: 0.6468\n",
      "Epoch 17/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6412\n",
      "Epoch 17: val_loss improved from 0.64683 to 0.63564, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6435 - val_loss: 0.6356\n",
      "Epoch 18/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6381\n",
      "Epoch 18: val_loss improved from 0.63564 to 0.63311, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6410 - val_loss: 0.6331\n",
      "Epoch 19/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6350\n",
      "Epoch 19: val_loss improved from 0.63311 to 0.63086, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6339 - val_loss: 0.6309\n",
      "Epoch 20/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6329\n",
      "Epoch 20: val_loss improved from 0.63086 to 0.62888, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6333 - val_loss: 0.6289\n",
      "Epoch 21/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6211\n",
      "Epoch 21: val_loss improved from 0.62888 to 0.62610, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6219 - val_loss: 0.6261\n",
      "Epoch 22/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6163\n",
      "Epoch 22: val_loss improved from 0.62610 to 0.62260, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6167 - val_loss: 0.6226\n",
      "Epoch 23/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6209\n",
      "Epoch 23: val_loss improved from 0.62260 to 0.61968, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6213 - val_loss: 0.6197\n",
      "Epoch 24/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6196\n",
      "Epoch 24: val_loss did not improve from 0.61968\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6205 - val_loss: 0.6285\n",
      "Epoch 25/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6068\n",
      "Epoch 25: val_loss improved from 0.61968 to 0.61841, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6081 - val_loss: 0.6184\n",
      "Epoch 26/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6002\n",
      "Epoch 26: val_loss improved from 0.61841 to 0.61593, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5996 - val_loss: 0.6159\n",
      "Epoch 27/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5968\n",
      "Epoch 27: val_loss improved from 0.61593 to 0.61132, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6012 - val_loss: 0.6113\n",
      "Epoch 28/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5924\n",
      "Epoch 28: val_loss did not improve from 0.61132\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5948 - val_loss: 0.6133\n",
      "Epoch 29/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6000\n",
      "Epoch 29: val_loss improved from 0.61132 to 0.61047, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5978 - val_loss: 0.6105\n",
      "Epoch 30/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5907\n",
      "Epoch 30: val_loss improved from 0.61047 to 0.61010, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5908 - val_loss: 0.6101\n",
      "Epoch 31/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5859\n",
      "Epoch 31: val_loss improved from 0.61010 to 0.60943, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5865 - val_loss: 0.6094\n",
      "Epoch 32/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5822\n",
      "Epoch 32: val_loss improved from 0.60943 to 0.60622, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5847 - val_loss: 0.6062\n",
      "Epoch 33/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5891\n",
      "Epoch 33: val_loss did not improve from 0.60622\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5862 - val_loss: 0.6067\n",
      "Epoch 34/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5772\n",
      "Epoch 34: val_loss did not improve from 0.60622\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5781 - val_loss: 0.6134\n",
      "Epoch 35/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5843\n",
      "Epoch 35: val_loss improved from 0.60622 to 0.60115, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5826 - val_loss: 0.6012\n",
      "Epoch 36/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5718\n",
      "Epoch 36: val_loss did not improve from 0.60115\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5742 - val_loss: 0.6094\n",
      "Epoch 37/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5857\n",
      "Epoch 37: val_loss did not improve from 0.60115\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5871 - val_loss: 0.6013\n",
      "Epoch 38/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5670\n",
      "Epoch 38: val_loss did not improve from 0.60115\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5672 - val_loss: 0.6034\n",
      "Epoch 39/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5684\n",
      "Epoch 39: val_loss improved from 0.60115 to 0.59888, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5677 - val_loss: 0.5989\n",
      "Epoch 40/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5692\n",
      "Epoch 40: val_loss did not improve from 0.59888\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5710 - val_loss: 0.6041\n",
      "Epoch 41/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5641\n",
      "Epoch 41: val_loss improved from 0.59888 to 0.59801, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5653 - val_loss: 0.5980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5501\n",
      "Epoch 42: val_loss improved from 0.59801 to 0.59755, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5501 - val_loss: 0.5976\n",
      "Epoch 43/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5466\n",
      "Epoch 43: val_loss did not improve from 0.59755\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5471 - val_loss: 0.5997\n",
      "Epoch 44/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5548\n",
      "Epoch 44: val_loss did not improve from 0.59755\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5545 - val_loss: 0.6073\n",
      "Epoch 45/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5571\n",
      "Epoch 45: val_loss did not improve from 0.59755\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5556 - val_loss: 0.5989\n",
      "Epoch 46/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5484\n",
      "Epoch 46: val_loss improved from 0.59755 to 0.59683, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5494 - val_loss: 0.5968\n",
      "Epoch 47/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5568\n",
      "Epoch 47: val_loss improved from 0.59683 to 0.59664, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5565 - val_loss: 0.5966\n",
      "Epoch 48/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5521\n",
      "Epoch 48: val_loss did not improve from 0.59664\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5515 - val_loss: 0.5998\n",
      "Epoch 49/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5472\n",
      "Epoch 49: val_loss did not improve from 0.59664\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5485 - val_loss: 0.5975\n",
      "Epoch 50/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5411\n",
      "Epoch 50: val_loss did not improve from 0.59664\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5406 - val_loss: 0.6020\n",
      "Epoch 51/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5520\n",
      "Epoch 51: val_loss improved from 0.59664 to 0.59568, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5491 - val_loss: 0.5957\n",
      "Epoch 52/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5416\n",
      "Epoch 52: val_loss did not improve from 0.59568\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5410 - val_loss: 0.5966\n",
      "Epoch 53/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5374\n",
      "Epoch 53: val_loss improved from 0.59568 to 0.59406, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5376 - val_loss: 0.5941\n",
      "Epoch 54/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5459\n",
      "Epoch 54: val_loss did not improve from 0.59406\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5454 - val_loss: 0.5949\n",
      "Epoch 55/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5386\n",
      "Epoch 55: val_loss did not improve from 0.59406\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5388 - val_loss: 0.5958\n",
      "Epoch 56/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5273\n",
      "Epoch 56: val_loss did not improve from 0.59406\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5273 - val_loss: 0.5962\n",
      "Epoch 57/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5367\n",
      "Epoch 57: val_loss did not improve from 0.59406\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5358 - val_loss: 0.5942\n",
      "Epoch 58/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5375\n",
      "Epoch 58: val_loss did not improve from 0.59406\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5384 - val_loss: 0.5942\n",
      "Epoch 59/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5374\n",
      "Epoch 59: val_loss did not improve from 0.59406\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5380 - val_loss: 0.5956\n",
      "Epoch 60/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5430\n",
      "Epoch 60: val_loss did not improve from 0.59406\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5406 - val_loss: 0.5976\n",
      "Epoch 61/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5284\n",
      "Epoch 61: val_loss did not improve from 0.59406\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5297 - val_loss: 0.6006\n",
      "Epoch 62/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5377\n",
      "Epoch 62: val_loss did not improve from 0.59406\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5382 - val_loss: 0.6056\n",
      "Epoch 63/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5496\n",
      "Epoch 63: val_loss improved from 0.59406 to 0.59202, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5491 - val_loss: 0.5920\n",
      "Epoch 64/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5345\n",
      "Epoch 64: val_loss improved from 0.59202 to 0.58936, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5333 - val_loss: 0.5894\n",
      "Epoch 65/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5341\n",
      "Epoch 65: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5337 - val_loss: 0.5927\n",
      "Epoch 66/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5258\n",
      "Epoch 66: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5276 - val_loss: 0.6002\n",
      "Epoch 67/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5314\n",
      "Epoch 67: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5326 - val_loss: 0.6026\n",
      "Epoch 68/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5318\n",
      "Epoch 68: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5321 - val_loss: 0.5959\n",
      "Epoch 69/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5233\n",
      "Epoch 69: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5217 - val_loss: 0.5935\n",
      "Epoch 70/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5273\n",
      "Epoch 70: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5278 - val_loss: 0.5963\n",
      "Epoch 71/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5195\n",
      "Epoch 71: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5172 - val_loss: 0.5977\n",
      "Epoch 72/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5204\n",
      "Epoch 72: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5195 - val_loss: 0.5910\n",
      "Epoch 73/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5244\n",
      "Epoch 73: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5253 - val_loss: 0.5977\n",
      "Epoch 74/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5334\n",
      "Epoch 74: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5347 - val_loss: 0.5926\n",
      "Epoch 75/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5210\n",
      "Epoch 75: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5193 - val_loss: 0.5924\n",
      "Epoch 76/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5212\n",
      "Epoch 76: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5215 - val_loss: 0.5920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5196\n",
      "Epoch 77: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5187 - val_loss: 0.5900\n",
      "Epoch 78/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5194\n",
      "Epoch 78: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5211 - val_loss: 0.5946\n",
      "Epoch 79/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5237\n",
      "Epoch 79: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5257 - val_loss: 0.5905\n",
      "Epoch 80/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5217\n",
      "Epoch 80: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5210 - val_loss: 0.5905\n",
      "Epoch 81/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5202\n",
      "Epoch 81: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5209 - val_loss: 0.5912\n",
      "Epoch 82/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5082\n",
      "Epoch 82: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5088 - val_loss: 0.5958\n",
      "Epoch 83/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5198\n",
      "Epoch 83: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5169 - val_loss: 0.6091\n",
      "Epoch 84/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5153\n",
      "Epoch 84: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5183 - val_loss: 0.5993\n",
      "Epoch 85/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5147\n",
      "Epoch 85: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5127 - val_loss: 0.5976\n",
      "Epoch 86/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5160\n",
      "Epoch 86: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5148 - val_loss: 0.5921\n",
      "Epoch 87/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5119\n",
      "Epoch 87: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5128 - val_loss: 0.5997\n",
      "Epoch 88/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5063\n",
      "Epoch 88: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5070 - val_loss: 0.5921\n",
      "Epoch 89/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5213\n",
      "Epoch 89: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5199 - val_loss: 0.5906\n",
      "Epoch 90/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5199\n",
      "Epoch 90: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5206 - val_loss: 0.5902\n",
      "Epoch 91/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5057\n",
      "Epoch 91: val_loss did not improve from 0.58936\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5064 - val_loss: 0.5956\n",
      "Epoch 92/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5197\n",
      "Epoch 92: val_loss improved from 0.58936 to 0.58588, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5212 - val_loss: 0.5859\n",
      "Epoch 93/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5157\n",
      "Epoch 93: val_loss did not improve from 0.58588\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5138 - val_loss: 0.5967\n",
      "Epoch 94/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5188\n",
      "Epoch 94: val_loss did not improve from 0.58588\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5179 - val_loss: 0.5871\n",
      "Epoch 95/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5148\n",
      "Epoch 95: val_loss did not improve from 0.58588\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5167 - val_loss: 0.5983\n",
      "Epoch 96/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5054\n",
      "Epoch 96: val_loss did not improve from 0.58588\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5061 - val_loss: 0.5973\n",
      "Epoch 97/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5031\n",
      "Epoch 97: val_loss did not improve from 0.58588\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5045 - val_loss: 0.5920\n",
      "Epoch 98/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.5175\n",
      "Epoch 98: val_loss did not improve from 0.58588\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5162 - val_loss: 0.5880\n",
      "Epoch 99/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5118\n",
      "Epoch 99: val_loss did not improve from 0.58588\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5135 - val_loss: 0.5861\n",
      "Epoch 100/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5200\n",
      "Epoch 100: val_loss did not improve from 0.58588\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5166 - val_loss: 0.5906\n",
      "\n",
      "Train/Test model on Fold #3.\n",
      "Epoch 1/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.8378\n",
      "Epoch 1: val_loss improved from inf to 0.80815, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 3s 15ms/step - loss: 0.8344 - val_loss: 0.8082\n",
      "Epoch 2/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.8107\n",
      "Epoch 2: val_loss improved from 0.80815 to 0.78993, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.8091 - val_loss: 0.7899\n",
      "Epoch 3/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.7862\n",
      "Epoch 3: val_loss improved from 0.78993 to 0.77797, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7851 - val_loss: 0.7780\n",
      "Epoch 4/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.7781\n",
      "Epoch 4: val_loss improved from 0.77797 to 0.76417, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7767 - val_loss: 0.7642\n",
      "Epoch 5/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.7604\n",
      "Epoch 5: val_loss improved from 0.76417 to 0.75114, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7596 - val_loss: 0.7511\n",
      "Epoch 6/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.7515\n",
      "Epoch 6: val_loss improved from 0.75114 to 0.73037, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7497 - val_loss: 0.7304\n",
      "Epoch 7/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.7360\n",
      "Epoch 7: val_loss improved from 0.73037 to 0.71377, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.7333 - val_loss: 0.7138\n",
      "Epoch 8/100\n",
      "66/74 [=========================>....] - ETA: 0s - loss: 0.7172\n",
      "Epoch 8: val_loss improved from 0.71377 to 0.70354, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7156 - val_loss: 0.7035\n",
      "Epoch 9/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6967\n",
      "Epoch 9: val_loss improved from 0.70354 to 0.67847, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6967 - val_loss: 0.6785\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/74 [============================>.] - ETA: 0s - loss: 0.6852\n",
      "Epoch 10: val_loss improved from 0.67847 to 0.66687, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6847 - val_loss: 0.6669\n",
      "Epoch 11/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6727\n",
      "Epoch 11: val_loss improved from 0.66687 to 0.65707, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6739 - val_loss: 0.6571\n",
      "Epoch 12/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.6764\n",
      "Epoch 12: val_loss improved from 0.65707 to 0.65494, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6750 - val_loss: 0.6549\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6680\n",
      "Epoch 13: val_loss improved from 0.65494 to 0.65184, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6680 - val_loss: 0.6518\n",
      "Epoch 14/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6511\n",
      "Epoch 14: val_loss improved from 0.65184 to 0.64233, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6516 - val_loss: 0.6423\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6452\n",
      "Epoch 15: val_loss improved from 0.64233 to 0.64017, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6452 - val_loss: 0.6402\n",
      "Epoch 16/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6488\n",
      "Epoch 16: val_loss improved from 0.64017 to 0.63883, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6479 - val_loss: 0.6388\n",
      "Epoch 17/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.6409\n",
      "Epoch 17: val_loss improved from 0.63883 to 0.63693, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6392 - val_loss: 0.6369\n",
      "Epoch 18/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6398\n",
      "Epoch 18: val_loss improved from 0.63693 to 0.63603, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6392 - val_loss: 0.6360\n",
      "Epoch 19/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6253\n",
      "Epoch 19: val_loss improved from 0.63603 to 0.63308, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6270 - val_loss: 0.6331\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6266\n",
      "Epoch 20: val_loss improved from 0.63308 to 0.63165, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6266 - val_loss: 0.6316\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6238\n",
      "Epoch 21: val_loss improved from 0.63165 to 0.63049, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6238 - val_loss: 0.6305\n",
      "Epoch 22/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.6165\n",
      "Epoch 22: val_loss improved from 0.63049 to 0.62290, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6169 - val_loss: 0.6229\n",
      "Epoch 23/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6131\n",
      "Epoch 23: val_loss improved from 0.62290 to 0.62138, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6141 - val_loss: 0.6214\n",
      "Epoch 24/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6056\n",
      "Epoch 24: val_loss improved from 0.62138 to 0.62028, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6078 - val_loss: 0.6203\n",
      "Epoch 25/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.6145\n",
      "Epoch 25: val_loss improved from 0.62028 to 0.61741, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6104 - val_loss: 0.6174\n",
      "Epoch 26/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.6004\n",
      "Epoch 26: val_loss did not improve from 0.61741\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6041 - val_loss: 0.6259\n",
      "Epoch 27/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.6029\n",
      "Epoch 27: val_loss did not improve from 0.61741\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6048 - val_loss: 0.6179\n",
      "Epoch 28/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5928\n",
      "Epoch 28: val_loss improved from 0.61741 to 0.61498, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5922 - val_loss: 0.6150\n",
      "Epoch 29/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5906\n",
      "Epoch 29: val_loss did not improve from 0.61498\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5918 - val_loss: 0.6150\n",
      "Epoch 30/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5897\n",
      "Epoch 30: val_loss improved from 0.61498 to 0.61422, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5887 - val_loss: 0.6142\n",
      "Epoch 31/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5687\n",
      "Epoch 31: val_loss improved from 0.61422 to 0.61418, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5687 - val_loss: 0.6142\n",
      "Epoch 32/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5895\n",
      "Epoch 32: val_loss improved from 0.61418 to 0.61002, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5901 - val_loss: 0.6100\n",
      "Epoch 33/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5838\n",
      "Epoch 33: val_loss did not improve from 0.61002\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5821 - val_loss: 0.6118\n",
      "Epoch 34/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5849\n",
      "Epoch 34: val_loss improved from 0.61002 to 0.60721, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5846 - val_loss: 0.6072\n",
      "Epoch 35/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5900\n",
      "Epoch 35: val_loss did not improve from 0.60721\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5911 - val_loss: 0.6074\n",
      "Epoch 36/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5748\n",
      "Epoch 36: val_loss did not improve from 0.60721\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5734 - val_loss: 0.6095\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/74 [============================>.] - ETA: 0s - loss: 0.5792\n",
      "Epoch 37: val_loss improved from 0.60721 to 0.60507, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5784 - val_loss: 0.6051\n",
      "Epoch 38/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5679\n",
      "Epoch 38: val_loss did not improve from 0.60507\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5695 - val_loss: 0.6078\n",
      "Epoch 39/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5725\n",
      "Epoch 39: val_loss did not improve from 0.60507\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5725 - val_loss: 0.6113\n",
      "Epoch 40/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5617\n",
      "Epoch 40: val_loss improved from 0.60507 to 0.60473, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5617 - val_loss: 0.6047\n",
      "Epoch 41/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5683\n",
      "Epoch 41: val_loss did not improve from 0.60473\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5685 - val_loss: 0.6049\n",
      "Epoch 42/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5644\n",
      "Epoch 42: val_loss did not improve from 0.60473\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5644 - val_loss: 0.6070\n",
      "Epoch 43/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5593\n",
      "Epoch 43: val_loss improved from 0.60473 to 0.60393, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5594 - val_loss: 0.6039\n",
      "Epoch 44/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5616\n",
      "Epoch 44: val_loss did not improve from 0.60393\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5632 - val_loss: 0.6057\n",
      "Epoch 45/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5599\n",
      "Epoch 45: val_loss did not improve from 0.60393\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5614 - val_loss: 0.6042\n",
      "Epoch 46/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5607\n",
      "Epoch 46: val_loss improved from 0.60393 to 0.60118, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5597 - val_loss: 0.6012\n",
      "Epoch 47/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5521\n",
      "Epoch 47: val_loss did not improve from 0.60118\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5544 - val_loss: 0.6056\n",
      "Epoch 48/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5576\n",
      "Epoch 48: val_loss improved from 0.60118 to 0.60083, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5556 - val_loss: 0.6008\n",
      "Epoch 49/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5456\n",
      "Epoch 49: val_loss did not improve from 0.60083\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5473 - val_loss: 0.6031\n",
      "Epoch 50/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5435\n",
      "Epoch 50: val_loss did not improve from 0.60083\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5435 - val_loss: 0.6042\n",
      "Epoch 51/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5534\n",
      "Epoch 51: val_loss improved from 0.60083 to 0.59925, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5527 - val_loss: 0.5992\n",
      "Epoch 52/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5404\n",
      "Epoch 52: val_loss did not improve from 0.59925\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5380 - val_loss: 0.6014\n",
      "Epoch 53/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.5359\n",
      "Epoch 53: val_loss did not improve from 0.59925\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5390 - val_loss: 0.6044\n",
      "Epoch 54/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5505\n",
      "Epoch 54: val_loss did not improve from 0.59925\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5469 - val_loss: 0.6011\n",
      "Epoch 55/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5330\n",
      "Epoch 55: val_loss did not improve from 0.59925\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5313 - val_loss: 0.6036\n",
      "Epoch 56/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.5514\n",
      "Epoch 56: val_loss did not improve from 0.59925\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5485 - val_loss: 0.6044\n",
      "Epoch 57/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5471\n",
      "Epoch 57: val_loss did not improve from 0.59925\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5468 - val_loss: 0.6054\n",
      "Epoch 58/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.5251\n",
      "Epoch 58: val_loss did not improve from 0.59925\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5288 - val_loss: 0.6028\n",
      "Epoch 59/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5278\n",
      "Epoch 59: val_loss improved from 0.59925 to 0.59649, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5292 - val_loss: 0.5965\n",
      "Epoch 60/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5401\n",
      "Epoch 60: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5412 - val_loss: 0.5994\n",
      "Epoch 61/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5210\n",
      "Epoch 61: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5204 - val_loss: 0.5996\n",
      "Epoch 62/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5417\n",
      "Epoch 62: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5434 - val_loss: 0.6015\n",
      "Epoch 63/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5242\n",
      "Epoch 63: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5242 - val_loss: 0.6096\n",
      "Epoch 64/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5445\n",
      "Epoch 64: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5445 - val_loss: 0.6049\n",
      "Epoch 65/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5316\n",
      "Epoch 65: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5316 - val_loss: 0.6009\n",
      "Epoch 66/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5320\n",
      "Epoch 66: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5306 - val_loss: 0.6027\n",
      "Epoch 67/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5197\n",
      "Epoch 67: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5197 - val_loss: 0.6044\n",
      "Epoch 68/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5320\n",
      "Epoch 68: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5320 - val_loss: 0.6009\n",
      "Epoch 69/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5308\n",
      "Epoch 69: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5308 - val_loss: 0.5979\n",
      "Epoch 70/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5204\n",
      "Epoch 70: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5204 - val_loss: 0.5978\n",
      "Epoch 71/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5184\n",
      "Epoch 71: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5179 - val_loss: 0.6077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5313\n",
      "Epoch 72: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5313 - val_loss: 0.6077\n",
      "Epoch 73/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5152\n",
      "Epoch 73: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5168 - val_loss: 0.5994\n",
      "Epoch 74/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5145\n",
      "Epoch 74: val_loss did not improve from 0.59649\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5133 - val_loss: 0.6119\n",
      "Epoch 75/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5352\n",
      "Epoch 75: val_loss improved from 0.59649 to 0.59333, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5367 - val_loss: 0.5933\n",
      "Epoch 76/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5245\n",
      "Epoch 76: val_loss did not improve from 0.59333\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5256 - val_loss: 0.6014\n",
      "Epoch 77/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5181\n",
      "Epoch 77: val_loss did not improve from 0.59333\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5190 - val_loss: 0.6020\n",
      "Epoch 78/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.5123\n",
      "Epoch 78: val_loss did not improve from 0.59333\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5121 - val_loss: 0.6040\n",
      "Epoch 79/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5260\n",
      "Epoch 79: val_loss improved from 0.59333 to 0.59305, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5260 - val_loss: 0.5930\n",
      "Epoch 80/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5229\n",
      "Epoch 80: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5243 - val_loss: 0.5980\n",
      "Epoch 81/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5049\n",
      "Epoch 81: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5049 - val_loss: 0.6049\n",
      "Epoch 82/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5095\n",
      "Epoch 82: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5097 - val_loss: 0.6019\n",
      "Epoch 83/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5198\n",
      "Epoch 83: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5198 - val_loss: 0.6001\n",
      "Epoch 84/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.5127\n",
      "Epoch 84: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5131 - val_loss: 0.6157\n",
      "Epoch 85/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5200\n",
      "Epoch 85: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5232 - val_loss: 0.6006\n",
      "Epoch 86/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5124\n",
      "Epoch 86: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5121 - val_loss: 0.5947\n",
      "Epoch 87/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5093\n",
      "Epoch 87: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5091 - val_loss: 0.6112\n",
      "Epoch 88/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5243\n",
      "Epoch 88: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5249 - val_loss: 0.5970\n",
      "Epoch 89/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5159\n",
      "Epoch 89: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5165 - val_loss: 0.5936\n",
      "Epoch 90/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5146\n",
      "Epoch 90: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5143 - val_loss: 0.6104\n",
      "Epoch 91/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5164\n",
      "Epoch 91: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5170 - val_loss: 0.5938\n",
      "Epoch 92/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5072\n",
      "Epoch 92: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5072 - val_loss: 0.5975\n",
      "Epoch 93/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5083\n",
      "Epoch 93: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5072 - val_loss: 0.5978\n",
      "Epoch 94/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4942\n",
      "Epoch 94: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.4942 - val_loss: 0.6062\n",
      "Epoch 95/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5112\n",
      "Epoch 95: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5144 - val_loss: 0.5990\n",
      "Epoch 96/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5139\n",
      "Epoch 96: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5139 - val_loss: 0.5945\n",
      "Epoch 97/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.5051\n",
      "Epoch 97: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5050 - val_loss: 0.5965\n",
      "Epoch 98/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5078\n",
      "Epoch 98: val_loss did not improve from 0.59305\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5112 - val_loss: 0.6039\n",
      "Epoch 99/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5004\n",
      "Epoch 99: val_loss improved from 0.59305 to 0.58923, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5017 - val_loss: 0.5892\n",
      "Epoch 100/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5144\n",
      "Epoch 100: val_loss did not improve from 0.58923\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5122 - val_loss: 0.5934\n",
      "\n",
      "Train/Test model on Fold #4.\n",
      "Epoch 1/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.8324\n",
      "Epoch 1: val_loss improved from inf to 0.80510, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 3s 13ms/step - loss: 0.8322 - val_loss: 0.8051\n",
      "Epoch 2/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.8103\n",
      "Epoch 2: val_loss improved from 0.80510 to 0.79385, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.8114 - val_loss: 0.7939\n",
      "Epoch 3/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.7921\n",
      "Epoch 3: val_loss improved from 0.79385 to 0.78387, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7910 - val_loss: 0.7839\n",
      "Epoch 4/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7864\n",
      "Epoch 4: val_loss improved from 0.78387 to 0.77567, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7862 - val_loss: 0.7757\n",
      "Epoch 5/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7770\n",
      "Epoch 5: val_loss improved from 0.77567 to 0.76691, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7768 - val_loss: 0.7669\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 0.7611\n",
      "Epoch 6: val_loss improved from 0.76691 to 0.75529, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7611 - val_loss: 0.7553\n",
      "Epoch 7/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.7486\n",
      "Epoch 7: val_loss improved from 0.75529 to 0.74238, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7488 - val_loss: 0.7424\n",
      "Epoch 8/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7430\n",
      "Epoch 8: val_loss improved from 0.74238 to 0.72640, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7434 - val_loss: 0.7264\n",
      "Epoch 9/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7270\n",
      "Epoch 9: val_loss improved from 0.72640 to 0.70371, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7266 - val_loss: 0.7037\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7067\n",
      "Epoch 10: val_loss improved from 0.70371 to 0.67656, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7067 - val_loss: 0.6766\n",
      "Epoch 11/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6979\n",
      "Epoch 11: val_loss improved from 0.67656 to 0.66855, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6974 - val_loss: 0.6685\n",
      "Epoch 12/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6864\n",
      "Epoch 12: val_loss improved from 0.66855 to 0.65605, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6869 - val_loss: 0.6561\n",
      "Epoch 13/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6775\n",
      "Epoch 13: val_loss improved from 0.65605 to 0.65116, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6775 - val_loss: 0.6512\n",
      "Epoch 14/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6686\n",
      "Epoch 14: val_loss improved from 0.65116 to 0.63538, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6679 - val_loss: 0.6354\n",
      "Epoch 15/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6575\n",
      "Epoch 15: val_loss improved from 0.63538 to 0.63124, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6573 - val_loss: 0.6312\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6602\n",
      "Epoch 16: val_loss improved from 0.63124 to 0.62666, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6602 - val_loss: 0.6267\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6406\n",
      "Epoch 17: val_loss improved from 0.62666 to 0.61757, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6406 - val_loss: 0.6176\n",
      "Epoch 18/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6473\n",
      "Epoch 18: val_loss improved from 0.61757 to 0.61665, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6478 - val_loss: 0.6166\n",
      "Epoch 19/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6329\n",
      "Epoch 19: val_loss improved from 0.61665 to 0.60972, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6325 - val_loss: 0.6097\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6293\n",
      "Epoch 20: val_loss improved from 0.60972 to 0.60821, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6293 - val_loss: 0.6082\n",
      "Epoch 21/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6345\n",
      "Epoch 21: val_loss improved from 0.60821 to 0.60682, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6348 - val_loss: 0.6068\n",
      "Epoch 22/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6255\n",
      "Epoch 22: val_loss did not improve from 0.60682\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6269 - val_loss: 0.6077\n",
      "Epoch 23/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6167\n",
      "Epoch 23: val_loss improved from 0.60682 to 0.59693, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6161 - val_loss: 0.5969\n",
      "Epoch 24/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6126\n",
      "Epoch 24: val_loss did not improve from 0.59693\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6137 - val_loss: 0.5971\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6087\n",
      "Epoch 25: val_loss improved from 0.59693 to 0.59460, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6087 - val_loss: 0.5946\n",
      "Epoch 26/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6092\n",
      "Epoch 26: val_loss improved from 0.59460 to 0.59416, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6102 - val_loss: 0.5942\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6060\n",
      "Epoch 27: val_loss improved from 0.59416 to 0.59071, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6060 - val_loss: 0.5907\n",
      "Epoch 28/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.6003\n",
      "Epoch 28: val_loss did not improve from 0.59071\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6014 - val_loss: 0.5931\n",
      "Epoch 29/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6009\n",
      "Epoch 29: val_loss improved from 0.59071 to 0.58965, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6009 - val_loss: 0.5896\n",
      "Epoch 30/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5976\n",
      "Epoch 30: val_loss improved from 0.58965 to 0.58556, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5994 - val_loss: 0.5856\n",
      "Epoch 31/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.6073\n",
      "Epoch 31: val_loss did not improve from 0.58556\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6065 - val_loss: 0.5946\n",
      "Epoch 32/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.6020\n",
      "Epoch 32: val_loss did not improve from 0.58556\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5979 - val_loss: 0.5859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5840\n",
      "Epoch 33: val_loss did not improve from 0.58556\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5889 - val_loss: 0.5881\n",
      "Epoch 34/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5874\n",
      "Epoch 34: val_loss improved from 0.58556 to 0.58300, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5863 - val_loss: 0.5830\n",
      "Epoch 35/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5780\n",
      "Epoch 35: val_loss improved from 0.58300 to 0.57981, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5765 - val_loss: 0.5798\n",
      "Epoch 36/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5806\n",
      "Epoch 36: val_loss did not improve from 0.57981\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5810 - val_loss: 0.5813\n",
      "Epoch 37/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5873\n",
      "Epoch 37: val_loss improved from 0.57981 to 0.57767, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5849 - val_loss: 0.5777\n",
      "Epoch 38/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5807\n",
      "Epoch 38: val_loss did not improve from 0.57767\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5800 - val_loss: 0.5779\n",
      "Epoch 39/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5780\n",
      "Epoch 39: val_loss did not improve from 0.57767\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5777 - val_loss: 0.5785\n",
      "Epoch 40/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5799\n",
      "Epoch 40: val_loss did not improve from 0.57767\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5783 - val_loss: 0.5783\n",
      "Epoch 41/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5619\n",
      "Epoch 41: val_loss did not improve from 0.57767\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5658 - val_loss: 0.5797\n",
      "Epoch 42/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5713\n",
      "Epoch 42: val_loss improved from 0.57767 to 0.57485, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5698 - val_loss: 0.5749\n",
      "Epoch 43/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5736\n",
      "Epoch 43: val_loss improved from 0.57485 to 0.57253, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5729 - val_loss: 0.5725\n",
      "Epoch 44/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5729\n",
      "Epoch 44: val_loss did not improve from 0.57253\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5735 - val_loss: 0.5726\n",
      "Epoch 45/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5678\n",
      "Epoch 45: val_loss improved from 0.57253 to 0.57003, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5694 - val_loss: 0.5700\n",
      "Epoch 46/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5672\n",
      "Epoch 46: val_loss did not improve from 0.57003\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5647 - val_loss: 0.5721\n",
      "Epoch 47/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.5606\n",
      "Epoch 47: val_loss improved from 0.57003 to 0.56799, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5637 - val_loss: 0.5680\n",
      "Epoch 48/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5507\n",
      "Epoch 48: val_loss did not improve from 0.56799\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5537 - val_loss: 0.5740\n",
      "Epoch 49/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5642\n",
      "Epoch 49: val_loss did not improve from 0.56799\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5642 - val_loss: 0.5687\n",
      "Epoch 50/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5702\n",
      "Epoch 50: val_loss did not improve from 0.56799\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5697 - val_loss: 0.5720\n",
      "Epoch 51/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5500\n",
      "Epoch 51: val_loss did not improve from 0.56799\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5529 - val_loss: 0.5682\n",
      "Epoch 52/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5507\n",
      "Epoch 52: val_loss did not improve from 0.56799\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5507 - val_loss: 0.5693\n",
      "Epoch 53/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5607\n",
      "Epoch 53: val_loss improved from 0.56799 to 0.56657, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5604 - val_loss: 0.5666\n",
      "Epoch 54/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5595\n",
      "Epoch 54: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5598 - val_loss: 0.5703\n",
      "Epoch 55/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5534\n",
      "Epoch 55: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5551 - val_loss: 0.5684\n",
      "Epoch 56/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5576\n",
      "Epoch 56: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5567 - val_loss: 0.5700\n",
      "Epoch 57/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5489\n",
      "Epoch 57: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.5477 - val_loss: 0.5677\n",
      "Epoch 58/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5473\n",
      "Epoch 58: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5481 - val_loss: 0.5699\n",
      "Epoch 59/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5496\n",
      "Epoch 59: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5492 - val_loss: 0.5694\n",
      "Epoch 60/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5547\n",
      "Epoch 60: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5547 - val_loss: 0.5719\n",
      "Epoch 61/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.5467\n",
      "Epoch 61: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5429 - val_loss: 0.5701\n",
      "Epoch 62/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5393\n",
      "Epoch 62: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5397 - val_loss: 0.5750\n",
      "Epoch 63/100\n",
      "66/74 [=========================>....] - ETA: 0s - loss: 0.5522\n",
      "Epoch 63: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5534 - val_loss: 0.5697\n",
      "Epoch 64/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5532\n",
      "Epoch 64: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5532 - val_loss: 0.5714\n",
      "Epoch 65/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5423\n",
      "Epoch 65: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5441 - val_loss: 0.5704\n",
      "Epoch 66/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5465\n",
      "Epoch 66: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5465 - val_loss: 0.5696\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/74 [============================>.] - ETA: 0s - loss: 0.5493\n",
      "Epoch 67: val_loss did not improve from 0.56657\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5498 - val_loss: 0.5706\n",
      "Epoch 68/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5461\n",
      "Epoch 68: val_loss improved from 0.56657 to 0.56615, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5459 - val_loss: 0.5661\n",
      "Epoch 69/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5336\n",
      "Epoch 69: val_loss improved from 0.56615 to 0.56597, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5355 - val_loss: 0.5660\n",
      "Epoch 70/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5463\n",
      "Epoch 70: val_loss did not improve from 0.56597\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5455 - val_loss: 0.5663\n",
      "Epoch 71/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5405\n",
      "Epoch 71: val_loss did not improve from 0.56597\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5398 - val_loss: 0.5665\n",
      "Epoch 72/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5369\n",
      "Epoch 72: val_loss did not improve from 0.56597\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5369 - val_loss: 0.5794\n",
      "Epoch 73/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5353\n",
      "Epoch 73: val_loss did not improve from 0.56597\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5355 - val_loss: 0.5674\n",
      "Epoch 74/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5408\n",
      "Epoch 74: val_loss did not improve from 0.56597\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5404 - val_loss: 0.5695\n",
      "Epoch 75/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5498\n",
      "Epoch 75: val_loss did not improve from 0.56597\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5498 - val_loss: 0.5672\n",
      "Epoch 76/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5373\n",
      "Epoch 76: val_loss improved from 0.56597 to 0.56513, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5398 - val_loss: 0.5651\n",
      "Epoch 77/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5226\n",
      "Epoch 77: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5216 - val_loss: 0.5667\n",
      "Epoch 78/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5421\n",
      "Epoch 78: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5419 - val_loss: 0.5671\n",
      "Epoch 79/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.5387\n",
      "Epoch 79: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5362 - val_loss: 0.5670\n",
      "Epoch 80/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5331\n",
      "Epoch 80: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5331 - val_loss: 0.5667\n",
      "Epoch 81/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5428\n",
      "Epoch 81: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5428 - val_loss: 0.5679\n",
      "Epoch 82/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5381\n",
      "Epoch 82: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5384 - val_loss: 0.5686\n",
      "Epoch 83/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5317\n",
      "Epoch 83: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5319 - val_loss: 0.5699\n",
      "Epoch 84/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5318\n",
      "Epoch 84: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5322 - val_loss: 0.5718\n",
      "Epoch 85/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.5207\n",
      "Epoch 85: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5271 - val_loss: 0.5717\n",
      "Epoch 86/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5307\n",
      "Epoch 86: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5287 - val_loss: 0.5705\n",
      "Epoch 87/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5217\n",
      "Epoch 87: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5209 - val_loss: 0.5701\n",
      "Epoch 88/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5317\n",
      "Epoch 88: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5297 - val_loss: 0.5697\n",
      "Epoch 89/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5433\n",
      "Epoch 89: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5433 - val_loss: 0.5674\n",
      "Epoch 90/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5174\n",
      "Epoch 90: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5159 - val_loss: 0.5729\n",
      "Epoch 91/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.5373\n",
      "Epoch 91: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5395 - val_loss: 0.5682\n",
      "Epoch 92/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5242\n",
      "Epoch 92: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5242 - val_loss: 0.5716\n",
      "Epoch 93/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5252\n",
      "Epoch 93: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5252 - val_loss: 0.5728\n",
      "Epoch 94/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.5116\n",
      "Epoch 94: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5182 - val_loss: 0.5766\n",
      "Epoch 95/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.5161\n",
      "Epoch 95: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5144 - val_loss: 0.5776\n",
      "Epoch 96/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5221\n",
      "Epoch 96: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5221 - val_loss: 0.5717\n",
      "Epoch 97/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5144\n",
      "Epoch 97: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5144 - val_loss: 0.5719\n",
      "Epoch 98/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5266\n",
      "Epoch 98: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5266 - val_loss: 0.5728\n",
      "Epoch 99/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5178\n",
      "Epoch 99: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5178 - val_loss: 0.5672\n",
      "Epoch 100/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.5154\n",
      "Epoch 100: val_loss did not improve from 0.56513\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5165 - val_loss: 0.5676\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Train/Test model on all folds, generate evaluations\n",
    "##################################################################################\n",
    "\n",
    "## Create and set directory to save model\n",
    "modelPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold), \"models\")\n",
    "if(not os.path.isdir(modelPath)):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "i = -1\n",
    "for fold in folds:\n",
    "    i += 1\n",
    "    \n",
    "    print(\"\\nTrain/Test model on Fold #\"+str(i)+\".\")\n",
    "    \n",
    "    model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "    ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    modelCallbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                           monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                           save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "    ]\n",
    "    \n",
    "    # adding random shuffling of the dataset for training purpose\n",
    "    index_arr = np.arange(fold[\"X_train\"].shape[0])\n",
    "    index_arr = np.random.permutation(index_arr)\n",
    "    \n",
    "    model.fit(x = fold[\"X_train\"][index_arr], y = fold[\"y_train\"][index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "              callbacks = modelCallbacks, validation_data = (fold[\"X_test\"], fold[\"y_test\"]))\n",
    "    \n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TRAIN dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_train\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Train\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TEST dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_test\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Test\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.714332</td>\n",
       "      <td>0.665938</td>\n",
       "      <td>0.781233</td>\n",
       "      <td>0.757308</td>\n",
       "      <td>0.665938</td>\n",
       "      <td>0.424997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.772953</td>\n",
       "      <td>0.891502</td>\n",
       "      <td>0.864983</td>\n",
       "      <td>0.772953</td>\n",
       "      <td>0.641003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                   \n",
       "Test        0.714332   0.665938  0.781233     0.757308     0.665938  0.424997\n",
       "Train       0.819977   0.772953  0.891502     0.864983     0.772953  0.641003"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.720812</td>\n",
       "      <td>0.675277</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.03076923076923077, 0.0307692...</td>\n",
       "      <td>[0.0, 0.0030211480362537764, 0.006042296072507...</td>\n",
       "      <td>[1.9448644, 0.9448644, 0.94219625, 0.8853597, ...</td>\n",
       "      <td>0.784941</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.675277</td>\n",
       "      <td>0.436315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>[0.0, 0.0038461538461538464, 0.007692307692307...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.006060606060606061, 0.006060...</td>\n",
       "      <td>[1.9125819, 0.912582, 0.90220594, 0.88552946, ...</td>\n",
       "      <td>0.764149</td>\n",
       "      <td>0.724551</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.380143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.645614</td>\n",
       "      <td>[0.0, 0.0038461538461538464, 0.015384615384615...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0030303030303030303, 0.00303...</td>\n",
       "      <td>[1.8855293, 0.88552934, 0.86125296, 0.8590325,...</td>\n",
       "      <td>0.779213</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.645614</td>\n",
       "      <td>0.399024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.727119</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>[0.0, 0.0038461538461538464, 0.034615384615384...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0030303030303030303, 0.00303...</td>\n",
       "      <td>[1.9041855, 0.9041855, 0.8712573, 0.8622, 0.81...</td>\n",
       "      <td>0.778945</td>\n",
       "      <td>0.766562</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.449810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>[0.0, 0.0038461538461538464, 0.030769230769230...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0030303030303030303, 0.00303...</td>\n",
       "      <td>[1.9034619, 0.9034619, 0.8533277, 0.8372267, 0...</td>\n",
       "      <td>0.798916</td>\n",
       "      <td>0.785235</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.459691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Train_Test  Accuracy  Precision  \\\n",
       "1     0       Test  0.720812   0.675277   \n",
       "3     1       Test  0.694915   0.656250   \n",
       "5     2       Test  0.700000   0.645614   \n",
       "7     3       Test  0.727119   0.681319   \n",
       "9     4       Test  0.728814   0.671233   \n",
       "\n",
       "                                                 TPR  \\\n",
       "1  [0.0, 0.0, 0.0, 0.03076923076923077, 0.0307692...   \n",
       "3  [0.0, 0.0038461538461538464, 0.007692307692307...   \n",
       "5  [0.0, 0.0038461538461538464, 0.015384615384615...   \n",
       "7  [0.0, 0.0038461538461538464, 0.034615384615384...   \n",
       "9  [0.0, 0.0038461538461538464, 0.030769230769230...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "1  [0.0, 0.0030211480362537764, 0.006042296072507...   \n",
       "3  [0.0, 0.0, 0.0, 0.006060606060606061, 0.006060...   \n",
       "5  [0.0, 0.0, 0.0, 0.0030303030303030303, 0.00303...   \n",
       "7  [0.0, 0.0, 0.0, 0.0030303030303030303, 0.00303...   \n",
       "9  [0.0, 0.0, 0.0, 0.0030303030303030303, 0.00303...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "1  [1.9448644, 0.9448644, 0.94219625, 0.8853597, ...  0.784941     0.759375   \n",
       "3  [1.9125819, 0.912582, 0.90220594, 0.88552946, ...  0.764149     0.724551   \n",
       "5  [1.8855293, 0.88552934, 0.86125296, 0.8590325,...  0.779213     0.750820   \n",
       "7  [1.9041855, 0.9041855, 0.8712573, 0.8622, 0.81...  0.778945     0.766562   \n",
       "9  [1.9034619, 0.9034619, 0.8533277, 0.8372267, 0...  0.798916     0.785235   \n",
       "\n",
       "   Specificity       MCC  \n",
       "1     0.675277  0.436315  \n",
       "3     0.656250  0.380143  \n",
       "5     0.645614  0.399024  \n",
       "7     0.681319  0.449810  \n",
       "9     0.671233  0.459691  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df[evaluations_df[\"Train_Test\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features\n",
    "train_labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read independent data file\n",
    "##################################################################################\n",
    "indpe_file_path = os.path.join(input_data_folder, independent_data_file)\n",
    "indpe_data = pd.read_csv(indpe_file_path, sep='\\t', header=None)\n",
    "indpe_data.columns = ['Sequence', 'name', 'id', 'flag', 'label_original', 'type']\n",
    "indpe_data.head()\n",
    "    \n",
    "##################################################################################\n",
    "##### Create OHE of sequence\n",
    "##################################################################################\n",
    "indpe_data['OHE_Sequence'] = pd.Series([one_hot_encode_nt(val, all_char_dict) \n",
    "                                        for val in indpe_data[\"Sequence\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Fix the labels\n",
    "##################################################################################\n",
    "indpe_data['label'] = pd.Series([1 if val == 1 else 0 \n",
    "                                 for val in indpe_data[\"label_original\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "indpe_features = np.array(list(indpe_data['OHE_Sequence']))\n",
    "indpe_labels = np.array(list(indpe_data['label']))\n",
    "indpe_labels = indpe_labels.reshape((indpe_labels.shape[0], 1))\n",
    "\n",
    "input_seq_shape = indpe_features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using k-fold Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of each k-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.641469</td>\n",
       "      <td>0.252983</td>\n",
       "      <td>0.670191</td>\n",
       "      <td>0.889272</td>\n",
       "      <td>0.252983</td>\n",
       "      <td>0.186062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.641469   0.252983  0.670191     0.889272     0.252983  0.186062"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    label_pred = pred2label(y_pred)\n",
    "\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(indpe_labels, label_pred)\n",
    "    prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "    conf = confusion_matrix(indpe_labels, label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "    auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.635102</td>\n",
       "      <td>0.243697</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.004892367906066536, 0.00489236790...</td>\n",
       "      <td>[1.9489883, 0.9489883, 0.8978106, 0.8920671, 0...</td>\n",
       "      <td>0.663742</td>\n",
       "      <td>0.883845</td>\n",
       "      <td>0.243697</td>\n",
       "      <td>0.167196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.679184</td>\n",
       "      <td>0.280093</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.005870841487279843, 0.00587084148...</td>\n",
       "      <td>[1.9189126, 0.9189127, 0.88077706, 0.8686836, ...</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.896595</td>\n",
       "      <td>0.280093</td>\n",
       "      <td>0.227045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.643265</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.0029354207436399216, 0.0029354207...</td>\n",
       "      <td>[1.9013371, 0.90133715, 0.8670612, 0.8646005, ...</td>\n",
       "      <td>0.666259</td>\n",
       "      <td>0.889481</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>0.186850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.638367</td>\n",
       "      <td>0.248954</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.009852216748768...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0009784735812133072, 0.00097...</td>\n",
       "      <td>[1.9167752, 0.9167752, 0.9035742, 0.89555687, ...</td>\n",
       "      <td>0.665757</td>\n",
       "      <td>0.887550</td>\n",
       "      <td>0.248954</td>\n",
       "      <td>0.179080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.611429</td>\n",
       "      <td>0.239006</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.00684931506849315, 0.006849315068...</td>\n",
       "      <td>[1.9023317, 0.9023317, 0.8423832, 0.83924377, ...</td>\n",
       "      <td>0.666273</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.239006</td>\n",
       "      <td>0.170137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold   Train_Test  Accuracy  Precision  \\\n",
       "0     0  Independent  0.635102   0.243697   \n",
       "1     1  Independent  0.679184   0.280093   \n",
       "2     2  Independent  0.643265   0.253165   \n",
       "3     3  Independent  0.638367   0.248954   \n",
       "4     4  Independent  0.611429   0.239006   \n",
       "\n",
       "                                                 TPR  \\\n",
       "0  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "1  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "2  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "3  [0.0, 0.0049261083743842365, 0.009852216748768...   \n",
       "4  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "0  [0.0, 0.0, 0.004892367906066536, 0.00489236790...   \n",
       "1  [0.0, 0.0, 0.005870841487279843, 0.00587084148...   \n",
       "2  [0.0, 0.0, 0.0029354207436399216, 0.0029354207...   \n",
       "3  [0.0, 0.0, 0.0, 0.0009784735812133072, 0.00097...   \n",
       "4  [0.0, 0.0, 0.00684931506849315, 0.006849315068...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0  [1.9489883, 0.9489883, 0.8978106, 0.8920671, 0...  0.663742     0.883845   \n",
       "1  [1.9189126, 0.9189127, 0.88077706, 0.8686836, ...  0.688923     0.896595   \n",
       "2  [1.9013371, 0.90133715, 0.8670612, 0.8646005, ...  0.666259     0.889481   \n",
       "3  [1.9167752, 0.9167752, 0.9035742, 0.89555687, ...  0.665757     0.887550   \n",
       "4  [1.9023317, 0.9023317, 0.8423832, 0.83924377, ...  0.666273     0.888889   \n",
       "\n",
       "   Specificity       MCC  \n",
       "0     0.243697  0.167196  \n",
       "1     0.280093  0.227045  \n",
       "2     0.253165  0.186850  \n",
       "3     0.248954  0.179080  \n",
       "4     0.239006  0.170137  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.66449</td>\n",
       "      <td>0.266816</td>\n",
       "      <td>0.681557</td>\n",
       "      <td>0.892169</td>\n",
       "      <td>0.266816</td>\n",
       "      <td>0.205741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent   0.66449   0.266816  0.681557     0.892169     0.266816  0.205741"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    total_pred += y_pred\n",
    "    all_preds.append(y_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "if(conf[0][0]+conf[1][0]):\n",
    "    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "else:\n",
    "    sens = 0.0\n",
    "if(conf[1][1]+conf[0][1]):\n",
    "    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "else:\n",
    "    spec = 0.0\n",
    "if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "else:\n",
    "    mcc= 0.0\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.259657</td>\n",
       "      <td>0.659079</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>0.259657</td>\n",
       "      <td>0.197969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.651429   0.259657  0.659079     0.891963     0.259657  0.197969"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    vote_pred = pred2label(y_pred)\n",
    "    total_pred += vote_pred\n",
    "    all_preds.append(vote_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "if(conf[0][0]+conf[1][0]):\n",
    "    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "else:\n",
    "    sens = 0.0\n",
    "if(conf[1][1]+conf[0][1]):\n",
    "    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "else:\n",
    "    spec = 0.0\n",
    "if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "else:\n",
    "    mcc= 0.0\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using New Model\n",
    "\n",
    "Train model on full data from training. Predict and evaluate on Independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8230\n",
      "Epoch 1: val_loss improved from inf to 0.80400, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "93/93 [==============================] - 3s 17ms/step - loss: 0.8230 - val_loss: 0.8040\n",
      "Epoch 2/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.8017\n",
      "Epoch 2: val_loss improved from 0.80400 to 0.74747, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.8024 - val_loss: 0.7475\n",
      "Epoch 3/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7808\n",
      "Epoch 3: val_loss improved from 0.74747 to 0.73115, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.7808 - val_loss: 0.7311\n",
      "Epoch 4/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.7654\n",
      "Epoch 4: val_loss improved from 0.73115 to 0.69444, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.7635 - val_loss: 0.6944\n",
      "Epoch 5/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.7525\n",
      "Epoch 5: val_loss improved from 0.69444 to 0.67448, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.7501 - val_loss: 0.6745\n",
      "Epoch 6/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.7255\n",
      "Epoch 6: val_loss improved from 0.67448 to 0.67313, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.7226 - val_loss: 0.6731\n",
      "Epoch 7/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.7024\n",
      "Epoch 7: val_loss improved from 0.67313 to 0.62725, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.7035 - val_loss: 0.6273\n",
      "Epoch 8/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.6890\n",
      "Epoch 8: val_loss did not improve from 0.62725\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6907 - val_loss: 0.6879\n",
      "Epoch 9/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.6779\n",
      "Epoch 9: val_loss did not improve from 0.62725\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6782 - val_loss: 0.6465\n",
      "Epoch 10/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.6744\n",
      "Epoch 10: val_loss did not improve from 0.62725\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.6730 - val_loss: 0.6698\n",
      "Epoch 11/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.6673\n",
      "Epoch 11: val_loss did not improve from 0.62725\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6657 - val_loss: 0.6465\n",
      "Epoch 12/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.6556\n",
      "Epoch 12: val_loss did not improve from 0.62725\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6560 - val_loss: 0.6765\n",
      "Epoch 13/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.6523\n",
      "Epoch 13: val_loss improved from 0.62725 to 0.59556, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.6490 - val_loss: 0.5956\n",
      "Epoch 14/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.6459\n",
      "Epoch 14: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.6460 - val_loss: 0.6622\n",
      "Epoch 15/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.6437\n",
      "Epoch 15: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6422 - val_loss: 0.6078\n",
      "Epoch 16/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.6333\n",
      "Epoch 16: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6352 - val_loss: 0.6317\n",
      "Epoch 17/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.6301\n",
      "Epoch 17: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6319 - val_loss: 0.6118\n",
      "Epoch 18/100\n",
      "90/93 [============================>.] - ETA: 0s - loss: 0.6269\n",
      "Epoch 18: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.6289 - val_loss: 0.6151\n",
      "Epoch 19/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.6249\n",
      "Epoch 19: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6257 - val_loss: 0.6448\n",
      "Epoch 20/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.6132\n",
      "Epoch 20: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6141 - val_loss: 0.6846\n",
      "Epoch 21/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6118\n",
      "Epoch 21: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6121 - val_loss: 0.6483\n",
      "Epoch 22/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.6086\n",
      "Epoch 22: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.6104 - val_loss: 0.6409\n",
      "Epoch 23/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5978\n",
      "Epoch 23: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5965 - val_loss: 0.6230\n",
      "Epoch 24/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5957\n",
      "Epoch 24: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5978 - val_loss: 0.6539\n",
      "Epoch 25/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5934\n",
      "Epoch 25: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5947 - val_loss: 0.5988\n",
      "Epoch 26/100\n",
      "90/93 [============================>.] - ETA: 0s - loss: 0.5947\n",
      "Epoch 26: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5947 - val_loss: 0.6489\n",
      "Epoch 27/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5964\n",
      "Epoch 27: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5995 - val_loss: 0.6123\n",
      "Epoch 28/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5924\n",
      "Epoch 28: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5877 - val_loss: 0.6176\n",
      "Epoch 29/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5857\n",
      "Epoch 29: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5854 - val_loss: 0.6093\n",
      "Epoch 30/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.6000\n",
      "Epoch 30: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5975 - val_loss: 0.6481\n",
      "Epoch 31/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5804\n",
      "Epoch 31: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5802 - val_loss: 0.6272\n",
      "Epoch 32/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.5856\n",
      "Epoch 32: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5873 - val_loss: 0.6329\n",
      "Epoch 33/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5791\n",
      "Epoch 33: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5772 - val_loss: 0.6405\n",
      "Epoch 34/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5741\n",
      "Epoch 34: val_loss did not improve from 0.59556\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5728 - val_loss: 0.6296\n",
      "Epoch 35/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5745\n",
      "Epoch 35: val_loss improved from 0.59556 to 0.59239, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5761 - val_loss: 0.5924\n",
      "Epoch 36/100\n",
      "90/93 [============================>.] - ETA: 0s - loss: 0.5814\n",
      "Epoch 36: val_loss did not improve from 0.59239\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5814 - val_loss: 0.6028\n",
      "Epoch 37/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.5773\n",
      "Epoch 37: val_loss did not improve from 0.59239\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5730 - val_loss: 0.6150\n",
      "Epoch 38/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5581\n",
      "Epoch 38: val_loss did not improve from 0.59239\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5608 - val_loss: 0.6162\n",
      "Epoch 39/100\n",
      "91/93 [============================>.] - ETA: 0s - loss: 0.5705\n",
      "Epoch 39: val_loss did not improve from 0.59239\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5699 - val_loss: 0.6284\n",
      "Epoch 40/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5661\n",
      "Epoch 40: val_loss did not improve from 0.59239\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5667 - val_loss: 0.6488\n",
      "Epoch 41/100\n",
      "91/93 [============================>.] - ETA: 0s - loss: 0.5660\n",
      "Epoch 41: val_loss did not improve from 0.59239\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5654 - val_loss: 0.6377\n",
      "Epoch 42/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.5732\n",
      "Epoch 42: val_loss improved from 0.59239 to 0.58598, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5725 - val_loss: 0.5860\n",
      "Epoch 43/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5606\n",
      "Epoch 43: val_loss did not improve from 0.58598\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5625 - val_loss: 0.6783\n",
      "Epoch 44/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5702\n",
      "Epoch 44: val_loss did not improve from 0.58598\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5731 - val_loss: 0.6488\n",
      "Epoch 45/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5736\n",
      "Epoch 45: val_loss improved from 0.58598 to 0.58269, saving model to Results\\NT_Site_PredNTS+iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5715 - val_loss: 0.5827\n",
      "Epoch 46/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5485\n",
      "Epoch 46: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5493 - val_loss: 0.6148\n",
      "Epoch 47/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.5552\n",
      "Epoch 47: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5546 - val_loss: 0.6510\n",
      "Epoch 48/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5572\n",
      "Epoch 48: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5560 - val_loss: 0.6272\n",
      "Epoch 49/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.5506\n",
      "Epoch 49: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5521 - val_loss: 0.6075\n",
      "Epoch 50/100\n",
      "91/93 [============================>.] - ETA: 0s - loss: 0.5545\n",
      "Epoch 50: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5545 - val_loss: 0.6391\n",
      "Epoch 51/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5513\n",
      "Epoch 51: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5519 - val_loss: 0.6545\n",
      "Epoch 52/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5488\n",
      "Epoch 52: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5486 - val_loss: 0.6444\n",
      "Epoch 53/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5485\n",
      "Epoch 53: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5489 - val_loss: 0.5929\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5474\n",
      "Epoch 54: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5474 - val_loss: 0.6112\n",
      "Epoch 55/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5459\n",
      "Epoch 55: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5479 - val_loss: 0.6506\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5482\n",
      "Epoch 56: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5482 - val_loss: 0.6402\n",
      "Epoch 57/100\n",
      "91/93 [============================>.] - ETA: 0s - loss: 0.5474\n",
      "Epoch 57: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5501 - val_loss: 0.6063\n",
      "Epoch 58/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5425\n",
      "Epoch 58: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5420 - val_loss: 0.6113\n",
      "Epoch 59/100\n",
      "91/93 [============================>.] - ETA: 0s - loss: 0.5393\n",
      "Epoch 59: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5384 - val_loss: 0.5912\n",
      "Epoch 60/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.5428\n",
      "Epoch 60: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5432 - val_loss: 0.6539\n",
      "Epoch 61/100\n",
      "90/93 [============================>.] - ETA: 0s - loss: 0.5456\n",
      "Epoch 61: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5442 - val_loss: 0.6464\n",
      "Epoch 62/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5399\n",
      "Epoch 62: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5370 - val_loss: 0.5849\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5301\n",
      "Epoch 63: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5301 - val_loss: 0.6495\n",
      "Epoch 64/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5443\n",
      "Epoch 64: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5441 - val_loss: 0.6318\n",
      "Epoch 65/100\n",
      "90/93 [============================>.] - ETA: 0s - loss: 0.5418\n",
      "Epoch 65: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5410 - val_loss: 0.6043\n",
      "Epoch 66/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5392\n",
      "Epoch 66: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5419 - val_loss: 0.6109\n",
      "Epoch 67/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5389\n",
      "Epoch 67: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5400 - val_loss: 0.6235\n",
      "Epoch 68/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5333\n",
      "Epoch 68: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5349 - val_loss: 0.6210\n",
      "Epoch 69/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5415\n",
      "Epoch 69: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5394 - val_loss: 0.6538\n",
      "Epoch 70/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5391\n",
      "Epoch 70: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5362 - val_loss: 0.5899\n",
      "Epoch 71/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5357\n",
      "Epoch 71: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5370 - val_loss: 0.6258\n",
      "Epoch 72/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5331\n",
      "Epoch 72: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5311 - val_loss: 0.6248\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5316\n",
      "Epoch 73: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5319 - val_loss: 0.6512\n",
      "Epoch 74/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5435\n",
      "Epoch 74: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5398 - val_loss: 0.6051\n",
      "Epoch 75/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5391\n",
      "Epoch 75: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5420 - val_loss: 0.6117\n",
      "Epoch 76/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5273\n",
      "Epoch 76: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5270 - val_loss: 0.6323\n",
      "Epoch 77/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5388\n",
      "Epoch 77: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5401 - val_loss: 0.6056\n",
      "Epoch 78/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.5285\n",
      "Epoch 78: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5290 - val_loss: 0.5890\n",
      "Epoch 79/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5229\n",
      "Epoch 79: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5221 - val_loss: 0.6213\n",
      "Epoch 80/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5337\n",
      "Epoch 80: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5340 - val_loss: 0.6329\n",
      "Epoch 81/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5349\n",
      "Epoch 81: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5320 - val_loss: 0.6723\n",
      "Epoch 82/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5357\n",
      "Epoch 82: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5348 - val_loss: 0.5863\n",
      "Epoch 83/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5335\n",
      "Epoch 83: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5328 - val_loss: 0.6419\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5337\n",
      "Epoch 84: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5337 - val_loss: 0.6307\n",
      "Epoch 85/100\n",
      "90/93 [============================>.] - ETA: 0s - loss: 0.5291\n",
      "Epoch 85: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5302 - val_loss: 0.6198\n",
      "Epoch 86/100\n",
      "90/93 [============================>.] - ETA: 0s - loss: 0.5305\n",
      "Epoch 86: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5294 - val_loss: 0.6876\n",
      "Epoch 87/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5258\n",
      "Epoch 87: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5249 - val_loss: 0.6047\n",
      "Epoch 88/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5242\n",
      "Epoch 88: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5240 - val_loss: 0.6579\n",
      "Epoch 89/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.5293\n",
      "Epoch 89: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5299 - val_loss: 0.6185\n",
      "Epoch 90/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5387\n",
      "Epoch 90: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5388 - val_loss: 0.6281\n",
      "Epoch 91/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5182\n",
      "Epoch 91: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5190 - val_loss: 0.6486\n",
      "Epoch 92/100\n",
      "87/93 [===========================>..] - ETA: 0s - loss: 0.5284\n",
      "Epoch 92: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5269 - val_loss: 0.6078\n",
      "Epoch 93/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.5306\n",
      "Epoch 93: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5296 - val_loss: 0.6487\n",
      "Epoch 94/100\n",
      "91/93 [============================>.] - ETA: 0s - loss: 0.5143\n",
      "Epoch 94: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5143 - val_loss: 0.6238\n",
      "Epoch 95/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5265\n",
      "Epoch 95: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5284 - val_loss: 0.5849\n",
      "Epoch 96/100\n",
      "89/93 [===========================>..] - ETA: 0s - loss: 0.5190\n",
      "Epoch 96: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5172 - val_loss: 0.6218\n",
      "Epoch 97/100\n",
      "88/93 [===========================>..] - ETA: 0s - loss: 0.5209\n",
      "Epoch 97: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 0.5200 - val_loss: 0.6298\n",
      "Epoch 98/100\n",
      "86/93 [==========================>...] - ETA: 0s - loss: 0.5158\n",
      "Epoch 98: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5189 - val_loss: 0.6460\n",
      "Epoch 99/100\n",
      "90/93 [============================>.] - ETA: 0s - loss: 0.5206\n",
      "Epoch 99: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5196 - val_loss: 0.6481\n",
      "Epoch 100/100\n",
      "91/93 [============================>.] - ETA: 0s - loss: 0.5088\n",
      "Epoch 100: val_loss did not improve from 0.58269\n",
      "93/93 [==============================] - 1s 8ms/step - loss: 0.5110 - val_loss: 0.6423\n"
     ]
    }
   ],
   "source": [
    "model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "current_model_path = os.path.join(modelPath, \"_fullModel.hdf5\")\n",
    "modelCallbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                       monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                       save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "]\n",
    "\n",
    "# adding random shuffling of the dataset for training purpose\n",
    "index_arr = np.arange(train_features.shape[0])\n",
    "index_arr = np.random.permutation(index_arr)\n",
    "\n",
    "model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "          callbacks = modelCallbacks, validation_data = (indpe_features, indpe_labels))\n",
    "# model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "#           callbacks = modelCallbacks, validation_split = 0.2)\n",
    "\n",
    "model = tf.keras.models.load_model(current_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.682449</td>\n",
       "      <td>0.262755</td>\n",
       "      <td>0.669025</td>\n",
       "      <td>0.879952</td>\n",
       "      <td>0.262755</td>\n",
       "      <td>0.179035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.682449   0.262755  0.669025     0.879952     0.262755  0.179035"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "y_pred = model.predict(indpe_features)\n",
    "label_pred = pred2label(y_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "if(conf[0][0]+conf[1][0]):\n",
    "    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "else:\n",
    "    sens = 0.0\n",
    "if(conf[1][1]+conf[0][1]):\n",
    "    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "else:\n",
    "    spec = 0.0\n",
    "if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "else:\n",
    "    mcc= 0.0\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
