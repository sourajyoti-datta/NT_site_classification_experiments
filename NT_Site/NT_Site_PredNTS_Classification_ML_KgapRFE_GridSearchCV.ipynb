{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"NT_Site_PredNTS_Classification_ML_KgapRFE_GridSearchCV\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "shuffle = True\n",
    "seed = None\n",
    "\n",
    "input_data_folder = \"PredNTS_MathFeature_ENC\"\n",
    "\n",
    "monitor = 'val_loss'\n",
    "\n",
    "sub_feature_count = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgap_max = 4\n",
    "\n",
    "train_data_filename = 'Training-datasets-PredNTS_kgap_{}.csv'\n",
    "indpe_data_filename = 'independent-dataset-PredNTS_kgap_{}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, classification_report, matthews_corrcoef\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Build k-fold functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(cw = None):\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100,\n",
    "                                   criterion='gini', \n",
    "                                   class_weight=cw,\n",
    "                                   bootstrap=True,\n",
    "                                   oob_score=True, \n",
    "                                  )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Read CSV data\n",
    "##################################################################################\n",
    "\n",
    "for i in range(kgap_max+1):\n",
    "    \n",
    "    current_train_data_filepath = os.path.join(input_data_folder, train_data_filename.format(i))\n",
    "    current_train_data = pd.read_csv(current_train_data_filepath, sep=',', header=0)\n",
    "    current_train_data = current_train_data.drop('label', axis=1)\n",
    "    \n",
    "    if i == 0:\n",
    "        train_data = current_train_data\n",
    "    else:\n",
    "        train_data = pd.merge(\n",
    "            train_data,\n",
    "            current_train_data,\n",
    "            how=\"inner\",\n",
    "            on='nameseq'\n",
    "        )\n",
    "\n",
    "train_data['label'] = pd.Series([int(val.split('_')[-2])\n",
    "                                 for val in train_data['nameseq']])\n",
    "\n",
    "train_data = train_data.drop('nameseq', axis=1)\n",
    "\n",
    "train_features = np.array(train_data.drop('label', axis=1))\n",
    "train_labels = np.array(train_data['label'])\n",
    "train_labels = train_labels.reshape((train_labels.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##################################################################################\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m##### Recursive feature selection\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m##################################################################################\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# model = DecisionTreeClassifier(criterion=\"gini\")\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m()\n\u001b[0;32m      8\u001b[0m selector \u001b[38;5;241m=\u001b[39m RFE(model, n_features_to_select\u001b[38;5;241m=\u001b[39msub_feature_count, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      9\u001b[0m selector \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mfit(train_features, train_labels\u001b[38;5;241m.\u001b[39mreshape(train_labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_model' is not defined"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### Recursive feature selection\n",
    "##################################################################################\n",
    "\n",
    "# model = DecisionTreeClassifier(criterion=\"gini\")\n",
    "model = get_model()\n",
    "\n",
    "selector = RFE(model, n_features_to_select=sub_feature_count, step=50)\n",
    "selector = selector.fit(train_features, train_labels.reshape(train_labels.shape[0]))\n",
    "\n",
    "feature_indices = np.where(selector.ranking_ == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "train_features = train_features[:, feature_indices]\n",
    "\n",
    "# folds = build_kfold(train_features, train_labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "# input_vec_shape = train_features[0].shape\n",
    "\n",
    "# ## Write the k-fold dataset to file\n",
    "# foldPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold))\n",
    "# if(not os.path.isdir(foldPath)):\n",
    "#     os.makedirs(foldPath)\n",
    "# pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Read CSV data\n",
    "##################################################################################\n",
    "\n",
    "for i in range(kgap_max+1):\n",
    "\n",
    "    current_indpe_data_filepath = os.path.join(input_data_folder, indpe_data_filename.format(i))\n",
    "    current_indpe_data = pd.read_csv(current_indpe_data_filepath, sep=',', header=0)\n",
    "    current_indpe_data = current_indpe_data.drop('label', axis=1)\n",
    "    \n",
    "    if i == 0:\n",
    "        indpe_data = current_indpe_data\n",
    "    else:\n",
    "        indpe_data = pd.merge(\n",
    "            indpe_data,\n",
    "            current_indpe_data,\n",
    "            how=\"inner\",\n",
    "            on='nameseq'\n",
    "        )\n",
    "\n",
    "indpe_data['label'] = pd.Series([int(val.split('_')[-2])\n",
    "                                 for val in indpe_data['nameseq']])\n",
    "\n",
    "indpe_data = indpe_data.drop('nameseq', axis=1)\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "indpe_features = np.array(indpe_data.drop('label', axis=1))\n",
    "indpe_features = indpe_features[:, feature_indices]\n",
    "\n",
    "indpe_labels = np.array(indpe_data['label'])\n",
    "indpe_labels = indpe_labels.reshape((indpe_labels.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch using full Model\n",
    "\n",
    "Train model on full data from training. Predict and evaluate on Independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model(cw={0:1, 1:0.1})\n",
    "model = RandomForestClassifier()\n",
    "param_dict = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 10, 50, 100],\n",
    "    \"min_samples_split\": [2, 10, 50, 100],\n",
    "    \"min_samples_leaf\": [1, 10, 25, 50],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True],\n",
    "    \"max_samples\": [0.25, 0.5, 0.75],\n",
    "    \"oob_score\": [True],\n",
    "    \"random_state\": [0],\n",
    "    \"class_weight\": [{0:1, 1:1}, \n",
    "                   {0:1, 1:0.1}],\n",
    "    \"ccp_alpha\": [0, 1, 0.1, 10]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "                   param_grid = param_dict,\n",
    "                   cv = 5,\n",
    "                   verbose = 2,\n",
    "                   scoring = \"accuracy\",\n",
    "                   n_jobs = 1,\n",
    "                  )\n",
    "\n",
    "clf.fit(train_features,\n",
    "        train_labels.reshape(train_labels.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = get_model(cw={0:1, 1:0.1})\n",
    "# model = get_model()\n",
    "    \n",
    "# ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "# current_model_path = os.path.join(modelPath, \"_fullModel.hdf5\")\n",
    "\n",
    "# # adding random shuffling of the dataset for training purpose\n",
    "# index_arr = np.arange(train_features.shape[0])\n",
    "# index_arr = np.random.permutation(index_arr)\n",
    "\n",
    "# model.fit(train_features[index_arr], train_labels[index_arr].reshape(train_labels.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## create the evaluation data structure for all iterations\n",
    "# evaluations = {\n",
    "#     \"Train_Test\" : [],\n",
    "#     \"Accuracy\" : [],\n",
    "#     \"Precision\": [],\n",
    "#     \"TPR\": [],\n",
    "#     \"FPR\": [],\n",
    "#     \"TPR_FPR_Thresholds\": [],\n",
    "#     \"AUC\": [],\n",
    "#     \"Sensitivity\": [],\n",
    "#     \"Specificity\": [],\n",
    "#     \"MCC\":[]\n",
    "# }\n",
    "\n",
    "# ##################################################################################\n",
    "# ##### Prediction and metrics for Train dataset\n",
    "# ##################################################################################\n",
    "\n",
    "# y_pred = model.predict(train_features)\n",
    "# label_pred = pred2label(y_pred)\n",
    "\n",
    "# # Compute precision, recall, sensitivity, specifity, mcc\n",
    "# acc = accuracy_score(train_labels, label_pred)\n",
    "# prec = precision_score(train_labels,label_pred)\n",
    "# mcc = matthews_corrcoef(train_labels, label_pred)\n",
    "\n",
    "# conf = confusion_matrix(train_labels, label_pred)\n",
    "# tn, fp, fn, tp = conf.ravel()\n",
    "# sens = tp/(tp+fn)\n",
    "# spec = tn/(tn+fp)\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(train_labels, y_pred)\n",
    "# auc = roc_auc_score(train_labels, y_pred)\n",
    "\n",
    "# evaluations[\"Train_Test\"].append(\"Train\")\n",
    "# evaluations[\"Accuracy\"].append(acc)\n",
    "# evaluations[\"Precision\"].append(prec)\n",
    "# evaluations[\"TPR\"].append(tpr)\n",
    "# evaluations[\"FPR\"].append(fpr)\n",
    "# evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "# evaluations[\"AUC\"].append(auc)\n",
    "# evaluations[\"Sensitivity\"].append(sens)\n",
    "# evaluations[\"Specificity\"].append(spec)\n",
    "# evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "# ##################################################################################\n",
    "# ##### Prediction and metrics for Independent dataset\n",
    "# ##################################################################################\n",
    "\n",
    "# y_pred = model.predict(indpe_features)\n",
    "# label_pred = pred2label(y_pred)\n",
    "\n",
    "# # Compute precision, recall, sensitivity, specifity, mcc\n",
    "# acc = accuracy_score(indpe_labels, label_pred)\n",
    "# prec = precision_score(indpe_labels,label_pred)\n",
    "# mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "# conf = confusion_matrix(indpe_labels, label_pred)\n",
    "# tn, fp, fn, tp = conf.ravel()\n",
    "# sens = tp/(tp+fn)\n",
    "# spec = tn/(tn+fp)\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "# auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "# evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "# evaluations[\"Accuracy\"].append(acc)\n",
    "# evaluations[\"Precision\"].append(prec)\n",
    "# evaluations[\"TPR\"].append(tpr)\n",
    "# evaluations[\"FPR\"].append(fpr)\n",
    "# evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "# evaluations[\"AUC\"].append(auc)\n",
    "# evaluations[\"Sensitivity\"].append(sens)\n",
    "# evaluations[\"Specificity\"].append(spec)\n",
    "# evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "# ##################################################################################\n",
    "\n",
    "# evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "# evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "#                                                                                'Precision', \n",
    "#                                                                                'AUC', \n",
    "#                                                                                'Sensitivity', \n",
    "#                                                                                'Specificity', \n",
    "#                                                                                'MCC'])\n",
    "\n",
    "# evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(indpe_labels, np.round(y_pred).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
