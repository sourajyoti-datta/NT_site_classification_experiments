{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "seed = None\n",
    "\n",
    "input_data_folder = \"Data\"\n",
    "training_data_file = \"Training-datasets-PredNTS.txt\"\n",
    "independent_data_file = \"independent dataset-PredNTS.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, classification_report\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define all CUSTOM functions\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode_nt(sequence, char_dict):\n",
    "    \n",
    "    seq_encoded = np.zeros((len(sequence),len(char_dict)))\n",
    "    \n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in char_dict.keys()):\n",
    "            seq_encoded[i][char_dict[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in NT sequence: '+sequence)\n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Build k-fold functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "def labels_1d_to_2d(labels_1d):\n",
    "    labels_2d = np.eye(2)[labels_1d]\n",
    "    return labels_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Function to customize the DLNN architecture with parameters\n",
    "# ##################################################################################\n",
    "\n",
    "# def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "#                  conv_filters_per_layer_1 = 50, kernel_length_1 = 5, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "#                  max_pool_width_1 = 2, max_pool_stride_1 = 2, ## 1st Maxpool layer parameters\n",
    "#                  lstm_decode_units = 50, ## LSTM layer parameters\n",
    "#                  conv_filters_per_layer_2 = 50,  kernel_length_2 = 10, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "#                  max_pool_width_2 = 2, max_pool_stride_2 = 2, ## 2nd Maxpool layer parameters\n",
    "#                  dense_decode_units = 370, ## Dense layer parameters\n",
    "#                  prob = 0.5, learn_rate = 0.0003, loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "#     beta = 0.005\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  SEQUENCE  ##################################################################################\n",
    "#     ######################################################################################################\n",
    "    \n",
    "#     input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "\n",
    "#     x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1,\n",
    "#                                 strides = conv_strides_1, \n",
    "#                                 kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                                 padding = \"same\")(input1)\n",
    "#     x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "#     x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "#     x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "#     ## LSTM Path\n",
    "\n",
    "#     x2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta))(x1)\n",
    "#     x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "#     x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "#     ## Conv Path\n",
    "\n",
    "#     x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, \n",
    "#                                 strides = conv_strides_2, \n",
    "#                                 kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                                 padding = 'same')(x1)\n",
    "#     x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "#     x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "#     x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "#     x3 = tf.keras.layers.Flatten()(x3)\n",
    "    \n",
    "#     x4 = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "#     ######################################################################################################\n",
    "#     ########  Classifier  ################################################################################\n",
    "#     ######################################################################################################\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(dense_decode_units, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'relu')(x4)\n",
    "    \n",
    "#     y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(1, \n",
    "#                               kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "#                               activation = 'sigmoid')(y)\n",
    "\n",
    "#     ## Generate Model from input and output\n",
    "#     model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "#     ## Compile model\n",
    "#     if(metrics != None):\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), \n",
    "#                       loss = loss, metrics = metrics)\n",
    "#     else:\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), \n",
    "#                       loss = loss)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "                 conv_filters_per_layer_1 = 10, kernel_length_1 = 10, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "                 max_pool_width_1 = 3, max_pool_stride_1 = 3, ## 1st Maxpool layer parameters\n",
    "                 lstm_decode_units = 10, ## LSTM layer parameters\n",
    "                 conv_filters_per_layer_2 = 10,  kernel_length_2 = 5, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "                 max_pool_width_2 = 3, max_pool_stride_2 = 3, ## 2nd Maxpool layer parameters\n",
    "                 dense_decode_units = 32, ## Dense layer parameters\n",
    "                 prob = 0.5, learn_rate = 0.0005, \n",
    "                 loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "    beta = 0.005\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  SEQUENCE  ##################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1,\n",
    "                                strides = conv_strides_1, kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = \"same\")(input1)\n",
    "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta))(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    ## Conv Path\n",
    "\n",
    "    x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), padding = 'same')(x1)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "    x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "    \n",
    "    x4 = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  Classifier  ################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    y = tf.keras.layers.Dense(dense_decode_units, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'relu')(x4)\n",
    "    \n",
    "    y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(1, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta),\n",
    "                              activation = 'sigmoid')(y)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 41, 21)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 41, 10)       2110        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 41, 10)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 13, 10)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 13, 10)       0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 13, 10)       510         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 13, 10)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 13, 10)       840         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 4, 10)       0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 13, 10)       0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 10)        0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 130)          0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 40)           0           ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 170)          0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           5472        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 32)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            33          ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,965\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DLNN_CORENup().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read training file\n",
    "##################################################################################\n",
    "train_file_path = os.path.join(input_data_folder, training_data_file)\n",
    "train_data = pd.read_csv(train_file_path, sep='\\t', header=None)\n",
    "train_data.columns = ['Sequence', 'name', 'id', 'flag', 'label_original', 'type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read independent data file\n",
    "##################################################################################\n",
    "indpe_file_path = os.path.join(input_data_folder, independent_data_file)\n",
    "indpe_data = pd.read_csv(indpe_file_path, sep='\\t', header=None)\n",
    "indpe_data.columns = ['Sequence', 'name', 'id', 'flag', 'label_original', 'type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty char count per sequence\n",
    "train_data['Empty_count'] = [np.sum(np.array(list(val)) == '-') for val in train_data['Sequence']]\n",
    "# incomplete sequence flag\n",
    "train_data['has_empty'] = [True if np.sum(np.array(list(val)) == '-') > 0 else False for val in train_data['Sequence']]\n",
    "\n",
    "indpe_data['Empty_count'] = [np.sum(np.array(list(val)) == '-') for val in indpe_data['Sequence']]\n",
    "indpe_data['has_empty'] = [True if np.sum(np.array(list(val)) == '-') > 0 else False for val in indpe_data['Sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_get_stats(source_data, target_data):\n",
    "    \n",
    "    # empty char count per sequence\n",
    "    source_data['Empty_count'] = [np.sum(np.array(list(val)) == '-') for val in source_data['Sequence']]\n",
    "    # incomplete sequence flag\n",
    "    source_data['has_empty'] = [True if np.sum(np.array(list(val)) == '-') > 0 else False for val in source_data['Sequence']]\n",
    "    \n",
    "    target_data['Empty_count'] = [np.sum(np.array(list(val)) == '-') for val in target_data['Sequence']]\n",
    "    target_data['has_empty'] = [True if np.sum(np.array(list(val)) == '-') > 0 else False for val in target_data['Sequence']]\n",
    "\n",
    "    # 0:1\n",
    "    train_label_nonempty_ratio = source_data.groupby([\"label_original\"]).sum().filter(['has_empty']).reset_index()['has_empty'][0] / source_data.groupby([\"label_original\"]).sum().filter(['has_empty']).reset_index()['has_empty'][1]\n",
    "    train_label_ratio = (source_data.shape[0]-sum(source_data[\"label_original\"] == 1)) / sum(source_data[\"label_original\"] == 1)\n",
    "\n",
    "    # 0:1\n",
    "    indpe_label_nonempty_ratio = target_data.groupby([\"label_original\"]).sum().filter(['has_empty']).reset_index()['has_empty'][0] / target_data.groupby([\"label_original\"]).sum().filter(['has_empty']).reset_index()['has_empty'][1]\n",
    "    indpe_label_ratio = (target_data.shape[0]-sum(target_data[\"label_original\"] == 1)) / sum(target_data[\"label_original\"] == 1)\n",
    "\n",
    "    print('Current train_label_nonempty_ratio:', train_label_nonempty_ratio, 'train_label_ratio:', train_label_ratio)\n",
    "    print('Target indpe_label_nonempty_ratio:', indpe_label_nonempty_ratio, 'indpe_label_ratio:', indpe_label_ratio)\n",
    "\n",
    "    increase_0_data_factor = int(round(indpe_label_ratio/train_label_ratio)) - 1\n",
    "    increase_empty_data_factor = int(round(indpe_label_nonempty_ratio/train_label_nonempty_ratio)) - 1\n",
    "    \n",
    "    return increase_0_data_factor, increase_empty_data_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty records: 183\n",
      "Ratio empty/total: 0.07682619647355164\n"
     ]
    }
   ],
   "source": [
    "plt.hist(train_data['Empty_count'][train_data['Empty_count'] != 0])\n",
    "plt.show()\n",
    "print('Total empty records:', sum(train_data['has_empty']))\n",
    "print('Ratio empty/total:', sum(train_data['has_empty'])/train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle('Train Data\\nlabel=0                                                                      label=1')\n",
    "axs[0].hist(train_data['Empty_count'][(train_data['Empty_count'] != 0) & (train_data['label_original'] == -1)])\n",
    "axs[1].hist(train_data['Empty_count'][(train_data['Empty_count'] != 0) & (train_data['label_original'] == 1)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_original</th>\n",
       "      <th>has_empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_original  has_empty\n",
       "0              -1         39\n",
       "1               1        144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby([\"label_original\"]).sum().filter(['has_empty']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty records: 68\n",
      "Ratio empty/total: 0.05551020408163265\n"
     ]
    }
   ],
   "source": [
    "plt.hist(indpe_data['Empty_count'][indpe_data['Empty_count'] != 0])\n",
    "plt.show()\n",
    "print('Total empty records:', sum(indpe_data['has_empty']))\n",
    "print('Ratio empty/total:', sum(indpe_data['has_empty'])/indpe_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle('Train Data\\nlabel=0                                                                      label=1')\n",
    "axs[0].hist(indpe_data['Empty_count'][(indpe_data['Empty_count'] != 0) & (indpe_data['label_original'] == -1)])\n",
    "axs[1].hist(indpe_data['Empty_count'][(indpe_data['Empty_count'] != 0) & (indpe_data['label_original'] == 1)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_empty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_original</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                has_empty\n",
       "label_original           \n",
       "-1                     52\n",
       " 1                     16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indpe_data.groupby([\"label_original\"]).sum().filter(['has_empty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train_label_nonempty_ratio: 0.2708333333333333 train_label_ratio: 1.0\n",
      "Target indpe_label_nonempty_ratio: 3.25 indpe_label_ratio: 5.0344827586206895\n"
     ]
    }
   ],
   "source": [
    "_,_ = print_and_get_stats(train_data, indpe_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation on Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sequence_truncate(seq, random_length):\n",
    "    rep_str = \"\".join(['-']*random_length)\n",
    "    if np.random.choice((True, False)):\n",
    "        return_seq = rep_str + seq[random_length:]\n",
    "    else:\n",
    "        return_seq = seq[:-random_length] + rep_str\n",
    "    return return_seq\n",
    "\n",
    "def random_sequence_truncate(seq):\n",
    "    random_length = np.random.randint(1, 20)\n",
    "    return_seq = sequence_truncate(seq, random_length)\n",
    "    return return_seq\n",
    "\n",
    "def repeat_truncate_sequence_steps(seq, factor):\n",
    "    random_length = random.sample(range(1, int(len(seq)/2)), \n",
    "                                  factor)\n",
    "    return_seqs = []\n",
    "    for i in range(factor):\n",
    "        ret_seq = sequence_truncate(seq, random_length[i])\n",
    "        return_seqs.append(ret_seq)\n",
    "    return return_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_get_stats(source_data, target_data):\n",
    "    \n",
    "    # empty char count per sequence\n",
    "    source_data['Empty_count'] = [np.sum(np.array(list(val)) == '-') for val in source_data['Sequence']]\n",
    "    # incomplete sequence flag\n",
    "    source_data['has_empty'] = [True if np.sum(np.array(list(val)) == '-') > 0 else False for val in source_data['Sequence']]\n",
    "    \n",
    "    target_data['Empty_count'] = [np.sum(np.array(list(val)) == '-') for val in target_data['Sequence']]\n",
    "    target_data['has_empty'] = [True if np.sum(np.array(list(val)) == '-') > 0 else False for val in target_data['Sequence']]\n",
    "\n",
    "    # 0:1\n",
    "    train_label_nonempty_ratio = source_data.groupby([\"label_original\"]).sum().filter(['has_empty']).reset_index()['has_empty'][0] / source_data.groupby([\"label_original\"]).sum().filter(['has_empty']).reset_index()['has_empty'][1]\n",
    "    train_label_ratio = (source_data.shape[0]-sum(source_data[\"label_original\"] == 1)) / sum(source_data[\"label_original\"] == 1)\n",
    "\n",
    "    # 0:1\n",
    "    indpe_label_nonempty_ratio = target_data.groupby([\"label_original\"]).sum().filter(['has_empty']).reset_index()['has_empty'][0] / target_data.groupby([\"label_original\"]).sum().filter(['has_empty']).reset_index()['has_empty'][1]\n",
    "    indpe_label_ratio = (target_data.shape[0]-sum(target_data[\"label_original\"] == 1)) / sum(target_data[\"label_original\"] == 1)\n",
    "\n",
    "    print('Current train_label_nonempty_ratio:', train_label_nonempty_ratio, 'train_label_ratio:', train_label_ratio)\n",
    "    print('Target indpe_label_nonempty_ratio:', indpe_label_nonempty_ratio, 'indpe_label_ratio:', indpe_label_ratio)\n",
    "\n",
    "    increase_0_data_factor = int(round(indpe_label_ratio/train_label_ratio)) - 1\n",
    "    increase_empty_data_factor = int(round(indpe_label_nonempty_ratio/train_label_nonempty_ratio)) - 1\n",
    "    \n",
    "    return increase_0_data_factor, increase_empty_data_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6963, 8)\n",
      "Current train_label_nonempty_ratio: 0.9213483146067416 train_label_ratio: 1.0306211723534557\n",
      "Target indpe_label_nonempty_ratio: 3.25 indpe_label_ratio: 5.0344827586206895\n",
      "(4581, 8)\n",
      "\n",
      "##### After removing duplicates #####\n",
      "\n",
      "Current train_label_nonempty_ratio: 1.0 train_label_ratio: 1.0469168900804289\n",
      "Target indpe_label_nonempty_ratio: 3.25 indpe_label_ratio: 5.0344827586206895\n"
     ]
    }
   ],
   "source": [
    "# train_data = train_data_backup\n",
    "\n",
    "########\n",
    "\n",
    "factor = 1\n",
    "data = train_data\n",
    "# neg_data = data[data['label_original'] == -1].reset_index(drop=True)\n",
    "neg_data = data.reset_index(drop=True)\n",
    "\n",
    "not_empty_idxs = np.where(neg_data['has_empty'] != True)[0]\n",
    "\n",
    "for idx in not_empty_idxs:\n",
    "    record = neg_data.iloc[idx].to_dict()\n",
    "    \n",
    "    seqs = repeat_truncate_sequence_steps(record['Sequence'], factor)\n",
    "    \n",
    "    for seq in seqs:\n",
    "        record['Sequence'] = seq\n",
    "        neg_data = neg_data.append(record, ignore_index=True)\n",
    "\n",
    "final_data = pd.concat((neg_data, data))\n",
    "print(final_data.shape)\n",
    "\n",
    "##########################\n",
    "\n",
    "_ , _ = print_and_get_stats(final_data, indpe_data)\n",
    "\n",
    "##########################\n",
    "\n",
    "final_data = final_data.drop_duplicates().reset_index(drop=True)\n",
    "print(final_data.shape)\n",
    "\n",
    "print('\\n##### After removing duplicates #####\\n')\n",
    "##########\n",
    "\n",
    "_ , _ = print_and_get_stats(final_data, indpe_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Final preparations for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = final_data\n",
    "\n",
    "##################################################################################\n",
    "##### Create dictionary of all characters in the NT sequence \n",
    "##################################################################################\n",
    "all_char_set = set({})\n",
    "for val in [set(val) for val in train_data['Sequence']]:\n",
    "    all_char_set = all_char_set.union(val)\n",
    "all_char_list = list(all_char_set)\n",
    "all_char_list.sort()\n",
    "all_char_dict = {}\n",
    "for i in range(len(all_char_list)):\n",
    "    all_char_dict[all_char_list[i]] = i\n",
    "    \n",
    "##################################################################################\n",
    "##### Create OHE of sequence\n",
    "##################################################################################\n",
    "train_data['OHE_Sequence'] = pd.Series([one_hot_encode_nt(val, all_char_dict) \n",
    "                                        for val in train_data[\"Sequence\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Fix the labels\n",
    "##################################################################################\n",
    "train_data['label'] = pd.Series([1 if val == 1 else 0 \n",
    "                                 for val in train_data[\"label_original\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "train_features = np.array(list(train_data['OHE_Sequence']))\n",
    "train_labels = np.array(list(train_data['label']))\n",
    "train_labels = train_labels.reshape((train_labels.shape[0], 1))\n",
    "\n",
    "input_seq_shape = train_features[0].shape\n",
    "\n",
    "folds = build_kfold(train_features, train_labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "## Write the k-fold dataset to file\n",
    "foldPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(foldPath)):\n",
    "    os.makedirs(foldPath)\n",
    "pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final prep for Independent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Create OHE of sequence\n",
    "##################################################################################\n",
    "indpe_data['OHE_Sequence'] = pd.Series([one_hot_encode_nt(val, all_char_dict) \n",
    "                                        for val in indpe_data[\"Sequence\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Fix the labels\n",
    "##################################################################################\n",
    "indpe_data['label'] = pd.Series([1 if val == 1 else 0 \n",
    "                                 for val in indpe_data[\"label_original\"]])\n",
    "\n",
    "##################################################################################\n",
    "##### Extract features and labels, create folds\n",
    "##################################################################################\n",
    "\n",
    "indpe_features = np.array(list(indpe_data['OHE_Sequence']))\n",
    "indpe_labels = np.array(list(indpe_data['label']))\n",
    "indpe_labels = indpe_labels.reshape((indpe_labels.shape[0], 1))\n",
    "\n",
    "input_seq_shape = indpe_features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test model on Fold #0.\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.1452\n",
      "Epoch 1: val_loss improved from inf to 1.08208, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 6s 17ms/step - loss: 1.1452 - val_loss: 1.0821\n",
      "Epoch 2/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 1.0551\n",
      "Epoch 2: val_loss improved from 1.08208 to 1.00930, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.0531 - val_loss: 1.0093\n",
      "Epoch 3/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.9839\n",
      "Epoch 3: val_loss improved from 1.00930 to 0.95044, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.9838 - val_loss: 0.9504\n",
      "Epoch 4/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.9285\n",
      "Epoch 4: val_loss improved from 0.95044 to 0.90279, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.9280 - val_loss: 0.9028\n",
      "Epoch 5/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.8834\n",
      "Epoch 5: val_loss improved from 0.90279 to 0.86318, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8831 - val_loss: 0.8632\n",
      "Epoch 6/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.8481\n",
      "Epoch 6: val_loss improved from 0.86318 to 0.82891, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8474 - val_loss: 0.8289\n",
      "Epoch 7/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.8140\n",
      "Epoch 7: val_loss improved from 0.82891 to 0.79509, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8142 - val_loss: 0.7951\n",
      "Epoch 8/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.7823\n",
      "Epoch 8: val_loss improved from 0.79509 to 0.74795, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.7816 - val_loss: 0.7480\n",
      "Epoch 9/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.7264\n",
      "Epoch 9: val_loss improved from 0.74795 to 0.67521, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.7264 - val_loss: 0.6752\n",
      "Epoch 10/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.6834\n",
      "Epoch 10: val_loss improved from 0.67521 to 0.65059, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6869 - val_loss: 0.6506\n",
      "Epoch 11/100\n",
      "51/58 [=========================>....] - ETA: 0s - loss: 0.6683\n",
      "Epoch 11: val_loss improved from 0.65059 to 0.63085, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.6647 - val_loss: 0.6309\n",
      "Epoch 12/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.6433\n",
      "Epoch 12: val_loss improved from 0.63085 to 0.61725, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6407 - val_loss: 0.6173\n",
      "Epoch 13/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.6264\n",
      "Epoch 13: val_loss improved from 0.61725 to 0.60531, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6248 - val_loss: 0.6053\n",
      "Epoch 14/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.6104\n",
      "Epoch 14: val_loss improved from 0.60531 to 0.59310, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6085 - val_loss: 0.5931\n",
      "Epoch 15/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.6063\n",
      "Epoch 15: val_loss improved from 0.59310 to 0.58563, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6063 - val_loss: 0.5856\n",
      "Epoch 16/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.5848\n",
      "Epoch 16: val_loss improved from 0.58563 to 0.57534, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5829 - val_loss: 0.5753\n",
      "Epoch 17/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.5808\n",
      "Epoch 17: val_loss improved from 0.57534 to 0.56520, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5825 - val_loss: 0.5652\n",
      "Epoch 18/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.5769\n",
      "Epoch 18: val_loss improved from 0.56520 to 0.55820, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5768 - val_loss: 0.5582\n",
      "Epoch 19/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5631\n",
      "Epoch 19: val_loss improved from 0.55820 to 0.54895, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5613 - val_loss: 0.5489\n",
      "Epoch 20/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5533\n",
      "Epoch 20: val_loss improved from 0.54895 to 0.54334, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5527 - val_loss: 0.5433\n",
      "Epoch 21/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5516\n",
      "Epoch 21: val_loss improved from 0.54334 to 0.53799, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5511 - val_loss: 0.5380\n",
      "Epoch 22/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5485\n",
      "Epoch 22: val_loss improved from 0.53799 to 0.53406, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5486 - val_loss: 0.5341\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5318\n",
      "Epoch 23: val_loss improved from 0.53406 to 0.52520, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5318 - val_loss: 0.5252\n",
      "Epoch 24/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.5236\n",
      "Epoch 24: val_loss did not improve from 0.52520\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5235 - val_loss: 0.5306\n",
      "Epoch 25/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.5149\n",
      "Epoch 25: val_loss improved from 0.52520 to 0.51688, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 9ms/step - loss: 0.5150 - val_loss: 0.5169\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5086\n",
      "Epoch 26: val_loss improved from 0.51688 to 0.50835, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5086 - val_loss: 0.5083\n",
      "Epoch 27/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4973\n",
      "Epoch 27: val_loss improved from 0.50835 to 0.49837, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4987 - val_loss: 0.4984\n",
      "Epoch 28/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4949\n",
      "Epoch 28: val_loss improved from 0.49837 to 0.49076, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4942 - val_loss: 0.4908\n",
      "Epoch 29/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4949\n",
      "Epoch 29: val_loss improved from 0.49076 to 0.48802, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4946 - val_loss: 0.4880\n",
      "Epoch 30/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4913\n",
      "Epoch 30: val_loss improved from 0.48802 to 0.48215, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4954 - val_loss: 0.4821\n",
      "Epoch 31/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4752\n",
      "Epoch 31: val_loss improved from 0.48215 to 0.47898, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4765 - val_loss: 0.4790\n",
      "Epoch 32/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4738\n",
      "Epoch 32: val_loss improved from 0.47898 to 0.47641, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4746 - val_loss: 0.4764\n",
      "Epoch 33/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4744\n",
      "Epoch 33: val_loss did not improve from 0.47641\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4739 - val_loss: 0.4996\n",
      "Epoch 34/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4800\n",
      "Epoch 34: val_loss improved from 0.47641 to 0.47530, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4801 - val_loss: 0.4753\n",
      "Epoch 35/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4729\n",
      "Epoch 35: val_loss improved from 0.47530 to 0.47455, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4723 - val_loss: 0.4746\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4672\n",
      "Epoch 36: val_loss improved from 0.47455 to 0.47055, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4672 - val_loss: 0.4706\n",
      "Epoch 37/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4608\n",
      "Epoch 37: val_loss improved from 0.47055 to 0.46487, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4609 - val_loss: 0.4649\n",
      "Epoch 38/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4491\n",
      "Epoch 38: val_loss improved from 0.46487 to 0.46215, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4486 - val_loss: 0.4622\n",
      "Epoch 39/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4568\n",
      "Epoch 39: val_loss improved from 0.46215 to 0.45672, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4581 - val_loss: 0.4567\n",
      "Epoch 40/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4590\n",
      "Epoch 40: val_loss did not improve from 0.45672\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4617 - val_loss: 0.4672\n",
      "Epoch 41/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4333\n",
      "Epoch 41: val_loss improved from 0.45672 to 0.45440, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4334 - val_loss: 0.4544\n",
      "Epoch 42/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4507\n",
      "Epoch 42: val_loss did not improve from 0.45440\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4504 - val_loss: 0.4567\n",
      "Epoch 43/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4476\n",
      "Epoch 43: val_loss improved from 0.45440 to 0.45062, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4467 - val_loss: 0.4506\n",
      "Epoch 44/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4448\n",
      "Epoch 44: val_loss did not improve from 0.45062\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4453 - val_loss: 0.4515\n",
      "Epoch 45/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4325\n",
      "Epoch 45: val_loss improved from 0.45062 to 0.44659, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4342 - val_loss: 0.4466\n",
      "Epoch 46/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4397\n",
      "Epoch 46: val_loss did not improve from 0.44659\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4368 - val_loss: 0.4473\n",
      "Epoch 47/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4159\n",
      "Epoch 47: val_loss improved from 0.44659 to 0.44429, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4147 - val_loss: 0.4443\n",
      "Epoch 48/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4273\n",
      "Epoch 48: val_loss improved from 0.44429 to 0.44292, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4287 - val_loss: 0.4429\n",
      "Epoch 49/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4326\n",
      "Epoch 49: val_loss did not improve from 0.44292\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4297 - val_loss: 0.4440\n",
      "Epoch 50/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4336\n",
      "Epoch 50: val_loss did not improve from 0.44292\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4332 - val_loss: 0.4462\n",
      "Epoch 51/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4199\n",
      "Epoch 51: val_loss improved from 0.44292 to 0.44049, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4202 - val_loss: 0.4405\n",
      "Epoch 52/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4109\n",
      "Epoch 52: val_loss improved from 0.44049 to 0.43228, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4109 - val_loss: 0.4323\n",
      "Epoch 53/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4207\n",
      "Epoch 53: val_loss improved from 0.43228 to 0.43016, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4206 - val_loss: 0.4302\n",
      "Epoch 54/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4148\n",
      "Epoch 54: val_loss did not improve from 0.43016\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4151 - val_loss: 0.4350\n",
      "Epoch 55/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4199\n",
      "Epoch 55: val_loss improved from 0.43016 to 0.42633, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4196 - val_loss: 0.4263\n",
      "Epoch 56/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4067\n",
      "Epoch 56: val_loss did not improve from 0.42633\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4061 - val_loss: 0.4322\n",
      "Epoch 57/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4052\n",
      "Epoch 57: val_loss did not improve from 0.42633\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4079 - val_loss: 0.4313\n",
      "Epoch 58/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4033\n",
      "Epoch 58: val_loss improved from 0.42633 to 0.42537, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4027 - val_loss: 0.4254\n",
      "Epoch 59/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4050\n",
      "Epoch 59: val_loss did not improve from 0.42537\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4053 - val_loss: 0.4261\n",
      "Epoch 60/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4234\n",
      "Epoch 60: val_loss improved from 0.42537 to 0.41951, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4234 - val_loss: 0.4195\n",
      "Epoch 61/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3925\n",
      "Epoch 61: val_loss did not improve from 0.41951\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3912 - val_loss: 0.4197\n",
      "Epoch 62/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4000\n",
      "Epoch 62: val_loss did not improve from 0.41951\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3996 - val_loss: 0.4307\n",
      "Epoch 63/100\n",
      "51/58 [=========================>....] - ETA: 0s - loss: 0.4091\n",
      "Epoch 63: val_loss did not improve from 0.41951\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4095 - val_loss: 0.4221\n",
      "Epoch 64/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4045\n",
      "Epoch 64: val_loss did not improve from 0.41951\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4039 - val_loss: 0.4230\n",
      "Epoch 65/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4038\n",
      "Epoch 65: val_loss did not improve from 0.41951\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4030 - val_loss: 0.4231\n",
      "Epoch 66/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3896\n",
      "Epoch 66: val_loss did not improve from 0.41951\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3893 - val_loss: 0.4266\n",
      "Epoch 67/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4028\n",
      "Epoch 67: val_loss did not improve from 0.41951\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4034 - val_loss: 0.4216\n",
      "Epoch 68/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3935\n",
      "Epoch 68: val_loss improved from 0.41951 to 0.41906, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3923 - val_loss: 0.4191\n",
      "Epoch 69/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3834\n",
      "Epoch 69: val_loss improved from 0.41906 to 0.41656, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3855 - val_loss: 0.4166\n",
      "Epoch 70/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3903\n",
      "Epoch 70: val_loss improved from 0.41656 to 0.41276, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3911 - val_loss: 0.4128\n",
      "Epoch 71/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3797\n",
      "Epoch 71: val_loss improved from 0.41276 to 0.41157, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3815 - val_loss: 0.4116\n",
      "Epoch 72/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3979\n",
      "Epoch 72: val_loss did not improve from 0.41157\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3966 - val_loss: 0.4130\n",
      "Epoch 73/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3871\n",
      "Epoch 73: val_loss improved from 0.41157 to 0.40829, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3885 - val_loss: 0.4083\n",
      "Epoch 74/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3782\n",
      "Epoch 74: val_loss improved from 0.40829 to 0.40146, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3782 - val_loss: 0.4015\n",
      "Epoch 75/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3835\n",
      "Epoch 75: val_loss did not improve from 0.40146\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3814 - val_loss: 0.4145\n",
      "Epoch 76/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3763\n",
      "Epoch 76: val_loss improved from 0.40146 to 0.40136, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3767 - val_loss: 0.4014\n",
      "Epoch 77/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3716\n",
      "Epoch 77: val_loss did not improve from 0.40136\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3709 - val_loss: 0.4031\n",
      "Epoch 78/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3828\n",
      "Epoch 78: val_loss did not improve from 0.40136\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3830 - val_loss: 0.4101\n",
      "Epoch 79/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3808\n",
      "Epoch 79: val_loss improved from 0.40136 to 0.40020, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3824 - val_loss: 0.4002\n",
      "Epoch 80/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3759\n",
      "Epoch 80: val_loss improved from 0.40020 to 0.39606, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3788 - val_loss: 0.3961\n",
      "Epoch 81/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3811\n",
      "Epoch 81: val_loss improved from 0.39606 to 0.39491, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3817 - val_loss: 0.3949\n",
      "Epoch 82/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3744\n",
      "Epoch 82: val_loss did not improve from 0.39491\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3744 - val_loss: 0.3999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3662\n",
      "Epoch 83: val_loss did not improve from 0.39491\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3679 - val_loss: 0.4005\n",
      "Epoch 84/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3650\n",
      "Epoch 84: val_loss did not improve from 0.39491\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3650 - val_loss: 0.4057\n",
      "Epoch 85/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3737\n",
      "Epoch 85: val_loss did not improve from 0.39491\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3747 - val_loss: 0.4005\n",
      "Epoch 86/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3763\n",
      "Epoch 86: val_loss improved from 0.39491 to 0.39347, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3739 - val_loss: 0.3935\n",
      "Epoch 87/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3715\n",
      "Epoch 87: val_loss did not improve from 0.39347\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3716 - val_loss: 0.4004\n",
      "Epoch 88/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3592\n",
      "Epoch 88: val_loss did not improve from 0.39347\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3600 - val_loss: 0.4006\n",
      "Epoch 89/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3556\n",
      "Epoch 89: val_loss improved from 0.39347 to 0.39155, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3562 - val_loss: 0.3916\n",
      "Epoch 90/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3690\n",
      "Epoch 90: val_loss did not improve from 0.39155\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3752 - val_loss: 0.3930\n",
      "Epoch 91/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3642\n",
      "Epoch 91: val_loss did not improve from 0.39155\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3639 - val_loss: 0.4017\n",
      "Epoch 92/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3732\n",
      "Epoch 92: val_loss did not improve from 0.39155\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3730 - val_loss: 0.3937\n",
      "Epoch 93/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3647\n",
      "Epoch 93: val_loss did not improve from 0.39155\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3640 - val_loss: 0.4072\n",
      "Epoch 94/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3810\n",
      "Epoch 94: val_loss improved from 0.39155 to 0.38815, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3810 - val_loss: 0.3881\n",
      "Epoch 95/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3587\n",
      "Epoch 95: val_loss did not improve from 0.38815\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3585 - val_loss: 0.3928\n",
      "Epoch 96/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3645\n",
      "Epoch 96: val_loss did not improve from 0.38815\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3655 - val_loss: 0.3914\n",
      "Epoch 97/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3820\n",
      "Epoch 97: val_loss improved from 0.38815 to 0.38709, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3821 - val_loss: 0.3871\n",
      "Epoch 98/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3578\n",
      "Epoch 98: val_loss improved from 0.38709 to 0.38528, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3602 - val_loss: 0.3853\n",
      "Epoch 99/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3764\n",
      "Epoch 99: val_loss improved from 0.38528 to 0.38114, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold0.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3759 - val_loss: 0.3811\n",
      "Epoch 100/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3706\n",
      "Epoch 100: val_loss did not improve from 0.38114\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3710 - val_loss: 0.3911\n",
      "\n",
      "Train/Test model on Fold #1.\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.1308\n",
      "Epoch 1: val_loss improved from inf to 1.07180, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 3s 19ms/step - loss: 1.1308 - val_loss: 1.0718\n",
      "Epoch 2/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 1.0366\n",
      "Epoch 2: val_loss improved from 1.07180 to 0.99129, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.0355 - val_loss: 0.9913\n",
      "Epoch 3/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.9613\n",
      "Epoch 3: val_loss improved from 0.99129 to 0.92854, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.9610 - val_loss: 0.9285\n",
      "Epoch 4/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.9041\n",
      "Epoch 4: val_loss improved from 0.92854 to 0.87880, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.9023 - val_loss: 0.8788\n",
      "Epoch 5/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.8588\n",
      "Epoch 5: val_loss improved from 0.87880 to 0.83473, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8569 - val_loss: 0.8347\n",
      "Epoch 6/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.8093\n",
      "Epoch 6: val_loss improved from 0.83473 to 0.77346, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8076 - val_loss: 0.7735\n",
      "Epoch 7/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.7519\n",
      "Epoch 7: val_loss improved from 0.77346 to 0.70830, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.7519 - val_loss: 0.7083\n",
      "Epoch 8/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.7217\n",
      "Epoch 8: val_loss improved from 0.70830 to 0.68272, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.7211 - val_loss: 0.6827\n",
      "Epoch 9/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.6874\n",
      "Epoch 9: val_loss improved from 0.68272 to 0.66200, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6867 - val_loss: 0.6620\n",
      "Epoch 10/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.6751\n",
      "Epoch 10: val_loss improved from 0.66200 to 0.65334, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6729 - val_loss: 0.6533\n",
      "Epoch 11/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.6449\n",
      "Epoch 11: val_loss improved from 0.65334 to 0.63316, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6448 - val_loss: 0.6332\n",
      "Epoch 12/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.6375\n",
      "Epoch 12: val_loss improved from 0.63316 to 0.62376, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6372 - val_loss: 0.6238\n",
      "Epoch 13/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.6297\n",
      "Epoch 13: val_loss improved from 0.62376 to 0.61533, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6290 - val_loss: 0.6153\n",
      "Epoch 14/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.6156\n",
      "Epoch 14: val_loss improved from 0.61533 to 0.60653, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6129 - val_loss: 0.6065\n",
      "Epoch 15/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.6066\n",
      "Epoch 15: val_loss improved from 0.60653 to 0.59923, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6061 - val_loss: 0.5992\n",
      "Epoch 16/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5966\n",
      "Epoch 16: val_loss improved from 0.59923 to 0.59634, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5957 - val_loss: 0.5963\n",
      "Epoch 17/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5837\n",
      "Epoch 17: val_loss improved from 0.59634 to 0.58599, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5838 - val_loss: 0.5860\n",
      "Epoch 18/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5833\n",
      "Epoch 18: val_loss improved from 0.58599 to 0.58122, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5802 - val_loss: 0.5812\n",
      "Epoch 19/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5728\n",
      "Epoch 19: val_loss did not improve from 0.58122\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5767 - val_loss: 0.5837\n",
      "Epoch 20/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5636\n",
      "Epoch 20: val_loss improved from 0.58122 to 0.57147, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5637 - val_loss: 0.5715\n",
      "Epoch 21/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5587\n",
      "Epoch 21: val_loss improved from 0.57147 to 0.56709, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5570 - val_loss: 0.5671\n",
      "Epoch 22/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5511\n",
      "Epoch 22: val_loss improved from 0.56709 to 0.56055, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5509 - val_loss: 0.5605\n",
      "Epoch 23/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5359\n",
      "Epoch 23: val_loss improved from 0.56055 to 0.55792, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5382 - val_loss: 0.5579\n",
      "Epoch 24/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5300\n",
      "Epoch 24: val_loss did not improve from 0.55792\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5307 - val_loss: 0.5709\n",
      "Epoch 25/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.5271\n",
      "Epoch 25: val_loss improved from 0.55792 to 0.55062, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5283 - val_loss: 0.5506\n",
      "Epoch 26/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5214\n",
      "Epoch 26: val_loss improved from 0.55062 to 0.54329, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5222 - val_loss: 0.5433\n",
      "Epoch 27/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.5181\n",
      "Epoch 27: val_loss improved from 0.54329 to 0.53628, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5172 - val_loss: 0.5363\n",
      "Epoch 28/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5110\n",
      "Epoch 28: val_loss improved from 0.53628 to 0.53334, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5116 - val_loss: 0.5333\n",
      "Epoch 29/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4999\n",
      "Epoch 29: val_loss improved from 0.53334 to 0.52634, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5027 - val_loss: 0.5263\n",
      "Epoch 30/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5011\n",
      "Epoch 30: val_loss improved from 0.52634 to 0.52184, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5009 - val_loss: 0.5218\n",
      "Epoch 31/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4883\n",
      "Epoch 31: val_loss improved from 0.52184 to 0.51928, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4865 - val_loss: 0.5193\n",
      "Epoch 32/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4910\n",
      "Epoch 32: val_loss did not improve from 0.51928\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4920 - val_loss: 0.5297\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4856\n",
      "Epoch 33: val_loss improved from 0.51928 to 0.51460, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4856 - val_loss: 0.5146\n",
      "Epoch 34/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4706\n",
      "Epoch 34: val_loss improved from 0.51460 to 0.50526, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4705 - val_loss: 0.5053\n",
      "Epoch 35/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4604\n",
      "Epoch 35: val_loss did not improve from 0.50526\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4601 - val_loss: 0.5087\n",
      "Epoch 36/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4806\n",
      "Epoch 36: val_loss improved from 0.50526 to 0.50127, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4808 - val_loss: 0.5013\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4797\n",
      "Epoch 37: val_loss did not improve from 0.50127\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4785 - val_loss: 0.5043\n",
      "Epoch 38/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4524\n",
      "Epoch 38: val_loss improved from 0.50127 to 0.49234, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4524 - val_loss: 0.4923\n",
      "Epoch 39/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4582\n",
      "Epoch 39: val_loss did not improve from 0.49234\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4603 - val_loss: 0.4999\n",
      "Epoch 40/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4630\n",
      "Epoch 40: val_loss did not improve from 0.49234\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4647 - val_loss: 0.4958\n",
      "Epoch 41/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4441\n",
      "Epoch 41: val_loss improved from 0.49234 to 0.48731, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4439 - val_loss: 0.4873\n",
      "Epoch 42/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4473\n",
      "Epoch 42: val_loss improved from 0.48731 to 0.48118, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4463 - val_loss: 0.4812\n",
      "Epoch 43/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4324\n",
      "Epoch 43: val_loss improved from 0.48118 to 0.47639, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4331 - val_loss: 0.4764\n",
      "Epoch 44/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4256\n",
      "Epoch 44: val_loss did not improve from 0.47639\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4259 - val_loss: 0.4864\n",
      "Epoch 45/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4334\n",
      "Epoch 45: val_loss did not improve from 0.47639\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4345 - val_loss: 0.4858\n",
      "Epoch 46/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4236\n",
      "Epoch 46: val_loss improved from 0.47639 to 0.47227, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4258 - val_loss: 0.4723\n",
      "Epoch 47/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4323\n",
      "Epoch 47: val_loss did not improve from 0.47227\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4316 - val_loss: 0.4805\n",
      "Epoch 48/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4231\n",
      "Epoch 48: val_loss improved from 0.47227 to 0.46694, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4219 - val_loss: 0.4669\n",
      "Epoch 49/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4172\n",
      "Epoch 49: val_loss improved from 0.46694 to 0.46112, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4171 - val_loss: 0.4611\n",
      "Epoch 50/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4241\n",
      "Epoch 50: val_loss did not improve from 0.46112\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4245 - val_loss: 0.4618\n",
      "Epoch 51/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4175\n",
      "Epoch 51: val_loss improved from 0.46112 to 0.45795, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4187 - val_loss: 0.4579\n",
      "Epoch 52/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4242\n",
      "Epoch 52: val_loss did not improve from 0.45795\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4236 - val_loss: 0.4621\n",
      "Epoch 53/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4142\n",
      "Epoch 53: val_loss did not improve from 0.45795\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4163 - val_loss: 0.4595\n",
      "Epoch 54/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4263\n",
      "Epoch 54: val_loss improved from 0.45795 to 0.45740, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4293 - val_loss: 0.4574\n",
      "Epoch 55/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4193\n",
      "Epoch 55: val_loss improved from 0.45740 to 0.45315, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4176 - val_loss: 0.4532\n",
      "Epoch 56/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4028\n",
      "Epoch 56: val_loss did not improve from 0.45315\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4059 - val_loss: 0.4537\n",
      "Epoch 57/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4161\n",
      "Epoch 57: val_loss did not improve from 0.45315\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4143 - val_loss: 0.4572\n",
      "Epoch 58/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4023\n",
      "Epoch 58: val_loss did not improve from 0.45315\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4053 - val_loss: 0.4560\n",
      "Epoch 59/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3985\n",
      "Epoch 59: val_loss improved from 0.45315 to 0.45126, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3982 - val_loss: 0.4513\n",
      "Epoch 60/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4082\n",
      "Epoch 60: val_loss did not improve from 0.45126\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4059 - val_loss: 0.4523\n",
      "Epoch 61/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4070\n",
      "Epoch 61: val_loss did not improve from 0.45126\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4039 - val_loss: 0.4547\n",
      "Epoch 62/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4059\n",
      "Epoch 62: val_loss improved from 0.45126 to 0.44926, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4056 - val_loss: 0.4493\n",
      "Epoch 63/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4046\n",
      "Epoch 63: val_loss improved from 0.44926 to 0.44435, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4073 - val_loss: 0.4443\n",
      "Epoch 64/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3910\n",
      "Epoch 64: val_loss improved from 0.44435 to 0.44416, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3908 - val_loss: 0.4442\n",
      "Epoch 65/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3937\n",
      "Epoch 65: val_loss improved from 0.44416 to 0.44180, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3930 - val_loss: 0.4418\n",
      "Epoch 66/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3883\n",
      "Epoch 66: val_loss did not improve from 0.44180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3903 - val_loss: 0.4526\n",
      "Epoch 67/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3962\n",
      "Epoch 67: val_loss improved from 0.44180 to 0.43972, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3954 - val_loss: 0.4397\n",
      "Epoch 68/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3882\n",
      "Epoch 68: val_loss did not improve from 0.43972\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3882 - val_loss: 0.4486\n",
      "Epoch 69/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3795\n",
      "Epoch 69: val_loss did not improve from 0.43972\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3796 - val_loss: 0.4418\n",
      "Epoch 70/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3863\n",
      "Epoch 70: val_loss did not improve from 0.43972\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3885 - val_loss: 0.4455\n",
      "Epoch 71/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3814\n",
      "Epoch 71: val_loss improved from 0.43972 to 0.43634, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3844 - val_loss: 0.4363\n",
      "Epoch 72/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3824\n",
      "Epoch 72: val_loss did not improve from 0.43634\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3847 - val_loss: 0.4445\n",
      "Epoch 73/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3853\n",
      "Epoch 73: val_loss did not improve from 0.43634\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3849 - val_loss: 0.4399\n",
      "Epoch 74/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3879\n",
      "Epoch 74: val_loss did not improve from 0.43634\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3888 - val_loss: 0.4399\n",
      "Epoch 75/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3792\n",
      "Epoch 75: val_loss did not improve from 0.43634\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3795 - val_loss: 0.4435\n",
      "Epoch 76/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3785\n",
      "Epoch 76: val_loss did not improve from 0.43634\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3789 - val_loss: 0.4533\n",
      "Epoch 77/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3938\n",
      "Epoch 77: val_loss did not improve from 0.43634\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3928 - val_loss: 0.4392\n",
      "Epoch 78/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3713\n",
      "Epoch 78: val_loss did not improve from 0.43634\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3763 - val_loss: 0.4437\n",
      "Epoch 79/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3775\n",
      "Epoch 79: val_loss improved from 0.43634 to 0.43483, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3781 - val_loss: 0.4348\n",
      "Epoch 80/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3711\n",
      "Epoch 80: val_loss did not improve from 0.43483\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3697 - val_loss: 0.4406\n",
      "Epoch 81/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3780\n",
      "Epoch 81: val_loss did not improve from 0.43483\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3784 - val_loss: 0.4445\n",
      "Epoch 82/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3822\n",
      "Epoch 82: val_loss did not improve from 0.43483\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3826 - val_loss: 0.4366\n",
      "Epoch 83/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3734\n",
      "Epoch 83: val_loss did not improve from 0.43483\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3757 - val_loss: 0.4402\n",
      "Epoch 84/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3826\n",
      "Epoch 84: val_loss did not improve from 0.43483\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3813 - val_loss: 0.4365\n",
      "Epoch 85/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3690\n",
      "Epoch 85: val_loss did not improve from 0.43483\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3734 - val_loss: 0.4366\n",
      "Epoch 86/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3870\n",
      "Epoch 86: val_loss did not improve from 0.43483\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3857 - val_loss: 0.4375\n",
      "Epoch 87/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3810\n",
      "Epoch 87: val_loss improved from 0.43483 to 0.42855, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3802 - val_loss: 0.4285\n",
      "Epoch 88/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3570\n",
      "Epoch 88: val_loss did not improve from 0.42855\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3580 - val_loss: 0.4358\n",
      "Epoch 89/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3768\n",
      "Epoch 89: val_loss improved from 0.42855 to 0.42704, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3771 - val_loss: 0.4270\n",
      "Epoch 90/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3651\n",
      "Epoch 90: val_loss improved from 0.42704 to 0.42702, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3647 - val_loss: 0.4270\n",
      "Epoch 91/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3519\n",
      "Epoch 91: val_loss did not improve from 0.42702\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3523 - val_loss: 0.4352\n",
      "Epoch 92/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3541\n",
      "Epoch 92: val_loss did not improve from 0.42702\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3523 - val_loss: 0.4358\n",
      "Epoch 93/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3726\n",
      "Epoch 93: val_loss improved from 0.42702 to 0.42391, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3744 - val_loss: 0.4239\n",
      "Epoch 94/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3639\n",
      "Epoch 94: val_loss did not improve from 0.42391\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3625 - val_loss: 0.4341\n",
      "Epoch 95/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3702\n",
      "Epoch 95: val_loss did not improve from 0.42391\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3708 - val_loss: 0.4313\n",
      "Epoch 96/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3578\n",
      "Epoch 96: val_loss did not improve from 0.42391\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3628 - val_loss: 0.4258\n",
      "Epoch 97/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3839\n",
      "Epoch 97: val_loss did not improve from 0.42391\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3816 - val_loss: 0.4368\n",
      "Epoch 98/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3618\n",
      "Epoch 98: val_loss did not improve from 0.42391\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3622 - val_loss: 0.4258\n",
      "Epoch 99/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3691\n",
      "Epoch 99: val_loss improved from 0.42391 to 0.42250, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3661 - val_loss: 0.4225\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/58 [============================>.] - ETA: 0s - loss: 0.3711\n",
      "Epoch 100: val_loss improved from 0.42250 to 0.42053, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold1.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3699 - val_loss: 0.4205\n",
      "\n",
      "Train/Test model on Fold #2.\n",
      "Epoch 1/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 1.1465\n",
      "Epoch 1: val_loss improved from inf to 1.07648, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 2s 16ms/step - loss: 1.1414 - val_loss: 1.0765\n",
      "Epoch 2/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 1.0482\n",
      "Epoch 2: val_loss improved from 1.07648 to 1.00579, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.0465 - val_loss: 1.0058\n",
      "Epoch 3/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.9807\n",
      "Epoch 3: val_loss improved from 1.00579 to 0.94815, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.9801 - val_loss: 0.9481\n",
      "Epoch 4/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.9257\n",
      "Epoch 4: val_loss improved from 0.94815 to 0.90155, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.9251 - val_loss: 0.9015\n",
      "Epoch 5/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.8837\n",
      "Epoch 5: val_loss improved from 0.90155 to 0.86305, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8833 - val_loss: 0.8631\n",
      "Epoch 6/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.8468\n",
      "Epoch 6: val_loss improved from 0.86305 to 0.82706, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8460 - val_loss: 0.8271\n",
      "Epoch 7/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.8121\n",
      "Epoch 7: val_loss improved from 0.82706 to 0.78138, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8107 - val_loss: 0.7814\n",
      "Epoch 8/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.7600\n",
      "Epoch 8: val_loss improved from 0.78138 to 0.71031, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.7588 - val_loss: 0.7103\n",
      "Epoch 9/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.7135\n",
      "Epoch 9: val_loss improved from 0.71031 to 0.67123, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.7124 - val_loss: 0.6712\n",
      "Epoch 10/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.6772\n",
      "Epoch 10: val_loss improved from 0.67123 to 0.64532, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6798 - val_loss: 0.6453\n",
      "Epoch 11/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.6748\n",
      "Epoch 11: val_loss improved from 0.64532 to 0.63217, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6743 - val_loss: 0.6322\n",
      "Epoch 12/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.6437\n",
      "Epoch 12: val_loss improved from 0.63217 to 0.61740, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6449 - val_loss: 0.6174\n",
      "Epoch 13/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.6370\n",
      "Epoch 13: val_loss improved from 0.61740 to 0.60957, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6343 - val_loss: 0.6096\n",
      "Epoch 14/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.6255\n",
      "Epoch 14: val_loss improved from 0.60957 to 0.59962, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6247 - val_loss: 0.5996\n",
      "Epoch 15/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.6098\n",
      "Epoch 15: val_loss improved from 0.59962 to 0.58701, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6080 - val_loss: 0.5870\n",
      "Epoch 16/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5990\n",
      "Epoch 16: val_loss improved from 0.58701 to 0.57816, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5993 - val_loss: 0.5782\n",
      "Epoch 17/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.5849\n",
      "Epoch 17: val_loss improved from 0.57816 to 0.57204, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5877 - val_loss: 0.5720\n",
      "Epoch 18/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5827\n",
      "Epoch 18: val_loss improved from 0.57204 to 0.56636, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5819 - val_loss: 0.5664\n",
      "Epoch 19/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5785\n",
      "Epoch 19: val_loss did not improve from 0.56636\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5779 - val_loss: 0.5688\n",
      "Epoch 20/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5773\n",
      "Epoch 20: val_loss improved from 0.56636 to 0.55353, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5767 - val_loss: 0.5535\n",
      "Epoch 21/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5626\n",
      "Epoch 21: val_loss improved from 0.55353 to 0.54610, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5635 - val_loss: 0.5461\n",
      "Epoch 22/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5607\n",
      "Epoch 22: val_loss improved from 0.54610 to 0.54247, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5591 - val_loss: 0.5425\n",
      "Epoch 23/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5411\n",
      "Epoch 23: val_loss improved from 0.54247 to 0.54096, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5423 - val_loss: 0.5410\n",
      "Epoch 24/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5380\n",
      "Epoch 24: val_loss improved from 0.54096 to 0.53690, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5394 - val_loss: 0.5369\n",
      "Epoch 25/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.5293\n",
      "Epoch 25: val_loss improved from 0.53690 to 0.53437, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5309 - val_loss: 0.5344\n",
      "Epoch 26/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.5212\n",
      "Epoch 26: val_loss improved from 0.53437 to 0.51777, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5212 - val_loss: 0.5178\n",
      "Epoch 27/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5230\n",
      "Epoch 27: val_loss did not improve from 0.51777\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5251 - val_loss: 0.5294\n",
      "Epoch 28/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5155\n",
      "Epoch 28: val_loss did not improve from 0.51777\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5173 - val_loss: 0.5236\n",
      "Epoch 29/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5089\n",
      "Epoch 29: val_loss improved from 0.51777 to 0.51188, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5098 - val_loss: 0.5119\n",
      "Epoch 30/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5117\n",
      "Epoch 30: val_loss improved from 0.51188 to 0.50933, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5098 - val_loss: 0.5093\n",
      "Epoch 31/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4995\n",
      "Epoch 31: val_loss improved from 0.50933 to 0.50730, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4992 - val_loss: 0.5073\n",
      "Epoch 32/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5078\n",
      "Epoch 32: val_loss improved from 0.50730 to 0.50378, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5075 - val_loss: 0.5038\n",
      "Epoch 33/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4990\n",
      "Epoch 33: val_loss improved from 0.50378 to 0.49894, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4967 - val_loss: 0.4989\n",
      "Epoch 34/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5007\n",
      "Epoch 34: val_loss improved from 0.49894 to 0.49535, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4992 - val_loss: 0.4954\n",
      "Epoch 35/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4863\n",
      "Epoch 35: val_loss did not improve from 0.49535\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4841 - val_loss: 0.5155\n",
      "Epoch 36/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4868\n",
      "Epoch 36: val_loss improved from 0.49535 to 0.49076, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4828 - val_loss: 0.4908\n",
      "Epoch 37/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4755\n",
      "Epoch 37: val_loss improved from 0.49076 to 0.48786, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4758 - val_loss: 0.4879\n",
      "Epoch 38/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4730\n",
      "Epoch 38: val_loss improved from 0.48786 to 0.48774, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4741 - val_loss: 0.4877\n",
      "Epoch 39/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4753\n",
      "Epoch 39: val_loss improved from 0.48774 to 0.48092, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4771 - val_loss: 0.4809\n",
      "Epoch 40/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4711\n",
      "Epoch 40: val_loss improved from 0.48092 to 0.47391, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4699 - val_loss: 0.4739\n",
      "Epoch 41/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4595\n",
      "Epoch 41: val_loss improved from 0.47391 to 0.46950, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4559 - val_loss: 0.4695\n",
      "Epoch 42/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4585\n",
      "Epoch 42: val_loss did not improve from 0.46950\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4596 - val_loss: 0.4702\n",
      "Epoch 43/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4548\n",
      "Epoch 43: val_loss improved from 0.46950 to 0.46841, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4575 - val_loss: 0.4684\n",
      "Epoch 44/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4614\n",
      "Epoch 44: val_loss did not improve from 0.46841\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4610 - val_loss: 0.4717\n",
      "Epoch 45/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4576\n",
      "Epoch 45: val_loss improved from 0.46841 to 0.46261, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4607 - val_loss: 0.4626\n",
      "Epoch 46/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4595\n",
      "Epoch 46: val_loss improved from 0.46261 to 0.45768, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4596 - val_loss: 0.4577\n",
      "Epoch 47/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4436\n",
      "Epoch 47: val_loss did not improve from 0.45768\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4413 - val_loss: 0.4593\n",
      "Epoch 48/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4469\n",
      "Epoch 48: val_loss did not improve from 0.45768\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4484 - val_loss: 0.4798\n",
      "Epoch 49/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4429\n",
      "Epoch 49: val_loss did not improve from 0.45768\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4431 - val_loss: 0.4667\n",
      "Epoch 50/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4341\n",
      "Epoch 50: val_loss improved from 0.45768 to 0.45497, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4351 - val_loss: 0.4550\n",
      "Epoch 51/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4402\n",
      "Epoch 51: val_loss improved from 0.45497 to 0.44810, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4405 - val_loss: 0.4481\n",
      "Epoch 52/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4350\n",
      "Epoch 52: val_loss did not improve from 0.44810\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4332 - val_loss: 0.4493\n",
      "Epoch 53/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4254\n",
      "Epoch 53: val_loss improved from 0.44810 to 0.44619, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4254 - val_loss: 0.4462\n",
      "Epoch 54/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4218\n",
      "Epoch 54: val_loss did not improve from 0.44619\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4226 - val_loss: 0.4466\n",
      "Epoch 55/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4389\n",
      "Epoch 55: val_loss improved from 0.44619 to 0.44158, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4361 - val_loss: 0.4416\n",
      "Epoch 56/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4257\n",
      "Epoch 56: val_loss improved from 0.44158 to 0.43915, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4295 - val_loss: 0.4391\n",
      "Epoch 57/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4264\n",
      "Epoch 57: val_loss did not improve from 0.43915\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4243 - val_loss: 0.4435\n",
      "Epoch 58/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4189\n",
      "Epoch 58: val_loss improved from 0.43915 to 0.43899, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4145 - val_loss: 0.4390\n",
      "Epoch 59/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4240\n",
      "Epoch 59: val_loss improved from 0.43899 to 0.43774, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4208 - val_loss: 0.4377\n",
      "Epoch 60/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4312\n",
      "Epoch 60: val_loss improved from 0.43774 to 0.43580, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4330 - val_loss: 0.4358\n",
      "Epoch 61/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4231\n",
      "Epoch 61: val_loss improved from 0.43580 to 0.43288, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4248 - val_loss: 0.4329\n",
      "Epoch 62/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4253\n",
      "Epoch 62: val_loss improved from 0.43288 to 0.43030, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4260 - val_loss: 0.4303\n",
      "Epoch 63/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4178\n",
      "Epoch 63: val_loss improved from 0.43030 to 0.42908, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4169 - val_loss: 0.4291\n",
      "Epoch 64/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4098\n",
      "Epoch 64: val_loss improved from 0.42908 to 0.42226, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4092 - val_loss: 0.4223\n",
      "Epoch 65/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4107\n",
      "Epoch 65: val_loss did not improve from 0.42226\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4083 - val_loss: 0.4570\n",
      "Epoch 66/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4227\n",
      "Epoch 66: val_loss did not improve from 0.42226\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4229 - val_loss: 0.4331\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4077\n",
      "Epoch 67: val_loss improved from 0.42226 to 0.42031, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4077 - val_loss: 0.4203\n",
      "Epoch 68/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4067\n",
      "Epoch 68: val_loss did not improve from 0.42031\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4067 - val_loss: 0.4370\n",
      "Epoch 69/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3941\n",
      "Epoch 69: val_loss did not improve from 0.42031\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3931 - val_loss: 0.4243\n",
      "Epoch 70/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3982\n",
      "Epoch 70: val_loss did not improve from 0.42031\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4031 - val_loss: 0.4295\n",
      "Epoch 71/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4200\n",
      "Epoch 71: val_loss did not improve from 0.42031\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4208 - val_loss: 0.4274\n",
      "Epoch 72/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3987\n",
      "Epoch 72: val_loss did not improve from 0.42031\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4000 - val_loss: 0.4266\n",
      "Epoch 73/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4092\n",
      "Epoch 73: val_loss improved from 0.42031 to 0.41629, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4080 - val_loss: 0.4163\n",
      "Epoch 74/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4085\n",
      "Epoch 74: val_loss improved from 0.41629 to 0.41300, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4115 - val_loss: 0.4130\n",
      "Epoch 75/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3920\n",
      "Epoch 75: val_loss did not improve from 0.41300\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3928 - val_loss: 0.4203\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3863\n",
      "Epoch 76: val_loss improved from 0.41300 to 0.41113, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3863 - val_loss: 0.4111\n",
      "Epoch 77/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4024\n",
      "Epoch 77: val_loss did not improve from 0.41113\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4024 - val_loss: 0.4127\n",
      "Epoch 78/100\n",
      "51/58 [=========================>....] - ETA: 0s - loss: 0.4068\n",
      "Epoch 78: val_loss improved from 0.41113 to 0.41067, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4052 - val_loss: 0.4107\n",
      "Epoch 79/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3906\n",
      "Epoch 79: val_loss improved from 0.41067 to 0.40716, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3894 - val_loss: 0.4072\n",
      "Epoch 80/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3982\n",
      "Epoch 80: val_loss improved from 0.40716 to 0.40562, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3956 - val_loss: 0.4056\n",
      "Epoch 81/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4036\n",
      "Epoch 81: val_loss improved from 0.40562 to 0.40261, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4003 - val_loss: 0.4026\n",
      "Epoch 82/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3950\n",
      "Epoch 82: val_loss did not improve from 0.40261\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3981 - val_loss: 0.4039\n",
      "Epoch 83/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3854\n",
      "Epoch 83: val_loss improved from 0.40261 to 0.40195, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3873 - val_loss: 0.4019\n",
      "Epoch 84/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4091\n",
      "Epoch 84: val_loss did not improve from 0.40195\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4096 - val_loss: 0.4024\n",
      "Epoch 85/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3956\n",
      "Epoch 85: val_loss did not improve from 0.40195\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3969 - val_loss: 0.4107\n",
      "Epoch 86/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3978\n",
      "Epoch 86: val_loss improved from 0.40195 to 0.40010, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3966 - val_loss: 0.4001\n",
      "Epoch 87/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3917\n",
      "Epoch 87: val_loss did not improve from 0.40010\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3912 - val_loss: 0.4103\n",
      "Epoch 88/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3984\n",
      "Epoch 88: val_loss did not improve from 0.40010\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3981 - val_loss: 0.4006\n",
      "Epoch 89/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3847\n",
      "Epoch 89: val_loss improved from 0.40010 to 0.39017, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3861 - val_loss: 0.3902\n",
      "Epoch 90/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3936\n",
      "Epoch 90: val_loss did not improve from 0.39017\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3939 - val_loss: 0.3921\n",
      "Epoch 91/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3843\n",
      "Epoch 91: val_loss did not improve from 0.39017\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3840 - val_loss: 0.3919\n",
      "Epoch 92/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3868\n",
      "Epoch 92: val_loss did not improve from 0.39017\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3878 - val_loss: 0.3910\n",
      "Epoch 93/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3901\n",
      "Epoch 93: val_loss improved from 0.39017 to 0.38991, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold2.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3916 - val_loss: 0.3899\n",
      "Epoch 94/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3673\n",
      "Epoch 94: val_loss did not improve from 0.38991\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3724 - val_loss: 0.3947\n",
      "Epoch 95/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4004\n",
      "Epoch 95: val_loss did not improve from 0.38991\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3985 - val_loss: 0.4046\n",
      "Epoch 96/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3749\n",
      "Epoch 96: val_loss did not improve from 0.38991\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3732 - val_loss: 0.3975\n",
      "Epoch 97/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3684\n",
      "Epoch 97: val_loss did not improve from 0.38991\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3701 - val_loss: 0.3962\n",
      "Epoch 98/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3835\n",
      "Epoch 98: val_loss did not improve from 0.38991\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3853 - val_loss: 0.3984\n",
      "Epoch 99/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3888\n",
      "Epoch 99: val_loss did not improve from 0.38991\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3860 - val_loss: 0.3903\n",
      "Epoch 100/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3740\n",
      "Epoch 100: val_loss did not improve from 0.38991\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3737 - val_loss: 0.3909\n",
      "\n",
      "Train/Test model on Fold #3.\n",
      "Epoch 1/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 1.1361\n",
      "Epoch 1: val_loss improved from inf to 1.07169, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 3s 17ms/step - loss: 1.1339 - val_loss: 1.0717\n",
      "Epoch 2/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 1.0405\n",
      "Epoch 2: val_loss improved from 1.07169 to 0.99541, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.0398 - val_loss: 0.9954\n",
      "Epoch 3/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.9658\n",
      "Epoch 3: val_loss improved from 0.99541 to 0.93468, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.9653 - val_loss: 0.9347\n",
      "Epoch 4/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.9105\n",
      "Epoch 4: val_loss improved from 0.93468 to 0.88601, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.9095 - val_loss: 0.8860\n",
      "Epoch 5/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.8666\n",
      "Epoch 5: val_loss improved from 0.88601 to 0.84341, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8662 - val_loss: 0.8434\n",
      "Epoch 6/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.8279\n",
      "Epoch 6: val_loss improved from 0.84341 to 0.80056, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8265 - val_loss: 0.8006\n",
      "Epoch 7/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.7806\n",
      "Epoch 7: val_loss improved from 0.80056 to 0.74309, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.7805 - val_loss: 0.7431\n",
      "Epoch 8/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.7274\n",
      "Epoch 8: val_loss improved from 0.74309 to 0.68023, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.7270 - val_loss: 0.6802\n",
      "Epoch 9/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.6906\n",
      "Epoch 9: val_loss improved from 0.68023 to 0.65912, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6888 - val_loss: 0.6591\n",
      "Epoch 10/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.6713\n",
      "Epoch 10: val_loss improved from 0.65912 to 0.64308, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6706 - val_loss: 0.6431\n",
      "Epoch 11/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.6483\n",
      "Epoch 11: val_loss improved from 0.64308 to 0.63007, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6483 - val_loss: 0.6301\n",
      "Epoch 12/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.6349\n",
      "Epoch 12: val_loss improved from 0.63007 to 0.62278, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6365 - val_loss: 0.6228\n",
      "Epoch 13/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.6301\n",
      "Epoch 13: val_loss improved from 0.62278 to 0.61409, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6302 - val_loss: 0.6141\n",
      "Epoch 14/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.6180\n",
      "Epoch 14: val_loss improved from 0.61409 to 0.60352, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6174 - val_loss: 0.6035\n",
      "Epoch 15/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.6009\n",
      "Epoch 15: val_loss improved from 0.60352 to 0.59773, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6001 - val_loss: 0.5977\n",
      "Epoch 16/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5973\n",
      "Epoch 16: val_loss improved from 0.59773 to 0.58959, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5982 - val_loss: 0.5896\n",
      "Epoch 17/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5880\n",
      "Epoch 17: val_loss improved from 0.58959 to 0.58136, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5877 - val_loss: 0.5814\n",
      "Epoch 18/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5784\n",
      "Epoch 18: val_loss improved from 0.58136 to 0.57587, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5801 - val_loss: 0.5759\n",
      "Epoch 19/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5801\n",
      "Epoch 19: val_loss improved from 0.57587 to 0.57173, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5782 - val_loss: 0.5717\n",
      "Epoch 20/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5654\n",
      "Epoch 20: val_loss improved from 0.57173 to 0.56569, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5624 - val_loss: 0.5657\n",
      "Epoch 21/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5573\n",
      "Epoch 21: val_loss did not improve from 0.56569\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5591 - val_loss: 0.5668\n",
      "Epoch 22/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5426\n",
      "Epoch 22: val_loss did not improve from 0.56569\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5420 - val_loss: 0.5723\n",
      "Epoch 23/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5404\n",
      "Epoch 23: val_loss improved from 0.56569 to 0.54947, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5416 - val_loss: 0.5495\n",
      "Epoch 24/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.5401\n",
      "Epoch 24: val_loss improved from 0.54947 to 0.54676, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5400 - val_loss: 0.5468\n",
      "Epoch 25/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5363\n",
      "Epoch 25: val_loss improved from 0.54676 to 0.54040, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5390 - val_loss: 0.5404\n",
      "Epoch 26/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5217\n",
      "Epoch 26: val_loss did not improve from 0.54040\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5213 - val_loss: 0.5413\n",
      "Epoch 27/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.5135\n",
      "Epoch 27: val_loss improved from 0.54040 to 0.52925, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5105 - val_loss: 0.5292\n",
      "Epoch 28/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5058\n",
      "Epoch 28: val_loss improved from 0.52925 to 0.52889, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5072 - val_loss: 0.5289\n",
      "Epoch 29/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.5015\n",
      "Epoch 29: val_loss improved from 0.52889 to 0.51741, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4984 - val_loss: 0.5174\n",
      "Epoch 30/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.5019\n",
      "Epoch 30: val_loss improved from 0.51741 to 0.51452, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5047 - val_loss: 0.5145\n",
      "Epoch 31/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4913\n",
      "Epoch 31: val_loss improved from 0.51452 to 0.51325, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4921 - val_loss: 0.5132\n",
      "Epoch 32/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4848\n",
      "Epoch 32: val_loss improved from 0.51325 to 0.50918, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4828 - val_loss: 0.5092\n",
      "Epoch 33/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4789\n",
      "Epoch 33: val_loss improved from 0.50918 to 0.50242, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4803 - val_loss: 0.5024\n",
      "Epoch 34/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4737\n",
      "Epoch 34: val_loss improved from 0.50242 to 0.50092, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4775 - val_loss: 0.5009\n",
      "Epoch 35/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4732\n",
      "Epoch 35: val_loss improved from 0.50092 to 0.49629, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4727 - val_loss: 0.4963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4655\n",
      "Epoch 36: val_loss did not improve from 0.49629\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4664 - val_loss: 0.4990\n",
      "Epoch 37/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4611\n",
      "Epoch 37: val_loss improved from 0.49629 to 0.48980, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4614 - val_loss: 0.4898\n",
      "Epoch 38/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4577\n",
      "Epoch 38: val_loss improved from 0.48980 to 0.48842, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4561 - val_loss: 0.4884\n",
      "Epoch 39/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4697\n",
      "Epoch 39: val_loss did not improve from 0.48842\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4696 - val_loss: 0.4984\n",
      "Epoch 40/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4644\n",
      "Epoch 40: val_loss improved from 0.48842 to 0.48639, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4639 - val_loss: 0.4864\n",
      "Epoch 41/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4576\n",
      "Epoch 41: val_loss improved from 0.48639 to 0.48148, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4579 - val_loss: 0.4815\n",
      "Epoch 42/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4603\n",
      "Epoch 42: val_loss improved from 0.48148 to 0.47869, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4609 - val_loss: 0.4787\n",
      "Epoch 43/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4472\n",
      "Epoch 43: val_loss improved from 0.47869 to 0.47412, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4476 - val_loss: 0.4741\n",
      "Epoch 44/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4370\n",
      "Epoch 44: val_loss improved from 0.47412 to 0.47098, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4389 - val_loss: 0.4710\n",
      "Epoch 45/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4522\n",
      "Epoch 45: val_loss did not improve from 0.47098\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4499 - val_loss: 0.4745\n",
      "Epoch 46/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4326\n",
      "Epoch 46: val_loss did not improve from 0.47098\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4326 - val_loss: 0.5027\n",
      "Epoch 47/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4392\n",
      "Epoch 47: val_loss did not improve from 0.47098\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4427 - val_loss: 0.4779\n",
      "Epoch 48/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4402\n",
      "Epoch 48: val_loss did not improve from 0.47098\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4389 - val_loss: 0.4712\n",
      "Epoch 49/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4379\n",
      "Epoch 49: val_loss did not improve from 0.47098\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4397 - val_loss: 0.4946\n",
      "Epoch 50/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4314\n",
      "Epoch 50: val_loss improved from 0.47098 to 0.46920, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4323 - val_loss: 0.4692\n",
      "Epoch 51/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4356\n",
      "Epoch 51: val_loss improved from 0.46920 to 0.45771, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4360 - val_loss: 0.4577\n",
      "Epoch 52/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4179\n",
      "Epoch 52: val_loss did not improve from 0.45771\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4191 - val_loss: 0.4609\n",
      "Epoch 53/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4294\n",
      "Epoch 53: val_loss did not improve from 0.45771\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4323 - val_loss: 0.4644\n",
      "Epoch 54/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4230\n",
      "Epoch 54: val_loss did not improve from 0.45771\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4232 - val_loss: 0.4635\n",
      "Epoch 55/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4355\n",
      "Epoch 55: val_loss improved from 0.45771 to 0.45563, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4334 - val_loss: 0.4556\n",
      "Epoch 56/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4189\n",
      "Epoch 56: val_loss did not improve from 0.45563\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4196 - val_loss: 0.4606\n",
      "Epoch 57/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4114\n",
      "Epoch 57: val_loss did not improve from 0.45563\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4147 - val_loss: 0.4614\n",
      "Epoch 58/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4254\n",
      "Epoch 58: val_loss did not improve from 0.45563\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4262 - val_loss: 0.4651\n",
      "Epoch 59/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4162\n",
      "Epoch 59: val_loss did not improve from 0.45563\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4167 - val_loss: 0.4652\n",
      "Epoch 60/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4143\n",
      "Epoch 60: val_loss did not improve from 0.45563\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4137 - val_loss: 0.4668\n",
      "Epoch 61/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4106\n",
      "Epoch 61: val_loss improved from 0.45563 to 0.45215, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4103 - val_loss: 0.4521\n",
      "Epoch 62/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4071\n",
      "Epoch 62: val_loss improved from 0.45215 to 0.45132, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4093 - val_loss: 0.4513\n",
      "Epoch 63/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4278\n",
      "Epoch 63: val_loss did not improve from 0.45132\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4245 - val_loss: 0.4515\n",
      "Epoch 64/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4082\n",
      "Epoch 64: val_loss did not improve from 0.45132\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4098 - val_loss: 0.4531\n",
      "Epoch 65/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4183\n",
      "Epoch 65: val_loss improved from 0.45132 to 0.44891, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4180 - val_loss: 0.4489\n",
      "Epoch 66/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4124\n",
      "Epoch 66: val_loss did not improve from 0.44891\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4133 - val_loss: 0.4687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4031\n",
      "Epoch 67: val_loss did not improve from 0.44891\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4055 - val_loss: 0.4521\n",
      "Epoch 68/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4122\n",
      "Epoch 68: val_loss did not improve from 0.44891\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4122 - val_loss: 0.4517\n",
      "Epoch 69/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4010\n",
      "Epoch 69: val_loss did not improve from 0.44891\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4010 - val_loss: 0.4544\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3976\n",
      "Epoch 70: val_loss did not improve from 0.44891\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3976 - val_loss: 0.4625\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4015\n",
      "Epoch 71: val_loss did not improve from 0.44891\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4015 - val_loss: 0.4567\n",
      "Epoch 72/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4146\n",
      "Epoch 72: val_loss did not improve from 0.44891\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4111 - val_loss: 0.4495\n",
      "Epoch 73/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3930\n",
      "Epoch 73: val_loss did not improve from 0.44891\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3930 - val_loss: 0.4508\n",
      "Epoch 74/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4046\n",
      "Epoch 74: val_loss improved from 0.44891 to 0.44301, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4047 - val_loss: 0.4430\n",
      "Epoch 75/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3999\n",
      "Epoch 75: val_loss improved from 0.44301 to 0.44165, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4000 - val_loss: 0.4416\n",
      "Epoch 76/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4059\n",
      "Epoch 76: val_loss improved from 0.44165 to 0.44164, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4077 - val_loss: 0.4416\n",
      "Epoch 77/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3987\n",
      "Epoch 77: val_loss did not improve from 0.44164\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3955 - val_loss: 0.4533\n",
      "Epoch 78/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3925\n",
      "Epoch 78: val_loss did not improve from 0.44164\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3906 - val_loss: 0.4441\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3971\n",
      "Epoch 79: val_loss improved from 0.44164 to 0.43682, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3971 - val_loss: 0.4368\n",
      "Epoch 80/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3889\n",
      "Epoch 80: val_loss did not improve from 0.43682\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3891 - val_loss: 0.4402\n",
      "Epoch 81/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3843\n",
      "Epoch 81: val_loss did not improve from 0.43682\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3844 - val_loss: 0.4517\n",
      "Epoch 82/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3856\n",
      "Epoch 82: val_loss did not improve from 0.43682\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3853 - val_loss: 0.4377\n",
      "Epoch 83/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3845\n",
      "Epoch 83: val_loss did not improve from 0.43682\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3841 - val_loss: 0.4402\n",
      "Epoch 84/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3937\n",
      "Epoch 84: val_loss improved from 0.43682 to 0.43285, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3932 - val_loss: 0.4329\n",
      "Epoch 85/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3830\n",
      "Epoch 85: val_loss did not improve from 0.43285\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3831 - val_loss: 0.4360\n",
      "Epoch 86/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3924\n",
      "Epoch 86: val_loss improved from 0.43285 to 0.42949, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3898 - val_loss: 0.4295\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3809\n",
      "Epoch 87: val_loss improved from 0.42949 to 0.42413, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3809 - val_loss: 0.4241\n",
      "Epoch 88/100\n",
      "51/58 [=========================>....] - ETA: 0s - loss: 0.3870\n",
      "Epoch 88: val_loss did not improve from 0.42413\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3875 - val_loss: 0.4306\n",
      "Epoch 89/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3855\n",
      "Epoch 89: val_loss did not improve from 0.42413\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3874 - val_loss: 0.4279\n",
      "Epoch 90/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3813\n",
      "Epoch 90: val_loss did not improve from 0.42413\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3821 - val_loss: 0.4265\n",
      "Epoch 91/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3892\n",
      "Epoch 91: val_loss did not improve from 0.42413\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3883 - val_loss: 0.4243\n",
      "Epoch 92/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3744\n",
      "Epoch 92: val_loss improved from 0.42413 to 0.42124, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3738 - val_loss: 0.4212\n",
      "Epoch 93/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3781\n",
      "Epoch 93: val_loss improved from 0.42124 to 0.42105, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold3.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3832 - val_loss: 0.4210\n",
      "Epoch 94/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3727\n",
      "Epoch 94: val_loss did not improve from 0.42105\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3765 - val_loss: 0.4213\n",
      "Epoch 95/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3795\n",
      "Epoch 95: val_loss did not improve from 0.42105\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3786 - val_loss: 0.4273\n",
      "Epoch 96/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3841\n",
      "Epoch 96: val_loss did not improve from 0.42105\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3863 - val_loss: 0.4430\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3760\n",
      "Epoch 97: val_loss did not improve from 0.42105\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3760 - val_loss: 0.4256\n",
      "Epoch 98/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3795\n",
      "Epoch 98: val_loss did not improve from 0.42105\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3832 - val_loss: 0.4218\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3603\n",
      "Epoch 99: val_loss did not improve from 0.42105\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3603 - val_loss: 0.4239\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3708\n",
      "Epoch 100: val_loss did not improve from 0.42105\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3711 - val_loss: 0.4244\n",
      "\n",
      "Train/Test model on Fold #4.\n",
      "Epoch 1/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 1.1347\n",
      "Epoch 1: val_loss improved from inf to 1.06384, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 2s 16ms/step - loss: 1.1296 - val_loss: 1.0638\n",
      "Epoch 2/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 1.0276\n",
      "Epoch 2: val_loss improved from 1.06384 to 0.98318, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 1.0264 - val_loss: 0.9832\n",
      "Epoch 3/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.9541\n",
      "Epoch 3: val_loss improved from 0.98318 to 0.92107, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.9536 - val_loss: 0.9211\n",
      "Epoch 4/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.9000\n",
      "Epoch 4: val_loss improved from 0.92107 to 0.87342, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.8996 - val_loss: 0.8734\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8559\n",
      "Epoch 5: val_loss improved from 0.87342 to 0.83628, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8559 - val_loss: 0.8363\n",
      "Epoch 6/100\n",
      "51/58 [=========================>....] - ETA: 0s - loss: 0.8248\n",
      "Epoch 6: val_loss improved from 0.83628 to 0.80643, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.8228 - val_loss: 0.8064\n",
      "Epoch 7/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.7938\n",
      "Epoch 7: val_loss improved from 0.80643 to 0.77891, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.7932 - val_loss: 0.7789\n",
      "Epoch 8/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.7655\n",
      "Epoch 8: val_loss improved from 0.77891 to 0.74201, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.7637 - val_loss: 0.7420\n",
      "Epoch 9/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.7191\n",
      "Epoch 9: val_loss improved from 0.74201 to 0.67806, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.7171 - val_loss: 0.6781\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6795\n",
      "Epoch 10: val_loss improved from 0.67806 to 0.64979, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.6795 - val_loss: 0.6498\n",
      "Epoch 11/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.6467\n",
      "Epoch 11: val_loss improved from 0.64979 to 0.62992, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.6476 - val_loss: 0.6299\n",
      "Epoch 12/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.6328\n",
      "Epoch 12: val_loss improved from 0.62992 to 0.61971, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6349 - val_loss: 0.6197\n",
      "Epoch 13/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.6151\n",
      "Epoch 13: val_loss improved from 0.61971 to 0.60867, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.6152 - val_loss: 0.6087\n",
      "Epoch 14/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.6103\n",
      "Epoch 14: val_loss improved from 0.60867 to 0.59885, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6085 - val_loss: 0.5988\n",
      "Epoch 15/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.5949\n",
      "Epoch 15: val_loss improved from 0.59885 to 0.58915, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5952 - val_loss: 0.5891\n",
      "Epoch 16/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.5851\n",
      "Epoch 16: val_loss did not improve from 0.58915\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5847 - val_loss: 0.5894\n",
      "Epoch 17/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5751\n",
      "Epoch 17: val_loss improved from 0.58915 to 0.58669, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5745 - val_loss: 0.5867\n",
      "Epoch 18/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.5775\n",
      "Epoch 18: val_loss improved from 0.58669 to 0.57491, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5784 - val_loss: 0.5749\n",
      "Epoch 19/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.5629\n",
      "Epoch 19: val_loss improved from 0.57491 to 0.56777, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5630 - val_loss: 0.5678\n",
      "Epoch 20/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.5516\n",
      "Epoch 20: val_loss improved from 0.56777 to 0.55984, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5501 - val_loss: 0.5598\n",
      "Epoch 21/100\n",
      "51/58 [=========================>....] - ETA: 0s - loss: 0.5480\n",
      "Epoch 21: val_loss improved from 0.55984 to 0.55405, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5514 - val_loss: 0.5540\n",
      "Epoch 22/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.5335\n",
      "Epoch 22: val_loss improved from 0.55405 to 0.54646, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5335 - val_loss: 0.5465\n",
      "Epoch 23/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5388\n",
      "Epoch 23: val_loss improved from 0.54646 to 0.54415, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5392 - val_loss: 0.5441\n",
      "Epoch 24/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.5288\n",
      "Epoch 24: val_loss improved from 0.54415 to 0.53766, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5286 - val_loss: 0.5377\n",
      "Epoch 25/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.5183\n",
      "Epoch 25: val_loss did not improve from 0.53766\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5238 - val_loss: 0.5392\n",
      "Epoch 26/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.5050\n",
      "Epoch 26: val_loss improved from 0.53766 to 0.52456, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5074 - val_loss: 0.5246\n",
      "Epoch 27/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.5044\n",
      "Epoch 27: val_loss improved from 0.52456 to 0.52366, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5033 - val_loss: 0.5237\n",
      "Epoch 28/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4994\n",
      "Epoch 28: val_loss improved from 0.52366 to 0.51255, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4993 - val_loss: 0.5126\n",
      "Epoch 29/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4944\n",
      "Epoch 29: val_loss did not improve from 0.51255\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4958 - val_loss: 0.5134\n",
      "Epoch 30/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4834\n",
      "Epoch 30: val_loss improved from 0.51255 to 0.50657, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4820 - val_loss: 0.5066\n",
      "Epoch 31/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4813\n",
      "Epoch 31: val_loss improved from 0.50657 to 0.50352, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4831 - val_loss: 0.5035\n",
      "Epoch 32/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4881\n",
      "Epoch 32: val_loss improved from 0.50352 to 0.50012, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4859 - val_loss: 0.5001\n",
      "Epoch 33/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4757\n",
      "Epoch 33: val_loss improved from 0.50012 to 0.49531, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4795 - val_loss: 0.4953\n",
      "Epoch 34/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4824\n",
      "Epoch 34: val_loss improved from 0.49531 to 0.49037, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4790 - val_loss: 0.4904\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4612\n",
      "Epoch 35: val_loss improved from 0.49037 to 0.48725, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4612 - val_loss: 0.4873\n",
      "Epoch 36/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4536\n",
      "Epoch 36: val_loss improved from 0.48725 to 0.48478, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4530 - val_loss: 0.4848\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4636\n",
      "Epoch 37: val_loss improved from 0.48478 to 0.48263, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4636 - val_loss: 0.4826\n",
      "Epoch 38/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4535\n",
      "Epoch 38: val_loss did not improve from 0.48263\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4521 - val_loss: 0.4850\n",
      "Epoch 39/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4580\n",
      "Epoch 39: val_loss improved from 0.48263 to 0.48010, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4624 - val_loss: 0.4801\n",
      "Epoch 40/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4492\n",
      "Epoch 40: val_loss did not improve from 0.48010\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4482 - val_loss: 0.4957\n",
      "Epoch 41/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4576\n",
      "Epoch 41: val_loss improved from 0.48010 to 0.47143, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4571 - val_loss: 0.4714\n",
      "Epoch 42/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4536\n",
      "Epoch 42: val_loss did not improve from 0.47143\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4508 - val_loss: 0.4757\n",
      "Epoch 43/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4441\n",
      "Epoch 43: val_loss improved from 0.47143 to 0.47092, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4435 - val_loss: 0.4709\n",
      "Epoch 44/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4390\n",
      "Epoch 44: val_loss did not improve from 0.47092\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4400 - val_loss: 0.4790\n",
      "Epoch 45/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4385\n",
      "Epoch 45: val_loss did not improve from 0.47092\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4382 - val_loss: 0.4740\n",
      "Epoch 46/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4300\n",
      "Epoch 46: val_loss improved from 0.47092 to 0.47013, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4331 - val_loss: 0.4701\n",
      "Epoch 47/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4402\n",
      "Epoch 47: val_loss did not improve from 0.47013\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4397 - val_loss: 0.4895\n",
      "Epoch 48/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4386\n",
      "Epoch 48: val_loss improved from 0.47013 to 0.46427, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4383 - val_loss: 0.4643\n",
      "Epoch 49/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4306\n",
      "Epoch 49: val_loss did not improve from 0.46427\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4303 - val_loss: 0.4647\n",
      "Epoch 50/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4185\n",
      "Epoch 50: val_loss improved from 0.46427 to 0.46118, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4203 - val_loss: 0.4612\n",
      "Epoch 51/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4161\n",
      "Epoch 51: val_loss did not improve from 0.46118\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4192 - val_loss: 0.4624\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4234\n",
      "Epoch 52: val_loss improved from 0.46118 to 0.45857, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4234 - val_loss: 0.4586\n",
      "Epoch 53/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4208\n",
      "Epoch 53: val_loss improved from 0.45857 to 0.45169, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4178 - val_loss: 0.4517\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4304\n",
      "Epoch 54: val_loss did not improve from 0.45169\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4304 - val_loss: 0.4519\n",
      "Epoch 55/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4074\n",
      "Epoch 55: val_loss improved from 0.45169 to 0.44528, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4058 - val_loss: 0.4453\n",
      "Epoch 56/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4185\n",
      "Epoch 56: val_loss did not improve from 0.44528\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4174 - val_loss: 0.4461\n",
      "Epoch 57/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4271\n",
      "Epoch 57: val_loss did not improve from 0.44528\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4248 - val_loss: 0.4545\n",
      "Epoch 58/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4250\n",
      "Epoch 58: val_loss did not improve from 0.44528\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4236 - val_loss: 0.4562\n",
      "Epoch 59/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4039\n",
      "Epoch 59: val_loss improved from 0.44528 to 0.44194, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4090 - val_loss: 0.4419\n",
      "Epoch 60/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4104\n",
      "Epoch 60: val_loss did not improve from 0.44194\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4105 - val_loss: 0.4503\n",
      "Epoch 61/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3913\n",
      "Epoch 61: val_loss improved from 0.44194 to 0.44102, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3897 - val_loss: 0.4410\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4165\n",
      "Epoch 62: val_loss did not improve from 0.44102\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4165 - val_loss: 0.4450\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4014\n",
      "Epoch 63: val_loss did not improve from 0.44102\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4014 - val_loss: 0.4514\n",
      "Epoch 64/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4028\n",
      "Epoch 64: val_loss did not improve from 0.44102\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4097 - val_loss: 0.4470\n",
      "Epoch 65/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.4099\n",
      "Epoch 65: val_loss did not improve from 0.44102\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4086 - val_loss: 0.4463\n",
      "Epoch 66/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.4073\n",
      "Epoch 66: val_loss did not improve from 0.44102\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4071 - val_loss: 0.4519\n",
      "Epoch 67/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.4013\n",
      "Epoch 67: val_loss did not improve from 0.44102\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4025 - val_loss: 0.4412\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3994\n",
      "Epoch 68: val_loss did not improve from 0.44102\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3994 - val_loss: 0.4712\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4155\n",
      "Epoch 69: val_loss did not improve from 0.44102\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4155 - val_loss: 0.4433\n",
      "Epoch 70/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4020\n",
      "Epoch 70: val_loss did not improve from 0.44102\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4006 - val_loss: 0.4413\n",
      "Epoch 71/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.4008\n",
      "Epoch 71: val_loss improved from 0.44102 to 0.43924, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4021 - val_loss: 0.4392\n",
      "Epoch 72/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3981\n",
      "Epoch 72: val_loss did not improve from 0.43924\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3984 - val_loss: 0.4399\n",
      "Epoch 73/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3904\n",
      "Epoch 73: val_loss did not improve from 0.43924\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3908 - val_loss: 0.4434\n",
      "Epoch 74/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3941\n",
      "Epoch 74: val_loss did not improve from 0.43924\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3995 - val_loss: 0.4425\n",
      "Epoch 75/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3927\n",
      "Epoch 75: val_loss did not improve from 0.43924\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3943 - val_loss: 0.4450\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3891\n",
      "Epoch 76: val_loss did not improve from 0.43924\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3891 - val_loss: 0.4415\n",
      "Epoch 77/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.4042\n",
      "Epoch 77: val_loss did not improve from 0.43924\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4062 - val_loss: 0.4425\n",
      "Epoch 78/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.3866\n",
      "Epoch 78: val_loss improved from 0.43924 to 0.43676, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3854 - val_loss: 0.4368\n",
      "Epoch 79/100\n",
      "51/58 [=========================>....] - ETA: 0s - loss: 0.3698\n",
      "Epoch 79: val_loss improved from 0.43676 to 0.43658, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3756 - val_loss: 0.4366\n",
      "Epoch 80/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3984\n",
      "Epoch 80: val_loss did not improve from 0.43658\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3989 - val_loss: 0.4527\n",
      "Epoch 81/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3864\n",
      "Epoch 81: val_loss improved from 0.43658 to 0.43513, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3950 - val_loss: 0.4351\n",
      "Epoch 82/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3942\n",
      "Epoch 82: val_loss improved from 0.43513 to 0.43451, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3953 - val_loss: 0.4345\n",
      "Epoch 83/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3809\n",
      "Epoch 83: val_loss did not improve from 0.43451\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3850 - val_loss: 0.4429\n",
      "Epoch 84/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3925\n",
      "Epoch 84: val_loss did not improve from 0.43451\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3980 - val_loss: 0.4348\n",
      "Epoch 85/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3811\n",
      "Epoch 85: val_loss did not improve from 0.43451\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3806 - val_loss: 0.4943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3839\n",
      "Epoch 86: val_loss did not improve from 0.43451\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3827 - val_loss: 0.4368\n",
      "Epoch 87/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3758\n",
      "Epoch 87: val_loss did not improve from 0.43451\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3786 - val_loss: 0.4353\n",
      "Epoch 88/100\n",
      "55/58 [===========================>..] - ETA: 0s - loss: 0.4048\n",
      "Epoch 88: val_loss improved from 0.43451 to 0.42955, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4023 - val_loss: 0.4296\n",
      "Epoch 89/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3880\n",
      "Epoch 89: val_loss did not improve from 0.42955\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3928 - val_loss: 0.4594\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3945\n",
      "Epoch 90: val_loss did not improve from 0.42955\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3945 - val_loss: 0.4309\n",
      "Epoch 91/100\n",
      "56/58 [===========================>..] - ETA: 0s - loss: 0.3730\n",
      "Epoch 91: val_loss did not improve from 0.42955\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3744 - val_loss: 0.4378\n",
      "Epoch 92/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3800\n",
      "Epoch 92: val_loss did not improve from 0.42955\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3810 - val_loss: 0.4393\n",
      "Epoch 93/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3732\n",
      "Epoch 93: val_loss improved from 0.42955 to 0.42877, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3732 - val_loss: 0.4288\n",
      "Epoch 94/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3789\n",
      "Epoch 94: val_loss did not improve from 0.42877\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3757 - val_loss: 0.4378\n",
      "Epoch 95/100\n",
      "54/58 [==========================>...] - ETA: 0s - loss: 0.3778\n",
      "Epoch 95: val_loss did not improve from 0.42877\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3805 - val_loss: 0.4300\n",
      "Epoch 96/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3772\n",
      "Epoch 96: val_loss improved from 0.42877 to 0.42454, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3765 - val_loss: 0.4245\n",
      "Epoch 97/100\n",
      "53/58 [==========================>...] - ETA: 0s - loss: 0.3692\n",
      "Epoch 97: val_loss did not improve from 0.42454\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3687 - val_loss: 0.4370\n",
      "Epoch 98/100\n",
      "52/58 [=========================>....] - ETA: 0s - loss: 0.3658\n",
      "Epoch 98: val_loss improved from 0.42454 to 0.41749, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\bestModel-fold4.hdf5\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3639 - val_loss: 0.4175\n",
      "Epoch 99/100\n",
      "51/58 [=========================>....] - ETA: 0s - loss: 0.3697\n",
      "Epoch 99: val_loss did not improve from 0.41749\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3693 - val_loss: 0.4203\n",
      "Epoch 100/100\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3600\n",
      "Epoch 100: val_loss did not improve from 0.41749\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3602 - val_loss: 0.4210\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Train/Test model on all folds, generate evaluations\n",
    "##################################################################################\n",
    "\n",
    "## Create and set directory to save model\n",
    "modelPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold), \"models\")\n",
    "if(not os.path.isdir(modelPath)):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "i = -1\n",
    "for fold in folds:\n",
    "    i += 1\n",
    "    \n",
    "    print(\"\\nTrain/Test model on Fold #\"+str(i)+\".\")\n",
    "    \n",
    "    model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "    ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    modelCallbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                           monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                           save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "    ]\n",
    "    \n",
    "    # adding random shuffling of the dataset for training purpose\n",
    "    index_arr = np.arange(fold[\"X_train\"].shape[0])\n",
    "    index_arr = np.random.permutation(index_arr)\n",
    "    \n",
    "    model.fit(x = fold[\"X_train\"][index_arr], y = fold[\"y_train\"][index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "              callbacks = modelCallbacks, validation_data = (fold[\"X_test\"], fold[\"y_test\"]))\n",
    "    \n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TRAIN dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_train\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "    mcc = matthews_corrcoef(fold[\"y_train\"], label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Train\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TEST dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_test\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "    mcc = matthews_corrcoef(fold[\"y_test\"], label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Test\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.854615</td>\n",
       "      <td>0.850285</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.852981</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.709429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.948915</td>\n",
       "      <td>0.988411</td>\n",
       "      <td>0.960569</td>\n",
       "      <td>0.950491</td>\n",
       "      <td>0.910963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                   \n",
       "Test        0.854615   0.850285  0.926398     0.852981     0.856159  0.709429\n",
       "Train       0.955414   0.948915  0.988411     0.960569     0.950491  0.910963"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.864776</td>\n",
       "      <td>0.856828</td>\n",
       "      <td>[0.0, 0.002232142857142857, 0.2053571428571428...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0021321961620469083, 0.00213...</td>\n",
       "      <td>[1.991244, 0.99124396, 0.9466795, 0.9463727, 0...</td>\n",
       "      <td>0.937595</td>\n",
       "      <td>0.868304</td>\n",
       "      <td>0.861407</td>\n",
       "      <td>0.729555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.855895</td>\n",
       "      <td>0.859091</td>\n",
       "      <td>[0.0, 0.002232142857142857, 0.1049107142857142...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.002136752136752137, 0.002136...</td>\n",
       "      <td>[1.9870536, 0.9870536, 0.97027326, 0.9702672, ...</td>\n",
       "      <td>0.918043</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.711652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.849345</td>\n",
       "      <td>0.827004</td>\n",
       "      <td>[0.0, 0.002232142857142857, 0.1808035714285714...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.002136752136752137, 0.002136...</td>\n",
       "      <td>[1.9909499, 0.9909498, 0.95515615, 0.9547177, ...</td>\n",
       "      <td>0.936918</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.700047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.848253</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>[0.0, 0.0022371364653243847, 0.102908277404921...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0021321961620469083, 0.00213...</td>\n",
       "      <td>[1.9965671, 0.99656713, 0.9780513, 0.97745377,...</td>\n",
       "      <td>0.918173</td>\n",
       "      <td>0.827740</td>\n",
       "      <td>0.867804</td>\n",
       "      <td>0.696467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.854803</td>\n",
       "      <td>0.852018</td>\n",
       "      <td>[0.0, 0.0022371364653243847, 0.096196868008948...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0021321961620469083, 0.00213...</td>\n",
       "      <td>[1.9930145, 0.99301445, 0.96695876, 0.96690774...</td>\n",
       "      <td>0.921261</td>\n",
       "      <td>0.850112</td>\n",
       "      <td>0.859275</td>\n",
       "      <td>0.709426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Train_Test  Accuracy  Precision  \\\n",
       "1     0       Test  0.864776   0.856828   \n",
       "3     1       Test  0.855895   0.859091   \n",
       "5     2       Test  0.849345   0.827004   \n",
       "7     3       Test  0.848253   0.856481   \n",
       "9     4       Test  0.854803   0.852018   \n",
       "\n",
       "                                                 TPR  \\\n",
       "1  [0.0, 0.002232142857142857, 0.2053571428571428...   \n",
       "3  [0.0, 0.002232142857142857, 0.1049107142857142...   \n",
       "5  [0.0, 0.002232142857142857, 0.1808035714285714...   \n",
       "7  [0.0, 0.0022371364653243847, 0.102908277404921...   \n",
       "9  [0.0, 0.0022371364653243847, 0.096196868008948...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "1  [0.0, 0.0, 0.0, 0.0021321961620469083, 0.00213...   \n",
       "3  [0.0, 0.0, 0.0, 0.002136752136752137, 0.002136...   \n",
       "5  [0.0, 0.0, 0.0, 0.002136752136752137, 0.002136...   \n",
       "7  [0.0, 0.0, 0.0, 0.0021321961620469083, 0.00213...   \n",
       "9  [0.0, 0.0, 0.0, 0.0021321961620469083, 0.00213...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "1  [1.991244, 0.99124396, 0.9466795, 0.9463727, 0...  0.937595     0.868304   \n",
       "3  [1.9870536, 0.9870536, 0.97027326, 0.9702672, ...  0.918043     0.843750   \n",
       "5  [1.9909499, 0.9909498, 0.95515615, 0.9547177, ...  0.936918     0.875000   \n",
       "7  [1.9965671, 0.99656713, 0.9780513, 0.97745377,...  0.918173     0.827740   \n",
       "9  [1.9930145, 0.99301445, 0.96695876, 0.96690774...  0.921261     0.850112   \n",
       "\n",
       "   Specificity       MCC  \n",
       "1     0.861407  0.729555  \n",
       "3     0.867521  0.711652  \n",
       "5     0.824786  0.700047  \n",
       "7     0.867804  0.696467  \n",
       "9     0.859275  0.709426  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df[evaluations_df[\"Train_Test\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent data testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using k-fold Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of each k-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.629061</td>\n",
       "      <td>0.247691</td>\n",
       "      <td>0.661831</td>\n",
       "      <td>0.606897</td>\n",
       "      <td>0.633464</td>\n",
       "      <td>0.182131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.629061   0.247691  0.661831     0.606897     0.633464  0.182131"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    label_pred = pred2label(y_pred)\n",
    "\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(indpe_labels, label_pred)\n",
    "    prec = precision_score(indpe_labels,label_pred)\n",
    "    mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "    conf = confusion_matrix(indpe_labels, label_pred)\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "    auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.626122</td>\n",
       "      <td>0.251462</td>\n",
       "      <td>[0.0, 0.0, 0.009852216748768473, 0.00985221674...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.000978473581213...</td>\n",
       "      <td>[1.9904221, 0.9904221, 0.98561865, 0.97923994,...</td>\n",
       "      <td>0.663256</td>\n",
       "      <td>0.635468</td>\n",
       "      <td>0.624266</td>\n",
       "      <td>0.195751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>[0.0, 0.0049261083743842365, 0.004926108374384...</td>\n",
       "      <td>[0.0, 0.0, 0.0009784735812133072, 0.0009784735...</td>\n",
       "      <td>[1.9852324, 0.98523235, 0.9845371, 0.9842869, ...</td>\n",
       "      <td>0.672544</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.175027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.604082</td>\n",
       "      <td>0.236940</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.009852216748768473, 0.009852...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.002935420743639...</td>\n",
       "      <td>[1.9878273, 0.98782724, 0.9864633, 0.985973, 0...</td>\n",
       "      <td>0.657529</td>\n",
       "      <td>0.625616</td>\n",
       "      <td>0.599804</td>\n",
       "      <td>0.168956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.646531</td>\n",
       "      <td>0.252155</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0049261083743842365, 0.00492...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.002935420743639...</td>\n",
       "      <td>[1.9939371, 0.99393713, 0.9923375, 0.9918413, ...</td>\n",
       "      <td>0.650372</td>\n",
       "      <td>0.576355</td>\n",
       "      <td>0.660470</td>\n",
       "      <td>0.181530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.251521</td>\n",
       "      <td>[0.0, 0.0, 0.0049261083743842365, 0.0049261083...</td>\n",
       "      <td>[0.0, 0.0009784735812133072, 0.000978473581213...</td>\n",
       "      <td>[1.9929299, 0.9929299, 0.98641866, 0.98562336,...</td>\n",
       "      <td>0.665454</td>\n",
       "      <td>0.610837</td>\n",
       "      <td>0.638943</td>\n",
       "      <td>0.189388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold   Train_Test  Accuracy  Precision  \\\n",
       "0     0  Independent  0.626122   0.251462   \n",
       "1     1  Independent  0.634286   0.246377   \n",
       "2     2  Independent  0.604082   0.236940   \n",
       "3     3  Independent  0.646531   0.252155   \n",
       "4     4  Independent  0.634286   0.251521   \n",
       "\n",
       "                                                 TPR  \\\n",
       "0  [0.0, 0.0, 0.009852216748768473, 0.00985221674...   \n",
       "1  [0.0, 0.0049261083743842365, 0.004926108374384...   \n",
       "2  [0.0, 0.0, 0.0, 0.009852216748768473, 0.009852...   \n",
       "3  [0.0, 0.0, 0.0, 0.0049261083743842365, 0.00492...   \n",
       "4  [0.0, 0.0, 0.0049261083743842365, 0.0049261083...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "0  [0.0, 0.0009784735812133072, 0.000978473581213...   \n",
       "1  [0.0, 0.0, 0.0009784735812133072, 0.0009784735...   \n",
       "2  [0.0, 0.0009784735812133072, 0.002935420743639...   \n",
       "3  [0.0, 0.0009784735812133072, 0.002935420743639...   \n",
       "4  [0.0, 0.0009784735812133072, 0.000978473581213...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0  [1.9904221, 0.9904221, 0.98561865, 0.97923994,...  0.663256     0.635468   \n",
       "1  [1.9852324, 0.98523235, 0.9845371, 0.9842869, ...  0.672544     0.586207   \n",
       "2  [1.9878273, 0.98782724, 0.9864633, 0.985973, 0...  0.657529     0.625616   \n",
       "3  [1.9939371, 0.99393713, 0.9923375, 0.9918413, ...  0.650372     0.576355   \n",
       "4  [1.9929299, 0.9929299, 0.98641866, 0.98562336,...  0.665454     0.610837   \n",
       "\n",
       "   Specificity       MCC  \n",
       "0     0.624266  0.195751  \n",
       "1     0.643836  0.175027  \n",
       "2     0.599804  0.168956  \n",
       "3     0.660470  0.181530  \n",
       "4     0.638943  0.189388  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.648163</td>\n",
       "      <td>0.263485</td>\n",
       "      <td>0.676752</td>\n",
       "      <td>0.625616</td>\n",
       "      <td>0.652642</td>\n",
       "      <td>0.211789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.648163   0.263485  0.676752     0.625616     0.652642  0.211789"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    total_pred += y_pred\n",
    "    all_preds.append(y_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>0.660908</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.206475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.645714    0.26087  0.660908      0.62069     0.650685  0.206475"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    vote_pred = pred2label(y_pred)\n",
    "    total_pred += vote_pred\n",
    "    all_preds.append(vote_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using New Model\n",
    "\n",
    "Train model on full data from training. Predict and evaluate on Independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1258\n",
      "Epoch 1: val_loss improved from inf to 1.03203, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "72/72 [==============================] - 3s 16ms/step - loss: 1.1258 - val_loss: 1.0320\n",
      "Epoch 2/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 1.0080\n",
      "Epoch 2: val_loss improved from 1.03203 to 0.94871, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 1.0046 - val_loss: 0.9487\n",
      "Epoch 3/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.9273\n",
      "Epoch 3: val_loss improved from 0.94871 to 0.88182, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.9261 - val_loss: 0.8818\n",
      "Epoch 4/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.8545\n",
      "Epoch 4: val_loss improved from 0.88182 to 0.83092, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.8519 - val_loss: 0.8309\n",
      "Epoch 5/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.7755\n",
      "Epoch 5: val_loss improved from 0.83092 to 0.78088, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.7743 - val_loss: 0.7809\n",
      "Epoch 6/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.7280\n",
      "Epoch 6: val_loss improved from 0.78088 to 0.74691, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.7267 - val_loss: 0.7469\n",
      "Epoch 7/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.6886\n",
      "Epoch 7: val_loss did not improve from 0.74691\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.6872 - val_loss: 0.7813\n",
      "Epoch 8/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.6642\n",
      "Epoch 8: val_loss did not improve from 0.74691\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.6639 - val_loss: 0.7906\n",
      "Epoch 9/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.6462\n",
      "Epoch 9: val_loss did not improve from 0.74691\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.6459 - val_loss: 0.7642\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.6279\n",
      "Epoch 10: val_loss did not improve from 0.74691\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.6279 - val_loss: 0.8229\n",
      "Epoch 11/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.6189\n",
      "Epoch 11: val_loss did not improve from 0.74691\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.6205 - val_loss: 0.7889\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5974\n",
      "Epoch 12: val_loss did not improve from 0.74691\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5974 - val_loss: 0.8111\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5912\n",
      "Epoch 13: val_loss improved from 0.74691 to 0.72275, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5912 - val_loss: 0.7228\n",
      "Epoch 14/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.5805\n",
      "Epoch 14: val_loss did not improve from 0.72275\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5811 - val_loss: 0.7899\n",
      "Epoch 15/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.5716\n",
      "Epoch 15: val_loss did not improve from 0.72275\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5724 - val_loss: 0.7977\n",
      "Epoch 16/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.5688\n",
      "Epoch 16: val_loss did not improve from 0.72275\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.5657 - val_loss: 0.7545\n",
      "Epoch 17/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.5565\n",
      "Epoch 17: val_loss improved from 0.72275 to 0.67570, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5567 - val_loss: 0.6757\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5496\n",
      "Epoch 18: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5496 - val_loss: 0.8015\n",
      "Epoch 19/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.5319\n",
      "Epoch 19: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.5336 - val_loss: 0.7636\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5326\n",
      "Epoch 20: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5326 - val_loss: 0.8167\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5271\n",
      "Epoch 21: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5271 - val_loss: 0.8200\n",
      "Epoch 22/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.5222\n",
      "Epoch 22: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.5206 - val_loss: 0.8265\n",
      "Epoch 23/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.5056\n",
      "Epoch 23: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5056 - val_loss: 0.8186\n",
      "Epoch 24/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.5045\n",
      "Epoch 24: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5082 - val_loss: 0.7580\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4996\n",
      "Epoch 25: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4996 - val_loss: 0.7528\n",
      "Epoch 26/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.4954\n",
      "Epoch 26: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4959 - val_loss: 0.8142\n",
      "Epoch 27/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 0.4899\n",
      "Epoch 27: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4902 - val_loss: 0.8546\n",
      "Epoch 28/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.4894\n",
      "Epoch 28: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4930 - val_loss: 0.8108\n",
      "Epoch 29/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.4786\n",
      "Epoch 29: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4803 - val_loss: 0.8184\n",
      "Epoch 30/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.4811\n",
      "Epoch 30: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4807 - val_loss: 0.8588\n",
      "Epoch 31/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.4739\n",
      "Epoch 31: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4730 - val_loss: 0.7735\n",
      "Epoch 32/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.4721\n",
      "Epoch 32: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4735 - val_loss: 0.7832\n",
      "Epoch 33/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 0.4727\n",
      "Epoch 33: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4736 - val_loss: 0.7296\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4727\n",
      "Epoch 34: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4727 - val_loss: 0.7245\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/72 [==========================>...] - ETA: 0s - loss: 0.4556\n",
      "Epoch 35: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4578 - val_loss: 0.8864\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4650\n",
      "Epoch 36: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4650 - val_loss: 0.8373\n",
      "Epoch 37/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.4646\n",
      "Epoch 37: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4618 - val_loss: 0.7974\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4573\n",
      "Epoch 38: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4573 - val_loss: 0.9021\n",
      "Epoch 39/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4443\n",
      "Epoch 39: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4448 - val_loss: 0.9306\n",
      "Epoch 40/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.4574\n",
      "Epoch 40: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4545 - val_loss: 0.8122\n",
      "Epoch 41/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.4420\n",
      "Epoch 41: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4430 - val_loss: 0.8873\n",
      "Epoch 42/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.4437\n",
      "Epoch 42: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4446 - val_loss: 0.8260\n",
      "Epoch 43/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.4438\n",
      "Epoch 43: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4401 - val_loss: 0.8352\n",
      "Epoch 44/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.4395\n",
      "Epoch 44: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4388 - val_loss: 0.7008\n",
      "Epoch 45/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.4397\n",
      "Epoch 45: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4404 - val_loss: 0.8481\n",
      "Epoch 46/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.4428\n",
      "Epoch 46: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4405 - val_loss: 0.7621\n",
      "Epoch 47/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4366\n",
      "Epoch 47: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4356 - val_loss: 0.8617\n",
      "Epoch 48/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4432\n",
      "Epoch 48: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4442 - val_loss: 0.8942\n",
      "Epoch 49/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.4396\n",
      "Epoch 49: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4413 - val_loss: 0.8850\n",
      "Epoch 50/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.4370\n",
      "Epoch 50: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4369 - val_loss: 0.7671\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4246\n",
      "Epoch 51: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4246 - val_loss: 0.7983\n",
      "Epoch 52/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4124\n",
      "Epoch 52: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4123 - val_loss: 0.8090\n",
      "Epoch 53/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.4347\n",
      "Epoch 53: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4370 - val_loss: 0.7876\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4210\n",
      "Epoch 54: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4210 - val_loss: 0.9898\n",
      "Epoch 55/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.4150\n",
      "Epoch 55: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4138 - val_loss: 0.7989\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4301\n",
      "Epoch 56: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4301 - val_loss: 0.8669\n",
      "Epoch 57/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4055\n",
      "Epoch 57: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4064 - val_loss: 0.8459\n",
      "Epoch 58/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.4121\n",
      "Epoch 58: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4135 - val_loss: 0.8647\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4143\n",
      "Epoch 59: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4143 - val_loss: 0.7806\n",
      "Epoch 60/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.4147\n",
      "Epoch 60: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4158 - val_loss: 0.8343\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4199\n",
      "Epoch 61: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4199 - val_loss: 0.8773\n",
      "Epoch 62/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 0.4246\n",
      "Epoch 62: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4238 - val_loss: 0.8811\n",
      "Epoch 63/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4067\n",
      "Epoch 63: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4074 - val_loss: 0.7384\n",
      "Epoch 64/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4155\n",
      "Epoch 64: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4153 - val_loss: 0.8145\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4099\n",
      "Epoch 65: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4099 - val_loss: 0.9712\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4201\n",
      "Epoch 66: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4201 - val_loss: 0.8803\n",
      "Epoch 67/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4092\n",
      "Epoch 67: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4083 - val_loss: 0.9546\n",
      "Epoch 68/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.4118\n",
      "Epoch 68: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4102 - val_loss: 0.8684\n",
      "Epoch 69/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3999\n",
      "Epoch 69: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4004 - val_loss: 0.8943\n",
      "Epoch 70/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.4100\n",
      "Epoch 70: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4092 - val_loss: 0.8649\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4082\n",
      "Epoch 71: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4082 - val_loss: 0.8279\n",
      "Epoch 72/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3973\n",
      "Epoch 72: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3983 - val_loss: 0.8658\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4028\n",
      "Epoch 73: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4028 - val_loss: 0.9561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4050\n",
      "Epoch 74: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4050 - val_loss: 0.9842\n",
      "Epoch 75/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.4119\n",
      "Epoch 75: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4122 - val_loss: 0.8221\n",
      "Epoch 76/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.3935\n",
      "Epoch 76: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3957 - val_loss: 0.8857\n",
      "Epoch 77/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.4012\n",
      "Epoch 77: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4031 - val_loss: 0.8439\n",
      "Epoch 78/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.3923\n",
      "Epoch 78: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3919 - val_loss: 0.9639\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3823\n",
      "Epoch 79: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3823 - val_loss: 0.9744\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3989\n",
      "Epoch 80: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3989 - val_loss: 0.9423\n",
      "Epoch 81/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.3970\n",
      "Epoch 81: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3969 - val_loss: 0.7492\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4025\n",
      "Epoch 82: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4025 - val_loss: 0.8197\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4009\n",
      "Epoch 83: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.4009 - val_loss: 0.8239\n",
      "Epoch 84/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3888\n",
      "Epoch 84: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3893 - val_loss: 0.9286\n",
      "Epoch 85/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.3937\n",
      "Epoch 85: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3954 - val_loss: 0.8664\n",
      "Epoch 86/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.3953\n",
      "Epoch 86: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3945 - val_loss: 0.8865\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3875\n",
      "Epoch 87: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3875 - val_loss: 0.9311\n",
      "Epoch 88/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3929\n",
      "Epoch 88: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3921 - val_loss: 1.0485\n",
      "Epoch 89/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.3868\n",
      "Epoch 89: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3850 - val_loss: 0.7345\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3910\n",
      "Epoch 90: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3910 - val_loss: 0.8922\n",
      "Epoch 91/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3774\n",
      "Epoch 91: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3768 - val_loss: 0.9516\n",
      "Epoch 92/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.3862\n",
      "Epoch 92: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3859 - val_loss: 0.8933\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3902\n",
      "Epoch 93: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3902 - val_loss: 0.8847\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3816\n",
      "Epoch 94: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3816 - val_loss: 0.9361\n",
      "Epoch 95/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3846\n",
      "Epoch 95: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3843 - val_loss: 0.8982\n",
      "Epoch 96/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.3904\n",
      "Epoch 96: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3898 - val_loss: 0.8002\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3926\n",
      "Epoch 97: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3926 - val_loss: 0.8111\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3779\n",
      "Epoch 98: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3779 - val_loss: 0.7812\n",
      "Epoch 99/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.3732\n",
      "Epoch 99: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3749 - val_loss: 0.8400\n",
      "Epoch 100/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3819\n",
      "Epoch 100: val_loss did not improve from 0.67570\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3812 - val_loss: 0.8604\n"
     ]
    }
   ],
   "source": [
    "model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "current_model_path = os.path.join(modelPath, \"_fullModel.hdf5\")\n",
    "modelCallbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                       monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                       save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "]\n",
    "\n",
    "# adding random shuffling of the dataset for training purpose\n",
    "index_arr = np.arange(train_features.shape[0])\n",
    "index_arr = np.random.permutation(index_arr)\n",
    "\n",
    "model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "          callbacks = modelCallbacks, validation_data = (indpe_features, indpe_labels))\n",
    "# model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "#           callbacks = modelCallbacks, validation_split = 0.2)\n",
    "\n",
    "model = tf.keras.models.load_model(current_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine tuning with independent dataset features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "indpe_features_test, indpe_features_train, indpe_labels_test, indpe_labels_train = train_test_split(indpe_features, \n",
    "                                                                                                    indpe_labels, \n",
    "                                                                                                    stratify=indpe_labels,\n",
    "                                                                                                    test_size=0.5,\n",
    "                                                                                                    random_state=seed, \n",
    "                                                                                                    shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6349\n",
      "Epoch 1: val_loss improved from 0.67570 to 0.51219, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 2s 79ms/step - loss: 0.6250 - val_loss: 0.5122\n",
      "Epoch 2/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.5614\n",
      "Epoch 2: val_loss improved from 0.51219 to 0.49904, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5425 - val_loss: 0.4990\n",
      "Epoch 3/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5260\n",
      "Epoch 3: val_loss improved from 0.49904 to 0.48633, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5313 - val_loss: 0.4863\n",
      "Epoch 4/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5197\n",
      "Epoch 4: val_loss did not improve from 0.48633\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5200 - val_loss: 0.4897\n",
      "Epoch 5/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4950\n",
      "Epoch 5: val_loss improved from 0.48633 to 0.48521, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4962 - val_loss: 0.4852\n",
      "Epoch 6/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4980\n",
      "Epoch 6: val_loss improved from 0.48521 to 0.48284, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.4942 - val_loss: 0.4828\n",
      "Epoch 7/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4990\n",
      "Epoch 7: val_loss improved from 0.48284 to 0.48197, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5111 - val_loss: 0.4820\n",
      "Epoch 8/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4773\n",
      "Epoch 8: val_loss improved from 0.48197 to 0.48126, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4872 - val_loss: 0.4813\n",
      "Epoch 9/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4913\n",
      "Epoch 9: val_loss improved from 0.48126 to 0.48105, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4914 - val_loss: 0.4811\n",
      "Epoch 10/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.5182\n",
      "Epoch 10: val_loss improved from 0.48105 to 0.48088, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5072 - val_loss: 0.4809\n",
      "Epoch 11/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4792\n",
      "Epoch 11: val_loss improved from 0.48088 to 0.47977, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4855 - val_loss: 0.4798\n",
      "Epoch 12/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4854\n",
      "Epoch 12: val_loss improved from 0.47977 to 0.47904, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4890 - val_loss: 0.4790\n",
      "Epoch 13/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4905\n",
      "Epoch 13: val_loss improved from 0.47904 to 0.47782, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4825 - val_loss: 0.4778\n",
      "Epoch 14/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4797\n",
      "Epoch 14: val_loss improved from 0.47782 to 0.47744, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4769 - val_loss: 0.4774\n",
      "Epoch 15/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4731\n",
      "Epoch 15: val_loss improved from 0.47744 to 0.47688, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4745 - val_loss: 0.4769\n",
      "Epoch 16/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4745\n",
      "Epoch 16: val_loss improved from 0.47688 to 0.47670, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4725 - val_loss: 0.4767\n",
      "Epoch 17/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4851\n",
      "Epoch 17: val_loss improved from 0.47670 to 0.47661, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4772 - val_loss: 0.4766\n",
      "Epoch 18/100\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 0.4236\n",
      "Epoch 18: val_loss did not improve from 0.47661\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4551 - val_loss: 0.4781\n",
      "Epoch 19/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4653\n",
      "Epoch 19: val_loss did not improve from 0.47661\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4578 - val_loss: 0.4766\n",
      "Epoch 20/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4468\n",
      "Epoch 20: val_loss did not improve from 0.47661\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4486 - val_loss: 0.4769\n",
      "Epoch 21/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4744\n",
      "Epoch 21: val_loss improved from 0.47661 to 0.47614, saving model to Results\\NT_Site_PredNTS_Classification_DLNN_CORENup_v2_TrainStrat_2_domain\\5fold\\models\\_fullModel.hdf5\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4694 - val_loss: 0.4761\n",
      "Epoch 22/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4566\n",
      "Epoch 22: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4536 - val_loss: 0.4763\n",
      "Epoch 23/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4486\n",
      "Epoch 23: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4585 - val_loss: 0.4780\n",
      "Epoch 24/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4375\n",
      "Epoch 24: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4390 - val_loss: 0.4772\n",
      "Epoch 25/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4418\n",
      "Epoch 25: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4425 - val_loss: 0.4773\n",
      "Epoch 26/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4490\n",
      "Epoch 26: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4435 - val_loss: 0.4777\n",
      "Epoch 27/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4528\n",
      "Epoch 27: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4463 - val_loss: 0.4797\n",
      "Epoch 28/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4391\n",
      "Epoch 28: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4392 - val_loss: 0.4796\n",
      "Epoch 29/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4330\n",
      "Epoch 29: val_loss did not improve from 0.47614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4408 - val_loss: 0.4799\n",
      "Epoch 30/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4543\n",
      "Epoch 30: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4409 - val_loss: 0.4802\n",
      "Epoch 31/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4284\n",
      "Epoch 31: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4165 - val_loss: 0.4829\n",
      "Epoch 32/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4142\n",
      "Epoch 32: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4163 - val_loss: 0.4860\n",
      "Epoch 33/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4166\n",
      "Epoch 33: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4186 - val_loss: 0.4842\n",
      "Epoch 34/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.4040\n",
      "Epoch 34: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3997 - val_loss: 0.4894\n",
      "Epoch 35/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3987\n",
      "Epoch 35: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4025 - val_loss: 0.4918\n",
      "Epoch 36/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4025\n",
      "Epoch 36: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4013 - val_loss: 0.4915\n",
      "Epoch 37/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4094\n",
      "Epoch 37: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4043 - val_loss: 0.4986\n",
      "Epoch 38/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3833\n",
      "Epoch 38: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3903 - val_loss: 0.5037\n",
      "Epoch 39/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3646\n",
      "Epoch 39: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3671 - val_loss: 0.5063\n",
      "Epoch 40/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3654\n",
      "Epoch 40: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3595 - val_loss: 0.5184\n",
      "Epoch 41/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3698\n",
      "Epoch 41: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3646 - val_loss: 0.5162\n",
      "Epoch 42/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.3642\n",
      "Epoch 42: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3707 - val_loss: 0.5242\n",
      "Epoch 43/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3521\n",
      "Epoch 43: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3476 - val_loss: 0.5322\n",
      "Epoch 44/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3534\n",
      "Epoch 44: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3418 - val_loss: 0.5460\n",
      "Epoch 45/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3254\n",
      "Epoch 45: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3260 - val_loss: 0.5611\n",
      "Epoch 46/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3359\n",
      "Epoch 46: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3362 - val_loss: 0.5492\n",
      "Epoch 47/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2898\n",
      "Epoch 47: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2970 - val_loss: 0.5721\n",
      "Epoch 48/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2925\n",
      "Epoch 48: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3094 - val_loss: 0.5746\n",
      "Epoch 49/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3222\n",
      "Epoch 49: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3161 - val_loss: 0.6139\n",
      "Epoch 50/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3024\n",
      "Epoch 50: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2994 - val_loss: 0.5875\n",
      "Epoch 51/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2980\n",
      "Epoch 51: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3025 - val_loss: 0.6088\n",
      "Epoch 52/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2751\n",
      "Epoch 52: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2777 - val_loss: 0.6214\n",
      "Epoch 53/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2696\n",
      "Epoch 53: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2663 - val_loss: 0.6348\n",
      "Epoch 54/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2947\n",
      "Epoch 54: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2905 - val_loss: 0.6052\n",
      "Epoch 55/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2843\n",
      "Epoch 55: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2853 - val_loss: 0.6806\n",
      "Epoch 56/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3061\n",
      "Epoch 56: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3154 - val_loss: 0.6021\n",
      "Epoch 57/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2709\n",
      "Epoch 57: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2738 - val_loss: 0.6596\n",
      "Epoch 58/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2534\n",
      "Epoch 58: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2510 - val_loss: 0.6313\n",
      "Epoch 59/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2835\n",
      "Epoch 59: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2812 - val_loss: 0.6342\n",
      "Epoch 60/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2524\n",
      "Epoch 60: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2500 - val_loss: 0.6483\n",
      "Epoch 61/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2364\n",
      "Epoch 61: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2406 - val_loss: 0.6824\n",
      "Epoch 62/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2656\n",
      "Epoch 62: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2633 - val_loss: 0.6866\n",
      "Epoch 63/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2414\n",
      "Epoch 63: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2486 - val_loss: 0.6742\n",
      "Epoch 64/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2372\n",
      "Epoch 64: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2378 - val_loss: 0.7467\n",
      "Epoch 65/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2618\n",
      "Epoch 65: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2612 - val_loss: 0.6804\n",
      "Epoch 66/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2178\n",
      "Epoch 66: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2160 - val_loss: 0.7490\n",
      "Epoch 67/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2722\n",
      "Epoch 67: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2688 - val_loss: 0.7044\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2402\n",
      "Epoch 68: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2460 - val_loss: 0.6997\n",
      "Epoch 69/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2367\n",
      "Epoch 69: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2363 - val_loss: 0.7369\n",
      "Epoch 70/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2726\n",
      "Epoch 70: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2681 - val_loss: 0.7055\n",
      "Epoch 71/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2211\n",
      "Epoch 71: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2213 - val_loss: 0.7367\n",
      "Epoch 72/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2242\n",
      "Epoch 72: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2203 - val_loss: 0.7093\n",
      "Epoch 73/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2075\n",
      "Epoch 73: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2180 - val_loss: 0.7897\n",
      "Epoch 74/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2306\n",
      "Epoch 74: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.2262 - val_loss: 0.7578\n",
      "Epoch 75/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2237\n",
      "Epoch 75: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2283 - val_loss: 0.8117\n",
      "Epoch 76/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2163\n",
      "Epoch 76: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2132 - val_loss: 0.7640\n",
      "Epoch 77/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.1872\n",
      "Epoch 77: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1882 - val_loss: 0.7907\n",
      "Epoch 78/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2115\n",
      "Epoch 78: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2063 - val_loss: 0.7875\n",
      "Epoch 79/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2061\n",
      "Epoch 79: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2053 - val_loss: 0.8203\n",
      "Epoch 80/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1896\n",
      "Epoch 80: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1869 - val_loss: 0.8324\n",
      "Epoch 81/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2057\n",
      "Epoch 81: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2054 - val_loss: 0.8032\n",
      "Epoch 82/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2124\n",
      "Epoch 82: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2098 - val_loss: 0.8066\n",
      "Epoch 83/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2129\n",
      "Epoch 83: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2106 - val_loss: 0.7789\n",
      "Epoch 84/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1931\n",
      "Epoch 84: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1905 - val_loss: 0.7930\n",
      "Epoch 85/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1828\n",
      "Epoch 85: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1782 - val_loss: 0.8042\n",
      "Epoch 86/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1733\n",
      "Epoch 86: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1736 - val_loss: 0.8305\n",
      "Epoch 87/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1964\n",
      "Epoch 87: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1928 - val_loss: 0.8214\n",
      "Epoch 88/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1794\n",
      "Epoch 88: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1790 - val_loss: 0.8938\n",
      "Epoch 89/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2135\n",
      "Epoch 89: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2314 - val_loss: 0.8178\n",
      "Epoch 90/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.1749\n",
      "Epoch 90: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.1847 - val_loss: 0.8551\n",
      "Epoch 91/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2043\n",
      "Epoch 91: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2007 - val_loss: 0.7703\n",
      "Epoch 92/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2054\n",
      "Epoch 92: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2054 - val_loss: 0.7853\n",
      "Epoch 93/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1760\n",
      "Epoch 93: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1732 - val_loss: 0.8325\n",
      "Epoch 94/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.1785\n",
      "Epoch 94: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1844 - val_loss: 0.8502\n",
      "Epoch 95/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1602\n",
      "Epoch 95: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1682 - val_loss: 0.8496\n",
      "Epoch 96/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1832\n",
      "Epoch 96: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1811 - val_loss: 0.8521\n",
      "Epoch 97/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1854\n",
      "Epoch 97: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1802 - val_loss: 0.8307\n",
      "Epoch 98/100\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2022\n",
      "Epoch 98: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.1917 - val_loss: 0.8305\n",
      "Epoch 99/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1703\n",
      "Epoch 99: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1691 - val_loss: 0.8224\n",
      "Epoch 100/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1708\n",
      "Epoch 100: val_loss did not improve from 0.47614\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1670 - val_loss: 0.8809\n"
     ]
    }
   ],
   "source": [
    "# adding random shuffling of the dataset for training purpose\n",
    "index_arr = np.arange(indpe_features_train.shape[0])\n",
    "index_arr = np.random.permutation(index_arr)\n",
    "\n",
    "model.fit(x = indpe_features_train[index_arr], y = indpe_labels_train[index_arr], \n",
    "          batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "          callbacks = modelCallbacks, validation_data = (indpe_features_test, indpe_labels_test))\n",
    "# model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "#           callbacks = modelCallbacks, validation_split = 0.2)\n",
    "\n",
    "model = tf.keras.models.load_model(current_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict on independent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.825163</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.68561</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>-0.012411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision      AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                   \n",
       "Independent  0.825163      0.125  0.68561     0.009901     0.986301 -0.012411"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "y_pred = model.predict(indpe_features_test)\n",
    "label_pred = pred2label(y_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels_test, label_pred)\n",
    "prec = precision_score(indpe_labels_test,label_pred)\n",
    "mcc = matthews_corrcoef(indpe_labels_test, label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels_test, label_pred)\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels_test, y_pred)\n",
    "auc = roc_auc_score(indpe_labels_test, y_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       511\n",
      "           1       0.12      0.01      0.02       101\n",
      "\n",
      "    accuracy                           0.83       612\n",
      "   macro avg       0.48      0.50      0.46       612\n",
      "weighted avg       0.72      0.83      0.76       612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(indpe_labels_test, np.round(y_pred).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big network\n",
    "# precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.84      0.99      0.91       511\n",
    "#            1       0.29      0.02      0.04       101\n",
    "\n",
    "#     accuracy                           0.83       612\n",
    "#    macro avg       0.56      0.51      0.47       612\n",
    "# weighted avg       0.75      0.83      0.76       612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(indpe_labels_test), np.sum(np.round(y_pred).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
