{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"NT_Site_iNitroY_Classification_DLNN_CORENup\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "shuffle = True\n",
    "seed = None\n",
    "\n",
    "input_data_folder = \"Data\\\\iNitroY-Deep-Dataset\"\n",
    "pos_data_file = \"raw-nitrotyrosine-pos.fasta\"\n",
    "neg_data_file = \"cdhit70-nitrotyr-neg.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import math\n",
    "\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define all CUSTOM functions\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode_nt(sequence, char_dict):\n",
    "    \n",
    "    seq_encoded = np.zeros((len(sequence),len(char_dict)))\n",
    "    \n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in char_dict.keys()):\n",
    "            seq_encoded[i][char_dict[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in NT sequence: '+sequence)\n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Build k-fold functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_CORENup(input_seq_shape = (41, 21),\n",
    "                 conv_filters_per_layer_1 = 50, kernel_length_1 = 5, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "                 max_pool_width_1 = 2, max_pool_stride_1 = 2, ## 1st Maxpool layer parameters\n",
    "                 lstm_decode_units = 50, ## LSTM layer parameters\n",
    "                 conv_filters_per_layer_2 = 50,  kernel_length_2 = 10, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "                 max_pool_width_2 = 2, max_pool_stride_2 = 2, ## 2nd Maxpool layer parameters\n",
    "                 dense_decode_units = 370, ## Dense layer parameters\n",
    "                 prob = 0.5, learn_rate = 0.0003, loss = 'binary_crossentropy', metrics = None):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  SEQUENCE  ##################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_seq_shape)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1,\n",
    "                                strides = conv_strides_1, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = \"same\")(input1)\n",
    "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta))(x1)\n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    ## Conv Path\n",
    "\n",
    "    x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, \n",
    "                                strides = conv_strides_2, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                                padding = 'same')(x1)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "    x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "    \n",
    "    x4 = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  Classifier  ################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    y = tf.keras.layers.Dense(dense_decode_units, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'relu')(x4)\n",
    "    \n",
    "    y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(1, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'sigmoid')(y)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=y)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), \n",
    "                      loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), \n",
    "                      loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step in range(10):\n",
    "#     initial_learning_rate=1e-1\n",
    "#     decay_steps=10000\n",
    "#     decay_rate=0.9\n",
    "#     print(step, ':', initial_learning_rate * decay_rate ** (step / decay_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 41, 21)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 41, 50)       5300        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 41, 50)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 20, 50)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 20, 50)       0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 20, 50)       25050       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 20, 50)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 20, 50)       20200       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 10, 50)      0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 20, 50)       0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 10, 50)       0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 500)          0           ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1500)         0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 370)          555370      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 370)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            371         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 606,291\n",
      "Trainable params: 606,291\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "DLNN_CORENup().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta_file(file_path):\n",
    "    \n",
    "    openFile = open(file_path)\n",
    "    fastaSequences = SeqIO.parse(openFile, \"fasta\")\n",
    "\n",
    "    name_list = []\n",
    "    seq_list = []\n",
    "\n",
    "    for fasta in fastaSequences: \n",
    "        name_list.append(fasta.id)\n",
    "        seq_list.append(str(fasta.seq))\n",
    "\n",
    "    openFile.close()\n",
    "    \n",
    "    return name_list, seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### read positive and negative files\n",
    "##################################################################################\n",
    "\n",
    "pos_file_path = os.path.join(input_data_folder, pos_data_file)\n",
    "_, pos_seq_list = read_fasta_file(pos_file_path)\n",
    "\n",
    "neg_file_path = os.path.join(input_data_folder, neg_data_file)\n",
    "_, neg_seq_list = read_fasta_file(neg_file_path)\n",
    "\n",
    "pos_seq_list = [val.replace('X', '-') for val in pos_seq_list]\n",
    "neg_seq_list = [val.replace('X', '-') for val in neg_seq_list]\n",
    "\n",
    "# remove duplicates in data\n",
    "pos_seq_list = list(set(pos_seq_list))\n",
    "neg_seq_list = list(set(neg_seq_list))\n",
    "\n",
    "all_seq_list = pos_seq_list + neg_seq_list\n",
    "\n",
    "all_seq_label_list = ([1] * len(pos_seq_list)) + ([0] * len(neg_seq_list))\n",
    "\n",
    "##################################################################################\n",
    "##### Create dictionary of all characters in the NT sequence \n",
    "##################################################################################\n",
    "all_char_set = set({})\n",
    "for val in [set(val) for val in all_seq_list]:\n",
    "    all_char_set = all_char_set.union(val)\n",
    "all_char_list = list(all_char_set)\n",
    "all_char_list.sort()\n",
    "all_char_dict = {}\n",
    "for i in range(len(all_char_list)):\n",
    "    all_char_dict[all_char_list[i]] = i\n",
    "    \n",
    "##################################################################################\n",
    "##### Create OHE of all sequences\n",
    "##################################################################################\n",
    "all_seq_OHE_list = [one_hot_encode_nt(val, all_char_dict)\n",
    "                    for val in all_seq_list]\n",
    "\n",
    "##################################################################################\n",
    "##### Create numpy array of features and sequences\n",
    "##################################################################################\n",
    "\n",
    "## create the features and labels datasets for the training\n",
    "features = np.array(all_seq_OHE_list)\n",
    "labels = np.array(all_seq_label_list)\n",
    "labels = labels.reshape((labels.shape[0], 1))\n",
    "\n",
    "##################################################################################\n",
    "##### Divide into Train/Independent datasets\n",
    "##################################################################################\n",
    "\n",
    "train_features, indpe_features, train_labels, indpe_labels = train_test_split(features, labels, \n",
    "                                                                              stratify=labels, test_size=0.3, \n",
    "                                                                              random_state=seed, shuffle=shuffle)\n",
    "\n",
    "##################################################################################\n",
    "##### Generate Folds from training dataset, and store to file\n",
    "##################################################################################\n",
    "\n",
    "## Generate the k-fold dataset\n",
    "folds = build_kfold(train_features, train_labels, k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "## Write the k-fold dataset to file\n",
    "foldPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold))\n",
    "if(not os.path.isdir(foldPath)):\n",
    "    os.makedirs(foldPath)\n",
    "pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "\n",
    "## Write the independent test dataset to file\n",
    "pickle.dump([indpe_features, indpe_labels], open(os.path.join(foldPath, 'independent_dataset.pickle'), \"wb\"))\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "input_seq_shape = features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 41, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indpe_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(indpe_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test model on Fold #0.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - ETA: 0s - loss: 1.3186\n",
      "Epoch 1: val_loss improved from inf to 1.26914, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 4s 33ms/step - loss: 1.3186 - val_loss: 1.2691\n",
      "Epoch 2/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.2289\n",
      "Epoch 2: val_loss improved from 1.26914 to 1.21524, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.2400 - val_loss: 1.2152\n",
      "Epoch 3/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1785\n",
      "Epoch 3: val_loss improved from 1.21524 to 1.16941, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.1826 - val_loss: 1.1694\n",
      "Epoch 4/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1226\n",
      "Epoch 4: val_loss improved from 1.16941 to 1.13064, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.1326 - val_loss: 1.1306\n",
      "Epoch 5/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 1.0953\n",
      "Epoch 5: val_loss improved from 1.13064 to 1.08837, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0919 - val_loss: 1.0884\n",
      "Epoch 6/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0576\n",
      "Epoch 6: val_loss improved from 1.08837 to 1.04938, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0547 - val_loss: 1.0494\n",
      "Epoch 7/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.9950\n",
      "Epoch 7: val_loss improved from 1.04938 to 1.01410, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.9932 - val_loss: 1.0141\n",
      "Epoch 8/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.9649\n",
      "Epoch 8: val_loss improved from 1.01410 to 0.99097, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9629 - val_loss: 0.9910\n",
      "Epoch 9/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8998\n",
      "Epoch 9: val_loss improved from 0.99097 to 0.95430, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9105 - val_loss: 0.9543\n",
      "Epoch 10/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.8664\n",
      "Epoch 10: val_loss did not improve from 0.95430\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8610 - val_loss: 0.9590\n",
      "Epoch 11/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8476\n",
      "Epoch 11: val_loss improved from 0.95430 to 0.94894, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.8462 - val_loss: 0.9489\n",
      "Epoch 12/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8295\n",
      "Epoch 12: val_loss improved from 0.94894 to 0.90487, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8282 - val_loss: 0.9049\n",
      "Epoch 13/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.7801\n",
      "Epoch 13: val_loss improved from 0.90487 to 0.88097, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7695 - val_loss: 0.8810\n",
      "Epoch 14/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.7243\n",
      "Epoch 14: val_loss improved from 0.88097 to 0.84855, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7360 - val_loss: 0.8485\n",
      "Epoch 15/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6891\n",
      "Epoch 15: val_loss improved from 0.84855 to 0.80766, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7017 - val_loss: 0.8077\n",
      "Epoch 16/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.6753\n",
      "Epoch 16: val_loss improved from 0.80766 to 0.80454, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6641 - val_loss: 0.8045\n",
      "Epoch 17/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6299\n",
      "Epoch 17: val_loss improved from 0.80454 to 0.80056, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6264 - val_loss: 0.8006\n",
      "Epoch 18/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6263\n",
      "Epoch 18: val_loss improved from 0.80056 to 0.75799, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6240 - val_loss: 0.7580\n",
      "Epoch 19/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5961\n",
      "Epoch 19: val_loss did not improve from 0.75799\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5947 - val_loss: 0.8120\n",
      "Epoch 20/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5909\n",
      "Epoch 20: val_loss improved from 0.75799 to 0.73958, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5896 - val_loss: 0.7396\n",
      "Epoch 21/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5616\n",
      "Epoch 21: val_loss improved from 0.73958 to 0.71746, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5555 - val_loss: 0.7175\n",
      "Epoch 22/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5462\n",
      "Epoch 22: val_loss improved from 0.71746 to 0.71071, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5536 - val_loss: 0.7107\n",
      "Epoch 23/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5335\n",
      "Epoch 23: val_loss did not improve from 0.71071\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5293 - val_loss: 0.7711\n",
      "Epoch 24/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4778\n",
      "Epoch 24: val_loss improved from 0.71071 to 0.68080, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4798 - val_loss: 0.6808\n",
      "Epoch 25/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4593\n",
      "Epoch 25: val_loss improved from 0.68080 to 0.67117, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4578 - val_loss: 0.6712\n",
      "Epoch 26/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4744\n",
      "Epoch 26: val_loss improved from 0.67117 to 0.64428, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4778 - val_loss: 0.6443\n",
      "Epoch 27/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4436\n",
      "Epoch 27: val_loss did not improve from 0.64428\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4537 - val_loss: 0.6505\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4473\n",
      "Epoch 28: val_loss improved from 0.64428 to 0.61516, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4488 - val_loss: 0.6152\n",
      "Epoch 29/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4385\n",
      "Epoch 29: val_loss improved from 0.61516 to 0.60604, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4353 - val_loss: 0.6060\n",
      "Epoch 30/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3872\n",
      "Epoch 30: val_loss improved from 0.60604 to 0.59531, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3942 - val_loss: 0.5953\n",
      "Epoch 31/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4111\n",
      "Epoch 31: val_loss did not improve from 0.59531\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4117 - val_loss: 0.6220\n",
      "Epoch 32/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3739\n",
      "Epoch 32: val_loss did not improve from 0.59531\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3713 - val_loss: 0.6422\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3886\n",
      "Epoch 33: val_loss improved from 0.59531 to 0.58991, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3886 - val_loss: 0.5899\n",
      "Epoch 34/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3885\n",
      "Epoch 34: val_loss improved from 0.58991 to 0.58809, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.3935 - val_loss: 0.5881\n",
      "Epoch 35/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3916\n",
      "Epoch 35: val_loss did not improve from 0.58809\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3933 - val_loss: 0.6274\n",
      "Epoch 36/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3858\n",
      "Epoch 36: val_loss did not improve from 0.58809\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3793 - val_loss: 0.6604\n",
      "Epoch 37/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3429\n",
      "Epoch 37: val_loss did not improve from 0.58809\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3414 - val_loss: 0.6066\n",
      "Epoch 38/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3278\n",
      "Epoch 38: val_loss did not improve from 0.58809\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3263 - val_loss: 0.6140\n",
      "Epoch 39/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3193\n",
      "Epoch 39: val_loss did not improve from 0.58809\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3194 - val_loss: 0.6015\n",
      "Epoch 40/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3204\n",
      "Epoch 40: val_loss did not improve from 0.58809\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3196 - val_loss: 0.5909\n",
      "Epoch 41/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2888\n",
      "Epoch 41: val_loss did not improve from 0.58809\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2917 - val_loss: 0.6200\n",
      "Epoch 42/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2974\n",
      "Epoch 42: val_loss did not improve from 0.58809\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2965 - val_loss: 0.6028\n",
      "Epoch 43/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2847\n",
      "Epoch 43: val_loss did not improve from 0.58809\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2876 - val_loss: 0.6486\n",
      "Epoch 44/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2982\n",
      "Epoch 44: val_loss improved from 0.58809 to 0.56473, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2967 - val_loss: 0.5647\n",
      "Epoch 45/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2674\n",
      "Epoch 45: val_loss did not improve from 0.56473\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2665 - val_loss: 0.5866\n",
      "Epoch 46/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2923\n",
      "Epoch 46: val_loss did not improve from 0.56473\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2910 - val_loss: 0.6242\n",
      "Epoch 47/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2715\n",
      "Epoch 47: val_loss did not improve from 0.56473\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2704 - val_loss: 0.5833\n",
      "Epoch 48/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2857\n",
      "Epoch 48: val_loss did not improve from 0.56473\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2825 - val_loss: 0.6041\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2796\n",
      "Epoch 49: val_loss did not improve from 0.56473\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2796 - val_loss: 0.5737\n",
      "Epoch 50/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2595\n",
      "Epoch 50: val_loss did not improve from 0.56473\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2576 - val_loss: 0.6528\n",
      "Epoch 51/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2605\n",
      "Epoch 51: val_loss did not improve from 0.56473\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2617 - val_loss: 0.5670\n",
      "Epoch 52/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2544\n",
      "Epoch 52: val_loss did not improve from 0.56473\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2540 - val_loss: 0.5665\n",
      "Epoch 53/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2575\n",
      "Epoch 53: val_loss improved from 0.56473 to 0.54655, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2546 - val_loss: 0.5465\n",
      "Epoch 54/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2606\n",
      "Epoch 54: val_loss did not improve from 0.54655\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2592 - val_loss: 0.6159\n",
      "Epoch 55/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2477\n",
      "Epoch 55: val_loss did not improve from 0.54655\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2488 - val_loss: 0.5646\n",
      "Epoch 56/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.2410\n",
      "Epoch 56: val_loss did not improve from 0.54655\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2456 - val_loss: 0.5692\n",
      "Epoch 57/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2394\n",
      "Epoch 57: val_loss did not improve from 0.54655\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2384 - val_loss: 0.5714\n",
      "Epoch 58/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2214\n",
      "Epoch 58: val_loss did not improve from 0.54655\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2198 - val_loss: 0.5970\n",
      "Epoch 59/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2175\n",
      "Epoch 59: val_loss did not improve from 0.54655\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2167 - val_loss: 0.6000\n",
      "Epoch 60/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2270\n",
      "Epoch 60: val_loss did not improve from 0.54655\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2259 - val_loss: 0.5558\n",
      "Epoch 61/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2356\n",
      "Epoch 61: val_loss did not improve from 0.54655\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2351 - val_loss: 0.6070\n",
      "Epoch 62/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2110\n",
      "Epoch 62: val_loss did not improve from 0.54655\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2102 - val_loss: 0.6069\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2240\n",
      "Epoch 63: val_loss did not improve from 0.54655\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2220 - val_loss: 0.6168\n",
      "Epoch 64/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2086\n",
      "Epoch 64: val_loss improved from 0.54655 to 0.54398, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2100 - val_loss: 0.5440\n",
      "Epoch 65/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.2229\n",
      "Epoch 65: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2200 - val_loss: 0.5907\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1973\n",
      "Epoch 66: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1973 - val_loss: 0.6629\n",
      "Epoch 67/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1973\n",
      "Epoch 67: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1995 - val_loss: 0.5780\n",
      "Epoch 68/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1968\n",
      "Epoch 68: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1964 - val_loss: 0.6232\n",
      "Epoch 69/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1993\n",
      "Epoch 69: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1987 - val_loss: 0.5854\n",
      "Epoch 70/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1958\n",
      "Epoch 70: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1960 - val_loss: 0.6265\n",
      "Epoch 71/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1908\n",
      "Epoch 71: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1894 - val_loss: 0.5611\n",
      "Epoch 72/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1989\n",
      "Epoch 72: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1982 - val_loss: 0.5485\n",
      "Epoch 73/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1965\n",
      "Epoch 73: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1957 - val_loss: 0.6035\n",
      "Epoch 74/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1853\n",
      "Epoch 74: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1842 - val_loss: 0.5629\n",
      "Epoch 75/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1958\n",
      "Epoch 75: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1963 - val_loss: 0.5813\n",
      "Epoch 76/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1826\n",
      "Epoch 76: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1815 - val_loss: 0.5899\n",
      "Epoch 77/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1818\n",
      "Epoch 77: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1850 - val_loss: 0.5805\n",
      "Epoch 78/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1852\n",
      "Epoch 78: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1920 - val_loss: 0.6108\n",
      "Epoch 79/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1757\n",
      "Epoch 79: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1749 - val_loss: 0.5578\n",
      "Epoch 80/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1896\n",
      "Epoch 80: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1881 - val_loss: 0.5870\n",
      "Epoch 81/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1713\n",
      "Epoch 81: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1715 - val_loss: 0.6204\n",
      "Epoch 82/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1925\n",
      "Epoch 82: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1905 - val_loss: 0.5874\n",
      "Epoch 83/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1634\n",
      "Epoch 83: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1632 - val_loss: 0.5716\n",
      "Epoch 84/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1664\n",
      "Epoch 84: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1656 - val_loss: 0.5602\n",
      "Epoch 85/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1684\n",
      "Epoch 85: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1672 - val_loss: 0.5477\n",
      "Epoch 86/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1644\n",
      "Epoch 86: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1639 - val_loss: 0.5607\n",
      "Epoch 87/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1641\n",
      "Epoch 87: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1628 - val_loss: 0.5538\n",
      "Epoch 88/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1641\n",
      "Epoch 88: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1627 - val_loss: 0.5698\n",
      "Epoch 89/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1632\n",
      "Epoch 89: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1619 - val_loss: 0.5889\n",
      "Epoch 90/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1721\n",
      "Epoch 90: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1697 - val_loss: 0.5890\n",
      "Epoch 91/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1510\n",
      "Epoch 91: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1514 - val_loss: 0.5588\n",
      "Epoch 92/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1546\n",
      "Epoch 92: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1540 - val_loss: 0.5686\n",
      "Epoch 93/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1495\n",
      "Epoch 93: val_loss did not improve from 0.54398\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1508 - val_loss: 0.6315\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1605\n",
      "Epoch 94: val_loss improved from 0.54398 to 0.52686, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1605 - val_loss: 0.5269\n",
      "Epoch 95/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1488\n",
      "Epoch 95: val_loss did not improve from 0.52686\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1505 - val_loss: 0.5929\n",
      "Epoch 96/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1501\n",
      "Epoch 96: val_loss did not improve from 0.52686\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1491 - val_loss: 0.5835\n",
      "Epoch 97/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1417\n",
      "Epoch 97: val_loss did not improve from 0.52686\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1440 - val_loss: 0.5726\n",
      "Epoch 98/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1529\n",
      "Epoch 98: val_loss improved from 0.52686 to 0.51956, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold0.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1517 - val_loss: 0.5196\n",
      "Epoch 99/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1512\n",
      "Epoch 99: val_loss did not improve from 0.51956\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1493 - val_loss: 0.5619\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1389\n",
      "Epoch 100: val_loss did not improve from 0.51956\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1385 - val_loss: 0.5256\n",
      "\n",
      "Train/Test model on Fold #1.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - ETA: 0s - loss: 1.3045\n",
      "Epoch 1: val_loss improved from inf to 1.25430, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 2s 36ms/step - loss: 1.3045 - val_loss: 1.2543\n",
      "Epoch 2/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.2308\n",
      "Epoch 2: val_loss improved from 1.25430 to 1.21053, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.2356 - val_loss: 1.2105\n",
      "Epoch 3/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1941\n",
      "Epoch 3: val_loss improved from 1.21053 to 1.15888, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.1833 - val_loss: 1.1589\n",
      "Epoch 4/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 1.1330\n",
      "Epoch 4: val_loss improved from 1.15888 to 1.12876, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.1293 - val_loss: 1.1288\n",
      "Epoch 5/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.0892\n",
      "Epoch 5: val_loss improved from 1.12876 to 1.06747, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0849 - val_loss: 1.0675\n",
      "Epoch 6/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 1.0500\n",
      "Epoch 6: val_loss improved from 1.06747 to 1.02936, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0518 - val_loss: 1.0294\n",
      "Epoch 7/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0040\n",
      "Epoch 7: val_loss improved from 1.02936 to 1.01795, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9985 - val_loss: 1.0180\n",
      "Epoch 8/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.9727\n",
      "Epoch 8: val_loss improved from 1.01795 to 0.98312, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.9768 - val_loss: 0.9831\n",
      "Epoch 9/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.9090\n",
      "Epoch 9: val_loss improved from 0.98312 to 0.91926, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9085 - val_loss: 0.9193\n",
      "Epoch 10/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8861\n",
      "Epoch 10: val_loss improved from 0.91926 to 0.87454, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8891 - val_loss: 0.8745\n",
      "Epoch 11/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8771\n",
      "Epoch 11: val_loss improved from 0.87454 to 0.84257, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.8764 - val_loss: 0.8426\n",
      "Epoch 12/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8147\n",
      "Epoch 12: val_loss improved from 0.84257 to 0.80659, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8073 - val_loss: 0.8066\n",
      "Epoch 13/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.7797\n",
      "Epoch 13: val_loss improved from 0.80659 to 0.79179, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7790 - val_loss: 0.7918\n",
      "Epoch 14/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8127\n",
      "Epoch 14: val_loss did not improve from 0.79179\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8086 - val_loss: 0.8879\n",
      "Epoch 15/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.7469\n",
      "Epoch 15: val_loss improved from 0.79179 to 0.73604, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7555 - val_loss: 0.7360\n",
      "Epoch 16/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.6766\n",
      "Epoch 16: val_loss improved from 0.73604 to 0.70946, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6912 - val_loss: 0.7095\n",
      "Epoch 17/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6740\n",
      "Epoch 17: val_loss improved from 0.70946 to 0.67375, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6803 - val_loss: 0.6737\n",
      "Epoch 18/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6521\n",
      "Epoch 18: val_loss improved from 0.67375 to 0.64582, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6490 - val_loss: 0.6458\n",
      "Epoch 19/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6396\n",
      "Epoch 19: val_loss improved from 0.64582 to 0.62566, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6393 - val_loss: 0.6257\n",
      "Epoch 20/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5867\n",
      "Epoch 20: val_loss improved from 0.62566 to 0.60081, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5961 - val_loss: 0.6008\n",
      "Epoch 21/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5762\n",
      "Epoch 21: val_loss improved from 0.60081 to 0.57894, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5874 - val_loss: 0.5789\n",
      "Epoch 22/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5576\n",
      "Epoch 22: val_loss improved from 0.57894 to 0.56751, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5549 - val_loss: 0.5675\n",
      "Epoch 23/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5569\n",
      "Epoch 23: val_loss improved from 0.56751 to 0.55240, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5528 - val_loss: 0.5524\n",
      "Epoch 24/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5214\n",
      "Epoch 24: val_loss did not improve from 0.55240\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5206 - val_loss: 0.5689\n",
      "Epoch 25/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5084\n",
      "Epoch 25: val_loss improved from 0.55240 to 0.50782, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5082 - val_loss: 0.5078\n",
      "Epoch 26/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5183\n",
      "Epoch 26: val_loss improved from 0.50782 to 0.47616, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5109 - val_loss: 0.4762\n",
      "Epoch 27/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4581\n",
      "Epoch 27: val_loss did not improve from 0.47616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4581 - val_loss: 0.4807\n",
      "Epoch 28/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.4771\n",
      "Epoch 28: val_loss improved from 0.47616 to 0.45196, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4698 - val_loss: 0.4520\n",
      "Epoch 29/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4460\n",
      "Epoch 29: val_loss improved from 0.45196 to 0.44466, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4474 - val_loss: 0.4447\n",
      "Epoch 30/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4300\n",
      "Epoch 30: val_loss did not improve from 0.44466\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4257 - val_loss: 0.4492\n",
      "Epoch 31/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3994\n",
      "Epoch 31: val_loss improved from 0.44466 to 0.42578, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4043 - val_loss: 0.4258\n",
      "Epoch 32/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3827\n",
      "Epoch 32: val_loss did not improve from 0.42578\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3818 - val_loss: 0.4293\n",
      "Epoch 33/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3861\n",
      "Epoch 33: val_loss did not improve from 0.42578\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3869 - val_loss: 0.4315\n",
      "Epoch 34/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3813\n",
      "Epoch 34: val_loss improved from 0.42578 to 0.39780, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3800 - val_loss: 0.3978\n",
      "Epoch 35/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3620\n",
      "Epoch 35: val_loss improved from 0.39780 to 0.38844, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3618 - val_loss: 0.3884\n",
      "Epoch 36/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3533\n",
      "Epoch 36: val_loss improved from 0.38844 to 0.37883, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3530 - val_loss: 0.3788\n",
      "Epoch 37/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3372\n",
      "Epoch 37: val_loss improved from 0.37883 to 0.37602, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3353 - val_loss: 0.3760\n",
      "Epoch 38/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3368\n",
      "Epoch 38: val_loss improved from 0.37602 to 0.37504, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3329 - val_loss: 0.3750\n",
      "Epoch 39/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3488\n",
      "Epoch 39: val_loss did not improve from 0.37504\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3465 - val_loss: 0.3803\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3192\n",
      "Epoch 40: val_loss improved from 0.37504 to 0.36713, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3192 - val_loss: 0.3671\n",
      "Epoch 41/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3287\n",
      "Epoch 41: val_loss did not improve from 0.36713\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3274 - val_loss: 0.3701\n",
      "Epoch 42/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3118\n",
      "Epoch 42: val_loss did not improve from 0.36713\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3204 - val_loss: 0.3807\n",
      "Epoch 43/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3021\n",
      "Epoch 43: val_loss improved from 0.36713 to 0.34862, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3029 - val_loss: 0.3486\n",
      "Epoch 44/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3118\n",
      "Epoch 44: val_loss did not improve from 0.34862\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3089 - val_loss: 0.3530\n",
      "Epoch 45/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3129\n",
      "Epoch 45: val_loss improved from 0.34862 to 0.33428, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3119 - val_loss: 0.3343\n",
      "Epoch 46/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2783\n",
      "Epoch 46: val_loss did not improve from 0.33428\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2770 - val_loss: 0.3433\n",
      "Epoch 47/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3072\n",
      "Epoch 47: val_loss did not improve from 0.33428\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3053 - val_loss: 0.3348\n",
      "Epoch 48/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2696\n",
      "Epoch 48: val_loss did not improve from 0.33428\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2701 - val_loss: 0.3712\n",
      "Epoch 49/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2831\n",
      "Epoch 49: val_loss did not improve from 0.33428\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2792 - val_loss: 0.3394\n",
      "Epoch 50/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2710\n",
      "Epoch 50: val_loss improved from 0.33428 to 0.32241, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2743 - val_loss: 0.3224\n",
      "Epoch 51/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2691\n",
      "Epoch 51: val_loss improved from 0.32241 to 0.32153, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2657 - val_loss: 0.3215\n",
      "Epoch 52/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2570\n",
      "Epoch 52: val_loss improved from 0.32153 to 0.30942, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2544 - val_loss: 0.3094\n",
      "Epoch 53/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2623\n",
      "Epoch 53: val_loss did not improve from 0.30942\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2585 - val_loss: 0.3500\n",
      "Epoch 54/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2492\n",
      "Epoch 54: val_loss did not improve from 0.30942\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2463 - val_loss: 0.3166\n",
      "Epoch 55/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2751\n",
      "Epoch 55: val_loss did not improve from 0.30942\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2746 - val_loss: 0.3599\n",
      "Epoch 56/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2408\n",
      "Epoch 56: val_loss did not improve from 0.30942\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2419 - val_loss: 0.3312\n",
      "Epoch 57/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2360\n",
      "Epoch 57: val_loss improved from 0.30942 to 0.30682, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2351 - val_loss: 0.3068\n",
      "Epoch 58/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2286\n",
      "Epoch 58: val_loss did not improve from 0.30682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2265 - val_loss: 0.3162\n",
      "Epoch 59/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2391\n",
      "Epoch 59: val_loss improved from 0.30682 to 0.30226, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2366 - val_loss: 0.3023\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2451\n",
      "Epoch 60: val_loss did not improve from 0.30226\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2451 - val_loss: 0.3153\n",
      "Epoch 61/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2041\n",
      "Epoch 61: val_loss did not improve from 0.30226\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2032 - val_loss: 0.3193\n",
      "Epoch 62/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2537\n",
      "Epoch 62: val_loss did not improve from 0.30226\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2512 - val_loss: 0.3439\n",
      "Epoch 63/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2206\n",
      "Epoch 63: val_loss improved from 0.30226 to 0.27676, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2200 - val_loss: 0.2768\n",
      "Epoch 64/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2122\n",
      "Epoch 64: val_loss did not improve from 0.27676\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2120 - val_loss: 0.3058\n",
      "Epoch 65/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2167\n",
      "Epoch 65: val_loss did not improve from 0.27676\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2188 - val_loss: 0.3170\n",
      "Epoch 66/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2035\n",
      "Epoch 66: val_loss did not improve from 0.27676\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2032 - val_loss: 0.2839\n",
      "Epoch 67/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1957\n",
      "Epoch 67: val_loss did not improve from 0.27676\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1942 - val_loss: 0.3015\n",
      "Epoch 68/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2183\n",
      "Epoch 68: val_loss did not improve from 0.27676\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2196 - val_loss: 0.2832\n",
      "Epoch 69/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2007\n",
      "Epoch 69: val_loss improved from 0.27676 to 0.26335, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1991 - val_loss: 0.2633\n",
      "Epoch 70/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1969\n",
      "Epoch 70: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1961 - val_loss: 0.3118\n",
      "Epoch 71/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1942\n",
      "Epoch 71: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1935 - val_loss: 0.2949\n",
      "Epoch 72/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2066\n",
      "Epoch 72: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2049 - val_loss: 0.3170\n",
      "Epoch 73/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1977\n",
      "Epoch 73: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1966 - val_loss: 0.3017\n",
      "Epoch 74/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1734\n",
      "Epoch 74: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1735 - val_loss: 0.2795\n",
      "Epoch 75/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1719\n",
      "Epoch 75: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1712 - val_loss: 0.2752\n",
      "Epoch 76/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1749\n",
      "Epoch 76: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1752 - val_loss: 0.3001\n",
      "Epoch 77/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1717\n",
      "Epoch 77: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1721 - val_loss: 0.2642\n",
      "Epoch 78/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1671\n",
      "Epoch 78: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1667 - val_loss: 0.2699\n",
      "Epoch 79/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1835\n",
      "Epoch 79: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1845 - val_loss: 0.3695\n",
      "Epoch 80/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1772\n",
      "Epoch 80: val_loss did not improve from 0.26335\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1799 - val_loss: 0.2635\n",
      "Epoch 81/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1690\n",
      "Epoch 81: val_loss improved from 0.26335 to 0.26185, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1692 - val_loss: 0.2619\n",
      "Epoch 82/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1838\n",
      "Epoch 82: val_loss did not improve from 0.26185\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1825 - val_loss: 0.2677\n",
      "Epoch 83/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1651\n",
      "Epoch 83: val_loss did not improve from 0.26185\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1642 - val_loss: 0.2636\n",
      "Epoch 84/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1694\n",
      "Epoch 84: val_loss improved from 0.26185 to 0.25630, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1681 - val_loss: 0.2563\n",
      "Epoch 85/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.1659\n",
      "Epoch 85: val_loss did not improve from 0.25630\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1632 - val_loss: 0.2753\n",
      "Epoch 86/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1711\n",
      "Epoch 86: val_loss did not improve from 0.25630\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1692 - val_loss: 0.3018\n",
      "Epoch 87/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1570\n",
      "Epoch 87: val_loss did not improve from 0.25630\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1562 - val_loss: 0.2744\n",
      "Epoch 88/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1625\n",
      "Epoch 88: val_loss did not improve from 0.25630\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1625 - val_loss: 0.2634\n",
      "Epoch 89/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1710\n",
      "Epoch 89: val_loss did not improve from 0.25630\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1751 - val_loss: 0.2672\n",
      "Epoch 90/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1754\n",
      "Epoch 90: val_loss did not improve from 0.25630\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1738 - val_loss: 0.3390\n",
      "Epoch 91/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1877\n",
      "Epoch 91: val_loss improved from 0.25630 to 0.22742, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold1.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1850 - val_loss: 0.2274\n",
      "Epoch 92/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1624\n",
      "Epoch 92: val_loss did not improve from 0.22742\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1620 - val_loss: 0.2380\n",
      "Epoch 93/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1681\n",
      "Epoch 93: val_loss did not improve from 0.22742\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1670 - val_loss: 0.2332\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1648\n",
      "Epoch 94: val_loss did not improve from 0.22742\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1641 - val_loss: 0.2753\n",
      "Epoch 95/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1806\n",
      "Epoch 95: val_loss did not improve from 0.22742\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1783 - val_loss: 0.2282\n",
      "Epoch 96/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1555\n",
      "Epoch 96: val_loss did not improve from 0.22742\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1572 - val_loss: 0.2651\n",
      "Epoch 97/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1524\n",
      "Epoch 97: val_loss did not improve from 0.22742\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1511 - val_loss: 0.2631\n",
      "Epoch 98/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1442\n",
      "Epoch 98: val_loss did not improve from 0.22742\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1470 - val_loss: 0.2579\n",
      "Epoch 99/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1638\n",
      "Epoch 99: val_loss did not improve from 0.22742\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1612 - val_loss: 0.2404\n",
      "Epoch 100/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1498\n",
      "Epoch 100: val_loss did not improve from 0.22742\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1487 - val_loss: 0.2391\n",
      "\n",
      "Train/Test model on Fold #2.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/24 [======================>.......] - ETA: 0s - loss: 1.3505\n",
      "Epoch 1: val_loss improved from inf to 1.26854, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 2s 36ms/step - loss: 1.3289 - val_loss: 1.2685\n",
      "Epoch 2/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.2597\n",
      "Epoch 2: val_loss improved from 1.26854 to 1.23458, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.2472 - val_loss: 1.2346\n",
      "Epoch 3/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1726\n",
      "Epoch 3: val_loss improved from 1.23458 to 1.17998, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.1874 - val_loss: 1.1800\n",
      "Epoch 4/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 1.1394\n",
      "Epoch 4: val_loss improved from 1.17998 to 1.14774, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.1388 - val_loss: 1.1477\n",
      "Epoch 5/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1041\n",
      "Epoch 5: val_loss improved from 1.14774 to 1.10363, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.1025 - val_loss: 1.1036\n",
      "Epoch 6/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0659\n",
      "Epoch 6: val_loss improved from 1.10363 to 1.07876, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0620 - val_loss: 1.0788\n",
      "Epoch 7/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0425\n",
      "Epoch 7: val_loss improved from 1.07876 to 1.05528, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0381 - val_loss: 1.0553\n",
      "Epoch 8/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.9842\n",
      "Epoch 8: val_loss improved from 1.05528 to 1.02217, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9810 - val_loss: 1.0222\n",
      "Epoch 9/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.9440\n",
      "Epoch 9: val_loss improved from 1.02217 to 1.00902, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.9365 - val_loss: 1.0090\n",
      "Epoch 10/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.9200\n",
      "Epoch 10: val_loss improved from 1.00902 to 0.98294, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9139 - val_loss: 0.9829\n",
      "Epoch 11/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8583\n",
      "Epoch 11: val_loss improved from 0.98294 to 0.95597, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8654 - val_loss: 0.9560\n",
      "Epoch 12/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.8185\n",
      "Epoch 12: val_loss improved from 0.95597 to 0.93531, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8058 - val_loss: 0.9353\n",
      "Epoch 13/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.7925\n",
      "Epoch 13: val_loss improved from 0.93531 to 0.92963, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7891 - val_loss: 0.9296\n",
      "Epoch 14/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.7490\n",
      "Epoch 14: val_loss improved from 0.92963 to 0.90149, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7543 - val_loss: 0.9015\n",
      "Epoch 15/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.7076\n",
      "Epoch 15: val_loss improved from 0.90149 to 0.89796, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7045 - val_loss: 0.8980\n",
      "Epoch 16/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6859\n",
      "Epoch 16: val_loss improved from 0.89796 to 0.85850, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6929 - val_loss: 0.8585\n",
      "Epoch 17/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6519\n",
      "Epoch 17: val_loss improved from 0.85850 to 0.82779, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6503 - val_loss: 0.8278\n",
      "Epoch 18/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6165\n",
      "Epoch 18: val_loss did not improve from 0.82779\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6088 - val_loss: 0.8378\n",
      "Epoch 19/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.6201\n",
      "Epoch 19: val_loss improved from 0.82779 to 0.77602, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6219 - val_loss: 0.7760\n",
      "Epoch 20/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6205\n",
      "Epoch 20: val_loss improved from 0.77602 to 0.76191, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6193 - val_loss: 0.7619\n",
      "Epoch 21/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5545\n",
      "Epoch 21: val_loss did not improve from 0.76191\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5526 - val_loss: 0.8114\n",
      "Epoch 22/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5318\n",
      "Epoch 22: val_loss did not improve from 0.76191\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5353 - val_loss: 0.8164\n",
      "Epoch 23/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5372\n",
      "Epoch 23: val_loss improved from 0.76191 to 0.74064, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5435 - val_loss: 0.7406\n",
      "Epoch 24/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5132\n",
      "Epoch 24: val_loss did not improve from 0.74064\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5104 - val_loss: 0.7802\n",
      "Epoch 25/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4876\n",
      "Epoch 25: val_loss improved from 0.74064 to 0.70666, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4842 - val_loss: 0.7067\n",
      "Epoch 26/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4592\n",
      "Epoch 26: val_loss improved from 0.70666 to 0.69535, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4673 - val_loss: 0.6954\n",
      "Epoch 27/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4388\n",
      "Epoch 27: val_loss did not improve from 0.69535\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4335 - val_loss: 0.7066\n",
      "Epoch 28/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4379\n",
      "Epoch 28: val_loss improved from 0.69535 to 0.66935, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4360 - val_loss: 0.6694\n",
      "Epoch 29/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4259\n",
      "Epoch 29: val_loss improved from 0.66935 to 0.64272, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4202 - val_loss: 0.6427\n",
      "Epoch 30/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3846\n",
      "Epoch 30: val_loss did not improve from 0.64272\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3867 - val_loss: 0.6587\n",
      "Epoch 31/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.3848\n",
      "Epoch 31: val_loss improved from 0.64272 to 0.63878, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3894 - val_loss: 0.6388\n",
      "Epoch 32/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4007\n",
      "Epoch 32: val_loss improved from 0.63878 to 0.62101, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3964 - val_loss: 0.6210\n",
      "Epoch 33/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3617\n",
      "Epoch 33: val_loss did not improve from 0.62101\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3657 - val_loss: 0.6364\n",
      "Epoch 34/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3852\n",
      "Epoch 34: val_loss did not improve from 0.62101\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3844 - val_loss: 0.6346\n",
      "Epoch 35/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.3500\n",
      "Epoch 35: val_loss did not improve from 0.62101\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3520 - val_loss: 0.6532\n",
      "Epoch 36/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3806\n",
      "Epoch 36: val_loss improved from 0.62101 to 0.59227, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3833 - val_loss: 0.5923\n",
      "Epoch 37/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3446\n",
      "Epoch 37: val_loss improved from 0.59227 to 0.54483, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3416 - val_loss: 0.5448\n",
      "Epoch 38/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3361\n",
      "Epoch 38: val_loss did not improve from 0.54483\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3332 - val_loss: 0.5754\n",
      "Epoch 39/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3397\n",
      "Epoch 39: val_loss did not improve from 0.54483\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3467 - val_loss: 0.5452\n",
      "Epoch 40/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3292\n",
      "Epoch 40: val_loss did not improve from 0.54483\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3393 - val_loss: 0.5799\n",
      "Epoch 41/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3226\n",
      "Epoch 41: val_loss did not improve from 0.54483\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3217 - val_loss: 0.5682\n",
      "Epoch 42/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3278\n",
      "Epoch 42: val_loss improved from 0.54483 to 0.53149, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3278 - val_loss: 0.5315\n",
      "Epoch 43/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3123\n",
      "Epoch 43: val_loss did not improve from 0.53149\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3090 - val_loss: 0.5483\n",
      "Epoch 44/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2824\n",
      "Epoch 44: val_loss did not improve from 0.53149\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2836 - val_loss: 0.5497\n",
      "Epoch 45/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3087\n",
      "Epoch 45: val_loss did not improve from 0.53149\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3071 - val_loss: 0.5613\n",
      "Epoch 46/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3024\n",
      "Epoch 46: val_loss did not improve from 0.53149\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2994 - val_loss: 0.5421\n",
      "Epoch 47/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2985\n",
      "Epoch 47: val_loss improved from 0.53149 to 0.52934, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2945 - val_loss: 0.5293\n",
      "Epoch 48/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2759\n",
      "Epoch 48: val_loss improved from 0.52934 to 0.52762, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2764 - val_loss: 0.5276\n",
      "Epoch 49/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2677\n",
      "Epoch 49: val_loss improved from 0.52762 to 0.49472, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2666 - val_loss: 0.4947\n",
      "Epoch 50/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2976\n",
      "Epoch 50: val_loss did not improve from 0.49472\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2976 - val_loss: 0.4949\n",
      "Epoch 51/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2591\n",
      "Epoch 51: val_loss did not improve from 0.49472\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2558 - val_loss: 0.4996\n",
      "Epoch 52/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2596\n",
      "Epoch 52: val_loss did not improve from 0.49472\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.2587 - val_loss: 0.5265\n",
      "Epoch 53/100\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.2420\n",
      "Epoch 53: val_loss did not improve from 0.49472\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2482 - val_loss: 0.5487\n",
      "Epoch 54/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2667\n",
      "Epoch 54: val_loss did not improve from 0.49472\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2683 - val_loss: 0.5195\n",
      "Epoch 55/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.2466\n",
      "Epoch 55: val_loss improved from 0.49472 to 0.47410, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.2480 - val_loss: 0.4741\n",
      "Epoch 56/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2390\n",
      "Epoch 56: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2406 - val_loss: 0.4889\n",
      "Epoch 57/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2476\n",
      "Epoch 57: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2448 - val_loss: 0.5092\n",
      "Epoch 58/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2455\n",
      "Epoch 58: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2433 - val_loss: 0.5354\n",
      "Epoch 59/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.2241\n",
      "Epoch 59: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2213 - val_loss: 0.5286\n",
      "Epoch 60/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2243\n",
      "Epoch 60: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2223 - val_loss: 0.5039\n",
      "Epoch 61/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2156\n",
      "Epoch 61: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2216 - val_loss: 0.5136\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2121\n",
      "Epoch 62: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2107 - val_loss: 0.5424\n",
      "Epoch 63/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.2089\n",
      "Epoch 63: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2063 - val_loss: 0.6233\n",
      "Epoch 64/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2327\n",
      "Epoch 64: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2289 - val_loss: 0.4861\n",
      "Epoch 65/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.2203\n",
      "Epoch 65: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2276 - val_loss: 0.5350\n",
      "Epoch 66/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2153\n",
      "Epoch 66: val_loss did not improve from 0.47410\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2183 - val_loss: 0.4966\n",
      "Epoch 67/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2175\n",
      "Epoch 67: val_loss improved from 0.47410 to 0.47016, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2169 - val_loss: 0.4702\n",
      "Epoch 68/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2015\n",
      "Epoch 68: val_loss improved from 0.47016 to 0.45403, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1994 - val_loss: 0.4540\n",
      "Epoch 69/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1929\n",
      "Epoch 69: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2067 - val_loss: 0.5271\n",
      "Epoch 70/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1842\n",
      "Epoch 70: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1841 - val_loss: 0.4978\n",
      "Epoch 71/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1890\n",
      "Epoch 71: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1932 - val_loss: 0.4797\n",
      "Epoch 72/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.1877\n",
      "Epoch 72: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1909 - val_loss: 0.5479\n",
      "Epoch 73/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1884\n",
      "Epoch 73: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1864 - val_loss: 0.5041\n",
      "Epoch 74/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.1912\n",
      "Epoch 74: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1884 - val_loss: 0.4937\n",
      "Epoch 75/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1771\n",
      "Epoch 75: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1770 - val_loss: 0.4805\n",
      "Epoch 76/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1745\n",
      "Epoch 76: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1747 - val_loss: 0.5117\n",
      "Epoch 77/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.1912\n",
      "Epoch 77: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1966 - val_loss: 0.5719\n",
      "Epoch 78/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.1837\n",
      "Epoch 78: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1800 - val_loss: 0.4668\n",
      "Epoch 79/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1691\n",
      "Epoch 79: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1690 - val_loss: 0.4701\n",
      "Epoch 80/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1614\n",
      "Epoch 80: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1623 - val_loss: 0.5270\n",
      "Epoch 81/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1769\n",
      "Epoch 81: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1755 - val_loss: 0.5019\n",
      "Epoch 82/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1760\n",
      "Epoch 82: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1759 - val_loss: 0.5095\n",
      "Epoch 83/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1760\n",
      "Epoch 83: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1761 - val_loss: 0.4939\n",
      "Epoch 84/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1687\n",
      "Epoch 84: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1681 - val_loss: 0.4949\n",
      "Epoch 85/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1639\n",
      "Epoch 85: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1628 - val_loss: 0.5230\n",
      "Epoch 86/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1679\n",
      "Epoch 86: val_loss did not improve from 0.45403\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1682 - val_loss: 0.5032\n",
      "Epoch 87/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1807\n",
      "Epoch 87: val_loss improved from 0.45403 to 0.45163, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1781 - val_loss: 0.4516\n",
      "Epoch 88/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1577\n",
      "Epoch 88: val_loss did not improve from 0.45163\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1575 - val_loss: 0.4624\n",
      "Epoch 89/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1719\n",
      "Epoch 89: val_loss improved from 0.45163 to 0.43029, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold2.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1719 - val_loss: 0.4303\n",
      "Epoch 90/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1554\n",
      "Epoch 90: val_loss did not improve from 0.43029\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1553 - val_loss: 0.4456\n",
      "Epoch 91/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1474\n",
      "Epoch 91: val_loss did not improve from 0.43029\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1470 - val_loss: 0.5308\n",
      "Epoch 92/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1738\n",
      "Epoch 92: val_loss did not improve from 0.43029\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1697 - val_loss: 0.4494\n",
      "Epoch 93/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1464\n",
      "Epoch 93: val_loss did not improve from 0.43029\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1457 - val_loss: 0.4492\n",
      "Epoch 94/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1585\n",
      "Epoch 94: val_loss did not improve from 0.43029\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1578 - val_loss: 0.4542\n",
      "Epoch 95/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1419\n",
      "Epoch 95: val_loss did not improve from 0.43029\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1413 - val_loss: 0.5157\n",
      "Epoch 96/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1499\n",
      "Epoch 96: val_loss did not improve from 0.43029\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1496 - val_loss: 0.4538\n",
      "Epoch 97/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1544\n",
      "Epoch 97: val_loss did not improve from 0.43029\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1551 - val_loss: 0.4434\n",
      "Epoch 98/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1477\n",
      "Epoch 98: val_loss did not improve from 0.43029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1485 - val_loss: 0.4729\n",
      "Epoch 99/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1490\n",
      "Epoch 99: val_loss did not improve from 0.43029\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1484 - val_loss: 0.4757\n",
      "Epoch 100/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1349\n",
      "Epoch 100: val_loss did not improve from 0.43029\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1342 - val_loss: 0.4932\n",
      "\n",
      "Train/Test model on Fold #3.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/24 [=========================>....] - ETA: 0s - loss: 1.3280\n",
      "Epoch 1: val_loss improved from inf to 1.26464, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 2s 34ms/step - loss: 1.3292 - val_loss: 1.2646\n",
      "Epoch 2/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.2447\n",
      "Epoch 2: val_loss improved from 1.26464 to 1.21792, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.2394 - val_loss: 1.2179\n",
      "Epoch 3/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1978\n",
      "Epoch 3: val_loss improved from 1.21792 to 1.17404, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.1900 - val_loss: 1.1740\n",
      "Epoch 4/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1395\n",
      "Epoch 4: val_loss improved from 1.17404 to 1.14274, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.1395 - val_loss: 1.1427\n",
      "Epoch 5/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1079\n",
      "Epoch 5: val_loss improved from 1.14274 to 1.10459, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.1011 - val_loss: 1.1046\n",
      "Epoch 6/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0586\n",
      "Epoch 6: val_loss improved from 1.10459 to 1.07559, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0596 - val_loss: 1.0756\n",
      "Epoch 7/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0186\n",
      "Epoch 7: val_loss improved from 1.07559 to 1.04076, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0188 - val_loss: 1.0408\n",
      "Epoch 8/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.0042\n",
      "Epoch 8: val_loss improved from 1.04076 to 1.02154, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.9938 - val_loss: 1.0215\n",
      "Epoch 9/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.9395\n",
      "Epoch 9: val_loss improved from 1.02154 to 1.01460, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9399 - val_loss: 1.0146\n",
      "Epoch 10/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8740\n",
      "Epoch 10: val_loss improved from 1.01460 to 0.98397, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8743 - val_loss: 0.9840\n",
      "Epoch 11/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8319\n",
      "Epoch 11: val_loss improved from 0.98397 to 0.97565, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8339 - val_loss: 0.9756\n",
      "Epoch 12/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8044\n",
      "Epoch 12: val_loss did not improve from 0.97565\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8036 - val_loss: 1.0026\n",
      "Epoch 13/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.7818\n",
      "Epoch 13: val_loss did not improve from 0.97565\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7853 - val_loss: 1.0059\n",
      "Epoch 14/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.7202\n",
      "Epoch 14: val_loss improved from 0.97565 to 0.95607, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7264 - val_loss: 0.9561\n",
      "Epoch 15/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6778\n",
      "Epoch 15: val_loss did not improve from 0.95607\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6919 - val_loss: 0.9795\n",
      "Epoch 16/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6950\n",
      "Epoch 16: val_loss did not improve from 0.95607\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6877 - val_loss: 0.9969\n",
      "Epoch 17/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6329\n",
      "Epoch 17: val_loss did not improve from 0.95607\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6272 - val_loss: 0.9703\n",
      "Epoch 18/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5810\n",
      "Epoch 18: val_loss improved from 0.95607 to 0.93852, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5852 - val_loss: 0.9385\n",
      "Epoch 19/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5686\n",
      "Epoch 19: val_loss did not improve from 0.93852\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5871 - val_loss: 0.9518\n",
      "Epoch 20/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5691\n",
      "Epoch 20: val_loss did not improve from 0.93852\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5648 - val_loss: 0.9872\n",
      "Epoch 21/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5299\n",
      "Epoch 21: val_loss did not improve from 0.93852\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5292 - val_loss: 0.9647\n",
      "Epoch 22/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.5512\n",
      "Epoch 22: val_loss improved from 0.93852 to 0.92198, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.5554 - val_loss: 0.9220\n",
      "Epoch 23/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4936\n",
      "Epoch 23: val_loss improved from 0.92198 to 0.90443, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4886 - val_loss: 0.9044\n",
      "Epoch 24/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4747\n",
      "Epoch 24: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4720 - val_loss: 0.9253\n",
      "Epoch 25/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4530\n",
      "Epoch 25: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4463 - val_loss: 1.0079\n",
      "Epoch 26/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4558\n",
      "Epoch 26: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4533 - val_loss: 0.9266\n",
      "Epoch 27/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4215\n",
      "Epoch 27: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4373 - val_loss: 0.9981\n",
      "Epoch 28/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4559\n",
      "Epoch 28: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4607 - val_loss: 0.9669\n",
      "Epoch 29/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4240\n",
      "Epoch 29: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4184 - val_loss: 0.9521\n",
      "Epoch 30/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4085\n",
      "Epoch 30: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4119 - val_loss: 0.9485\n",
      "Epoch 31/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3784\n",
      "Epoch 31: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3754 - val_loss: 0.9431\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3717\n",
      "Epoch 32: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3679 - val_loss: 0.9200\n",
      "Epoch 33/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3651\n",
      "Epoch 33: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3636 - val_loss: 0.9586\n",
      "Epoch 34/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3615\n",
      "Epoch 34: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3655 - val_loss: 0.9225\n",
      "Epoch 35/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3350\n",
      "Epoch 35: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3358 - val_loss: 0.9363\n",
      "Epoch 36/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3394\n",
      "Epoch 36: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3355 - val_loss: 1.0320\n",
      "Epoch 37/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3543\n",
      "Epoch 37: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3500 - val_loss: 0.9947\n",
      "Epoch 38/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3472\n",
      "Epoch 38: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3435 - val_loss: 0.9557\n",
      "Epoch 39/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3223\n",
      "Epoch 39: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3219 - val_loss: 0.9186\n",
      "Epoch 40/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3173\n",
      "Epoch 40: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3200 - val_loss: 0.9827\n",
      "Epoch 41/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3151\n",
      "Epoch 41: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3269 - val_loss: 0.9389\n",
      "Epoch 42/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3040\n",
      "Epoch 42: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3027 - val_loss: 0.9136\n",
      "Epoch 43/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2885\n",
      "Epoch 43: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2870 - val_loss: 0.9956\n",
      "Epoch 44/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2804\n",
      "Epoch 44: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2862 - val_loss: 1.0242\n",
      "Epoch 45/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2823\n",
      "Epoch 45: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2819 - val_loss: 1.0047\n",
      "Epoch 46/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2670\n",
      "Epoch 46: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2664 - val_loss: 0.9913\n",
      "Epoch 47/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2733\n",
      "Epoch 47: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2746 - val_loss: 1.1307\n",
      "Epoch 48/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2709\n",
      "Epoch 48: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2695 - val_loss: 0.9564\n",
      "Epoch 49/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2644\n",
      "Epoch 49: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2634 - val_loss: 0.9760\n",
      "Epoch 50/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2692\n",
      "Epoch 50: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2718 - val_loss: 1.0100\n",
      "Epoch 51/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2709\n",
      "Epoch 51: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2691 - val_loss: 1.0374\n",
      "Epoch 52/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2606\n",
      "Epoch 52: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2585 - val_loss: 0.9239\n",
      "Epoch 53/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2497\n",
      "Epoch 53: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2485 - val_loss: 0.9757\n",
      "Epoch 54/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2402\n",
      "Epoch 54: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2398 - val_loss: 0.9304\n",
      "Epoch 55/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2330\n",
      "Epoch 55: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2321 - val_loss: 1.0445\n",
      "Epoch 56/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2480\n",
      "Epoch 56: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2457 - val_loss: 1.0080\n",
      "Epoch 57/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2260\n",
      "Epoch 57: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2251 - val_loss: 0.9922\n",
      "Epoch 58/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2091\n",
      "Epoch 58: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2122 - val_loss: 0.9944\n",
      "Epoch 59/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2183\n",
      "Epoch 59: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2169 - val_loss: 1.0533\n",
      "Epoch 60/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2214\n",
      "Epoch 60: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2197 - val_loss: 0.9529\n",
      "Epoch 61/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2266\n",
      "Epoch 61: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2243 - val_loss: 0.9849\n",
      "Epoch 62/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2162\n",
      "Epoch 62: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2211 - val_loss: 0.9957\n",
      "Epoch 63/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2075\n",
      "Epoch 63: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2060 - val_loss: 0.9607\n",
      "Epoch 64/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2026\n",
      "Epoch 64: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2013 - val_loss: 1.0754\n",
      "Epoch 65/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2141\n",
      "Epoch 65: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2156 - val_loss: 0.9589\n",
      "Epoch 66/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1998\n",
      "Epoch 66: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1984 - val_loss: 0.9984\n",
      "Epoch 67/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1966\n",
      "Epoch 67: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1961 - val_loss: 1.0495\n",
      "Epoch 68/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1877\n",
      "Epoch 68: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1873 - val_loss: 1.0231\n",
      "Epoch 69/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1932\n",
      "Epoch 69: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1938 - val_loss: 1.0327\n",
      "Epoch 70/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1931\n",
      "Epoch 70: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1916 - val_loss: 1.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2013\n",
      "Epoch 71: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2005 - val_loss: 1.0325\n",
      "Epoch 72/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1899\n",
      "Epoch 72: val_loss did not improve from 0.90443\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1893 - val_loss: 0.9684\n",
      "Epoch 73/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1920\n",
      "Epoch 73: val_loss improved from 0.90443 to 0.90310, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold3.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1913 - val_loss: 0.9031\n",
      "Epoch 74/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1907\n",
      "Epoch 74: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1893 - val_loss: 1.0180\n",
      "Epoch 75/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1808\n",
      "Epoch 75: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1799 - val_loss: 0.9522\n",
      "Epoch 76/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1790\n",
      "Epoch 76: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1788 - val_loss: 1.0234\n",
      "Epoch 77/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1945\n",
      "Epoch 77: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1935 - val_loss: 1.0065\n",
      "Epoch 78/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1693\n",
      "Epoch 78: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1683 - val_loss: 1.0086\n",
      "Epoch 79/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1756\n",
      "Epoch 79: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1758 - val_loss: 0.9477\n",
      "Epoch 80/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1789\n",
      "Epoch 80: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1783 - val_loss: 1.0584\n",
      "Epoch 81/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1728\n",
      "Epoch 81: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1714 - val_loss: 0.9550\n",
      "Epoch 82/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1647\n",
      "Epoch 82: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1637 - val_loss: 1.0139\n",
      "Epoch 83/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1607\n",
      "Epoch 83: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1601 - val_loss: 1.0636\n",
      "Epoch 84/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1618\n",
      "Epoch 84: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1618 - val_loss: 1.0412\n",
      "Epoch 85/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1584\n",
      "Epoch 85: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1605 - val_loss: 1.0507\n",
      "Epoch 86/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1617\n",
      "Epoch 86: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1598 - val_loss: 1.0138\n",
      "Epoch 87/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1568\n",
      "Epoch 87: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1594 - val_loss: 0.9820\n",
      "Epoch 88/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1511\n",
      "Epoch 88: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1537 - val_loss: 0.9890\n",
      "Epoch 89/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1610\n",
      "Epoch 89: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1604 - val_loss: 1.0588\n",
      "Epoch 90/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1581\n",
      "Epoch 90: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1582 - val_loss: 0.9413\n",
      "Epoch 91/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1517\n",
      "Epoch 91: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1510 - val_loss: 1.0473\n",
      "Epoch 92/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1439\n",
      "Epoch 92: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1455 - val_loss: 1.0419\n",
      "Epoch 93/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1463\n",
      "Epoch 93: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1475 - val_loss: 1.0598\n",
      "Epoch 94/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1547\n",
      "Epoch 94: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1544 - val_loss: 1.0329\n",
      "Epoch 95/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1463\n",
      "Epoch 95: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1453 - val_loss: 1.0039\n",
      "Epoch 96/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1400\n",
      "Epoch 96: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1403 - val_loss: 0.9646\n",
      "Epoch 97/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1407\n",
      "Epoch 97: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1407 - val_loss: 1.0180\n",
      "Epoch 98/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1545\n",
      "Epoch 98: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1531 - val_loss: 0.9254\n",
      "Epoch 99/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1432\n",
      "Epoch 99: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1430 - val_loss: 0.9756\n",
      "Epoch 100/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1404\n",
      "Epoch 100: val_loss did not improve from 0.90310\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1395 - val_loss: 1.0031\n",
      "\n",
      "Train/Test model on Fold #4.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/24 [=========================>....] - ETA: 0s - loss: 1.3134\n",
      "Epoch 1: val_loss improved from inf to 1.25792, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 2s 33ms/step - loss: 1.3104 - val_loss: 1.2579\n",
      "Epoch 2/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 1.2447\n",
      "Epoch 2: val_loss improved from 1.25792 to 1.20627, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.2475 - val_loss: 1.2063\n",
      "Epoch 3/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1776\n",
      "Epoch 3: val_loss improved from 1.20627 to 1.15740, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.1795 - val_loss: 1.1574\n",
      "Epoch 4/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.1525\n",
      "Epoch 4: val_loss improved from 1.15740 to 1.10342, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.1490 - val_loss: 1.1034\n",
      "Epoch 5/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0949\n",
      "Epoch 5: val_loss improved from 1.10342 to 1.07366, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.1080 - val_loss: 1.0737\n",
      "Epoch 6/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0796\n",
      "Epoch 6: val_loss improved from 1.07366 to 1.02735, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0763 - val_loss: 1.0273\n",
      "Epoch 7/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.0285\n",
      "Epoch 7: val_loss improved from 1.02735 to 0.99218, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0192 - val_loss: 0.9922\n",
      "Epoch 8/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.9986\n",
      "Epoch 8: val_loss improved from 0.99218 to 0.96947, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.9986 - val_loss: 0.9695\n",
      "Epoch 9/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.9680\n",
      "Epoch 9: val_loss improved from 0.96947 to 0.93951, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.9643 - val_loss: 0.9395\n",
      "Epoch 10/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.9214\n",
      "Epoch 10: val_loss did not improve from 0.93951\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.9218 - val_loss: 0.9560\n",
      "Epoch 11/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8936\n",
      "Epoch 11: val_loss improved from 0.93951 to 0.83960, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8859 - val_loss: 0.8396\n",
      "Epoch 12/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8415\n",
      "Epoch 12: val_loss improved from 0.83960 to 0.78819, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8564 - val_loss: 0.7882\n",
      "Epoch 13/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.8019\n",
      "Epoch 13: val_loss improved from 0.78819 to 0.74969, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7945 - val_loss: 0.7497\n",
      "Epoch 14/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.7892\n",
      "Epoch 14: val_loss improved from 0.74969 to 0.71302, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7834 - val_loss: 0.7130\n",
      "Epoch 15/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.7106\n",
      "Epoch 15: val_loss improved from 0.71302 to 0.70764, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7097 - val_loss: 0.7076\n",
      "Epoch 16/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.6888\n",
      "Epoch 16: val_loss improved from 0.70764 to 0.68033, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6842 - val_loss: 0.6803\n",
      "Epoch 17/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6633\n",
      "Epoch 17: val_loss improved from 0.68033 to 0.62195, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6672 - val_loss: 0.6220\n",
      "Epoch 18/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6212\n",
      "Epoch 18: val_loss improved from 0.62195 to 0.60570, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6147 - val_loss: 0.6057\n",
      "Epoch 19/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.6314\n",
      "Epoch 19: val_loss did not improve from 0.60570\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6306 - val_loss: 0.6521\n",
      "Epoch 20/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5936\n",
      "Epoch 20: val_loss improved from 0.60570 to 0.59533, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5902 - val_loss: 0.5953\n",
      "Epoch 21/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5493\n",
      "Epoch 21: val_loss improved from 0.59533 to 0.55892, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5511 - val_loss: 0.5589\n",
      "Epoch 22/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5294\n",
      "Epoch 22: val_loss did not improve from 0.55892\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5376 - val_loss: 0.5605\n",
      "Epoch 23/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.5033\n",
      "Epoch 23: val_loss did not improve from 0.55892\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5000 - val_loss: 0.6557\n",
      "Epoch 24/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.5364\n",
      "Epoch 24: val_loss did not improve from 0.55892\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5392 - val_loss: 0.6150\n",
      "Epoch 25/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.4762\n",
      "Epoch 25: val_loss improved from 0.55892 to 0.51963, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4870 - val_loss: 0.5196\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4715\n",
      "Epoch 26: val_loss improved from 0.51963 to 0.50290, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4715 - val_loss: 0.5029\n",
      "Epoch 27/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4532\n",
      "Epoch 27: val_loss did not improve from 0.50290\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4520 - val_loss: 0.5083\n",
      "Epoch 28/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4267\n",
      "Epoch 28: val_loss improved from 0.50290 to 0.47833, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4234 - val_loss: 0.4783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4277\n",
      "Epoch 29: val_loss did not improve from 0.47833\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4314 - val_loss: 0.5263\n",
      "Epoch 30/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3908\n",
      "Epoch 30: val_loss did not improve from 0.47833\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3924 - val_loss: 0.4793\n",
      "Epoch 31/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3995\n",
      "Epoch 31: val_loss improved from 0.47833 to 0.45652, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4110 - val_loss: 0.4565\n",
      "Epoch 32/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3756\n",
      "Epoch 32: val_loss did not improve from 0.45652\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3768 - val_loss: 0.4581\n",
      "Epoch 33/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.3706\n",
      "Epoch 33: val_loss improved from 0.45652 to 0.44119, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3677 - val_loss: 0.4412\n",
      "Epoch 34/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3786\n",
      "Epoch 34: val_loss improved from 0.44119 to 0.42325, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3809 - val_loss: 0.4233\n",
      "Epoch 35/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3397\n",
      "Epoch 35: val_loss did not improve from 0.42325\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3401 - val_loss: 0.4997\n",
      "Epoch 36/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3463\n",
      "Epoch 36: val_loss improved from 0.42325 to 0.41782, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.3478 - val_loss: 0.4178\n",
      "Epoch 37/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3593\n",
      "Epoch 37: val_loss did not improve from 0.41782\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3553 - val_loss: 0.4224\n",
      "Epoch 38/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3422\n",
      "Epoch 38: val_loss did not improve from 0.41782\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3423 - val_loss: 0.4548\n",
      "Epoch 39/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3584\n",
      "Epoch 39: val_loss did not improve from 0.41782\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3534 - val_loss: 0.4623\n",
      "Epoch 40/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3217\n",
      "Epoch 40: val_loss improved from 0.41782 to 0.37711, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3272 - val_loss: 0.3771\n",
      "Epoch 41/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3113\n",
      "Epoch 41: val_loss did not improve from 0.37711\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3098 - val_loss: 0.4493\n",
      "Epoch 42/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3204\n",
      "Epoch 42: val_loss did not improve from 0.37711\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3186 - val_loss: 0.3873\n",
      "Epoch 43/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2796\n",
      "Epoch 43: val_loss did not improve from 0.37711\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2887 - val_loss: 0.4078\n",
      "Epoch 44/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2901\n",
      "Epoch 44: val_loss did not improve from 0.37711\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2876 - val_loss: 0.4085\n",
      "Epoch 45/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2818\n",
      "Epoch 45: val_loss did not improve from 0.37711\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2819 - val_loss: 0.3777\n",
      "Epoch 46/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2942\n",
      "Epoch 46: val_loss did not improve from 0.37711\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2939 - val_loss: 0.4114\n",
      "Epoch 47/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2888\n",
      "Epoch 47: val_loss did not improve from 0.37711\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2875 - val_loss: 0.3835\n",
      "Epoch 48/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2678\n",
      "Epoch 48: val_loss did not improve from 0.37711\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2852 - val_loss: 0.3819\n",
      "Epoch 49/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3045\n",
      "Epoch 49: val_loss improved from 0.37711 to 0.34906, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3000 - val_loss: 0.3491\n",
      "Epoch 50/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2698\n",
      "Epoch 50: val_loss did not improve from 0.34906\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2730 - val_loss: 0.4162\n",
      "Epoch 51/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2692\n",
      "Epoch 51: val_loss did not improve from 0.34906\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2683 - val_loss: 0.4083\n",
      "Epoch 52/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2521\n",
      "Epoch 52: val_loss did not improve from 0.34906\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2593 - val_loss: 0.4137\n",
      "Epoch 53/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2861\n",
      "Epoch 53: val_loss did not improve from 0.34906\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2820 - val_loss: 0.3962\n",
      "Epoch 54/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2450\n",
      "Epoch 54: val_loss did not improve from 0.34906\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2423 - val_loss: 0.3613\n",
      "Epoch 55/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2457\n",
      "Epoch 55: val_loss did not improve from 0.34906\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2455 - val_loss: 0.3737\n",
      "Epoch 56/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2466\n",
      "Epoch 56: val_loss did not improve from 0.34906\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2447 - val_loss: 0.3707\n",
      "Epoch 57/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2366\n",
      "Epoch 57: val_loss did not improve from 0.34906\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2358 - val_loss: 0.3886\n",
      "Epoch 58/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2315\n",
      "Epoch 58: val_loss improved from 0.34906 to 0.34182, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2289 - val_loss: 0.3418\n",
      "Epoch 59/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2170\n",
      "Epoch 59: val_loss did not improve from 0.34182\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2223 - val_loss: 0.3924\n",
      "Epoch 60/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2199\n",
      "Epoch 60: val_loss did not improve from 0.34182\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2183 - val_loss: 0.4072\n",
      "Epoch 61/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2476\n",
      "Epoch 61: val_loss did not improve from 0.34182\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2444 - val_loss: 0.3670\n",
      "Epoch 62/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2192\n",
      "Epoch 62: val_loss did not improve from 0.34182\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2184 - val_loss: 0.3550\n",
      "Epoch 63/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2334\n",
      "Epoch 63: val_loss improved from 0.34182 to 0.34097, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2341 - val_loss: 0.3410\n",
      "Epoch 64/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2085\n",
      "Epoch 64: val_loss did not improve from 0.34097\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2116 - val_loss: 0.3670\n",
      "Epoch 65/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2116\n",
      "Epoch 65: val_loss improved from 0.34097 to 0.33974, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.2106 - val_loss: 0.3397\n",
      "Epoch 66/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2026\n",
      "Epoch 66: val_loss improved from 0.33974 to 0.32761, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.2023 - val_loss: 0.3276\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1980\n",
      "Epoch 67: val_loss improved from 0.32761 to 0.32334, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1980 - val_loss: 0.3233\n",
      "Epoch 68/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2291\n",
      "Epoch 68: val_loss did not improve from 0.32334\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2256 - val_loss: 0.3468\n",
      "Epoch 69/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2103\n",
      "Epoch 69: val_loss did not improve from 0.32334\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2106 - val_loss: 0.3943\n",
      "Epoch 70/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2000\n",
      "Epoch 70: val_loss did not improve from 0.32334\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1989 - val_loss: 0.3347\n",
      "Epoch 71/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1831\n",
      "Epoch 71: val_loss did not improve from 0.32334\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1850 - val_loss: 0.3567\n",
      "Epoch 72/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1882\n",
      "Epoch 72: val_loss improved from 0.32334 to 0.31671, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1877 - val_loss: 0.3167\n",
      "Epoch 73/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1904\n",
      "Epoch 73: val_loss improved from 0.31671 to 0.30700, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1888 - val_loss: 0.3070\n",
      "Epoch 74/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2002\n",
      "Epoch 74: val_loss did not improve from 0.30700\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1992 - val_loss: 0.3356\n",
      "Epoch 75/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1795\n",
      "Epoch 75: val_loss did not improve from 0.30700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1791 - val_loss: 0.3281\n",
      "Epoch 76/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1834\n",
      "Epoch 76: val_loss did not improve from 0.30700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1845 - val_loss: 0.3557\n",
      "Epoch 77/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1708\n",
      "Epoch 77: val_loss did not improve from 0.30700\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1713 - val_loss: 0.3213\n",
      "Epoch 78/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1755\n",
      "Epoch 78: val_loss improved from 0.30700 to 0.30386, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1754 - val_loss: 0.3039\n",
      "Epoch 79/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1802\n",
      "Epoch 79: val_loss improved from 0.30386 to 0.29643, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1793 - val_loss: 0.2964\n",
      "Epoch 80/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1852\n",
      "Epoch 80: val_loss did not improve from 0.29643\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1861 - val_loss: 0.3806\n",
      "Epoch 81/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1855\n",
      "Epoch 81: val_loss did not improve from 0.29643\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1871 - val_loss: 0.3178\n",
      "Epoch 82/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1674\n",
      "Epoch 82: val_loss did not improve from 0.29643\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1722 - val_loss: 0.3092\n",
      "Epoch 83/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1619\n",
      "Epoch 83: val_loss did not improve from 0.29643\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1618 - val_loss: 0.3337\n",
      "Epoch 84/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1645\n",
      "Epoch 84: val_loss did not improve from 0.29643\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1634 - val_loss: 0.2991\n",
      "Epoch 85/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1634\n",
      "Epoch 85: val_loss did not improve from 0.29643\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1632 - val_loss: 0.3281\n",
      "Epoch 86/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1638\n",
      "Epoch 86: val_loss did not improve from 0.29643\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1640 - val_loss: 0.3013\n",
      "Epoch 87/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1665\n",
      "Epoch 87: val_loss did not improve from 0.29643\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1653 - val_loss: 0.3051\n",
      "Epoch 88/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1643\n",
      "Epoch 88: val_loss did not improve from 0.29643\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1635 - val_loss: 0.3501\n",
      "Epoch 89/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1626\n",
      "Epoch 89: val_loss improved from 0.29643 to 0.28597, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1618 - val_loss: 0.2860\n",
      "Epoch 90/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1679\n",
      "Epoch 90: val_loss did not improve from 0.28597\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1662 - val_loss: 0.2955\n",
      "Epoch 91/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1611\n",
      "Epoch 91: val_loss improved from 0.28597 to 0.27482, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1601 - val_loss: 0.2748\n",
      "Epoch 92/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1619\n",
      "Epoch 92: val_loss did not improve from 0.27482\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1624 - val_loss: 0.3688\n",
      "Epoch 93/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1531\n",
      "Epoch 93: val_loss improved from 0.27482 to 0.27193, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1531 - val_loss: 0.2719\n",
      "Epoch 94/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1492\n",
      "Epoch 94: val_loss did not improve from 0.27193\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1490 - val_loss: 0.2830\n",
      "Epoch 95/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1497\n",
      "Epoch 95: val_loss did not improve from 0.27193\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1497 - val_loss: 0.2819\n",
      "Epoch 96/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1681\n",
      "Epoch 96: val_loss did not improve from 0.27193\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1682 - val_loss: 0.3403\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1539\n",
      "Epoch 97: val_loss improved from 0.27193 to 0.25635, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\bestModel-fold4.hdf5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1527 - val_loss: 0.2564\n",
      "Epoch 98/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1485\n",
      "Epoch 98: val_loss did not improve from 0.25635\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1473 - val_loss: 0.3285\n",
      "Epoch 99/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1413\n",
      "Epoch 99: val_loss did not improve from 0.25635\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1408 - val_loss: 0.3160\n",
      "Epoch 100/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.1444\n",
      "Epoch 100: val_loss did not improve from 0.25635\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1441 - val_loss: 0.3274\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Train/Test model on all folds, generate evaluations\n",
    "##################################################################################\n",
    "\n",
    "## Create and set directory to save model\n",
    "modelPath = os.path.join(outPath, expName, \"{}fold\".format(n_fold), \"models\")\n",
    "if(not os.path.isdir(modelPath)):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "i = -1\n",
    "for fold in folds:\n",
    "    i += 1\n",
    "    \n",
    "    print(\"\\nTrain/Test model on Fold #\"+str(i)+\".\")\n",
    "    \n",
    "    model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "    ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    modelCallbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                           monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                           save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "    ]\n",
    "    \n",
    "    # adding random shuffling of the dataset for training purpose\n",
    "    index_arr = np.arange(fold[\"X_train\"].shape[0])\n",
    "    index_arr = np.random.permutation(index_arr)\n",
    "    \n",
    "    model.fit(x = fold[\"X_train\"][index_arr], y = fold[\"y_train\"][index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "              callbacks = modelCallbacks, validation_data = (fold[\"X_test\"], fold[\"y_test\"]))\n",
    "    \n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TRAIN dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_train\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Train\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ##### Prediction and metrics for TEST dataset\n",
    "    ##################################################################################\n",
    "\n",
    "    y_pred = model.predict(fold[\"X_test\"])\n",
    "    label_pred = pred2label(y_pred)\n",
    "    \n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "    prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "    conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "    auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "    \n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Test\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.927816</td>\n",
       "      <td>0.891339</td>\n",
       "      <td>0.889294</td>\n",
       "      <td>0.938522</td>\n",
       "      <td>0.891339</td>\n",
       "      <td>0.79906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Precision       AUC  Sensitivity  Specificity      MCC\n",
       "Train_Test                                                                  \n",
       "Test        0.927816   0.891339  0.889294     0.938522     0.891339  0.79906\n",
       "Train       1.000000   1.000000  1.000000     1.000000     1.000000  1.00000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 64\n",
    "# \tAccuracy\tPrecision\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# Train_Test\t\t\t\t\t\t\n",
    "# Test\t0.962275\t0.964691\t0.968595\t0.961289\t0.964691\t0.921092\n",
    "# Train\t0.998285\t0.995658\t0.999909\t1.000000\t0.995658\t0.996416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 32\n",
    "# Accuracy\tPrecision\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# Train_Test\t\t\t\t\t\t\n",
    "# Test\t0.953655\t0.947710\t0.957286\t0.958667\t0.947710\t0.903487\n",
    "# Train\t0.998284\t0.995658\t0.999985\t1.000000\t0.995658\t0.996415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 16\n",
    "# \tAccuracy\tPrecision\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# Train_Test\t\t\t\t\t\t\n",
    "# Test\t0.957029\t0.955322\t0.972796\t0.958206\t0.955322\t0.909738\n",
    "# Train\t0.998285\t0.995658\t0.999977\t1.000000\t0.995658\t0.996416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.926316</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>[0.0, 0.041666666666666664, 0.4583333333333333...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.014084507042253521, 0.014084...</td>\n",
       "      <td>[1.9994674, 0.9994673, 0.9968348, 0.99101806, ...</td>\n",
       "      <td>0.872066</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.799497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>[0.0, 0.043478260869565216, 0.8695652173913043...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.014084507042253521, 0.014084...</td>\n",
       "      <td>[1.9974787, 0.99747866, 0.92067057, 0.88028693...</td>\n",
       "      <td>0.993876</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.884874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>[0.0, 0.043478260869565216, 0.6956521739130435...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.014084507042253521, 0.014084...</td>\n",
       "      <td>[1.9995296, 0.9995296, 0.9187731, 0.6772609, 0...</td>\n",
       "      <td>0.926516</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.792165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>[0.0, 0.043478260869565216, 0.6086956521739131...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.2676056338028169, 0.26760563...</td>\n",
       "      <td>[1.9992847, 0.9992848, 0.91563433, 0.03892002,...</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.603490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>[0.0, 0.043478260869565216, 0.9565217391304348...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.5492957746478874, 0.54929577...</td>\n",
       "      <td>[1.997889, 0.9978891, 0.774578, 0.0012208459, ...</td>\n",
       "      <td>0.976118</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.915275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Train_Test  Accuracy  Precision  \\\n",
       "1     0       Test  0.926316   0.904762   \n",
       "3     1       Test  0.957447   0.913043   \n",
       "5     2       Test  0.925532   0.944444   \n",
       "7     3       Test  0.861702   0.777778   \n",
       "9     4       Test  0.968085   0.916667   \n",
       "\n",
       "                                                 TPR  \\\n",
       "1  [0.0, 0.041666666666666664, 0.4583333333333333...   \n",
       "3  [0.0, 0.043478260869565216, 0.8695652173913043...   \n",
       "5  [0.0, 0.043478260869565216, 0.6956521739130435...   \n",
       "7  [0.0, 0.043478260869565216, 0.6086956521739131...   \n",
       "9  [0.0, 0.043478260869565216, 0.9565217391304348...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "1  [0.0, 0.0, 0.0, 0.014084507042253521, 0.014084...   \n",
       "3  [0.0, 0.0, 0.0, 0.014084507042253521, 0.014084...   \n",
       "5  [0.0, 0.0, 0.0, 0.014084507042253521, 0.014084...   \n",
       "7  [0.0, 0.0, 0.0, 0.2676056338028169, 0.26760563...   \n",
       "9  [0.0, 0.0, 0.0, 0.5492957746478874, 0.54929577...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "1  [1.9994674, 0.9994673, 0.9968348, 0.99101806, ...  0.872066     0.932432   \n",
       "3  [1.9974787, 0.99747866, 0.92067057, 0.88028693...  0.993876     0.971831   \n",
       "5  [1.9995296, 0.9995296, 0.9187731, 0.6772609, 0...  0.926516     0.921053   \n",
       "7  [1.9992847, 0.9992848, 0.91563433, 0.03892002,...  0.677893     0.881579   \n",
       "9  [1.997889, 0.9978891, 0.774578, 0.0012208459, ...  0.976118     0.985714   \n",
       "\n",
       "   Specificity       MCC  \n",
       "1     0.904762  0.799497  \n",
       "3     0.913043  0.884874  \n",
       "5     0.944444  0.792165  \n",
       "7     0.777778  0.603490  \n",
       "9     0.916667  0.915275  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df[evaluations_df[\"Train_Test\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using k-fold Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of each k-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.912871</td>\n",
       "      <td>0.924495</td>\n",
       "      <td>0.862553</td>\n",
       "      <td>0.912884</td>\n",
       "      <td>0.924495</td>\n",
       "      <td>0.761365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.912871   0.924495  0.862553     0.912884     0.924495  0.761365"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    label_pred = pred2label(y_pred)\n",
    "\n",
    "    # Compute precision, recall, sensitivity, specifity, mcc\n",
    "    acc = accuracy_score(indpe_labels, label_pred)\n",
    "    prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "    conf = confusion_matrix(indpe_labels, label_pred)\n",
    "    if(conf[0][0]+conf[1][0]):\n",
    "        sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "    else:\n",
    "        sens = 0.0\n",
    "    if(conf[1][1]+conf[0][1]):\n",
    "        spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "    else:\n",
    "        spec = 0.0\n",
    "    if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "        mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "    else:\n",
    "        mcc= 0.0\n",
    "    fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "    auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "    evaluations[\"Fold\"].append(i)\n",
    "    evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "    evaluations[\"Accuracy\"].append(acc)\n",
    "    evaluations[\"Precision\"].append(prec)\n",
    "    evaluations[\"TPR\"].append(tpr)\n",
    "    evaluations[\"FPR\"].append(fpr)\n",
    "    evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "    evaluations[\"AUC\"].append(auc)\n",
    "    evaluations[\"Sensitivity\"].append(sens)\n",
    "    evaluations[\"Specificity\"].append(spec)\n",
    "    evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR_FPR_Thresholds</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.915842</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>[0.0, 0.02, 0.68, 0.68, 0.7, 0.7, 0.74, 0.74, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...</td>\n",
       "      <td>[1.9996885, 0.9996885, 0.8709528, 0.75188875, ...</td>\n",
       "      <td>0.869474</td>\n",
       "      <td>0.904192</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.767894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.925743</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.02, 0.7, 0.7, 0.72, 0.72, 0.74, 0.74, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.039473684210526314, 0.039473...</td>\n",
       "      <td>[1.999047, 0.999047, 0.6875863, 0.16631983, 0....</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.910180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.798202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.915842</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>[0.0, 0.02, 0.66, 0.66, 0.72, 0.72, 0.74, 0.74...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.013157894736842105, 0.013157...</td>\n",
       "      <td>[1.9992348, 0.9992348, 0.8868928, 0.7917781, 0...</td>\n",
       "      <td>0.857368</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.766339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>[0.0, 0.02, 0.74, 0.74, 0.76, 0.76, 0.78, 0.78...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.14473684210526316, 0.1447368...</td>\n",
       "      <td>[1.9998719, 0.99987185, 0.9158982, 0.27986592,...</td>\n",
       "      <td>0.851579</td>\n",
       "      <td>0.915033</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.665578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0.930693</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>[0.0, 0.04, 0.74, 0.74, 0.76, 0.76, 0.78, 0.78...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...</td>\n",
       "      <td>[1.9992347, 0.9992347, 0.70704263, 0.66808397,...</td>\n",
       "      <td>0.861842</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.808813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold   Train_Test  Accuracy  Precision  \\\n",
       "0     0  Independent  0.915842   0.971429   \n",
       "1     1  Independent  0.925743   1.000000   \n",
       "2     2  Independent  0.915842   0.945946   \n",
       "3     3  Independent  0.876238   0.755102   \n",
       "4     4  Independent  0.930693   0.950000   \n",
       "\n",
       "                                                 TPR  \\\n",
       "0  [0.0, 0.02, 0.68, 0.68, 0.7, 0.7, 0.74, 0.74, ...   \n",
       "1  [0.0, 0.02, 0.7, 0.7, 0.72, 0.72, 0.74, 0.74, ...   \n",
       "2  [0.0, 0.02, 0.66, 0.66, 0.72, 0.72, 0.74, 0.74...   \n",
       "3  [0.0, 0.02, 0.74, 0.74, 0.76, 0.76, 0.78, 0.78...   \n",
       "4  [0.0, 0.04, 0.74, 0.74, 0.76, 0.76, 0.78, 0.78...   \n",
       "\n",
       "                                                 FPR  \\\n",
       "0  [0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...   \n",
       "1  [0.0, 0.0, 0.0, 0.039473684210526314, 0.039473...   \n",
       "2  [0.0, 0.0, 0.0, 0.013157894736842105, 0.013157...   \n",
       "3  [0.0, 0.0, 0.0, 0.14473684210526316, 0.1447368...   \n",
       "4  [0.0, 0.0, 0.0, 0.006578947368421052, 0.006578...   \n",
       "\n",
       "                                  TPR_FPR_Thresholds       AUC  Sensitivity  \\\n",
       "0  [1.9996885, 0.9996885, 0.8709528, 0.75188875, ...  0.869474     0.904192   \n",
       "1  [1.999047, 0.999047, 0.6875863, 0.16631983, 0....  0.872500     0.910180   \n",
       "2  [1.9992348, 0.9992348, 0.8868928, 0.7917781, 0...  0.857368     0.909091   \n",
       "3  [1.9998719, 0.99987185, 0.9158982, 0.27986592,...  0.851579     0.915033   \n",
       "4  [1.9992347, 0.9992347, 0.70704263, 0.66808397,...  0.861842     0.925926   \n",
       "\n",
       "   Specificity       MCC  \n",
       "0     0.971429  0.767894  \n",
       "1     1.000000  0.798202  \n",
       "2     0.945946  0.766339  \n",
       "3     0.755102  0.665578  \n",
       "4     0.950000  0.808813  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.935644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.876316</td>\n",
       "      <td>0.921212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.825649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.935644        1.0  0.876316     0.921212          1.0  0.825649"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    total_pred += y_pred\n",
    "    all_preds.append(y_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "if(conf[0][0]+conf[1][0]):\n",
    "    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "else:\n",
    "    sens = 0.0\n",
    "if(conf[1][1]+conf[0][1]):\n",
    "    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "else:\n",
    "    spec = 0.0\n",
    "if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "else:\n",
    "    mcc= 0.0\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting score with k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.930693</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.889079</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.809928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.930693   0.973684  0.889079     0.920732     0.973684  0.809928"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "total_pred = np.zeros(indpe_labels.shape)\n",
    "all_preds = []\n",
    "\n",
    "for i in range(n_fold):\n",
    "    \n",
    "    current_model_path = os.path.join(modelPath, \"bestModel-fold{}.hdf5\".format(i))\n",
    "    model = tf.keras.models.load_model(current_model_path)\n",
    "\n",
    "    y_pred = model.predict(indpe_features)\n",
    "    vote_pred = pred2label(y_pred)\n",
    "    total_pred += vote_pred\n",
    "    all_preds.append(vote_pred)\n",
    "    \n",
    "total_pred = total_pred / n_fold\n",
    "label_pred = pred2label(total_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "if(conf[0][0]+conf[1][0]):\n",
    "    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "else:\n",
    "    sens = 0.0\n",
    "if(conf[1][1]+conf[0][1]):\n",
    "    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "else:\n",
    "    spec = 0.0\n",
    "if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "else:\n",
    "    mcc= 0.0\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, total_pred)\n",
    "auc = roc_auc_score(indpe_labels, total_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using New Model\n",
    "\n",
    "Train one model on full data from training. Predict and evaluate on Independent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2_8_py_3_10\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - ETA: 0s - loss: 1.2818\n",
      "Epoch 1: val_loss improved from inf to 1.23890, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 2s 32ms/step - loss: 1.2818 - val_loss: 1.2389\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.2253\n",
      "Epoch 2: val_loss improved from 1.23890 to 1.18821, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.2253 - val_loss: 1.1882\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.1613\n",
      "Epoch 3: val_loss improved from 1.18821 to 1.12475, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1613 - val_loss: 1.1248\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.1086\n",
      "Epoch 4: val_loss improved from 1.12475 to 1.07983, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1086 - val_loss: 1.0798\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.0553\n",
      "Epoch 5: val_loss improved from 1.07983 to 1.02851, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0553 - val_loss: 1.0285\n",
      "Epoch 6/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.0023\n",
      "Epoch 6: val_loss improved from 1.02851 to 0.98422, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.0077 - val_loss: 0.9842\n",
      "Epoch 7/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.9576\n",
      "Epoch 7: val_loss improved from 0.98422 to 0.95209, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9604 - val_loss: 0.9521\n",
      "Epoch 8/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.9204\n",
      "Epoch 8: val_loss improved from 0.95209 to 0.91502, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.9227 - val_loss: 0.9150\n",
      "Epoch 9/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8717\n",
      "Epoch 9: val_loss improved from 0.91502 to 0.87866, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.8719 - val_loss: 0.8787\n",
      "Epoch 10/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8425\n",
      "Epoch 10: val_loss did not improve from 0.87866\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.8426 - val_loss: 0.8898\n",
      "Epoch 11/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.8050\n",
      "Epoch 11: val_loss improved from 0.87866 to 0.82165, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.8118 - val_loss: 0.8217\n",
      "Epoch 12/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7512\n",
      "Epoch 12: val_loss improved from 0.82165 to 0.79353, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7497 - val_loss: 0.7935\n",
      "Epoch 13/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7352\n",
      "Epoch 13: val_loss improved from 0.79353 to 0.76492, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.7358 - val_loss: 0.7649\n",
      "Epoch 14/100\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.6827\n",
      "Epoch 14: val_loss did not improve from 0.76492\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6859 - val_loss: 0.7790\n",
      "Epoch 15/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6412\n",
      "Epoch 15: val_loss improved from 0.76492 to 0.72610, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.6425 - val_loss: 0.7261\n",
      "Epoch 16/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6241\n",
      "Epoch 16: val_loss improved from 0.72610 to 0.70650, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6220 - val_loss: 0.7065\n",
      "Epoch 17/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5762\n",
      "Epoch 17: val_loss improved from 0.70650 to 0.68729, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5805 - val_loss: 0.6873\n",
      "Epoch 18/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5644\n",
      "Epoch 18: val_loss improved from 0.68729 to 0.66484, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5620 - val_loss: 0.6648\n",
      "Epoch 19/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5404\n",
      "Epoch 19: val_loss improved from 0.66484 to 0.65814, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5393 - val_loss: 0.6581\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5456\n",
      "Epoch 20: val_loss did not improve from 0.65814\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5456 - val_loss: 0.6842\n",
      "Epoch 21/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5126\n",
      "Epoch 21: val_loss improved from 0.65814 to 0.64094, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5251 - val_loss: 0.6409\n",
      "Epoch 22/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5028\n",
      "Epoch 22: val_loss improved from 0.64094 to 0.62670, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5035 - val_loss: 0.6267\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4709\n",
      "Epoch 23: val_loss improved from 0.62670 to 0.62288, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4709 - val_loss: 0.6229\n",
      "Epoch 24/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4614\n",
      "Epoch 24: val_loss improved from 0.62288 to 0.61867, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4606 - val_loss: 0.6187\n",
      "Epoch 25/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4379\n",
      "Epoch 25: val_loss improved from 0.61867 to 0.60289, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4367 - val_loss: 0.6029\n",
      "Epoch 26/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4156\n",
      "Epoch 26: val_loss improved from 0.60289 to 0.59498, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4137 - val_loss: 0.5950\n",
      "Epoch 27/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4233\n",
      "Epoch 27: val_loss did not improve from 0.59498\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4218 - val_loss: 0.6202\n",
      "Epoch 28/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4148\n",
      "Epoch 28: val_loss improved from 0.59498 to 0.58305, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4136 - val_loss: 0.5830\n",
      "Epoch 29/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3861\n",
      "Epoch 29: val_loss improved from 0.58305 to 0.57925, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3957 - val_loss: 0.5793\n",
      "Epoch 30/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3748\n",
      "Epoch 30: val_loss improved from 0.57925 to 0.55587, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3722 - val_loss: 0.5559\n",
      "Epoch 31/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.3821\n",
      "Epoch 31: val_loss did not improve from 0.55587\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3775 - val_loss: 0.5834\n",
      "Epoch 32/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3297\n",
      "Epoch 32: val_loss did not improve from 0.55587\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3297 - val_loss: 0.5721\n",
      "Epoch 33/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3403\n",
      "Epoch 33: val_loss did not improve from 0.55587\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3396 - val_loss: 0.6232\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3428\n",
      "Epoch 34: val_loss did not improve from 0.55587\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3428 - val_loss: 0.5828\n",
      "Epoch 35/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3097\n",
      "Epoch 35: val_loss improved from 0.55587 to 0.54995, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3087 - val_loss: 0.5499\n",
      "Epoch 36/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3241\n",
      "Epoch 36: val_loss improved from 0.54995 to 0.54943, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3228 - val_loss: 0.5494\n",
      "Epoch 37/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3118\n",
      "Epoch 37: val_loss did not improve from 0.54943\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3107 - val_loss: 0.6058\n",
      "Epoch 38/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3320\n",
      "Epoch 38: val_loss improved from 0.54943 to 0.53246, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3314 - val_loss: 0.5325\n",
      "Epoch 39/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3020\n",
      "Epoch 39: val_loss improved from 0.53246 to 0.52931, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3012 - val_loss: 0.5293\n",
      "Epoch 40/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2894\n",
      "Epoch 40: val_loss did not improve from 0.52931\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2886 - val_loss: 0.5590\n",
      "Epoch 41/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2652\n",
      "Epoch 41: val_loss did not improve from 0.52931\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2646 - val_loss: 0.5633\n",
      "Epoch 42/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2715\n",
      "Epoch 42: val_loss did not improve from 0.52931\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2711 - val_loss: 0.5533\n",
      "Epoch 43/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2750\n",
      "Epoch 43: val_loss did not improve from 0.52931\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2741 - val_loss: 0.5704\n",
      "Epoch 44/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2628\n",
      "Epoch 44: val_loss did not improve from 0.52931\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2628 - val_loss: 0.5456\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2620\n",
      "Epoch 45: val_loss did not improve from 0.52931\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2620 - val_loss: 0.5686\n",
      "Epoch 46/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2565\n",
      "Epoch 46: val_loss did not improve from 0.52931\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2558 - val_loss: 0.5401\n",
      "Epoch 47/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2426\n",
      "Epoch 47: val_loss did not improve from 0.52931\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2426 - val_loss: 0.5451\n",
      "Epoch 48/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2486\n",
      "Epoch 48: val_loss improved from 0.52931 to 0.51647, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2482 - val_loss: 0.5165\n",
      "Epoch 49/100\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.2210\n",
      "Epoch 49: val_loss did not improve from 0.51647\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2209 - val_loss: 0.5473\n",
      "Epoch 50/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2623\n",
      "Epoch 50: val_loss did not improve from 0.51647\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2612 - val_loss: 0.5263\n",
      "Epoch 51/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2408\n",
      "Epoch 51: val_loss improved from 0.51647 to 0.50050, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2400 - val_loss: 0.5005\n",
      "Epoch 52/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2386\n",
      "Epoch 52: val_loss improved from 0.50050 to 0.49236, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2378 - val_loss: 0.4924\n",
      "Epoch 53/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2195\n",
      "Epoch 53: val_loss did not improve from 0.49236\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2189 - val_loss: 0.5087\n",
      "Epoch 54/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2174\n",
      "Epoch 54: val_loss did not improve from 0.49236\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2170 - val_loss: 0.5179\n",
      "Epoch 55/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2408\n",
      "Epoch 55: val_loss improved from 0.49236 to 0.48572, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2398 - val_loss: 0.4857\n",
      "Epoch 56/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2319\n",
      "Epoch 56: val_loss improved from 0.48572 to 0.47946, saving model to Results\\NT_Site_iNitroY_Classification_DLNN_CORENup\\5fold\\models\\_fullModel.hdf5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2312 - val_loss: 0.4795\n",
      "Epoch 57/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2031\n",
      "Epoch 57: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2028 - val_loss: 0.5110\n",
      "Epoch 58/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2093\n",
      "Epoch 58: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2109 - val_loss: 0.5159\n",
      "Epoch 59/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2077\n",
      "Epoch 59: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2074 - val_loss: 0.5431\n",
      "Epoch 60/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2048\n",
      "Epoch 60: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2042 - val_loss: 0.5246\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2034\n",
      "Epoch 61: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2034 - val_loss: 0.5096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.1885\n",
      "Epoch 62: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1892 - val_loss: 0.5427\n",
      "Epoch 63/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1842\n",
      "Epoch 63: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1841 - val_loss: 0.5538\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1894\n",
      "Epoch 64: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1894 - val_loss: 0.5215\n",
      "Epoch 65/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1806\n",
      "Epoch 65: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1802 - val_loss: 0.5244\n",
      "Epoch 66/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1743\n",
      "Epoch 66: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1747 - val_loss: 0.5460\n",
      "Epoch 67/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1784\n",
      "Epoch 67: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1779 - val_loss: 0.6038\n",
      "Epoch 68/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1944\n",
      "Epoch 68: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1941 - val_loss: 0.5422\n",
      "Epoch 69/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1765\n",
      "Epoch 69: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1762 - val_loss: 0.5304\n",
      "Epoch 70/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1818\n",
      "Epoch 70: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1813 - val_loss: 0.5486\n",
      "Epoch 71/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1699\n",
      "Epoch 71: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1785 - val_loss: 0.5451\n",
      "Epoch 72/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1692\n",
      "Epoch 72: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1688 - val_loss: 0.5303\n",
      "Epoch 73/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1635\n",
      "Epoch 73: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1633 - val_loss: 0.5058\n",
      "Epoch 74/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1714\n",
      "Epoch 74: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1715 - val_loss: 0.5695\n",
      "Epoch 75/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1697\n",
      "Epoch 75: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1696 - val_loss: 0.5136\n",
      "Epoch 76/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1706\n",
      "Epoch 76: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1701 - val_loss: 0.5519\n",
      "Epoch 77/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1592\n",
      "Epoch 77: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1588 - val_loss: 0.5074\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1685\n",
      "Epoch 78: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1685 - val_loss: 0.5175\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1586\n",
      "Epoch 79: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1586 - val_loss: 0.5051\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1454\n",
      "Epoch 80: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1454 - val_loss: 0.5324\n",
      "Epoch 81/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1473\n",
      "Epoch 81: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1476 - val_loss: 0.5256\n",
      "Epoch 82/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1483\n",
      "Epoch 82: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1480 - val_loss: 0.5573\n",
      "Epoch 83/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.1622\n",
      "Epoch 83: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1587 - val_loss: 0.5360\n",
      "Epoch 84/100\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.1462\n",
      "Epoch 84: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1481 - val_loss: 0.5121\n",
      "Epoch 85/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.1474\n",
      "Epoch 85: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1484 - val_loss: 0.5254\n",
      "Epoch 86/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.1494\n",
      "Epoch 86: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1491 - val_loss: 0.5349\n",
      "Epoch 87/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1373\n",
      "Epoch 87: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1380 - val_loss: 0.5952\n",
      "Epoch 88/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1484\n",
      "Epoch 88: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1481 - val_loss: 0.5494\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1575\n",
      "Epoch 89: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1575 - val_loss: 0.4824\n",
      "Epoch 90/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.1431\n",
      "Epoch 90: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1427 - val_loss: 0.4924\n",
      "Epoch 91/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.1442\n",
      "Epoch 91: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1457 - val_loss: 0.5608\n",
      "Epoch 92/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1403\n",
      "Epoch 92: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1401 - val_loss: 0.4986\n",
      "Epoch 93/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1393\n",
      "Epoch 93: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1391 - val_loss: 0.4945\n",
      "Epoch 94/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.1380\n",
      "Epoch 94: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1381 - val_loss: 0.5133\n",
      "Epoch 95/100\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.1276\n",
      "Epoch 95: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1282 - val_loss: 0.5036\n",
      "Epoch 96/100\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.1247\n",
      "Epoch 96: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1254 - val_loss: 0.5469\n",
      "Epoch 97/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1448\n",
      "Epoch 97: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1467 - val_loss: 0.5132\n",
      "Epoch 98/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1394\n",
      "Epoch 98: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1390 - val_loss: 0.5237\n",
      "Epoch 99/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1277\n",
      "Epoch 99: val_loss did not improve from 0.47946\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1278 - val_loss: 0.5560\n",
      "Epoch 100/100\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1279\n",
      "Epoch 100: val_loss did not improve from 0.47946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1278 - val_loss: 0.5683\n"
     ]
    }
   ],
   "source": [
    "model = DLNN_CORENup(input_seq_shape = input_seq_shape)\n",
    "    \n",
    "## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "current_model_path = os.path.join(modelPath, \"_fullModel.hdf5\")\n",
    "modelCallbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(current_model_path,\n",
    "                                       monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                       save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "]\n",
    "\n",
    "# adding random shuffling of the dataset for training purpose\n",
    "index_arr = np.arange(train_features.shape[0])\n",
    "index_arr = np.random.permutation(index_arr)\n",
    "\n",
    "model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "          callbacks = modelCallbacks, validation_data = (indpe_features, indpe_labels))\n",
    "# model.fit(x = train_features[index_arr], y = train_labels[index_arr], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "#           callbacks = modelCallbacks, validation_split = 0.2)\n",
    "\n",
    "model = tf.keras.models.load_model(current_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent</th>\n",
       "      <td>0.915842</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.891842</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.765787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision       AUC  Sensitivity  Specificity       MCC\n",
       "Train_Test                                                                    \n",
       "Independent  0.915842   0.902439  0.891842     0.919255     0.902439  0.765787"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "##################################################################################\n",
    "##### Prediction and metrics for Independent dataset\n",
    "##################################################################################\n",
    "\n",
    "y_pred = model.predict(indpe_features)\n",
    "label_pred = pred2label(y_pred)\n",
    "\n",
    "# Compute precision, recall, sensitivity, specifity, mcc\n",
    "acc = accuracy_score(indpe_labels, label_pred)\n",
    "prec = precision_score(indpe_labels,label_pred)\n",
    "\n",
    "conf = confusion_matrix(indpe_labels, label_pred)\n",
    "if(conf[0][0]+conf[1][0]):\n",
    "    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "else:\n",
    "    sens = 0.0\n",
    "if(conf[1][1]+conf[0][1]):\n",
    "    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "else:\n",
    "    spec = 0.0\n",
    "if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "else:\n",
    "    mcc= 0.0\n",
    "fpr, tpr, thresholds = roc_curve(indpe_labels, y_pred)\n",
    "auc = roc_auc_score(indpe_labels, y_pred)\n",
    "\n",
    "evaluations[\"Train_Test\"].append(\"Independent\")\n",
    "evaluations[\"Accuracy\"].append(acc)\n",
    "evaluations[\"Precision\"].append(prec)\n",
    "evaluations[\"TPR\"].append(tpr)\n",
    "evaluations[\"FPR\"].append(fpr)\n",
    "evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "evaluations[\"AUC\"].append(auc)\n",
    "evaluations[\"Sensitivity\"].append(sens)\n",
    "evaluations[\"Specificity\"].append(spec)\n",
    "evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 64\n",
    "# \tAccuracy\tPrecision\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# Train_Test\t\t\t\t\t\t\n",
    "# Independent\t0.98008\t0.979381\t0.987061\t0.980519\t0.979381\t0.958107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 32\n",
    "# \tAccuracy\tPrecision\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# Train_Test\t\t\t\t\t\t\n",
    "# Independent\t0.960159\t0.94\t0.985928\t0.97351\t0.94\t0.916733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch: 16\n",
    "# \tAccuracy\tPrecision\tAUC\tSensitivity\tSpecificity\tMCC\n",
    "# Train_Test\t\t\t\t\t\t\n",
    "# Independent\t0.956175\t0.957895\t0.953381\t0.955128\t0.957895\t0.90771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_fasta_file_name = '.'.join((training_data_file.split('.')[0], 'fasta'))\n",
    "# out_fasta_file_path = os.path.join(input_data_folder, out_fasta_file_name)\n",
    "\n",
    "# count = 0\n",
    "# list_seqs = list(train_data['Sequence'])\n",
    "\n",
    "# with open(out_fasta_file_path, \"w\") as out_file_obj:\n",
    "#     for strLine in list_seqs:\n",
    "        \n",
    "#         #Output the header\n",
    "#         out_file_obj.write(\">\" + str(count+1) + \"\\n\")\n",
    "#         out_file_obj.write(strLine + \"\\n\")\n",
    "        \n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
